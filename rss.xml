<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Simplex Sigillum Veri</title>
        <link>https://remusao.github.io</link>
        <description>Simplex Sigillum Veri</description>
        <lastBuildDate>Wed, 13 Aug 2025 14:09:45 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <copyright>All rights reserved 2023, Rémi Berson</copyright>
        <atom:link href="https://remusao.github.io/rss.xml" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[What's exciting in Cliqz 1.35]]></title>
            <link>https://remusao.github.io//posts/cliqz-1.35-notes.html</link>
            <guid>https://remusao.github.io//posts/cliqz-1.35-notes.html</guid>
            <pubDate>Fri, 22 Mar 2019 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><a href="https://cliqz.com/en/download" target="_blank" rel="noopener noreferrer">Cliqz 1.35</a> is just being released as I write
these lines and there is a lot to talk about in there: performance, more
privacy, more polish. Let me share a few of the things that make me excited!</p>
<h2>Privacy</h2>
<p>There is continuous work to make sure Cliqz users always get the best privacy
protection. In this release, there were three major improvements when it comes
to privacy: human proxy network, a more efficient adblocker and better cookie
retention policies.</p>
<ul>
<li>
<p><strong>Human Proxy Network</strong> (or, HPN), allows our users to stay anonymous when
the browser contacts our backend (e.g.: for search or telemetry). This is the
heart of our <em>privacy by design approach</em>, where you don’t even need to trust
us to not do bad things: we simply don’t know anything personal about you. In
this case, we now use a <em>third-party VPN provider to also hide any
network-level identifiers like IPs</em>. We were already providing this
protection before but we were operating the network of proxies ourselves.
What I’m especially excited about is that now, there is <em>no way Cliqz can
learn anything about who you are using your IP</em> (because of the third-party
VPN relaying the messages); and there is also no way the third-party VPN
provider can learn anything about you, because all messages are encrypted
client-side!</p>
</li>
<li>
<p><strong>Adblocker</strong>. We wrote about it recently in our <a href="https://whotracks.me/blog/adblockers_performance_study.html" target="_blank" rel="noopener noreferrer">performance study</a>
in the context of Manifest v3; <em>Cliqz has the fastest and most memory
efficient adblocker around</em> and we are very proud of it. In this release we
made sure that the latest improvements are included in the browser: blocking ads
was never faster!</p>
</li>
</ul>
<figure>
<a href="../images/cliqz_1.35/adblockerSpeed.png">
<img src="../images/cliqz_1.35/adblockerSpeed.png" alt="Adblock Speed" style="width:100.0%">
</a>
<figcaption>Adblocker Speed</figcaption>
</figure>
<ul>
<li><strong>Better cookies retention policies</strong>. We’re constantly fine-tuning our
Anti-tracking as well as cookies retention policies. In a nutshell, we make
sure that cookies cannot be used to track you by limiting their life-time
depending on if they are needed for a service/website you are using or not.</li>
</ul>
<figure>
<a href="../images/cliqz_1.35/cookies.jpg">
<img src="../images/cliqz_1.35/cookies.jpg" alt="Cookies Retention" style="width:70.0%">
</a>
<figcaption>Cookies Retention</figcaption>
</figure>
<h2>Performance</h2>
<p>We’re pushing super hard for our mobile products to offer the best possible
experience even on slow devices. This means that usability, privacy protection
and performance need to be great. There was a lot of work on these aspects in
the last few months and because most of our core features share the same
codebase across products, this impacts positively Cliqz desktop browser as
well.</p>
<ul>
<li>
<p><strong>Faster URL parsing</strong>. To make sure no identifiers or ads slip through when
you browser the web, Cliqz needs to analyze and filter <em>a lot</em> of URLs (to
load a single page, it can go up to hundreds of network requests). Because
this represents a lot of work, it was a good candidate for optimization. My
co-worker <a href="https://twitter.com/sammacbeth" target="_blank" rel="noopener noreferrer">sammacbeth</a> did a fantastic job
and was able to replicate the API of the native URL parser provided by the
browser: except it’s now <em>4-5x faster</em>. This means users get the same great
privacy protection, but the browser sweats less for it!</p>
</li>
<li>
<p>Along those lines, we made sure that the processing of requests in the
extension (not just parsing the URLs) is as fast as possible. We removed lots
of friction so that <em>when an ad needs to get blocked, or a fingerprint needs
to be removed, it happens as fast as possible</em> and more resources can be
dedicated to load pages faster. This also greatly improves the experience on
mobile!</p>
</li>
</ul>
<h2>What Else?</h2>
<p>There were a lot of other changes to polish the overall Cliqz experience. For
example: the weather smart Cliqz is now… much smarter and will display very
detailed information about the forcasts (temperatures, wind, etc.)!</p>
<figure>
<a href="../images/cliqz_1.35/weather.png">
<img src="../images/cliqz_1.35/weather.png" alt="Weather Smart Cliqz" style="width:100.0%">
</a>
<figcaption>Advanced Weather Smart Cliqz</figcaption>
</figure>
<p>The estimation of time saved on Freshtab now takes into account the time saved
when using Cliqz results directly in the dropdown instead of going to a search
result page. This comes as an addition to the time saved by blocking ads or
trackers.</p>
<figure>
<a href="../images/cliqz_1.35/timeSaved.png">
<img src="../images/cliqz_1.35/timeSaved.png" alt="Time Saved by Cliqz" style="width:100.0%">
</a>
<figcaption>Updated Time Saved on Freshtab</figcaption>
</figure>
<h2>What’s Next?</h2>
<p>I am also super excited with the changes coming to mobile. We’ve been doing <em>a
lot</em> of performance work to ensure that our mobile browser can run at full
speed while enabling all privacy protections, even on very slow devices (in
fact, we’re even more aggressive when blocking ads and trackers!).</p>
<p>In the next release, we have more coming: the infrastructure distributing
adblocker rules has been revamped and allows most of the heavy lifting of
parsing the rules and initializing the engine to be performed on the backend,
which means much faster updates for clients as well as drastically reduced data
usage (we’re talking of at least one order of magnitude less)! Stay tuned.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Adblockers performance study]]></title>
            <link>https://remusao.github.io//posts/adblockers_performance_study.html</link>
            <guid>https://remusao.github.io//posts/adblockers_performance_study.html</guid>
            <pubDate>Fri, 15 Feb 2019 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><strong>Disclaimer</strong>: This study was originally posted on <a href="https://whotracks.me/blog/adblockers_performance_study.html" target="_blank" rel="noopener noreferrer">WhoTracks.me</a>.</p>
<p>Summary: <em>In this study we show</em></p>
<ul>
<li><em>That all popular content-blockers are very efficient, having sub-millisecond
median decision time per request</em></li>
<li><em>That the manifest v3 performance claim does not hold based on our
measurements</em></li>
<li><em>That the adblocker used by Cliqz and Ghostery consistently performs as well
or better than other popular content-blockers.</em></li>
</ul>
<hr>
<p>Here we present a detailed analysis of the performance of some of the
most popular content-blocker engines: <em>uBlock Origin</em>, <em>Adblock Plus</em>,
<em>Brave</em>, <em>DuckDuckGo</em> and <em>Cliqz/Ghostery’s</em> advanced adblocker (shipped
since Ghostery 8), which we will refer to as <em>Ghostery</em> for the rest of
the article.</p>
<p>This study was motivated by the recent <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=896897" target="_blank" rel="noopener noreferrer">Manifest V3
controversy</a>.
One of the proposed changes involves crippling the WebRequest APIs to
limit their blocking abilities. Two justifications were put forth:
one related to <em>performance</em> and another related to privacy. The
privacy argument deserves its own separate analysis and will not be
covered here. In this study, we show that the <em>performance</em> argument
does not hold. Our comparison demonstrates that the most popular
content-blockers are already very efficient (having a sub-millisecond
median decision time per request) and should not result in any
over-head noticeable by users. We showed in another study <a href="https://www.ghostery.com/lp/trackertax/" target="_blank" rel="noopener noreferrer">The Tracker
Tax</a> that blocking ads and
trackers actually reduces the loading time of websites by <strong>up to
a factor of 2</strong>. Besides, efficiency is continuously improved and
technologies such as WebAssembly will allow to go even further.</p>
<p>This comparison does not involve full extensions, but instead <strong>focuses
on network request blocking engines</strong>, which is the most CPU intensive
task performed by content-blockers (in particular, this does not account
for cosmetics engines or subscription management). Here are the home
pages for all content-blockers compared:</p>
<ul>
<li>Ghostery and Cliqz’s adblocker: <a href="https://github.com/cliqz-oss/adblocker" target="_blank" rel="noopener noreferrer">https://github.com/cliqz-oss/adblocker</a></li>
<li>Brave’s adblocker: <a href="https://github.com/brave/ad-block" target="_blank" rel="noopener noreferrer">https://github.com/brave/ad-block</a></li>
<li>DuckDuckGo’s adblocker: <a href="https://github.com/duckduckgo/abp-filter-parser" target="_blank" rel="noopener noreferrer">https://github.com/duckduckgo/abp-filter-parser</a></li>
<li>uBlock Origin: <a href="https://github.com/gorhill/uBlock" target="_blank" rel="noopener noreferrer">https://github.com/gorhill/uBlock</a></li>
<li>Adblock Plus: <a href="https://github.com/adblockplus/adblockpluscore" target="_blank" rel="noopener noreferrer">https://github.com/adblockplus/adblockpluscore</a></li>
</ul>
<p>We did not include native blockers from Chromium and Safari projects
as this would require some significant effort to package them in a way
that allows benchmarking against the other libraries. We leave this for
future work.</p>
<p>All blockers except <em>uBlock Origin</em> are available as JavaScript libraries which
can be loaded in Node.js. To allow comparing <em>uBlock Origin</em> as well, we had to
extract the static network filtering engine <a href="https://github.com/cliqz-oss/adblocker/blob/master/bench/comparison/ublock.js" target="_blank" rel="noopener noreferrer">out of the
extension</a>.
The version of <em>uBlock Origin</em> running in this benchmark <em>does not make
use of the Webassembly</em> version of domain matching.</p>
<p>All benchmarks were ran on an X1 Carbon 2016 (i7 U6600 + 16 GB) in
Node.js 11.9.0. Memory measurements were performed in Google Chrome version
72.0.3626.96 using the memory snapshot tool.</p>
<h2>Results</h2>
<p>Before presenting the detailed analysis of the results, let us highlight
our findings in a nutshell:</p>
<ul>
<li>
<p>All content-blockers except <em>DuckDuckGo</em> have <strong>sub-millisecond median decision
time</strong> per request.</p>
</li>
<li>
<p><strong>Time to Process a Request in Ghostery</strong> (median): <strong>0.007 ms</strong></p>
<ul>
<li>2.7x faster than <em>uBlock Origin</em></li>
<li>2.9x faster than <em>Adblock Plus</em></li>
<li>6.3x faster than <em>Brave</em>’s Adblocker</li>
<li>1258.4x faster than <em>DuckDuckGo</em>’s adblocker</li>
</ul>
</li>
<li>
<p><strong>Loading Ghostery’s Blocking Engine</strong> (from cache): <strong>0.03 ms</strong></p>
<ul>
<li>368x faster than <em>Brave</em>’s Adblocker</li>
<li>588x faster than <em>uBlock Origin</em></li>
<li>3575x faster than <em>Adblock Plus</em></li>
<li><em>DuckDuckGo</em>’s adblocker does not offer serialization, so the loading cost is always the one from parsing the lists.</li>
</ul>
</li>
<li>
<p><strong>Memory Consumption of Ghostery’s Blocking Engine</strong> (at startup, in Chrome): <strong>1.8 MB</strong></p>
<ul>
<li>1.6x less memory than <em>uBlock Origin</em></li>
<li>8.4x less memory than <em>Adblock Plus</em></li>
<li>8.8x less memory than <em>DuckDuckGo</em>’s adblocker</li>
<li>The memory usage of <em>Brave</em> could not be evaluated using the devtools
and thus is not included in this section.</li>
</ul>
</li>
</ul>
<h3>About the Dataset</h3>
<p>To measure the performance of each content-blocker, we replayed requests
from popular domains <em>once</em> and kept track of the time it took to decide
if they should be blocked or not. We then analyzed the results in three
different ways: all requests, blocked only and not blocked (taken from
the same run).</p>
<p>This requests dataset was created using a pool of Chrome
headless browsers (driven by the <a href="https://github.com/GoogleChrome/puppeteer" target="_blank" rel="noopener noreferrer"><code>puppeteer</code> library</a>)
to visit home pages of the <em>top 500 domains</em> (as reported by Cliqz
Search), as well as up to 3 pages of each domain (picked randomly from
the home page) and collecting all the network requests seen (URL, frame
URL and type). The dataset was shuffled in such a way that the different
pages were visited in a random order, but requests seen on each page
were replayed as they were recorded initially.</p>
<p>The dataset is composed of 242944 requests. We released the data publicly at
this URL: <a href="https://cdn.cliqz.com/adblocking/requests_top500.json.gz" target="_blank" rel="noopener noreferrer">requests_top500.json.gz</a>.
The script to create the dataset is also available:
<a href="https://github.com/cliqz-oss/adblocker/blob/master/bench/comparison/create_dataset.js" target="_blank" rel="noopener noreferrer">create_dataset.js</a> and
<a href="https://github.com/cliqz-oss/adblocker/blob/master/bench/comparison/shuffle_dataset.js" target="_blank" rel="noopener noreferrer">shuffle_dataset.js</a> was used to shuffle the
requests to produce the final data.</p>
<h3>Composition of Requests</h3>
<p>For the purpose of this comparison, we consider that each network
request can be either blocked or allowed by the content-blocker; we call
the process of deciding whether a request should be blocked or not:
<em>matching</em>. We observed that from our dataset, only ~19.2% are blocked
(average across all content-blockers).</p>
<figure>
<a href="../images/adblockers_performance_study/requests-composition.svg">
<img src="../images/adblockers_performance_study/requests-composition.svg" alt="Proportion of requests blocked">
</a>
</figure>
<p>It results from this observation that content-blockers will perform better on
average if they can efficiently decide which requests to <em>not block</em>.</p>
<p>The filters used to determine whether or not a request is to be blocked
are the ones from <a href="https://easylist-downloads.adblockplus.org/easylist.txt" target="_blank" rel="noopener noreferrer">Easylist</a>,
where we removed all the cosmetic rules before running the benchmarks.
The final list contains <em>38978 network filters</em> and is available here:
<a href="https://github.com/cliqz-oss/adblocker/blob/master/bench/comparison/easylist.txt" target="_blank" rel="noopener noreferrer">easylist.txt</a>.</p>
<p>It should be noted at this point that a larger proportion of requests
would be blocked by enabling extra filters lists such as <em>EasyPrivacy</em>.</p>
<h3>Time To Match All Requests</h3>
<p>We first look at all of the requests (whether they will eventually
be blocked or not). We use a log-scale for the x-axis (time in
milliseconds) to facilitate the comparison of the cumulative
distribution of the time it takes for content-blockers to decide whether
or not a request should be blocked.</p>
<p>Here is a break-down of the 99th percentile and median times for each
content-blocker:</p>
<table>
<thead>
<tr>
<th></th>
<th>99% OF REQUESTS</th>
<th>MEDIAN</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ghostery</strong></td>
<td><strong>0.050ms</strong></td>
<td><strong>0.007ms</strong></td>
</tr>
<tr>
<td>uBlock Origin</td>
<td>0.124ms (<strong>2.5x slower</strong>)</td>
<td>0.017ms (<strong>2.7x slower</strong>)</td>
</tr>
<tr>
<td>Adblock Plus</td>
<td>0.103ms (<strong>2.1x slower</strong>)</td>
<td>0.019ms (<strong>2.9x slower</strong>)</td>
</tr>
<tr>
<td>Brave</td>
<td>1.288ms (<strong>25.9x slower</strong>)</td>
<td>0.041ms (<strong>6.3x slower</strong>)</td>
</tr>
<tr>
<td>DuckDuckGo</td>
<td>12.085ms (<strong>242.5x slower</strong>)</td>
<td>8.270ms (<strong>1258.4x slower</strong>)</td>
</tr>
</tbody>
</table>
<p>Below you can find the cumulative distribution plots of these timings:</p>
<figure>
<a href="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-all.svg">
<img src="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-all.svg" alt="Time to match all requests">
</a>
</figure>
<h3>Time To Match Requests Which Are Not Blocked</h3>
<p>The following table details 99th percentile and median timings for requests not
blocked:</p>
<table>
<thead>
<tr>
<th></th>
<th>99% OF REQUESTS</th>
<th>MEDIAN</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ghostery</strong></td>
<td><strong>0.049ms</strong></td>
<td><strong>0.006ms</strong></td>
</tr>
<tr>
<td>uBlock Origin</td>
<td>0.112ms (<strong>2.3x slower</strong>)</td>
<td>0.018ms (<strong>2.8x slower</strong>)</td>
</tr>
<tr>
<td>Adblock Plus</td>
<td>0.105ms (<strong>2.2x slower</strong>)</td>
<td>0.020ms (<strong>3.1x slower</strong>)</td>
</tr>
<tr>
<td>Brave</td>
<td>1.270ms (<strong>26.2x slower</strong>)</td>
<td>0.038ms (<strong>5.9x slower</strong>)</td>
</tr>
<tr>
<td>DuckDuckGo</td>
<td>11.190ms (<strong>230.5x slower</strong>)</td>
<td>6.781ms (<strong>1060.5x slower</strong>)</td>
</tr>
</tbody>
</table>
<figure>
<a href="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-not-blocked.svg">
<img src="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-not-blocked.svg" alt="Time to match requests which are not blocked">
</a>
</figure>
<h3>Time To Match Requests Which Are Blocked</h3>
<p>The following table details 99th percentile and median timings for requests blocked:</p>
<table>
<thead>
<tr>
<th></th>
<th>99% OF REQUESTS</th>
<th>MEDIAN</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ghostery</strong></td>
<td><strong>0.052ms</strong></td>
<td><strong>0.007ms</strong></td>
</tr>
<tr>
<td>uBlock Origin</td>
<td>0.165ms (<strong>3.1x slower</strong>)</td>
<td>0.016ms (<strong>2.2x slower</strong>)</td>
</tr>
<tr>
<td>Adblock Plus</td>
<td>0.099ms (<strong>1.9x slower</strong>)</td>
<td>0.014ms (<strong>1.9x slower</strong>)</td>
</tr>
<tr>
<td>Brave</td>
<td>1.468ms (<strong>28.0x slower</strong>)</td>
<td>0.062ms (<strong>8.5x slower</strong>)</td>
</tr>
<tr>
<td>DuckDuckGo</td>
<td>13.025ms (<strong>248.5x slower</strong>)</td>
<td>8.31ms (<strong>1130.6x slower</strong>)</td>
</tr>
</tbody>
</table>
<figure>
<a href="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-blocked.svg">
<img src="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-blocked.svg" alt="Time to match requests which are blocked">
</a>
</figure>
<p>On these graphs we observe a plateau for <em>Adblock Plus</em>, <em>Brave</em> and
<em>Duckduckgo</em>. This can be explained by the fact that these engines
implement some form of caching internally, thus having a very fast
response time for some requests which were already seen (redundancy in
requests comes from both common third-parties seen on multiple websites
as well as the fact that we load several pages for each domain). This
caching can be implemented on top of any content-blocker and does not
tell much about the efficiency of each; we can see this as a means to
trade <em>memory</em> against <em>CPU usage</em>.</p>
<p>From the previous measurements we see that Ghostery out-performs other
libraries in terms of matching speed. Without going into too many
details, here are some of the optimizations which can explain these
results:</p>
<ul>
<li>Ghostery makes use of a reverse index associating tokens to filters. Contrary
to other libraries, we make sure that we pick <em>the best</em> token for each filter
at construction time (best being defined as the <em>least seen token</em>). This incurs
a one-time extra cost but results in maximized dispatching capabilities.</li>
<li>Filters are stored in a very compact form, in typed arrays, and only loaded in
memory lazily, when there is a chance they will be blocked (if we encounter
identical tokens in URLs).</li>
<li>Filters loaded in memory are optimized on-the-fly and multiple filters can be
combined for increased efficiency. The optimizations were carefully crafted
based on common cases observed in Easylist.</li>
</ul>
<h3>Serialization And Deserialization</h3>
<p>In this section we have a look at the performance of content-blockers
when it comes to serializing their internal representation for faster
subsequent loading. Only <em>DuckDuckGo</em>’s engine does not provide this
feature. <em>uBlock Origin</em>, <em>Ghostery</em>, <em>Adblock Plus</em> and <em>Brave</em> all allow to
serialize or cache (<em>uBlock Origin</em>’s terminology is: <em>selfies</em>) the
entire blocking engine to either a string or a buffer, which can then be
used to speed-up subsequent loads.</p>
<p>Because this is a one-time operation, having a higher loading-time does not
impact significantly desktop users. On the other hand, the ability to quickly
initialize the content-blocker is critical on mobile.</p>
<p>Another use-case allowed by such capability is to perform the parsing
of the lists on the backend and ship the serialized form of the
content-blocker to clients directly, which removes the cost of
initialization completely.</p>
<p>We performed 100 serializations for each content-blocker and display the
results below:</p>
<figure>
<a href="../images/adblockers_performance_study/ghostery-ublock-origin-brave-adblock-plus-serializationtimings.svg">
<img src="../images/adblockers_performance_study/ghostery-ublock-origin-brave-adblock-plus-serializationtimings.svg" alt="Serialization timings">
</a>
</figure>
<p>This bar plot contains the median time taken to serialize the engine for each
content-blocker:</p>
<figure>
<a href="../images/adblockers_performance_study/serializationtimings.svg">
<img src="../images/adblockers_performance_study/serializationtimings.svg" alt="Serialization timings">
</a>
</figure>
<p>Similarly, we measure the time it takes to restore the content-blocker from its
serialized form:</p>
<figure>
<a href="../images/adblockers_performance_study/ghostery-ublock-origin-brave-adblock-plus-deserializationtimings.svg">
<img src="../images/adblockers_performance_study/ghostery-ublock-origin-brave-adblock-plus-deserializationtimings.svg" alt="Deserialization timings">
</a>
</figure>
<p>And here is the median time:</p>
<figure>
<a href="../images/adblockers_performance_study/deserializationtimings.svg">
<img src="../images/adblockers_performance_study/deserializationtimings.svg" alt="Deserialization timings">
</a>
</figure>
<p>Last but not least, we measured the size of the serialized buffer for each
content-blocker:</p>
<figure>
<a href="../images/adblockers_performance_study/cache-size.svg">
<img src="../images/adblockers_performance_study/cache-size.svg" alt="Cache size">
</a>
</figure>
<p>From these measurements we see that <em>Ghostery</em> offers both significantly
faster serialization and deserialization times as well as a smaller
cache size.</p>
<p>The reason is the following: the internal representation is already
mostly stored in a compact form (using typed arrays); this means that
serialization only consists in adding a small amount of metadata
along-side the already available arrays and deserialization is
<em>essentially instantaneous</em> since it’s enough to create some typed array
views on top of the serialized buffer (think of <code>mmap</code> but using typed
arrays). This also explains the very low memory consumption: after
initialization, the memory usage is only slightly higher than the size
of the serialized form.</p>
<h3>Memory Consumption at Start-up</h3>
<p>Here we consider the memory usage of each content-blocker, initialized
from lists (not from cache) after one full garbage collection. The
measurements were performed using Chrome’s devtools memory snapshot. We
did not measure Brave here since the memory used from C++ side does not
seem to be taken into account in the snapshot. Also keep in mind that
this memory usage can vary at run-time as content-blockers might cache
frequently used resources, etc.</p>
<figure>
<a href="../images/adblockers_performance_study/memory-usage-at-startup.svg">
<img src="../images/adblockers_performance_study/memory-usage-at-startup.svg" alt="Memory usage at start-up">
</a>
</figure>
<p>As mentioned in the previous section on serialization, the very low
memory usage of <em>Ghostery</em> can be explained by the fact that the
internal representation mostly consists of very compact typed arrays
with some small over-head for extra meta-data. Again, we need to stress
here that this measures the network filtering engine of Ghostery only,
not the full extension, as described in the introduction.</p>
<h3>Parsing Lists</h3>
<p>In this graph, we present the time it takes for each content-blocker to
be initialized from the lists (without any prior caching, which means
initializing all internal resources by parsing the raw list). We see
that only Brave seems to be significantly slower and that <em>uBlock Origin</em>,
<em>Ghostery</em>, <em>Adblock Plus</em> and <em>DuckDuckGo</em> all perform well.</p>
<figure>
<a href="../images/adblockers_performance_study/time-to-parse-easylist-all.svg">
<img src="../images/adblockers_performance_study/time-to-parse-easylist-all.svg" alt="Time to parse Easylist">
</a>
</figure>
<p>It seems that the long parsing time for Brave is a <a href="https://github.com/brave/ad-block/issues/158" target="_blank" rel="noopener noreferrer">known
issue</a> tracked on their
GitHub repository.</p>
<p>Now if we remove Brave, we see that there are still differences between
<em>uBlock Origin</em>, <em>Ghostery</em>, <em>Adblock Plus</em> and <em>DuckDuckGo</em>. One reason
<em>Ghostery</em> is slower than <em>uBlock Origin</em> and <em>AdblockPlus</em> here is that to
achieve maximum performance while matching as well as minimize memory
usage, there is a bit more work to do up-front. In practice this does
not matter so much since it is a one-time operation and that subsequent
loads are performed from cache, and this is really fast (in fact, we
can even perform the parsing backend-side and just ship the serialized
version of the blocker, which removes this step completely).</p>
<figure>
<a href="../images/adblockers_performance_study/time-to-parse-easylist-without-brave.svg">
<img src="../images/adblockers_performance_study/time-to-parse-easylist-without-brave.svg" alt="Time to parse Easylist without Brave">
</a>
</figure>
<h3>Conclusion</h3>
<p>In this study we looked closely at the performance of some of the most
popular content-blockers in use today. In particular, we focused on the
efficiency of their network filtering engines, which is the most CPU
intensive task they perform.</p>
<p>This work was motivated by one of the claims formulated in the <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=896897" target="_blank" rel="noopener noreferrer">Manifest V3
proposal</a>
of the Chromium project: <em>“the extension then performs arbitrary (and
potentially very slow) JavaScript”</em>, talking about content-blockers’
ability to process all network requests. From the measurements, we do
not think this claim holds, as all popular content-blockers are already
very efficient and should not incur any noticeable slow-down for users.
Moreover, the efficiency of content-blockers is <em>continuously improving</em>,
either thanks to more innovative approaches or using technologies like
WebAssembly to reach native performance.</p>
<p>While most content-blockers are indeed efficient, they are not
equivalent and we observed that <em>Ghostery</em> performs consistently as well
or better across all dimensions, often surpassing other libraries.</p>
<p>We hope that these benchmarks will give an opportunity for content-blockers
developers to measure their own progress against other popular libraries;
benefiting all users, no matter which extension they use, as the efficiency of
content-blockers improves.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Debugging iptables rules]]></title>
            <link>https://remusao.github.io//posts/test-iptables-rules.html</link>
            <guid>https://remusao.github.io//posts/test-iptables-rules.html</guid>
            <pubDate>Wed, 24 Oct 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>A very quick one! I’ve been playing with <code>iptables</code> rules lately and was
wondering: “How do I debug these things?”. How can I know if the rule is
matching what I want, or if it’s doing something at all? I found <em>one way</em> to do
so, and it’s probably not the only one (or the best one), but I thought I’d
share it anyway. Feel free to send me your tips and tricks!</p>
<p>Using the <code>LOG</code> action and optionally specifying a custom log prefix, it’s
relatively easy to see what packets are targeted by a rule. For example:</p>
<pre class="code" data-lang="sh"><code>iptables -A FORWARD -p tcp -j LOG --log-prefix=<span class="hljs-string">&#x27;[netfilter] &#x27;</span>
</code></pre>
<p>Will then write logs into <code>/var/log/kern.log</code>, which you can monitor using <code>tail</code>:</p>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">tail</span> -f /var/log/kern.log
</code></pre>
<p>I found this to be pretty convenient!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[TypeScript performance tip—Escaping partial]]></title>
            <link>https://remusao.github.io//posts/typescript-escaping-optional.html</link>
            <guid>https://remusao.github.io//posts/typescript-escaping-optional.html</guid>
            <pubDate>Tue, 25 Sep 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>A common pattern in JavaScript or TypeScript is to pass options to
a function or constructor as an object with optional attributes
(meaning, only a subset of the attributes can be specified). Since v2.1,
TypeScript offers a great way to make this type-safe in the form of
<code>Partial&lt;T&gt;</code> which allows to specify a type for exactly this pattern. In
practice this looks like:</p>
<pre class="code" data-lang="javascript"><code>interface <span class="hljs-title class_">IOptions</span> {
  <span class="hljs-attr">option1</span>: boolean;
  <span class="hljs-attr">option2</span>: string;
}

<span class="hljs-keyword">function</span> <span class="hljs-title function_">doSomething</span>(<span class="hljs-params">options: Partial&lt;IOptions&gt; = {}</span>): <span class="hljs-keyword">void</span> {
  ...
}
</code></pre>
<p>This definition allows to give a subset of the options to the function,
or all of them, or no argument at all!</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-title function_">doSomething</span>(); <span class="hljs-comment">// OK</span>
<span class="hljs-title function_">doSomething</span>({ <span class="hljs-attr">option1</span>: <span class="hljs-literal">true</span> }); <span class="hljs-comment">// OK</span>
<span class="hljs-title function_">doSomething</span>({ <span class="hljs-attr">option1</span>: <span class="hljs-literal">true</span>, <span class="hljs-attr">option2</span>: <span class="hljs-string">&#x27;foo&#x27;</span> }); <span class="hljs-comment">// OK</span>

<span class="hljs-title function_">doSomething</span>({ <span class="hljs-attr">option3</span>: <span class="hljs-number">42</span> }); <span class="hljs-comment">// NOT OK</span>
</code></pre>
<p>Now, something you might want to do is to provide a set of default
values for each attribute of your <code>IOptions</code> passed as argument. One
way this could be done is to use <code>Object.assign</code> to merge the partial
options given as argument with a set of default values:</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">options: Partial&lt;IOptions&gt; = {}</span>): <span class="hljs-title class_">IOptions</span> {
  <span class="hljs-keyword">return</span> <span class="hljs-title class_">Object</span>.<span class="hljs-title function_">assign</span>({
    <span class="hljs-attr">option1</span>: <span class="hljs-literal">true</span>,
    <span class="hljs-attr">option2</span>: <span class="hljs-string">&#x27;bar&#x27;</span>,
  }, options);
}
</code></pre>
<p>This is elegant and it works. However, this is not the optimal solution
in terms of performance. There is still some overhead in the call
to <code>assign</code>, and although it might not matter most of the time,
sometimes you just want to make things go as fast as possible. As a
baseline, let’s measure the performance of this solution using the
<a href="https://www.npmjs.com/package/benchmark" target="_blank" rel="noopener noreferrer">benchmark</a> library:</p>
<blockquote>
<p><strong>14M</strong> calls/second</p>
</blockquote>
<p>To by-pass the use of <code>Object.assign</code>, we could try to use the spread operator:</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">options: Partial&lt;IOptions&gt; = {}</span>): <span class="hljs-title class_">IOptions</span> {
  <span class="hljs-keyword">return</span> {
    <span class="hljs-attr">option1</span>: <span class="hljs-literal">true</span>,
    <span class="hljs-attr">option2</span>: <span class="hljs-string">&#x27;bar&#x27;</span>,
    ...options,
  };
}
</code></pre>
<p>This is even terser, but unfortunately it’s not as fast, at least when
<code>esnext</code> is targeted. For <code>ES6</code> or lower, a call to <code>Object.assign</code> will
be made, which makes this solution equivalent to the first one.</p>
<blockquote>
<p><strong>7M</strong> calls/second (<strong>x0.6</strong>)</p>
</blockquote>
<p>Another solution would be to hard-code the creation of the object
with the existence of each attribute checked:</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">options?: Partial&lt;IOptions&gt;</span>): <span class="hljs-title class_">IOptions</span> {
  <span class="hljs-keyword">return</span> {
    <span class="hljs-attr">option1</span>: options.<span class="hljs-property">option1</span> !=== <span class="hljs-literal">undefined</span> ? options.<span class="hljs-property">options1</span> : <span class="hljs-literal">true</span>,
    <span class="hljs-attr">option2</span>: options.<span class="hljs-property">option2</span> !=== <span class="hljs-literal">undefined</span> ? options.<span class="hljs-property">options2</span> : <span class="hljs-string">&#x27;bar&#x27;</span>,
  };
}
</code></pre>
<p>This does the job, but is much more verbose, and you will have to write the name
of each attribute several times. It does not get better as your option type
grows. The performance is much better though:</p>
<blockquote>
<p><strong>215M</strong> calls/second (<strong>x15</strong>)</p>
</blockquote>
<p>If you already looked at the code generated by Babel or TypeScript to
transpile arguments destructuring, this should look familiar. We could
try to make TypeScript generate the boilerplate code for us by targeting
an older version of ECMAScript (which does not support destructuring).
On top of that, destructuring allows to specify default values for some
(or all) of the attributes. Let’s combine these two ideas to create a
fourth version of our <code>setDefaults</code> function:</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">{
  option1 = <span class="hljs-literal">true</span>,
  option2 = <span class="hljs-string">&#x27;bar&#x27;</span>,
}: Partial&lt;IOptions&gt; = {}</span>): <span class="hljs-title class_">IOptions</span> {
  <span class="hljs-keyword">return</span> { option1, option2 };
}
</code></pre>
<p>This is almost as terse as the first version based on <code>Object.assign</code>
and much better than the second version. It is also the fastest version:</p>
<blockquote>
<p><strong>230M</strong> calls/second (<strong>x16</strong>)</p>
</blockquote>
<p>Out of curiosity, we can check the code generated by TypeScript
depending on the <code>target</code> you specify. Keep in mind that the performance
seen above corresponds to the <code>ES3</code> target.</p>
<ul>
<li><strong>ES3 and ES5</strong></li>
</ul>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">_a</span>) {
  <span class="hljs-keyword">var</span> _b = _a === <span class="hljs-keyword">void</span> <span class="hljs-number">0</span> ? {} : _a, _c = _b.<span class="hljs-property">option1</span>, option1 = _c === <span class="hljs-keyword">void</span> <span class="hljs-number">0</span> ? <span class="hljs-literal">true</span> : _c, _d = _b.<span class="hljs-property">option2</span>, option2 = _d === <span class="hljs-keyword">void</span> <span class="hljs-number">0</span> ? <span class="hljs-string">&#x27;bar&#x27;</span> : _d;
  <span class="hljs-keyword">return</span> { <span class="hljs-attr">option1</span>: option1, <span class="hljs-attr">option2</span>: option2 };
}
</code></pre>
<p>Yey, fast and ugly!</p>
<blockquote>
<p><strong>230M</strong> calls/second (<strong>x16</strong>)</p>
</blockquote>
<ul>
<li><strong>ES6</strong></li>
</ul>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">{ option1 = <span class="hljs-literal">true</span>, option2 = <span class="hljs-string">&#x27;bar&#x27;</span>, } = {}</span>) {
  <span class="hljs-keyword">return</span> { option1, option2 };
}
</code></pre>
<p>Yey, nice and not as fast…</p>
<blockquote>
<p><strong>170M</strong> calls/second (<strong>x12</strong>)</p>
</blockquote>
<p>Here we can see that the implementation of <code>ES6</code> destructuring with
defaults is not yet as fast as the transpiled version, at least on V8
(Node.js 10.11.0). In practice that is not an issue as TypeScript will
allow you to write high-level, type-safe code, while still giving you
the best performance by targeting low-level JavaScript (e.g.: <code>ES3</code>!).</p>
<p>The full source-code for benchmarks can be found there: <a href="../snippets/typescript-options-bench.ts" target="_blank" rel="noopener noreferrer">typescript-options-bench.ts</a>.
All the results were obtained using Node.js v10.11.0 on an Intel
i7-6600U (2,60-3,40 GHz) with 16GB of Ram, running Ubuntu 18.04.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Monitoring your Internet bandwidth with a Raspberry Pi]]></title>
            <link>https://remusao.github.io//posts/raspberrypi-home-network-monitoring.html</link>
            <guid>https://remusao.github.io//posts/raspberrypi-home-network-monitoring.html</guid>
            <pubDate>Sat, 13 Jan 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>After having switched to a new Internet Provider a few months ago, I
was often disappointed by the bandwidth I got (or perceived). It’s not
always easy to know if your connection is the problem, or is it Wi-Fi
connectivity? Or the website you are trying to connect to, etc. So to
get a better idea, I decided to create a simple setup to continuously
monitor my connection, using two independent methods that I will
describe below. Before digging into the details, here is how it currently looks
like:</p>
<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  }
</script>
<iframe
  frameborder="0"
  onload="resizeIframe(this)"
  scrolling="no"
  style="width:100%;height:100%;overflow:hidden;display:block"
  src='../images/bandwidth.html'>
</iframe>
<h2>Setup</h2>
<ul>
<li>RaspberryPi 3.</li>
<li>Latest version of Raspbian.</li>
<li>Direct Ethernet connection to the router.</li>
</ul>
<h2>Measurements</h2>
<p>To get a better idea of the bandwidth (I also measure upload and ping, but that
is not the most important for me, and I’m not sure how robust the measurements
are), I decided to implement two separate methods:</p>
<ol>
<li>The first one is using <a href="https://github.com/sivel/speedtest-cli" target="_blank" rel="noopener noreferrer">speedtest-cli</a>,
a Python project which allows you to measure you connection using servers from
<a href="http://www.speedtest.net/" target="_blank" rel="noopener noreferrer">speedtest.net</a>. It is very simple to use and the
project seems to be pretty mature.</li>
<li>For the second measurement, I wanted to use <a href="https://fast.com/" target="_blank" rel="noopener noreferrer">fast.com</a>, a
service provided by Netflix. I could not find a way to use it easily
from the command line (and I could not find an easy way to get a
driver for Selenium for either Firefox or Chromium), but I managed
to get the measurements using <code>chromium</code> headless mode, which is
available on <code>raspbian</code>, so no extra dependency is required!</li>
</ol>
<p>Here is the current way measurements are performed:</p>
<ol>
<li>The script <code>speed.py</code> is triggered from a <code>watch</code> command every 30 minutes (it
runs in a detached <code>screen</code>).</li>
<li><code>speedtest-cli</code> measurement is triggered.</li>
<li>Then we wait for 15 seconds.</li>
<li><code>fast.com</code> measurement is triggered.</li>
<li>Results are persisted into a local sqlite3 database.</li>
</ol>
<p>In parallel, the <code>app.py</code> runs in another <code>screen</code> to allow visualizing
the results stored in the database. This is not mandatory, but it’s nice
to see the bandwidth over time (the fluctuations reminds me of Bitcoin
pricing…).</p>
<h2>Results</h2>
<p>I have uploaded the scripts I’m using on <a href="https://github.com/remusao/bandwidth-monitor" target="_blank" rel="noopener noreferrer">GitHub</a>
so that it can be re-used or modified.</p>
<p>It should be noted that I now have more measurements and that both
methods (speedtest and <a href="http://fast.com" target="_blank" rel="noopener noreferrer">fast.com</a>) yield similar results. Another
interesting thing is that the bandwidth is usually higher than what I
perceive in normal usage. I have currently two hypotheses:</p>
<ol>
<li>It could be that the provider is playing nice with servers used to measure
bandwidth and artificially increases the bandwidth for those?</li>
<li>My Wi-Fi setup might not be optimal, and I need to investigate if changing
the channel or other settings would improve the situation.</li>
</ol>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS NVMe storage optimized instances]]></title>
            <link>https://remusao.github.io//posts/aws-nvme-storage-instance.html</link>
            <guid>https://remusao.github.io//posts/aws-nvme-storage-instance.html</guid>
            <pubDate>Wed, 27 Dec 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I recently had the need for very fast storage on an Amazon AWS machine. I gave a
try to their “NVMe Storage Optimized” instances. I was a bit surprised though
that the drive was not accessible straight away. To make it work, you need to
format and mount it manually.</p>
<p>Formatting the drive found at <code>/dev/nvme0n1</code>:</p>
<pre class="code" data-lang="sh"><code>$ sudo mkfs -t ext4 /dev/nvme0n1
</code></pre>
<p>Mounting to <code>/ebs/</code>:</p>
<pre class="code" data-lang="sh"><code>$ sudo <span class="hljs-built_in">mkdir</span> /ebs
$ sudo mount -o rw /dev/nvme0n1 /ebs/
$ <span class="hljs-built_in">cd</span> /ebs/
</code></pre>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A simple HTTP server in Haskell]]></title>
            <link>https://remusao.github.io//posts/simple-http-server-haskell.html</link>
            <guid>https://remusao.github.io//posts/simple-http-server-haskell.html</guid>
            <pubDate>Sun, 12 Nov 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I was recently looking for a way to create a very simple <code>HTTP</code> Server to serve
static files in the current directory, in Haskell. The way we would do it in
Python:</p>
<pre class="code" data-lang="sh"><code>$ python -m SimpleHTTPServer 8000
</code></pre>
<p>That’s dead simple, exactly what I needed. It took me some time, but I finally
found a very simple (and efficient) solution:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-meta">#! /usr/bin/env stack</span>
<span class="hljs-comment">{-
  stack --resolver lts-9.12
        --install-ghc runghc
        --package wai-app-static
-}</span>
<span class="hljs-keyword">import</span> Network.Wai.Handler.Warp (<span class="hljs-title">run</span>)
<span class="hljs-keyword">import</span> Network.Wai.Application.Static

<span class="hljs-title">main</span> :: <span class="hljs-type">IO</span> ()
<span class="hljs-title">main</span> = run <span class="hljs-number">8000</span> (staticApp (defaultFileServerSettings <span class="hljs-string">&quot;.&quot;</span>))
</code></pre>
<p>That’s it! And it’s using the super efficient <a href="http://www.aosabook.org/en/posa/warp.html" target="_blank" rel="noopener noreferrer">warp</a>
HTTP server.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[State of privacy in statically generated blogs]]></title>
            <link>https://remusao.github.io//posts/state-of-static-blogs.html</link>
            <guid>https://remusao.github.io//posts/state-of-static-blogs.html</guid>
            <pubDate>Sun, 08 Oct 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I woke up one morning and realized that my “static blog” (hosted on
Github pages), contained around <strong>14 trackers</strong> on every page. By
tracker I mean a third-party company having some piece of <code>javascript</code>
injected on the page. Each tracker would also try to send unsafe data
to their backend (You can observe this behavior using any privacy
extension: Ghostery or Cliqz for example).</p>
<p>The truth is, most static blog embed <em>Google</em> for analytics, <em>Disqus</em>
for comments, <em>Mathjax</em> for Latex rendering, extra fonts, CSS, etc.</p>
<p>This is nice, and it brings many benefits to your blog, but people are
probably not aware of what the consequences are for their readers.
Instead of having a nice static html page containing only the content
you’d like to read, you get third-party scripts tracking you on every
page you visit (my content blocker extension even blocked a few advertising
requests).</p>
<figure>
<a href="../images/static-site-ghostery-trackers.png">
<img src="../images/static-site-ghostery-trackers.png" alt="Ghostery Trackers">
</a>
<figcaption>Advertisers joined the party...</figcaption>
</figure>
<p>If you wonder why there are so many, let’s just say that once you allow
a third-party script to execute on your page, you loose control over what
happens next. It might be that any script you include on your page,
will also inject a script from another company, which might make a few
requests as well, etc. If you want to see for yourself, go on a random site
having Disqus and Google Analytics (or your own blog if you have one), and open
the <em>Network Monitor</em> while loading the page. You will see all the resources
fetched (which can be scary…).</p>
<figure>
<a href="../images/network-monitor-tracking.png">
<img src="../images/network-monitor-tracking.png" alt="Network Monitor">
</a>
<figcaption>74 requests seems like a lot for a static page.</figcaption>
</figure>
<p>And they all send unsafe data (unique identifiers) back! I agree that
features like comments and math rendering are sometimes unavoidable, but
there should be a way to do it without all the tracking.</p>
<p>Unfortunately, the alternatives (if there is one at all), represent more
work to integrate and use.</p>
<p>For my own blog I decided to first strip all superfluous external
dependencies (meaning basically anything but the content of the blog),
and then find a way to introduce extra features one by one if needed.</p>
<p>It means that currently, there are no comments and no analytics report
on the number of readers/visits. But there are some promising solutions.</p>
<h2>Comments</h2>
<p>That is one of the most wanted features on a blog, and yet it requires having a
central server to store the comments. <em>Disqus</em> comes pretty handy here, with
only one small line of javascript to include on the page to load the entire
commenting system (but it comes with a high price, as we saw above).</p>
<p>Some possible alternatives are:</p>
<ul>
<li>Using <em>Github Issues</em> to host the comments. Here are a few posts about how that
can work for you:
<ul>
<li><a href="https://mademistakes.com/articles/jekyll-static-comments/" target="_blank" rel="noopener noreferrer">Going Static: Episode II — Attack of the Comments</a></li>
<li><a href="http://ivanzuzak.info/2011/02/18/github-hosted-comments-for-github-hosted-blogs.html" target="_blank" rel="noopener noreferrer">GitHub hosted comments for GitHub hosted blogs</a></li>
<li><a href="http://artsy.github.io/blog/2017/07/15/Comments-are-on/" target="_blank" rel="noopener noreferrer">Using GitHub Issues for Blog Comments</a></li>
<li><a href="http://sean.lane.sh/blog/2016/Hosting_comments_within_issues_on_Github_Pages" target="_blank" rel="noopener noreferrer">Hosting comments within issues on Github Pages</a></li>
<li>Last but not least, I seriously consider <em>embedding the comments
statically in the page</em> (since Github’s API returns the markdown, it
would allow to style the comments like the rest of your blog). That
would require you to fetch all the comments when you generate your
page (yes it takes extra time, but I would rather pay this price
once, instead of making users do it at every page load). Then there
could be some automated task scheduled using Travis to re-generate
the blog (or only the pages with new comments) every time there is a
new comment. I admit that this does not scale for a popular blog
with a lot of comments, but most of the times comments are scarce,
so this solution would work pretty well!</li>
</ul>
</li>
<li><a href="https://posativ.org/isso/" target="_blank" rel="noopener noreferrer">Isso</a>, which requires self-hosting.</li>
<li>There is also <em>Talk</em>, from the <a href="https://coralproject.net/about.html" target="_blank" rel="noopener noreferrer">Mozilla Coral Project</a>. I’m not sure if it can be used on any static website, but it might be something worth investigating.</li>
</ul>
<p>That does not seem to exist yet, but a totally distributed
commenting system would be an ideal fit here (using something like
<a href="https://ipfs.io/" target="_blank" rel="noopener noreferrer">IPFS</a>). There are some discussions about that on this
<a href="https://www.reddit.com/r/ipfs/comments/4om8c0/how_to_create_a_fairly_decentralized_commenting/" target="_blank" rel="noopener noreferrer">reddit thread</a>.</p>
<p>I’m not sure yet if I will add one of those on this blog, since I don’t
really have enough readers to justify the extra complexity (and it’s
still possible to leave some feedback on Github or Twitter if you really
want to). But if I were to choose one solution, I would probably go for
the Github Issues solution, which seems to fit nicely with a blog hosted
on Github Pages.</p>
<h2>Math Rendering</h2>
<p>One solution for privacy-preserving math rendering is to render the
equations at build-time and then embed them in the html as data urls.
That might not be the perfect solution, but it actually works pretty
well, and does not require any third-party resource. I used the
<a href="https://github.com/liamoc/latex-formulae" target="_blank" rel="noopener noreferrer">latex-formulae</a> plugin of
Hakyll, which worked pretty smoothly!</p>
<p>For example:</p>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mn>42</mn></munderover><msup><mi>i</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sum^{42}_{i=0} i^2 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0788em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">42</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>But it can also be inlined like that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mn>42</mn></msubsup><msup><mi>i</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sum^{42}_{i=0} i^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2537em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.954em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">42</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>.</p>
<h2>Analytics</h2>
<p>I have to admit that I totally dropped this feature for now. Ideally,
Github would provide a very basic visit counter for each page of your
blog by default.</p>
<p>Otherwise, there are some nicer alternatives to <em>Google Analytics</em> such as:</p>
<ul>
<li><a href="https://piwik.org/" target="_blank" rel="noopener noreferrer">Piwik</a> – probably the most serious alternative.</li>
<li><a href="https://github.com/cliqz-oss/green-analytics" target="_blank" rel="noopener noreferrer">Green Tracker</a> – still experimental but demonstrates some very promising capabilities, and it requires self-hosting as well.</li>
</ul>
<p>And probably more, although none of them will be as convenient/powerful as
Google Analytics (for now at least…), but do you need as much?</p>
<h2>Fonts and styling</h2>
<p>This is obviously a very personal choice here, and most people will go with
pre-existing templates or frameworks such as <em>Bootstrap</em>.</p>
<p>I took the path of more simplicity and tried to roll-out my own super minimal
template. I also tried to use only fonts available widely (and provide
fall-backs in case a font is not present on the system).</p>
<h2>Social sharing</h2>
<p>It’s nice to have a few buttons to share an article quickly on Twitter,
Facebook or other social network using the social sharing widgets. The
downside is that most of the time, you’re also including trackers on
your page! (e.g.: Facebook will be able to track users reading your
page).</p>
<p>One option is to insert static buttons on your page, instead of the official
widgets. More information can be found there:</p>
<ul>
<li><a href="https://www.savjee.be/2015/01/Creating-static-social-share-buttons/" target="_blank" rel="noopener noreferrer">Creating static social share buttons</a></li>
</ul>
<p>Check them out at the bottom of the page!</p>
<h2>Conclusion</h2>
<p>The main down-side of this path, is that most of the time you will be on your
own. You might get lucky and find a plugin for your favorite static blog
generator (Jekyll, Pelican, Hugo, Hakyll), but if there is nothing, you will
have to come up with a solution from scratch.</p>
<p>At the end, I think it’s possible to get a mostly static site, with
no or very few external dependencies. This post was probably loaded
using only one request (the main document + the example images), which
includes everything needed. Yes it’s super minimal, and it could look
better, and it could use some comments, but most personal static
blogs don’t need as much, and if they do, and you’re willing to spend
the extra time – having totally private analytics, comments or math
rendering, could make for a very interesting and rewarding side-project!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Installing IHaskell on Ubuntu 16.04 with Stack]]></title>
            <link>https://remusao.github.io//posts/ihaskell-ubuntu-16-04-install.html</link>
            <guid>https://remusao.github.io//posts/ihaskell-ubuntu-16-04-install.html</guid>
            <pubDate>Sat, 07 Oct 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Last year I wrote a tutorial to install iHaskell on Ubuntu 14.04. Since it’s a
bit out-dated now, but I still think iHaskell can be super useful, I decided to
update it for Ubuntu 16.04.</p>
<p>Before we start, please be aware that you can use IHaskell directly in your
browser by visiting this website: <a href="https://try.jupyter.org/" target="_blank" rel="noopener noreferrer">try.jupyter.org</a>.
The following tutorial is only meant for those who want IHaskell to run locally.</p>
<h2>Install Stack</h2>
<p>Compared to Ubuntu 14.04, it is now easier to install <code>stack</code> thanks to the
<code>haskell-stack</code> package:</p>
<pre class="code" data-lang="sh"><code>$ sudo apt-get install haskell-stack
</code></pre>
<p>Now let’s make sure we have the latest version of stack, as well as the latest
snapshot from <a href="stackage.org/lts" target="_blank" rel="noopener noreferrer">stackage</a>:</p>
<pre class="code" data-lang="sh"><code>$ stack upgrade
$ stack update
$ stack setup
</code></pre>
<h2>Dependencies</h2>
<p>Some <a href="https://github.com/gibiansky/IHaskell#linux" target="_blank" rel="noopener noreferrer">dependencies</a> are
required before building the IHaskell kernel, let’s install them:</p>
<pre class="code" data-lang="sh"><code>$ sudo apt-get install -y   \
    git                     \
    libtinfo-dev            \
    libzmq3-dev             \
    libcairo2-dev           \
    libpango1.0-dev         \
    libmagic-dev            \
    libblas-dev             \
    liblapack-dev
</code></pre>
<h2>Install Jupyter</h2>
<p>IHaskell requires a recent version of <em>Jupyter</em>, so we need to install
it ourselves. There are several options:</p>
<ol>
<li>Use pip and install it globally (<code>pip install jupyter</code>)</li>
<li><strong>Use pip and install it in a <a href="https://virtualenv.pypa.io/en/stable/" target="_blank" rel="noopener noreferrer"><code>virtualenv</code></a></strong></li>
<li>Use <a href="https://nixos.org/nix/" target="_blank" rel="noopener noreferrer">nix</a> <em>(You’re on your own)</em></li>
<li>Use <a href="https://www.continuum.io/downloads" target="_blank" rel="noopener noreferrer">conda</a> (<code>conda update jupyter</code>)</li>
</ol>
<p>Let’s go with option <code>2.</code>. I usually never install python packages globally
using <code>sudo pip</code>, and prefer to create a fresh <a href="https://virtualenv.pypa.io/en/stable/" target="_blank" rel="noopener noreferrer"><code>virtualenv</code></a> for each project.
Let’s proceed!</p>
<p>If you’re on a fresh install, we need to install virtualenv first:</p>
<pre class="code" data-lang="sh"><code>$ sudo apt-get install virtualenv python3-dev ncurses-base
</code></pre>
<p>Then let’s install <code>jupyter</code> inside of our virtualenv <code>virtualenv</code>:</p>
<pre class="code" data-lang="sh"><code>$ virtualenv venv-ihaskell -p /usr/bin/python3 <span class="hljs-comment"># Create a virtualenv</span>
$ <span class="hljs-built_in">source</span> venv-ihaskell/bin/activate <span class="hljs-comment"># Active it</span>
$ pip install                                   \
    jupyter==1.0.0                              \
    jupyter-contrib-core==0.3.3                 \
    jupyter-contrib-nbextensions==0.3.1         \
    jupyter-highlight-selected-word==0.0.11     \
    jupyter-latex-envs==1.3.8.4                 \
    jupyter-nbextensions-configurator==0.2.8
</code></pre>
<h2>Install IHaskell</h2>
<p>Since IHaskell is not available in the latest stackage LTS snapshot, we have two
options to install it:</p>
<ul>
<li>Compile from source</li>
<li>Use the latest snapshot supporting IHaskell (<code>lts-6.35</code>)</li>
</ul>
<p>I will present both methods.</p>
<h3>From source</h3>
<p>The instructions can be found in the github <a href="https://github.com/gibiansky/IHaskell#linux" target="_blank" rel="noopener noreferrer">repository</a>:</p>
<blockquote>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">source</span> ihaskell-venv/bin/activate
$ git <span class="hljs-built_in">clone</span> git@github.com:gibiansky/IHaskell.git
$ <span class="hljs-built_in">cd</span> IHaskell
$ pip install -r requirements.txt
$ stack setup
$ stack install gtk2hs-buildtools
$ stack install --fast
$ stack <span class="hljs-built_in">exec</span> ihaskell -- install --stack
</code></pre>
</blockquote>
<p>Then it can be started using:</p>
<pre class="code" data-lang="sh"><code>$ stack <span class="hljs-built_in">exec</span> jupyter -- notebook
</code></pre>
<h3>From stackage lts-6.35</h3>
<p>Unfortunately, it is not possible to build IHaskell using the latest snapshot,
as it does not seem to work with GHC 8.x. The latest supported LTS snapshot is
<code>6.35</code>, so we will have to specify it explicitly:</p>
<pre class="code" data-lang="sh"><code>$ stack --resolver lts-6.35 setup --install-ghc
$ stack --resolver lts-6.35 install ihaskell
$ stack --resolver lts-6.35 <span class="hljs-built_in">exec</span> ihaskell -- install --stack
</code></pre>
<p>You may want to install extra packages to enhance <em>IHaskell</em>’s capabilities. Here are the ones supported by stackage:</p>
<ul>
<li><code>ihaskell-aeson</code></li>
<li><code>ihaskell-basic</code></li>
<li><code>ihaskell-blaze</code></li>
<li><code>ihaskell-charts</code></li>
<li><code>ihaskell-diagrams</code></li>
<li><code>ihaskell-hatex</code></li>
<li><code>ihaskell-inline-r</code></li>
<li><code>ihaskell-juicypixels</code></li>
<li><code>ihaskell-magic</code></li>
<li><code>ihaskell-rlangqq</code></li>
</ul>
<p>Some others are not in the snapshot, but could be very useful and can probably
be installed from source:</p>
<ul>
<li><code>ihaskell-widgets</code></li>
<li><code>ihaskell-parsec</code></li>
<li><code>ihaskell-plot</code></li>
</ul>
<h2>What’s next</h2>
<p>The installation of IHaskell on Ubuntu 16.04 is a bit easier than on 14.04
thanks to more up-to-date dependencies. Unfortunately, the latest IHaskell is
not available on stackage LTS, which requires to use an older snapshot (<code>6.35</code>).
It is still possible to build IHaskell from source, which allows you to
run the latest version of the code! It’s up to you to choose the method you prefer.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[What's in a parser combinator?]]></title>
            <link>https://remusao.github.io//posts/whats-in-a-parser-combinator.html</link>
            <guid>https://remusao.github.io//posts/whats-in-a-parser-combinator.html</guid>
            <pubDate>Tue, 23 Feb 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>As part of my ongoing effort to make progress in Haskell (that’s
one of my goals for 2016!), I’m following the <a href="https://courses.edx.org/courses/course-v1:DelftX+FP101x+3T2015/info" target="_blank" rel="noopener noreferrer">MOOC on functionnal programming</a>
by <a href="https://twitter.com/headinthebox" target="_blank" rel="noopener noreferrer">Erik Meijer</a> on <em>edX</em>.</p>
<p>The first lessons were pretty basic stuff, and I got through
them quickly. Lesson 7 is about <em>Functional parsers</em> and
M***** (scary). This is where I encountered my first
difficulties, and I thought it would be an interesting writing.
I already used parser combinators in Haskell before (mainly
<a href="https://hackage.haskell.org/package/parsec" target="_blank" rel="noopener noreferrer">Parsec</a> and
<a href="http://hackage.haskell.org/package/attoparsec" target="_blank" rel="noopener noreferrer">Attoparsec</a>), but never
really understood how they worked, or at least not enough to implement
one myself. So here is my take on the subject. Don’t expect really
advanced stuff! It’s just an introduction to the basic concepts, on
which we could build more complex and useful tools. In particular, <strong>I
won’t talk about</strong>:</p>
<ol>
<li>How to report errors.</li>
<li>How to recover from errors.</li>
<li>How to write a parser for a concrete grammar.</li>
</ol>
<p>Instead <strong>I’ll focus on</strong>:</p>
<ol>
<li>What a parser <em>is</em>.</li>
<li>How to make parsers <em>compose</em>.</li>
<li>How to use <em>do notation</em> to implement more complex parsers.</li>
</ol>
<p>One of the interesting facts about writing your own parser combinators
library, is that you will learn (or consolidate) other knowledges in
the process, like: <em>Functors</em>, <em>Applicatives</em> and, of course, <em>Monads</em>,
and more generaly, how to <em>design DSL in Haskell</em>. I already knew about
this concepts (at least, that’s what I thought…), but knowing what
something is from a high level of abstraction, <em>is not the same as
knowing how to implement it on a concrete type</em> (like a Parser)!</p>
<h3>So what’s a parser?</h3>
<p>We can view a <em>Parser</em> as <em>something</em> that consumes some input, and
outputs a structured representation of what was consumed. For the sake
of simplicity, we’ll only consume strings (Haskell type <code>String</code>). So
that would be something like:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-type">Parser</span> a = <span class="hljs-type">String</span> -&gt; a</span>
</code></pre>
<p>Here <code>a</code> represents the type of what is <em>built</em> from the stream of
characters (<code>String</code>). This could be a syntactic tree, or a list
of numbers, or anything else. For example a parser that is able to
recognize a string like <code>&quot;[1, 2, 3, 4]&quot;</code> could have the type: <code>Parser [Int]</code>
(expended to <code>String -&gt; [Int]</code>), which means it takes a <code>String</code>
and output a <code>list</code> of integers.</p>
<p>But we’re missing two important properties of a <em>Parser</em>:</p>
<ol>
<li>It can <strong>fail to parse</strong> something.</li>
<li>It can <strong>partially consume</strong> its input.</li>
</ol>
<p>To take into account the first point, we could return <code>Maybe a</code> instead
of <code>a</code> (resulting in <code>Nothing</code> in case of failure). Note that we could
also use a richer type like <code>Either</code> to handle parsing errors. And for
the second point, we can return a tuple of a <code>a</code> and a <code>String</code>, which
represents the part of the string that wasn’t consumed by the parser.
The type would then become:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">Parser</span> a = <span class="hljs-type">Parser</span> { <span class="hljs-title">runParser</span> :: <span class="hljs-type">String</span> -&gt; <span class="hljs-type">Maybe</span> (<span class="hljs-title">a</span>, <span class="hljs-type">String</span>) }</span>
</code></pre>
<p>As an example of a parser that would fail, if you take our previous
<em>parser</em> that is able to handle a list of integers, if you give it the
string <code>&quot;[1 ,2&quot;</code>, it will fail, and return <code>Nothing</code>.</p>
<p>Similarly, if we feed the <em>parser</em> with <code>&quot;[1, 2, 3, 4]toto&quot;</code>, it will
consume the part of the string that represents the list of integers, and
leave <code>&quot;toto&quot;</code> as a remaining input. Thus the result would be: <code>Just ([1, 2, 3, 4], &quot;toto&quot;)</code>.</p>
<p>Let’s implement some very basic parsers:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This parser always fails</span>
<span class="hljs-title">failure</span> :: <span class="hljs-type">Parser</span> a
<span class="hljs-title">failure</span> = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-type">Nothing</span>
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This parser always succeeds and returns the value given as input</span>
<span class="hljs-comment">-- (leaving the input string intact)</span>
<span class="hljs-title">return</span> :: a -&gt; <span class="hljs-type">Parser</span> a
<span class="hljs-title">return</span> a = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-type">Just</span> (a, s)
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This parser returns the first char of the input string, and</span>
<span class="hljs-comment">-- fail on empty input</span>
<span class="hljs-title">oneChar</span> :: <span class="hljs-type">Parser</span> <span class="hljs-type">Char</span>
<span class="hljs-title">oneChar</span> = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-keyword">case</span> s <span class="hljs-keyword">of</span>
            [] -&gt; <span class="hljs-type">Nothing</span>
            (c:xs) -&gt; <span class="hljs-type">Just</span> (c, xs)
</code></pre>
<p>Let’s test these parsers:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> failure <span class="hljs-string">&quot;Hello Parser!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (return <span class="hljs-number">42</span>) <span class="hljs-string">&quot;Hello Parser!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-number">42</span>, <span class="hljs-string">&quot;Hello Parser!&quot;</span>)
</code></pre>
</blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> oneChar <span class="hljs-string">&quot;Hello Parser!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-string">&#x27;H&#x27;</span>,<span class="hljs-string">&quot;ello Parser!&quot;</span>)
</code></pre>
</blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> oneChar <span class="hljs-string">&quot;&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<p>The basic parsers seem to behave as expected. We get <code>Nothing</code> in case
of failure, and they are able to partially consume the input. So all
is good, but what about more complex parsers? We would like to parse
strings, or more complex patterns. Let’s try to recognize a string from
the input, using our basic parsers:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">string</span> :: <span class="hljs-type">String</span> -&gt; <span class="hljs-type">Parser</span> <span class="hljs-type">String</span>
<span class="hljs-title">string</span> <span class="hljs-string">&quot;&quot;</span> = return <span class="hljs-string">&quot;&quot;</span>
<span class="hljs-title">string</span> (c1:xs1) = <span class="hljs-type">Parser</span> $ \s -&gt;
  <span class="hljs-keyword">case</span> runParser oneChar s <span class="hljs-keyword">of</span>
    <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
    <span class="hljs-type">Just</span> (c2, rest) -&gt;
      <span class="hljs-keyword">if</span> c1 == c2
      <span class="hljs-keyword">then</span> <span class="hljs-keyword">case</span> runParser (string xs1) rest <span class="hljs-keyword">of</span>
        <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
        <span class="hljs-type">Just</span> (match, rest2) -&gt; <span class="hljs-type">Just</span> (c2:match, rest2)
      <span class="hljs-keyword">else</span> <span class="hljs-type">Nothing</span>
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (string <span class="hljs-string">&quot;Hello&quot;</span>) <span class="hljs-string">&quot;Hello Parser!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-string">&quot;Hello&quot;</span>, <span class="hljs-string">&quot; Parser!&quot;</span>)
</code></pre>
</blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (string <span class="hljs-string">&quot;Hello&quot;</span>) <span class="hljs-string">&quot;Foo Bar&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (string <span class="hljs-string">&quot;&quot;</span>) <span class="hljs-string">&quot;Hello Parser!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-string">&quot;&quot;</span>,<span class="hljs-string">&quot;Hello Parser!&quot;</span>)
</code></pre>
</blockquote>
<p>This isn’t very convenient (but it works)… Because we have to write
the boilerplate to <em>compose parsers</em> over and over. Hopefully, we know a
famous structure that allows composition in Haskell, and this is called
<em>Monad</em> (and I won’t make yet another tutorial on <em>Monads</em>, so I will
assume you already are familiar with this concept). That means we could
avoid all the boilerplate, by making our <code>Parser</code> type an instance of
<em>Monad</em>. This would allow us to use the <em>do syntax</em> to cleanly compose
our parsers! Sweet!</p>
<p>To do so, we’ll have to make our <em>Parser</em> an instance of: <em>Functor</em>,
<em>Applicative</em> and <em>Monad</em>.</p>
<h4>Parser is a Functor</h4>
<p>First of all, our Parser is an instance of <a href="https://en.wikibooks.org/wiki/Haskell/The_Functor_class" target="_blank" rel="noopener noreferrer"><em>Functor</em></a>,
which means we can <code>map</code> functions over the result of our parsing:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">instance</span> <span class="hljs-type">Functor</span> <span class="hljs-type">Parser</span> <span class="hljs-keyword">where</span></span>
    <span class="hljs-comment">-- fmap :: (a -&gt; b) -&gt; Parser a -&gt; Parser b</span>
    <span class="hljs-comment">-- 1. Run parser on input string.</span>
    <span class="hljs-comment">-- 2. Apply function on result of parsing.</span>
    fmap f p = <span class="hljs-type">Parser</span> $ \s -&gt;
      <span class="hljs-keyword">case</span> runParser p s <span class="hljs-keyword">of</span>
        <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
        <span class="hljs-type">Just</span> (a, rest) -&gt; <span class="hljs-type">Just</span> (f a, rest)
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- Parse `String` &quot;42&quot; and then convert it to `Int` using `read`</span>
<span class="hljs-title">parse42</span> :: <span class="hljs-type">Parser</span> <span class="hljs-type">Int</span>
<span class="hljs-title">parse42</span> = (fmap read $ string <span class="hljs-string">&quot;42&quot;</span>)

<span class="hljs-title">runParser</span> parse42 <span class="hljs-string">&quot;42 is the answer!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-number">42</span>, <span class="hljs-string">&quot; is the answer!&quot;</span>)
</code></pre>
</blockquote>
<h4>Parser is an Applicative</h4>
<p>Secondly, we can make our parser an instance of
<a href="https://en.wikibooks.org/wiki/Haskell/Applicative_functors" target="_blank" rel="noopener noreferrer"><em>Applicative</em></a>.
This part wasn’t obvious for me. All the examples I found were
about instances for easy types like <code>Maybe</code>, but I found a <em>Parser</em> to
be pretty different. But thanks to the types and some use-cases (that
you’ll find below), I figured the following implementation (which will
hopefully be correct…):</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">instance</span> <span class="hljs-type">Applicative</span> <span class="hljs-type">Parser</span> <span class="hljs-keyword">where</span></span>
    <span class="hljs-comment">-- pure :: a -&gt; Parser a</span>
    <span class="hljs-comment">-- Wrap a value inside a parser, leaving input unchanged.</span>
    pure a = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-type">Just</span> (a, s)
    <span class="hljs-comment">-- (&lt;*&gt;) :: Parser (a -&gt; b) -&gt; Parser a -&gt; Parser b</span>
    <span class="hljs-comment">-- 1. Run first parser on input (resulting in a function (a -&gt; b).</span>
    <span class="hljs-comment">-- 2. Run second parser on remaining input, left by first parser.</span>
    <span class="hljs-comment">-- 3. Apply function (a -&gt; b) on result of second parser.</span>
    p1 &lt;*&gt; p2 = <span class="hljs-type">Parser</span> $ \s -&gt;
      <span class="hljs-keyword">case</span> runParser p1 s <span class="hljs-keyword">of</span>
        <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
        <span class="hljs-type">Just</span> (f, rest) -&gt; <span class="hljs-keyword">case</span> runParser p2 rest <span class="hljs-keyword">of</span>
          <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
          <span class="hljs-type">Just</span> (a, rest2) -&gt; <span class="hljs-type">Just</span> (f a, rest2)
</code></pre>
<p>The usefulness of the previous instance might not be obvious, but it
allows us to <code>lift</code> some function inside the realm of parsers. For
example if we want to take the result of several parsers and then group
their results into a tuple, we can do it using <em>Applicatives</em>:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">parseTuple</span> :: <span class="hljs-type">Parser</span> (<span class="hljs-type">Char</span>, <span class="hljs-type">Char</span>)
<span class="hljs-title">parseTuple</span> =  (,) &lt;$&gt; oneChar &lt;*&gt; oneChar
<span class="hljs-title">runParser</span> parseTuple <span class="hljs-string">&quot;ab&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> ((<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>), <span class="hljs-string">&quot;&quot;</span>)
</code></pre>
</blockquote>
<p>This is the kind of constructs we will use to convert the raw parsed
structure into our own types (e.g: an AST).</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">AST</span> =</span>
    <span class="hljs-type">Foo</span> <span class="hljs-type">String</span>
  | <span class="hljs-type">Bar</span> <span class="hljs-type">String</span>
  | <span class="hljs-type">Pair</span> <span class="hljs-type">Char</span> <span class="hljs-type">Char</span>
  <span class="hljs-keyword">deriving</span> (<span class="hljs-type">Show</span>)

<span class="hljs-title">parseFoo</span>, parseBar, parsePair :: <span class="hljs-type">Parser</span> <span class="hljs-type">AST</span>
<span class="hljs-title">parseFoo</span> = <span class="hljs-type">Foo</span> &lt;$&gt; string <span class="hljs-string">&quot;foo&quot;</span>
<span class="hljs-title">parseBar</span> = <span class="hljs-type">Bar</span> &lt;$&gt; string <span class="hljs-string">&quot;bar&quot;</span>
<span class="hljs-title">parsePair</span> = <span class="hljs-type">Pair</span> &lt;$&gt; oneChar &lt;*&gt; oneChar
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> parseFoo <span class="hljs-string">&quot;foo bar&quot;</span>
<span class="hljs-title">runParser</span> parseBar <span class="hljs-string">&quot;bar baz&quot;</span>
<span class="hljs-title">runParser</span> parsePair <span class="hljs-string">&quot;xyz&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-type">Foo</span> <span class="hljs-string">&quot;foo&quot;</span>, <span class="hljs-string">&quot; bar&quot;</span>)
</code></pre>
</blockquote>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span>(<span class="hljs-type">Bar</span> <span class="hljs-string">&quot;bar&quot;</span>, <span class="hljs-string">&quot; baz&quot;</span>)
</code></pre>
</blockquote>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-type">Pair</span> <span class="hljs-string">&#x27;x&#x27;</span> <span class="hljs-string">&#x27;y&#x27;</span>, <span class="hljs-string">&quot;z&quot;</span>)
</code></pre>
</blockquote>
<h4>Parser is a Monad</h4>
<p>Last but not least, our parser is a <a href="https://en.wikibooks.org/wiki/Haskell/Understanding_monads" target="_blank" rel="noopener noreferrer"><em>Monad</em></a>. Which means it must implement: <code>&gt;&gt;=</code>, <code>&gt;&gt;</code>, <code>return</code> and <code>fail</code>:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">instance</span> <span class="hljs-type">Monad</span> <span class="hljs-type">Parser</span> <span class="hljs-keyword">where</span></span>
    <span class="hljs-comment">-- (&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b</span>
    <span class="hljs-comment">-- 1. Run first parser on input.</span>
    <span class="hljs-comment">-- 2. Feed result of parsing to `f`.</span>
    <span class="hljs-comment">-- 3. Run second parser (result of `f`) on remaining</span>
    <span class="hljs-comment">--    input (left by first parser)</span>
    p &gt;&gt;= f = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-keyword">case</span> runParser p s <span class="hljs-keyword">of</span>
                    <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
                    <span class="hljs-type">Just</span> (a, rest) -&gt; runParser (f a) rest
    <span class="hljs-comment">-- (&gt;&gt;) :: Parser a -&gt; Parser b -&gt; Parser b</span>
    <span class="hljs-comment">-- 1. Run first parser on input.</span>
    <span class="hljs-comment">-- 2. Run second parser on remaining input (left by first parser)</span>
    <span class="hljs-comment">-- We ignore result of first parser.</span>
    p1 &gt;&gt; p2 = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-keyword">case</span> runParser p1 s <span class="hljs-keyword">of</span>
                    <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
                    <span class="hljs-type">Just</span> (_, rest) -&gt; runParser p2 rest
    <span class="hljs-comment">-- return :: a -&gt; Parser a</span>
    return = pure
    <span class="hljs-comment">-- fail :: String -&gt; Parser a</span>
    fail _ = <span class="hljs-type">Parser</span> (const <span class="hljs-type">Nothing</span>)
</code></pre>
<p>Thanks to this definition we can use the <code>do</code> syntactic sugar, which
will ease the implementation of more complex parsers. Let’s see what we
can do.</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- Parse a specific `Char` from the input</span>
<span class="hljs-title">char</span> :: <span class="hljs-type">Char</span> -&gt; <span class="hljs-type">Parser</span> <span class="hljs-type">Char</span>
<span class="hljs-title">char</span> c = <span class="hljs-keyword">do</span>
    c1 &lt;- oneChar
    <span class="hljs-keyword">if</span> c == c1
       <span class="hljs-keyword">then</span> return c1
       <span class="hljs-keyword">else</span> failure
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (char <span class="hljs-string">&#x27;H&#x27;</span>) <span class="hljs-string">&quot;Hello!&quot;</span>
<span class="hljs-title">runParser</span> (char <span class="hljs-string">&#x27;e&#x27;</span>) <span class="hljs-string">&quot;Hello!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span>(‘<span class="hljs-type">H</span>’,“ello!”)
</code></pre>
</blockquote>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<p>We can also implement a cleaner version of our <code>string</code> parser (found above):</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- Parse a specific pattern from the input</span>
<span class="hljs-title">string&#x27;</span> :: <span class="hljs-type">String</span> -&gt; <span class="hljs-type">Parser</span> <span class="hljs-type">String</span>
<span class="hljs-title">string&#x27;</span> [] = return []
<span class="hljs-title">string&#x27;</span> (c:xs) = <span class="hljs-keyword">do</span>
    c1 &lt;- char c
    rest &lt;- string&#x27; xs
    return (c1:rest)
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (string&#x27; <span class="hljs-string">&quot;Hello&quot;</span>) <span class="hljs-string">&quot;Hello&quot;</span>
<span class="hljs-title">runParser</span> (string&#x27; <span class="hljs-string">&quot;Hello&quot;</span>) <span class="hljs-string">&quot;Foo&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span>(<span class="hljs-string">&quot;Hello&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)
</code></pre>
</blockquote>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<p>The <code>do</code> notation makes it very easy to combine parsers! We now have
some basic building blocks that we could use to implement more parsing
combinators: <code>choice</code>, <code>many</code>, <code>option</code>, etc. But I’ll leave it as an
exercise.</p>
<p>Moreover, it would be interesting to implement an error reporting
mechanism, as well as position tracking (to locate errors in the input),
but I’ll leave it for another blog-post (or as an exercise for the
reader!).</p>
<h2>What I learned while reinventing the wheel</h2>
<p>Implementing (very) basic parsing combinators led me to better
understand the foundation of libraries like <em>Parsec</em> or <em>Attoparsec</em>,
and to implement not so trivial instances of typeclasses like
<em>Applicatives</em> and <em>Monads</em>. Although basic, I think it’s a good way
to be more familiar with the <em>DSL</em>-like capabilities of Haskell, and
to feel the power that the language offers in term of domain-specific
modeling.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Feedback from Hash Code 2016 qualification round]]></title>
            <link>https://remusao.github.io//posts/hashcode-2016-feedback.html</link>
            <guid>https://remusao.github.io//posts/hashcode-2016-feedback.html</guid>
            <pubDate>Fri, 12 Feb 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<figure><a href="../images/hashcode2016.jpg" target="_blank" rel="noopener noreferrer"><img src="../images/hashcode2016.jpg" alt=""></a><figcaption>hashcode</figcaption></figure>
<p>Yesterday was the qualification round for <a href="https://hashcode.withgoogle.com/" target="_blank" rel="noopener noreferrer">Hash Code 2016</a> contest, organized by
Google. I already had the opportunity to participate next, and made it to the
final round with my team.  For this new edition, the team and motivation was
the same but we thought a bit about how we could improve our organization to be
more efficient. This post is about what I will take away from this competition.</p>
<h1>The Competition</h1>
<p>For this third edition, the concept stays the same, you can participate in
<em>teams</em>, and must perform well during the qualification round to make it to the
final round (which takes place in Google headquarters in Paris). Duration of
qualification round is about <em>4 hours</em>, and <em>final is a whole day</em>. Usually the
difficulty of the problem of qualification is lower than for the final. Though
this year’s challenged seemed a bit more complex than the previous one.</p>
<h1>The problems</h1>
<p>All the problems from Hash Codes contests are pretty much of the same kind
everytime since they are <em>optimization problems</em>. You’re given a situation, and
you want to maximize some output of the problem given an initial step:</p>
<ul>
<li><strong>2014 Final</strong>: <a href="https://hashcode.withgoogle.com/2014/tasks/hashcode2014_final_task.pdf" target="_blank" rel="noopener noreferrer">Optimize routing of Street view cars</a> in a city.</li>
<li><strong>2015 Qualification</strong>: The task was about <a href="https://hashcode.withgoogle.com/2015/tasks/hashcode2015_qualification_task.pdf" target="_blank" rel="noopener noreferrer">optimizing a data center</a>.</li>
<li><strong>2015 Final</strong>: <a href="https://hashcode.withgoogle.com/2015/tasks/hashcode2015_final_task.pdf" target="_blank" rel="noopener noreferrer">Optimize wireless internet coverage</a> using Loons.</li>
<li><strong>2016 Qualification</strong>: Optimize schedule of drones to deliver orders to customers on a 2D grid.</li>
<li><strong>2016 Final</strong>: Optimize something else…</li>
</ul>
<p>This kind of problems are interesting because it takes a <em>broad range of skill
and knowledge to solve them</em>, plus, <em>you can’t find the global optimum</em> (or at
least not easily/in a reasonnable time).  So the goal of any of this
competitions it to find a better solution than your competitors, or a least, a
good enough solution.</p>
<h1>Team Organization</h1>
<p>Organizing a team during such a short period of time, on a complex problem is
challenging. There are a lot of ways you can do it:</p>
<ul>
<li><em>Everyone is programming</em>.</li>
<li><em>Split the tasks among team members</em>.</li>
<li><em>You can define a schedule to brainstorm/code/visualize/give feedback</em>.</li>
<li>etc.</li>
</ul>
<p>Last year, we chose an approach where we would <em>talk and brainstorm with the
whole team</em> during the contest. <em>Not everyone was coding</em> and one of the team
member did some very <em>useful visualization</em> to gain insight, while others were
implementing some ideas from the discussions we had about the challenge.  This
approach was kind of Ok, we made it to the final, but didn’t perform very well
during the final round. Here are some short comings:</p>
<ul>
<li>Not everyone was at ease with programming.</li>
<li>Not everyone knows the same programming languages.</li>
<li>We didn’t participate in this kind of competition before.</li>
<li>Brainstorming a lot can bring a lot of ideas, but <em>you can’t try everything</em>, so it’s better to stick to one or two promising ideas that aren’t too difficult to implement in a short time.</li>
<li>Coding speed matters so you better go with a programming language that you know very well.</li>
</ul>
<p>We weren’t very satisfied with what we did that year, so we tried a different
approach this year. We observed that a lot of teams seem to go with a more
individual approach, where everyone is programming. That’s what we tried:</p>
<ol>
<li>Read problem statement, <strong>making sure everyone understood the same things</strong>.</li>
<li>Carefully consider the inputs, to <strong>list every information at our disposal</strong>.</li>
<li><strong>Made sure that the score to optimize was clear to everyone</strong>.</li>
<li>Initial brainstorm on some solutions, ways to solve the problem.</li>
<li>Then everyone tried to implement a working solution, using what we discussed.</li>
</ol>
<p>We had little interactions after <strong>step 4</strong>, which wasn’t a good thing in my
opinion. What we observed is that <strong>we talked less</strong>, and had <strong>a bit less
fun</strong>. We didn’t interact as much as last year, and <strong>not everyone felt like
they participated</strong> in the team’s work, due to individual solutions.</p>
<h1>Challenges</h1>
<p>Here is what I found to be difficult during this qualification round:</p>
<ul>
<li><strong>Your worst ennemy is complexity</strong>.</li>
<li><em>Your second worst is your concentration</em>.</li>
<li>Being reasonable about the solution to choose.</li>
</ul>
<p>What I found useful was to decide early on <em>a method that isn’t too complex</em> or
too hard to implement. The most important is to <em>submit a solution</em>. <em>Better
have a simple solution that works than a complex one that doesn’t</em>. Your goal
is not to find the best solution ever, but to find a solution <em>good enough</em> to
make if to the final round.  Moreover if your first simple solution works, you
should have sufficient time to improve it before the end of the round (if you
don’t, that means your solution was maybe too complex, or that you took a big
risk).</p>
<p>One of my teammates, Florian, posted a <a href="https://flothesof.github.io/thoughts-before-hashcode-2016.html" target="_blank" rel="noopener noreferrer">blog post</a>
this week, before the competition to explain what he thought would be a good
way to tackle the coming qualification. I mainly agree with him, in the light
of what happened yesterday, but I tried to clarify some point in the comments
(that was before the contest). Some of my thoughts on the subject evolved:</p>
<blockquote>
<p>[…] the top-down divide and conquer approach that you describe (as lazy
evaluation), is more about breaking the problem into a maximum number of small
sub-parts than it is about modelling the problem. You can see that, for
example, last year’s winners didn’t create classes or structs, they just used
plain C arrays. And this is more about breaking the complexity of the problem,
and deferring complexity to later as much as you can. This helps keep track of
what you’ve done, what you’re doing, and what remain to be done, while managing
complexity: “I know my solution must look like do A, then B, and C at a high
level, and I know I can do A, B, C later, with the same top-down approach.
Let’s not think about this know, it would waste time and concentration.”</p>
</blockquote>
<p>What I think now is that, you can go with a low-level language and less
modelization if you are well prepared to program in a short period of time.
Otherwise, you would better stick with the clean step-by-step approach to limit
complexity, and <strong>validate your steps as you go</strong>. It’s crucial to limit
potential errors and bugs, so that you are confident your solution will work.
<strong>You can’t afford lot of debug in a competition</strong>.</p>
<blockquote>
<p>[…] the code doesn’t have to be clean, or readable, in a general way. It
must be clear to you, at least during the time of the competition, which is
only a few hours. This is why I think it’s not necessary to add comments, or
create classes/struct/etc. to model your ideas into code. Rather it’s a race
against time and complexity and you can use this kind of programming constructs
to break the complexity of the problem even further, but not to be readable.
Breaking into small part is also useful to refactor, try new ideas, change
stuff, quickly (and I agree that modelling can help too there, but I don’t
think it’s a low hanging fruit in this kind of competition) .</p>
</blockquote>
<p>This point is similar to the previous one, except that you should not be too
confident in your ability to handle a complex problem/solution in a short
amount of time. <strong>Better be slow and right, than fast and wrong</strong>.</p>
<blockquote>
<p>[…] it’s better to have a slow solution that works than a quick solution
that doesn’t. But I would argue that this argument can be held against what you
say too, because we also can say that it’s better to have an ugly/dirty/oneshot
solution that works, than a beautifully designed/readable solution that
doesn’t. So it’s more quick &amp; dirty but works, than high-level/well-designed
code that doesn’t […]</p>
</blockquote>
<blockquote>
<p>[…] it can be an advantage to develop the solution in a fast language like
C++ or Java, instead of a more dynamic language like Python. I may be wrong,
but I think you have better chances to have a fast-enough solution in C++ with
ugly code, no modelling or optimization effort than it is to achieve reasonable
performance in Python (this is mainly true for the kind of problem we have to
tackle in the Hash Code: optimization and number crunching). When you have to
explore big solution spaces looking for an optimum, with little time to think
about an elegant solution, you’re playing against time, so it’s good to use a
language in which you can go quick and dirty, but still get reasonable
performances.</p>
</blockquote>
<p>It’s true only if you can come up with a working program in this language,
during the time of the competition. If you don’t feel like you can, stick with
the easier, well-known language. <strong>Working but slow solution in <em>Python</em> is
better than a fast non-working solution in <em>C++</em>.</strong></p>
<h1>Take-away</h1>
<p><strong>TL;DR</strong>:</p>
<ul>
<li><em>Master your programming environment</em>.</li>
<li><em>Manage/avoid complexity if you can</em>.</li>
<li>Don’t go for a too complex/fancy solution.</li>
<li><em>Communication with your team members is good</em> if you want to feel like you’re competing together.</li>
<li><strong>Have fun!</strong></li>
</ul>
<p>Now we’ll try to improve our solutions during the extended round. I’m eager to
read some blog posts on the problem we had to tackle. Insight from other teams
will definitely be interesting!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rubik's Cube records]]></title>
            <link>https://remusao.github.io//posts/rubiks-cube-records.html</link>
            <guid>https://remusao.github.io//posts/rubiks-cube-records.html</guid>
            <pubDate>Wed, 27 Jan 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Following on the recent hype around the robot
that is able to solve a Rubik’s cube <a href="http://hackaday.com/2016/01/27/robot-solves-rubiks-cube-in-just-one-second/" target="_blank" rel="noopener noreferrer">in a second</a>
(which seems a big improvement over the previous robot that was able to
solve it in about 3 seconds), I got interested in human records, and
their evolution over the year.</p>
<p>The <a href="https://www.worldcubeassociation.org" target="_blank" rel="noopener noreferrer">World Cube Association</a>
provides dataset about ranking, records, players in
Rubik’s Cube competitions. They offer a <a href="https://www.worldcubeassociation.org/results/misc/export.html" target="_blank" rel="noopener noreferrer">downloadable
dataset</a>
for data science purpose. But since it would be too easy to use a TSV
;), I’ll show how we can extract data from this website, and use Pandas
get some insight.</p>
<h1>Players</h1>
<p>We’ll first try to explore data about results of
Worldwide competitions that we can find on <a href="https://www.worldcubeassociation.org/results" target="_blank" rel="noopener noreferrer">this
page</a>.</p>
<p>Let’s use <code>requests</code> to fetch HTML from the URL. If you go directly on
the page, you’ll see that you can select the number of results you’re
interested in, countries, years, etc. All theses parameters can be
specified in the URL too. In this post, I’ll use all the data (all
players, all years, all countries):</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> requests
r = requests.get(<span class="hljs-string">&quot;https://www.worldcubeassociation.org/results/events.php?eventId=333&amp;regionId=&amp;years=&amp;show=All%2BPersons&amp;single=Single&quot;</span>)
</code></pre>
<p>Beautifulsoup will let you manipulate HTML without dealing too much with
low-level details.</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
soup = BeautifulSoup(r.text, <span class="hljs-string">&#x27;html.parser&#x27;</span>)
</code></pre>
<p>You can ask him to find and extract one particular part of the HTML, in
our case it would be <code>table-responsive</code> which represents the array of
results:</p>
<pre class="code" data-lang="python"><code>table = soup.find(<span class="hljs-string">&quot;div&quot;</span>, {<span class="hljs-string">&quot;class&quot;</span>: <span class="hljs-string">&quot;table-responsive&quot;</span>})
raw_lines = [
    line.contents[:<span class="hljs-number">5</span>]
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> table.find_all(<span class="hljs-string">&quot;tr&quot;</span>)
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(line) == <span class="hljs-number">6</span>
]
raw_lines[<span class="hljs-number">0</span>]
</code></pre>
<blockquote>
<p>1 | <a href="/results/p.php?i=2011ETTE01" target="_blank" rel="noopener noreferrer">Lucas Etter</a> | 4.90 | USA | <a href="/results/c.php?i=RiverHillFall2015" target="_blank" rel="noopener noreferrer">River Hill Fall 2015</a>
— | — | — | — |</p>
</blockquote>
<p>We get a list of <code>HMTL Entities</code> that we will process to extract the
data we need. But first, let’s automate this extraction process with a
function, since every tables on this website respect the same format:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
<span class="hljs-keyword">import</span> requests

<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_table_raws</span>(<span class="hljs-params">url, cols</span>):
    r = requests.get(url)
    soup = BeautifulSoup(r.text, <span class="hljs-string">&#x27;html.parser&#x27;</span>)
    table = soup.find(<span class="hljs-string">&quot;div&quot;</span>, {
        <span class="hljs-string">&quot;class&quot;</span>: <span class="hljs-string">&quot;table-responsive&quot;</span>
    })

    raw_lines = [
        line.contents
        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> table.find_all(<span class="hljs-string">&quot;tr&quot;</span>)
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(line) == cols
    ]

    <span class="hljs-keyword">return</span> [[c.text <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> line] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> raw_lines]
</code></pre>
<p>Since we’ll have to deal with dates and timings, we could use this
little helpers to do the conversions:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">extract_year_from_competition</span>(<span class="hljs-params">competition</span>):
    <span class="hljs-comment"># Format is [name] [year]</span>
    <span class="hljs-keyword">return</span> <span class="hljs-built_in">int</span>(competition.strip().rsplit(<span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-number">1</span>)[-<span class="hljs-number">1</span>])

<span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_timing_to_seconds</span>(<span class="hljs-params">timing</span>):
    <span class="hljs-keyword">try</span>:
        <span class="hljs-comment"># Try to convert directly in seconds</span>
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(timing)
    <span class="hljs-keyword">except</span> ValueError:
        <span class="hljs-keyword">try</span>:
            <span class="hljs-comment"># Format should be [minutes]:[seconds].[tenth]</span>
            minutes, rest = timing.split(<span class="hljs-string">&quot;:&quot;</span>, <span class="hljs-number">1</span>)
            seconds, tenth = rest.split(<span class="hljs-string">&quot;.&quot;</span>, <span class="hljs-number">1</span>)
            <span class="hljs-keyword">return</span> (
                <span class="hljs-built_in">float</span>(minutes) * <span class="hljs-number">60</span> +
                <span class="hljs-built_in">float</span>(seconds) +
                <span class="hljs-built_in">float</span>(tenth) / <span class="hljs-number">100</span>
            )
        <span class="hljs-keyword">except</span> ValueError:
            <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>
</code></pre>
<p>Let’s use our helpers to extract all the data:</p>
<pre class="code" data-lang="python"><code>url = <span class="hljs-string">&quot;https://www.worldcubeassociation.org/results/events.php?eventId=333&amp;regionId=&amp;years=&amp;show=All%2BPersons&amp;single=Single&quot;</span>
clean_table = []
<span class="hljs-keyword">for</span> rank, (_, person, timing, country, competition, _) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(get_table_raws(url, <span class="hljs-number">6</span>)):
    year = extract_year_from_competition(competition)
    timing = convert_timing_to_seconds(timing)
    clean_table.append((rank + <span class="hljs-number">1</span>, person, timing, country, competition, year))

clean_table[:<span class="hljs-number">5</span>]
</code></pre>
<blockquote>
<pre class="code" data-lang="python"><code>[(<span class="hljs-number">1</span>, <span class="hljs-string">u&#x27;Lucas Etter&#x27;</span>, <span class="hljs-number">4.9</span>, <span class="hljs-string">u&#x27;USA&#x27;</span>, <span class="hljs-string">u&#x27;River Hill Fall 2015&#x27;</span>, <span class="hljs-number">2015</span>),
 (<span class="hljs-number">2</span>, <span class="hljs-string">u&#x27;Keaton Ellis&#x27;</span>, <span class="hljs-number">5.09</span>, <span class="hljs-string">u&#x27;USA&#x27;</span>, <span class="hljs-string">u&#x27;River Hill Fall 2015&#x27;</span>, <span class="hljs-number">2015</span>),
 (<span class="hljs-number">3</span>, <span class="hljs-string">u&#x27;Collin Burns&#x27;</span>, <span class="hljs-number">5.25</span>, <span class="hljs-string">u&#x27;USA&#x27;</span>, <span class="hljs-string">u&#x27;Doylestown Spring 2015&#x27;</span>, <span class="hljs-number">2015</span>),
 (<span class="hljs-number">4</span>, <span class="hljs-string">u&#x27;Feliks Zemdegs&#x27;</span>, <span class="hljs-number">5.39</span>, <span class="hljs-string">u&#x27;Australia&#x27;</span>, <span class="hljs-string">u&#x27;World Championship 2015&#x27;</span>, <span class="hljs-number">2015</span>),
 (<span class="hljs-number">5</span>, <span class="hljs-string">u&#x27;Mats Valk&#x27;</span>, <span class="hljs-number">5.55</span>, <span class="hljs-string">u&#x27;Netherlands&#x27;</span>, <span class="hljs-string">u&#x27;Zonhoven Open 2013&#x27;</span>, <span class="hljs-number">2013</span>)]
</code></pre>
</blockquote>
<pre class="code" data-lang="python"><code><span class="hljs-built_in">len</span>(clean_table)
</code></pre>
<blockquote>
<pre class="code" data-lang="python"><code><span class="hljs-number">47465</span>
</code></pre>
</blockquote>
<p>Let’s see if we can gain some insight from this dataset using Pandas:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

df = pd.DataFrame(
    data=clean_table,
    columns=(
        <span class="hljs-string">&#x27;Rank&#x27;</span>,
        <span class="hljs-string">&#x27;Person&#x27;</span>,
        <span class="hljs-string">&#x27;Timing&#x27;</span>,
        <span class="hljs-string">&#x27;Country&#x27;</span>,
        <span class="hljs-string">&#x27;Competition&#x27;</span>,
        <span class="hljs-string">&#x27;Year&#x27;</span>
    ))

df.head()
</code></pre>
<blockquote>
<table>
<thead>
<tr>
<th>Rank</th>
<th>Person</th>
<th>Timing</th>
<th>Country</th>
<th>Competition</th>
<th>Year</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Lucas Etter</td>
<td>4.9</td>
<td>USA</td>
<td>River Hill Fall 2015</td>
<td>2015</td>
</tr>
<tr>
<td>2</td>
<td>Keaton Ellis</td>
<td>5.09</td>
<td>USA</td>
<td>River Hill Fall 2015</td>
<td>2015</td>
</tr>
<tr>
<td>3</td>
<td>Collin Burns</td>
<td>5.25</td>
<td>USA</td>
<td>Doylestown Spring 2015</td>
<td>2015</td>
</tr>
<tr>
<td>4</td>
<td>Feliks Zemdegs</td>
<td>5.39</td>
<td>Australia</td>
<td>World Championship 2015</td>
<td>2015</td>
</tr>
<tr>
<td>5</td>
<td>Mats Valk</td>
<td>5.55</td>
<td>Netherlands</td>
<td>Zonhoven Open 2013</td>
<td>2013</td>
</tr>
</tbody>
</table>
</blockquote>
<p>We see that the first entry is the <em>World record</em> by <a href="https://www.youtube.com/watch?v=vh0W8E4cNkQ" target="_blank" rel="noopener noreferrer">Lucas
Etter</a>. If you didn’t see,
watch it now, it’s very impressive.</p>
<pre class="code" data-lang="python"><code>df[<span class="hljs-string">&quot;Timing&quot;</span>].describe()
</code></pre>
<blockquote>
<p>|
— | —
count | <code>47465.000000</code>
mean  | <code>35.078421</code>
std   | <code>27.492358</code>
min   | <code>4.900000</code>
25%   | <code>17.350000</code>
50%   | <code>26.720000</code>
75%   | <code>43.830000</code>
max   | <code>648.000000</code></p>
</blockquote>
<blockquote>
<p>Name: Timing, dtype: float64</p>
</blockquote>
<p>We have 47465 entries. The average time of resolution in these
competitions is 35 seconds, which is actually pretty fast. The maximum,
of 648 seconds (10 minutes) seems more reasonable to me…</p>
<pre class="code" data-lang="python"><code>%matplotlib inline
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
plt.style.use(<span class="hljs-string">&#x27;ggplot&#x27;</span>)
</code></pre>
<p>We can count the number of players for each country:</p>
<pre class="code" data-lang="python"><code>country_count = df[[<span class="hljs-string">&quot;Country&quot;</span>]].apply(pd.value_counts)
country_count[:<span class="hljs-number">20</span>]
</code></pre>
<blockquote>
<table>
<thead>
<tr>
<th>Country</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>USA</td>
<td>8918</td>
</tr>
<tr>
<td>China</td>
<td>6286</td>
</tr>
<tr>
<td>India</td>
<td>4659</td>
</tr>
<tr>
<td>Brazil</td>
<td>2039</td>
</tr>
<tr>
<td>Poland</td>
<td>1739</td>
</tr>
<tr>
<td>Canada</td>
<td>1526</td>
</tr>
<tr>
<td>Germany</td>
<td>1092</td>
</tr>
<tr>
<td>Indonesia</td>
<td>1090</td>
</tr>
<tr>
<td>France</td>
<td>1065</td>
</tr>
<tr>
<td>Japan</td>
<td>999</td>
</tr>
<tr>
<td>Philippines</td>
<td>993</td>
</tr>
<tr>
<td>Spain</td>
<td>977</td>
</tr>
<tr>
<td>Mexico</td>
<td>932</td>
</tr>
<tr>
<td>Korea</td>
<td>869</td>
</tr>
<tr>
<td>Ukraine</td>
<td>848</td>
</tr>
<tr>
<td>Taiwan</td>
<td>828</td>
</tr>
<tr>
<td>Russia</td>
<td>817</td>
</tr>
<tr>
<td>Australia</td>
<td>766</td>
</tr>
<tr>
<td>Peru</td>
<td>671</td>
</tr>
<tr>
<td>Colombia</td>
<td>627</td>
</tr>
</tbody>
</table>
</blockquote>
<p>No surprise, bigger countries are more represented in Rubik’s Cube
competitions. It would be interesting to compare these numbers with the
actual population, to see if Rubik’s Cube is more <em>“popular”</em> in some
countries.</p>
<p>Let’s visualize the countries with more than 200 players using a barplot:</p>
<pre class="code" data-lang="python"><code>country_count[country_count &gt; <span class="hljs-number">200</span>].dropna().plot(kind=<span class="hljs-string">&quot;bar&quot;</span>)
</code></pre>
<figure><a href="../images/output_27_1.png" target="_blank" rel="noopener noreferrer"><img src="../images/output_27_1.png" alt=""></a><figcaption>Players per country</figcaption></figure>
<p>We can do the same for players:</p>
<pre class="code" data-lang="python"><code>df[[<span class="hljs-string">&quot;Person&quot;</span>]]
    .apply(pd.value_counts)
    .apply(pd.value_counts)
</code></pre>
<blockquote>
<table>
<thead>
<tr>
<th>Number of participations</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>46709</td>
</tr>
<tr>
<td>2</td>
<td>305</td>
</tr>
<tr>
<td>3</td>
<td>26</td>
</tr>
<tr>
<td>4</td>
<td>13</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
</tr>
<tr>
<td>6</td>
<td>1</td>
</tr>
</tbody>
</table>
</blockquote>
<p>It appears that the vast majority of player only <em>participated one
time</em>. And only about 0.007% participated more than once. Can we
conclude that players are more hobbyist than professional? Another
information that could be interesting is the age of the participants,
since the World Champion is very young, it would be fun to have more
insight about the average or mean age of Rubik’s Cube champions.</p>
<h1>Records</h1>
<p>Let’s now get to the world records, and try to see how they evolve over
the years. The code is pretty similar to the previous section, so we’ll
just use our generic function for table extraction:</p>
<pre class="code" data-lang="python"><code>url = <span class="hljs-string">&quot;https://www.worldcubeassociation.org/results/regions.php?regionId=&amp;eventId=333&amp;years=&amp;history=History&quot;</span>
clean_table = []
<span class="hljs-keyword">for</span> (_, single, avg, person, country, competition, _) <span class="hljs-keyword">in</span> get_table_raws(url, <span class="hljs-number">7</span>):
    single = convert_timing_to_seconds(single.strip())
    avg = convert_timing_to_seconds(avg.strip())
    year = <span class="hljs-built_in">float</span>(extract_year_from_competition(competition))
    clean_table.append((person, single, avg, country, competition, year))

clean_table[:<span class="hljs-number">5</span>]
</code></pre>
<pre class="code" data-lang="python"><code>[
  (<span class="hljs-string">u&#x27;Lucas Etter&#x27;</span>, <span class="hljs-number">4.9</span>, <span class="hljs-literal">None</span>, <span class="hljs-string">u&#x27;USA&#x27;</span>, <span class="hljs-string">u&#x27;River Hill Fall 2015&#x27;</span>, <span class="hljs-number">2015.0</span>),
  (<span class="hljs-string">u&#x27;Collin Burns&#x27;</span>, <span class="hljs-number">5.25</span>, <span class="hljs-literal">None</span>, <span class="hljs-string">u&#x27;USA&#x27;</span>, <span class="hljs-string">u&#x27;Doylestown Spring 2015&#x27;</span>, <span class="hljs-number">2015.0</span>),
  (<span class="hljs-string">u&#x27;Mats Valk&#x27;</span>, <span class="hljs-number">5.55</span>, <span class="hljs-literal">None</span>, <span class="hljs-string">u&#x27;Netherlands&#x27;</span>, <span class="hljs-string">u&#x27;Zonhoven Open 2013&#x27;</span>, <span class="hljs-number">2013.0</span>),
  (<span class="hljs-string">u&#x27;Feliks Zemdegs&#x27;</span>, <span class="hljs-number">5.66</span>, <span class="hljs-literal">None</span>, <span class="hljs-string">u&#x27;Australia&#x27;</span>, <span class="hljs-string">u&#x27;Melbourne Winter Open 2011&#x27;</span>,
  <span class="hljs-number">2011.0</span>),
  (<span class="hljs-string">u&#x27;Feliks Zemdegs&#x27;</span>,
   <span class="hljs-number">6.18</span>,
   <span class="hljs-literal">None</span>,
   <span class="hljs-string">u&#x27;Australia&#x27;</span>,
   <span class="hljs-string">u&#x27;Melbourne Winter Open 2011&#x27;</span>,
   <span class="hljs-number">2011.0</span>)
]
</code></pre>
<pre class="code" data-lang="python"><code>df = pd.DataFrame(
    data=clean_table,
    columns=(<span class="hljs-string">&#x27;Person&#x27;</span>, <span class="hljs-string">&#x27;Single&#x27;</span>, <span class="hljs-string">&#x27;Avg&#x27;</span>, <span class="hljs-string">&#x27;Country&#x27;</span>, <span class="hljs-string">&#x27;Competition&#x27;</span>, <span class="hljs-string">&#x27;Year&#x27;</span>))

df.head()
</code></pre>
<blockquote>
<p>Person | Single | Avg | Country | Competition | Year
—    | —    | — | —     | —         |
0 | Lucas Etter | 4.90 | <code>NaN</code> | USA | River Hill Fall 2015 | 2015
1 | Collin Burns | 5.25 | <code>NaN</code> | USA | Doylestown Spring 2015 | 2015
2 | Mats Valk | 5.55 | <code>NaN</code> | Netherlands | Zonhoven Open 2013 | 2013
3 | Feliks Zemdegs | 5.66 | <code>NaN</code> | Australia | Melbourne Winter Open 2011 | 2011
4 | Feliks Zemdegs | 6.18 | <code>NaN</code> | Australia | Melbourne Winter Open 2011 | 2011</p>
</blockquote>
<pre class="code" data-lang="python"><code>df = df.sort([<span class="hljs-string">&quot;Year&quot;</span>, <span class="hljs-string">&quot;Single&quot;</span>], ascending=[<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>])
df[df[<span class="hljs-string">&quot;Single&quot;</span>].notnull()].plot(x=<span class="hljs-string">&quot;Year&quot;</span>, y=<span class="hljs-string">&quot;Single&quot;</span>, legend=<span class="hljs-string">&quot;Test&quot;</span>)
plt.title(<span class="hljs-string">&quot;World records of Rubik&#x27;s Cube&quot;</span>)
</code></pre>
<figure><a href="../images/output_36_1.png" target="_blank" rel="noopener noreferrer"><img src="../images/output_36_1.png" alt=""></a><figcaption>World records of Rubik’s Cube</figcaption></figure>
<h1>Last words</h1>
<p>It would seem reasonable to conclude that <em>we are now on a plateau</em>. One think that could bring even more insight would be to compare this evolution to, say, evolution among sprinters’ world records over time, etc. I guess we’re hitting the same kind of limitation.</p>
<p>A major difference is that in Rubik’s Cube, you’re limited both by your fingers’ dexterity, and the speed at which your brain can process information, whereas in athletics, it’s more about physical performance. <em>I would be curious to see which one is more limiting: brain, or body</em>.</p>
<p>Another open question for me is: <em>how much does the final score depends on the initial configuration of the Rubik’s Cube?</em> I know that they are able to look at it before the beginning, so maybe this is negligible, maybe not.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Learning a new language]]></title>
            <link>https://remusao.github.io//posts/learning-a-new-language.html</link>
            <guid>https://remusao.github.io//posts/learning-a-new-language.html</guid>
            <pubDate>Mon, 25 Jan 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<figure>
<a href="../images/learning.png">
<img src="../images/learning.png" alt="learning" style="width:80.0%">
</a>
</figure>
<p><strong>Facts</strong>:</p>
<ol>
<li>I’m leaving for Germany in 2 months, for an undetermined duration.</li>
<li>I don’t speak German.</li>
<li>I decided to learn it.</li>
</ol>
<p>In this post, I intend to give a short description of the <em>tools and methodology I use to learn German</em>.
Keep in mind that this is neither a “definitive guide”, nor a “how to”, only some notes on what I found on my journey to learning a new language (which just began).
I would be glad to get some tricks, advices and such from the comments as well.</p>
<p>Here is an overview of what we will talk about in this post:</p>
<ul>
<li><strong>Duolingo</strong></li>
<li><strong>Memrise</strong></li>
<li><strong>Readlang</strong></li>
<li><strong>Anki</strong></li>
<li>Good will and method</li>
</ul>
<h1>What it takes to learn a new language</h1>
<p><em>One</em> of the main difficulties in learning a language is <strong>memorizing stuff</strong>.
This is what I’ll focus on in this post (and this is by no mean the only difficulty!).
You have to learn new things: news <em>words</em>, new <em>rules</em>, new <em>pronunciations</em>, <em>new everything</em>.
And it can be hard to make it stick in your head for good, especially if it’s very different from what you already know.</p>
<p>It has been shown that it’s not efficient to just learn something in one shot, by simply reading it.
<em>Your memories are highly organized, structured, connected</em>. So it’s much more efficient to:</p>
<ul>
<li><strong>Create context</strong> around something you want to remember (sounds, images, videos, mnemonics)</li>
<li><strong>Structure your learning</strong> (connect to existing knowledge, learn similar things in batch)</li>
<li><strong>Review your new knowledge</strong> at the right time, with <a href="https://en.wikipedia.org/wiki/Spaced_learning" target="_blank" rel="noopener noreferrer">increasing spacing</a>.</li>
</ul>
<p>As it happens, there are lot of applications that can help you organize and optimize your learning.
Some are generic in the kind of knowledge you can learn, others focus on languages.
I’m mainly using the following four tools at the moment: <a href="http://ankisrs.net/" target="_blank" rel="noopener noreferrer">Anki</a>, <a href="https://www.memrise.com/" target="_blank" rel="noopener noreferrer">Memrise</a>, <a href="https://www.duolingo.com/" target="_blank" rel="noopener noreferrer">Duolingo</a>, <a href="https://readlang.com" target="_blank" rel="noopener noreferrer">ReadLang</a> (with no particular order of importance).
In fact, I’m trying to combine multiple ways of learning, so that I can see the same stuff <em>several times</em>, with <em>different point of views</em>, <em>different materials</em> (images, sounds, etc.).
Right now, I’m only exploring the potential ways of using the tools, and I expect the way I use them will evolve over time.</p>
<h1>The Apps</h1>
<h2>Anki</h2>
<figure><a href="../images/anki.jpg" target="_blank" rel="noopener noreferrer"><img src="../images/anki.jpg" alt=""></a><figcaption>anki</figcaption></figure>
<p><a href="https://en.wikipedia.org/wiki/Anki_%28software%29" target="_blank" rel="noopener noreferrer">Anki</a> is an application that helps you create cards, and then make you review them at the right time.
This is based on a <a href="https://en.wikipedia.org/wiki/Spaced_repetition" target="_blank" rel="noopener noreferrer">spaced repetition method</a>, that helps you review stuff just when you’re about to forget it!
You can attach text, images, sound and videos to a card, so that you have context associated with each new knowledge (this helps to remember, a lot…).
I use it to create my own card to remember the new vocabulary I encounter, that I can then review later.</p>
<p>I also like that it provides a web interface, an Android App and a Desktop client (for GNU/Linux).
If you create an account, it’s possible to synchronize your cards between devices and download decks from other people, although it’s recommanded to create your own cards.</p>
<h4>Pros</h4>
<ul>
<li>Does one thing, well.</li>
<li>Multi-plateform (Webapp, mobile, desktop), Anki got you covered.</li>
<li><em>Create your own cards</em>.</li>
<li>Attach any content you’d like to cards.</li>
<li>Sync across devices.</li>
<li>Extensive <a href="http://ankisrs.net/docs/manual.html" target="_blank" rel="noopener noreferrer">documentation</a>.</li>
<li><em>Open-source</em>.</li>
<li>Nothing fancy, only what is needed.</li>
</ul>
<h4>Cons</h4>
<ul>
<li>Reviews feel a bit “simplistic” compared to other tools (Memrise, Duolingo).</li>
</ul>
<h2>Memrise</h2>
<figure><a href="../images/memrise.png" target="_blank" rel="noopener noreferrer"><img src="../images/memrise.png" alt=""></a><figcaption>memrise</figcaption></figure>
<p><a href="https://www.memrise.com/" target="_blank" rel="noopener noreferrer">Memrise</a> is a collaborative platform that provides the tools to make you learn almost any kind of content — although it’s used a lot for languages.
People can follow “classes” on the topics they like. It’s a bit like Anki, but more social, you don’t have to create your own card (I know you can download decks for Anki too),
instead, you get to select topics that you want to learn, and start straight away to learn new “words”. You can follow friends, compare your progress, gain “experience”, etc.
The development is pretty active too, so expect to see lot of new features.</p>
<p>To better understand how it works, <a href="http://www.memrise.com/science/" target="_blank" rel="noopener noreferrer">they highlight</a> that Memrise is built on three main “scientific” principles:</p>
<ol>
<li><em>Elaborate encoding</em>: Memrise helps you vividly assimilate new knowledge, promoting deep encoding and superior memory.</li>
<li><em>Choreographed testing</em>: Testing strengthens memories in variety of ways.</li>
<li><em>Scheduled reminders</em>: By spacing reminders, learning can be made up to x3 more efficient.</li>
</ol>
<p>The third “fact” is one of the selling points of the app (according to me). <strong>I like that</strong> they offer a great variety of ways to review stuff:</p>
<ul>
<li><em>[listening]</em> Write German from a German audio record</li>
<li><em>[listening]</em> Select German audio record from an English Sentence</li>
<li><em>[writing]</em> Write English translation from German sentence</li>
<li><em>[writing]</em> Write German from an English sentence</li>
<li><em>[selection]</em> Select English translation from a selection of words</li>
<li><em>[selection]</em> Select English translation from a selection of translations</li>
</ul>
<h4>Pros</h4>
<ul>
<li>Makes you practice <em>listening</em> skill (from and to German) and <em>writing</em> skills in multiple ways (English to German, German to English).</li>
<li>Tests diversity allows the reviews to <em>stay interesting and stimulating</em>.</li>
<li>Remainders to make you <em>review</em> and <em>learn</em> new words.</li>
<li>Allows you to <em>download</em> all the assets of the classes, so that you can practice <em>fully off-line</em>.</li>
</ul>
<h4>Cons</h4>
<ul>
<li><em>Misses the ability to make you speak</em> in German, and this is something Duolingo does.</li>
<li>The classes are more <em>“basic”</em> and a bit less organized than in duolingo.</li>
</ul>
<h2>Duolingo</h2>
<figure><a href="../images/duolingo.png" target="_blank" rel="noopener noreferrer"><img src="../images/duolingo.png" alt=""></a><figcaption>duolingo</figcaption></figure>
<p><a href="https://www.duolingo.com" target="_blank" rel="noopener noreferrer">Duolingo</a> is an application that helps you learn various languages.
It’s a bit more structured than Memrise (as it’s specifically designed to teach languages), and group knowledge by “lessons” that form a kind of <em>“learning unit”</em>.
Behind the scene, it uses more or less the same tools (or at least ideas) to help you remember your lessons:
<em>“Duolingo’s algorithms figure out when you should practice words to get them into your long-term memory.”</em>.
What I find interesting is that, once you master some subject for the first time, you get rewarded by a “strong” power-bar that means it’s still “fresh” in your memory.
Then, as time goes, Duolingo acknowledges that the memory of this particular lesson will fade, and make you review it, just in time to make the memory stronger.</p>
<p>Furthermore, once you get a good mastery of a language, you can access the <a href="https://www.duolingo.com/translations" target="_blank" rel="noopener noreferrer">Immersion</a> section of the application,
that allows you to practice your skills on translation of real content.
And I think this is part of their business model (Duolingo is free and doesn’t make use of ads, it’s a rare thing…).</p>
<h4>Pros</h4>
<ul>
<li>Makes you learn by <em>batch of coherent topics</em>.</li>
<li><em>Difficulty gradually increases</em>.</li>
<li>Experience and progress is pretty smooth.</li>
<li>Great Webapp and mobile app.</li>
<li>Keep track of your progress.</li>
<li><em>Well-structured lessons</em>.</li>
</ul>
<h4>Cons</h4>
<ul>
<li>Exercices could be even more diverse.</li>
<li>Difficult to use with a bad connection.</li>
<li>Any way to download content for off*line usage?</li>
</ul>
<h2>ReadLang</h2>
<p><strong>Edit</strong>: As mentionned in the comments by Steve Ridout (creator of Readlang), I made a few mistakes in my description of ReadLang:</p>
<ol>
<li>Firefox is supported using the <a href="http://readlang.com/webReader" target="_blank" rel="noopener noreferrer">Bookmarks</a>.</li>
<li>There is some support for mobile devices using <a href="https://readlang.uservoice.com/knowledgebase/articles/342854-is-there-a-readlang-android-app" target="_blank" rel="noopener noreferrer">Chrome on android</a> and <a href="https://readlang.uservoice.com/knowledgebase/articles/342855-is-there-a-readlang-ios-ipad-or-iphone-app" target="_blank" rel="noopener noreferrer">Safari on iOS</a>.</li>
<li>You can export your flashcards from the web interface and import it in Anki right away, which is very nice.</li>
</ol>
<figure><a href="../images/readlang.png" target="_blank" rel="noopener noreferrer"><img src="../images/readlang.png" alt=""></a><figcaption>readlang</figcaption></figure>
<p><a href="https://readlang.com/" target="_blank" rel="noopener noreferrer">ReadLang</a> is a bit different from the other tools… at first. It doesn’t seem like it will help you remember stuff, instead,
it’s a wonderful webapp that can assist you in the wild, while you’re reading content on the Internet (blog-posts, news, etc.).
You can see him as your reading companion, always there to offer you a hand while stuck at understanding content in your target language.
It’s a <em>WebReader</em>, that allows you to <em>click on words</em>, or <em>highlight sentences</em> as you read, to translate and speak the text.
It works really well, and is so discrete that you would forget it’s there, if it was not for the little green icon at the top of your screen.</p>
<p>To be totally honest, when I told you ReadLang wasn’t meant to make you remember stuff… <em>I lied!</em>
Because it automatically creates flashcards of words and sentences you translate, so that you can review them later. Like Memrise or Duolingo, it will help you review the right cards at the right time.
It also automatically extract information from online dictionaries to fill the cards, but you can edit them anyway to add even more context.
So it’s pretty full of useful features. But I only started to use it a few days ago, and I’m sure I’ll get to know the tool better in the next weeks/month.</p>
<p>There is a Free version, limited in terms of number of translations per day, but you can get away with 5 dollars per month to unleash its full power.
It’s the only tool I give money for, but it’s worth it. I would also like to mention that this is the work of only one man, Steve Ridout, so <em>kudos</em> to him, because Readlang can compete with applications developed by much larger teams.</p>
<p>The only (small) drawback is that, it’s a little bit less intuitive to use on mobile devices, since there is no native application, but it’s totally doable thanks to the Chrome extension and Bookmarks for Firefox and Safari.</p>
<p>So at the end, I really like Readlang, which offers a unique set of features. It could replace Anki for a day-to-day use, and if you ever need to review your cards offline, you can export your cards and import them in Anki seamlessly.</p>
<h4>Pros</h4>
<ul>
<li>Unique set of features, and <em>all batteries included</em>.</li>
<li><em>Translation</em> and <em>speaking</em> of sentences as you read.</li>
<li>Multiple languages supported.</li>
<li>You can use any online dictionary.</li>
<li><em>Automatic flashcard creation</em>.</li>
<li>Flashcard export to Anki.</li>
<li>Well designed.</li>
</ul>
<h4>Cons</h4>
<ul>
<li>Limited support for mobile (no native application).</li>
<li><s>No support for Firefox</s></li>
</ul>
<p>All this tools help you to review your knowledge in some spaced repetition way.
Memrise and Duolingo are somehow <em>in the same niche</em>, and ReadLang seems to be pretty much as feature-full as Anki.
But I found their approach to be slightly different, and each tool brings its own benefits so I like to use both at the same time… for now.
In the long run, I suspect I would only need either Anki or ReadLang (or both if I can synchronize my cards between ReadLand and Anki), and maybe one of Duolingo or Memrise.</p>
<h2>Adding context</h2>
<p>Context is important because it helps you make links with things you already know, hence, ease the memorization.
There are multiple ways of creating contexts, and the best is to combine them.
The more context you have, the better. Here is what I usually do when I encounter a new word, or sentence:</p>
<ul>
<li>Find an <em>image associated with the word</em> in some way.</li>
<li><em>Speak the words</em>, phrases (en register that in Anki)</li>
<li>Instead of just associating a word in English to a German word, <em>use a canned sentence</em>.</li>
<li>Do I know a word that looks or sound like the new word I’m trying to learn? Maybe, so this is good to write it down on the card too, as a <em>mnemonic</em>.</li>
</ul>
<p>The very fact of looking for context to add to your cards… creates context by itself.
<em>Spending time polishing your cards is good</em>, and will help you remember them.
You can even improve them over time, adding more context, finding new canned sentences, etc.
It takes time, but it’s worth it. You can even create several cards for the same knowledge, but with different contexts.</p>
<p>For example, if I were to remember the word <em>“Todesstern”</em> which means <em>“Death Star”</em>. I can create the following card:</p>
<h3>Front</h3>
<figure><a href="../images/deathstar.jpg" target="_blank" rel="noopener noreferrer"><img src="../images/deathstar.jpg" alt=""></a><figcaption>deathstar</figcaption></figure>
<p><em>“Wie wir sehen, umkreist der &lt;?&gt; den Waldmond Endor.”</em></p>
<h3>Back</h3>
<ul>
<li><em>Speak the word death star in German</em></li>
<li>German Word:“Todesstern”</li>
<li>English Word: “Death Star”</li>
<li>Mnemonic: stern = star and in “todes” we have “des” that we can read as “death”.</li>
</ul>
<h1>What I learned so far</h1>
<p>I’m doing my first steps in German, and I realize that the ecosystem of applications that can help you learn (and in particular, learn a new language), is rich.
There are so much tools that it’s hard to know which one(s) to use.
Moreover, you often find the same features in different tools. But I think it’s already a big win to use at least one tool, even if you chose it randomly,
because almost every apps selling improved memorization use the same kind of methods (spaced increasing reviews), which is <em>much more efficient</em> than a naive learning.
I hope that as I progress, I can take advantage of this tools to learn faster, better and more durably.</p>
<p>Furthermore, I think we shouldn’t take the quest of the best tools as the goal, it’s just a way to ease the learning.
Also, you should prefer being in direct contact with people speaking your target language if you can, and try to learn by speaking, which is invaluable.</p>
<p>To put it in a nutshell:</p>
<ol>
<li>Duolingo and Memrise can help you learn the basics of the language step-by-step, starting with most common words and increasing difficulty smoothly toward more advanced topics.</li>
<li>ReadLang is a companion of choice during your day-to-day reading, it’s non-obstrusive and can greatly help you improve your undestanding of the language, automatically creating flashcard for you to review later.</li>
<li>Anki is a solid choice for card edition and review, but I feel it’s not at all vital if you already use Readlang. It can nonetheless be used in complement when you need to review knowledge without an internet connection or to keep track of new words if you don’t have access to ReadLang for some reason.</li>
</ol>
<h3>References</h3>
<p>For further reading, here are some references.</p>
<h4>From Memrise science page</h4>
<p>V. A. Benassi, C. E. Overson &amp; C. M. Hakala (Eds.) (2014). <em>Applying the science of learning in education: Infusing psychological science into the curriculum</em>. Society for the Teaching of Psychology web site: <a href="http://teachpsych.org/ebooks/asle2014/index.php" target="_blank" rel="noopener noreferrer">http://teachpsych.org/ebooks/asle2014/index.php</a>.</p>
<p>Bjork, R. A., Dunlosky, J. &amp; Kornell, N. (2013). <em>Self-regulated learning: Beliefs, techniques, and illusions</em>. Annual Review of Psychology, 64, 417-444. <a href="http://bjorklab.psych.ucla.edu/pubs/RBjork_Dunlosky_Kornell_2013.pdf" target="_blank" rel="noopener noreferrer">http://bjorklab.psych.ucla.edu/pubs/RBjork_Dunlosky_Kornell_2013.pdf</a>.</p>
<p>Brown, P. C., Roediger, H. L., &amp; McDaniel, M. A. (2014). <em>Make it stick: The science of successful learning</em>. Cambridge, MA: Harvard University Press.</p>
<p>Pashler, H., Bain, P. M., Bottge, B. A., Graesser, A., McDaniel, M. A., &amp; Metcalfe, J. (2007). <em>Organizing instruction and study to improve student learning</em> (NCER Publication No. 2007–2004). Washington, DC: National Center for Education Research, Institute of Education Sciences, U.S. Department of Education. <a href="http://ies.ed.gov/ncee/wwc/pdf/practice_guides/20072004.pdf" target="_blank" rel="noopener noreferrer">http://ies.ed.gov/ncee/wwc/pdf/practice_guides/20072004.pdf</a>.</p>
<p>Potts, R. &amp; Shanks, D. R. (2014). <em>The benefit of generating errors during learning</em>. Journal of Experimental Psychology: General, 143, 644-667. <a href="http://discovery.ucl.ac.uk/1399515/1/RPottsLastRevision.pdf" target="_blank" rel="noopener noreferrer">http://discovery.ucl.ac.uk/1399515/1/RPottsLastRevision.pdf</a></p>
<p>Roediger, H. L., Putnam, A. L., &amp; Smith, M. A. (2011). Ten benefits of testing and their applications to educational practice. In J. Mestre &amp; B. Ross (Eds.), Psychology of learning and motivation: Cognition in education (pp. 1-36). <a href="http://psych.wustl.edu/memory/Roddy%20article%20PDF's/BC_Roediger%20et%20al%20(2011)_PLM.pdf" target="_blank" rel="noopener noreferrer">http://psych.wustl.edu/memory/Roddy%20article%20PDF’s/BC_Roediger%20et%20al%20(2011)_PLM.pdf</a></p>
<h4>Misc posts</h4>
<ul>
<li><a href="http://www.wired.com/2008/04/ff-wozniak/" target="_blank" rel="noopener noreferrer">Want to Remember Everything You’ll Ever Learn? Surrender to this Algorithm</a></li>
<li><a href="https://medium.com/life-learning/how-to-learn-5c6c815051#.7hiowltv7" target="_blank" rel="noopener noreferrer">How to Learn</a></li>
<li><a href="http://www.memrise.com/science" target="_blank" rel="noopener noreferrer">Memrise Science</a></li>
<li><a href="http://fourhourworkweek.com/2014/03/21/how-to-learn-a-foreign-language-2/" target="_blank" rel="noopener noreferrer">12 Rules for Learning Foreign Languages in Record Time</a></li>
</ul>
<p>And much, much more…</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A tour of IHaskell extensions]]></title>
            <link>https://remusao.github.io//posts/ihashell-extensions-tour.html</link>
            <guid>https://remusao.github.io//posts/ihashell-extensions-tour.html</guid>
            <pubDate>Mon, 11 Jan 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<h2>Introduction</h2>
<p>In my previous <a href="https://remusao.github.io/install-ihaskell-on-ubuntu-1404-with-stack.html" target="_blank" rel="noopener noreferrer">post</a>,
I tried to provide a step-by-step explanation of how to install
<a href="https://github.com/gibiansky/IHaskell" target="_blank" rel="noopener noreferrer">IHaskell</a> on Ubuntu 14.04 (Should also
work on other versions). Now is time to start using it!</p>
<p>This post is not a quickstart on how to use IHaskell, as it has already been
covered in the <a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/IHaskell.ipynb" target="_blank" rel="noopener noreferrer">official documentation</a>.
And there are more advanced examples here:</p>
<ul>
<li><a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Conjugate%20Gradient.ipynb" target="_blank" rel="noopener noreferrer">Conjugate Gradient</a></li>
<li><a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Gradient-Descent.ipynb" target="_blank" rel="noopener noreferrer">Gradient Descent</a></li>
<li><a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Homophones.ipynb" target="_blank" rel="noopener noreferrer">Homophones</a></li>
<li><a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Static%20Canvas%20IHaskell%20Display.ipynb" target="_blank" rel="noopener noreferrer">Static Canvas IHaskell Display</a></li>
</ul>
<p>Instead, I’ll focus more on something a bit more mysterious for me:
<em>displaying custom Haskell types in notebooks</em>. I’ll first try to give a
quick explanation on how it works, and then give basic examples of the
provided integrations with existing libraries (aeson, blaze, charts,
diagrams, etc.). I’ll also try to show how to support your custom types.</p>
<p><strong>Disclaimer</strong>: Some of the information found in the post may be
redundant with other sources (like official documentation, and in
particular the last post in the list above: <em>Static Canvas IHaskell
Display</em>), but I hope this post will bring value by giving an overview
of what is possible with <em>IHaskell</em>, explained with the words of a
newcomer. Comments and fixes would be greatly appreciated!</p>
<h2>How does it work?</h2>
<p>Jupyter allows you to embed arbitrary HTML, and this mechanism is used
by IHaskell to display values in custom ways. The <code>IHaskellDisplay</code>
typeclass is used to this effect. By providing an instance for
your own types, they can be displayed in notebooks (we’ll see
later that some extensions already exist to provide such display
to known Haskell libraries). A <code>Display</code> can be of several types,
but for now we will focus on <code>html</code> and <code>plain</code> (see <a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Static%20Canvas%20IHaskell%20Display.ipynb" target="_blank" rel="noopener noreferrer">this notebook</a> for more information).</p>
<p>Note that you can provide several choices of display outputs so that
your custom type can be display in notebooks <em>(html)</em> or console <em>(plain
text)</em>, the frontend will then select the best choice.</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-keyword">import</span> IHaskell.Display

<span class="hljs-comment">-- Custom data type</span>
<span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">Answer</span> = <span class="hljs-type">Answer</span></span>

<span class="hljs-comment">-- Make it &quot;displayable&quot;</span>
<span class="hljs-class"><span class="hljs-keyword">instance</span> <span class="hljs-type">IHaskellDisplay</span> <span class="hljs-type">Answer</span> <span class="hljs-keyword">where</span></span>
    <span class="hljs-comment">-- List of two kinds of Display: html and plain text</span>
    display value = return $ <span class="hljs-type">Display</span> [htmlDisplay, txtDisplay]
        <span class="hljs-keyword">where</span>
            <span class="hljs-comment">-- HTML Display</span>
            htmlDisplay = html <span class="hljs-string">&quot;&lt;div&gt;The answer is 42!&lt;/div&gt;&quot;</span>
            <span class="hljs-comment">-- Plain Text Display</span>
            txtDisplay = plain <span class="hljs-string">&quot;42&quot;</span>

<span class="hljs-comment">-- Display an instance of our type</span>
<span class="hljs-type">Answer</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="sh"><code>The answer is 42!
</code></pre>
</blockquote>
<p>In the following sections we’ll see how to use some of the extensions
officially provided by <em>IHaskell</em> to display types of known libraries.
The packages we’ll need are:</p>
<ul>
<li>ihaskell-basic</li>
<li>ihaskell-aeson</li>
<li>ihaskell-blaze</li>
<li>ihaskell-charts</li>
<li>ihaskell-diagrams</li>
<li>ihaskell-magic</li>
</ul>
<p>You can install them using stack if you intend to try this out yourself:</p>
<pre class="code" data-lang="sh"><code>stack build             \
    ihaskell-basic      \
    ihaskell-aeson      \
    ihaskell-blaze      \
    ihaskell-charts     \
    ihaskell-diagrams   \
    ihaskell-magic
</code></pre>
<h2>ihaskell-basic</h2>
<p>IHaskell <a href="https://hackage.haskell.org/package/ihaskell-basic" target="_blank" rel="noopener noreferrer">basic</a> contains
<em>“Instances of IHaskellDisplay for default prelude data types”</em>. Currently,
only <code>Maybe</code> seems to be supported. Maybe some more <em>Displays</em> will be provided
in the future?</p>
<p>Anyway, here is how you can use it, and what it looks like:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- import IHaskell.Display.Basic</span>
<span class="hljs-type">Just</span> <span class="hljs-number">42</span>
<span class="hljs-type">Just</span> (<span class="hljs-type">Just</span> <span class="hljs-string">&quot;Foo Bar Baz&quot;</span>)
<span class="hljs-type">Nothing</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> <span class="hljs-number">42</span>
<span class="hljs-type">Just</span> <span class="hljs-type">Just</span> <span class="hljs-string">&quot;Foo Bar Baz&quot;</span>
<span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<h2>ihaskell-aeson</h2>
<p><a href="https://hackage.haskell.org/package/aeson" target="_blank" rel="noopener noreferrer">Aeson</a> is a library used to
manipulate <em>JSON</em> format from Haskell. It allows you to use <code>ToJSON</code> and
<code>FromJSON</code> typeclasses to convert your custom data-types <em>to</em> and <em>from</em>
JSON format.</p>
<p>In our small example, we declare a type of document with an arbitrary
number of metadata attached, here is how we could do it:</p>
<pre class="code" data-lang="haskell"><code>:extension <span class="hljs-type">OverloadedStrings</span>

<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.Text <span class="hljs-keyword">as</span> T
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.Aeson <span class="hljs-keyword">as</span> A
<span class="hljs-comment">-- IHaskell.Display.Aeson</span>

<span class="hljs-class"><span class="hljs-keyword">newtype</span> <span class="hljs-type">Property</span> = <span class="hljs-type">Property</span> <span class="hljs-type">T</span>.<span class="hljs-type">Text</span></span>
<span class="hljs-class"><span class="hljs-keyword">newtype</span> <span class="hljs-type">Value</span> = <span class="hljs-type">Value</span> <span class="hljs-type">T</span>.<span class="hljs-type">Text</span></span>
<span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">Metadata</span> = <span class="hljs-type">Metadata</span> [(<span class="hljs-type">Property</span>, <span class="hljs-type">Value</span>)]</span>

<span class="hljs-class"><span class="hljs-keyword">newtype</span> <span class="hljs-type">Body</span> = <span class="hljs-type">Body</span> <span class="hljs-type">T</span>.<span class="hljs-type">Text</span></span>
<span class="hljs-class"><span class="hljs-keyword">newtype</span> <span class="hljs-type">Title</span> = <span class="hljs-type">Title</span> <span class="hljs-type">T</span>.<span class="hljs-type">Text</span></span>
<span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">Document</span>  = <span class="hljs-type">Document</span></span>
    { _title :: <span class="hljs-type">Title</span>
    , _body :: <span class="hljs-type">Body</span>
    , _metadata :: <span class="hljs-type">Metadata</span>}
<span class="hljs-class">
<span class="hljs-keyword">instance</span> <span class="hljs-type">A</span>.<span class="hljs-type">ToJSON</span> <span class="hljs-type">Metadata</span> <span class="hljs-keyword">where</span></span>
   toJSON (<span class="hljs-type">Metadata</span> d) = <span class="hljs-type">A</span>.object $ [p <span class="hljs-type">A</span>..= v | (<span class="hljs-type">Property</span> p, <span class="hljs-type">Value</span> v) &lt;- d]
<span class="hljs-class">
<span class="hljs-keyword">instance</span> <span class="hljs-type">A</span>.<span class="hljs-type">ToJSON</span> <span class="hljs-type">Document</span> <span class="hljs-keyword">where</span></span>
   toJSON (<span class="hljs-type">Document</span> (<span class="hljs-type">Title</span> t) (<span class="hljs-type">Body</span> b) m) = <span class="hljs-type">A</span>.object [
       <span class="hljs-string">&quot;title&quot;</span> <span class="hljs-type">A</span>..= t,
       <span class="hljs-string">&quot;body&quot;</span> <span class="hljs-type">A</span>..= b,
       <span class="hljs-string">&quot;metadata&quot;</span> <span class="hljs-type">A</span>..= <span class="hljs-type">A</span>.toJSON m]

<span class="hljs-title">document</span> = <span class="hljs-keyword">let</span> body = <span class="hljs-type">Body</span> <span class="hljs-string">&quot;Lorem Ipsum&quot;</span>
               title = <span class="hljs-type">Title</span> <span class="hljs-string">&quot;Foo Bar&quot;</span>
               metadata = <span class="hljs-type">Metadata</span> [
                   (<span class="hljs-type">Property</span> <span class="hljs-string">&quot;Encoding&quot;</span>, <span class="hljs-type">Value</span> <span class="hljs-string">&quot;UTF-8&quot;</span>),
                   (<span class="hljs-type">Property</span> <span class="hljs-string">&quot;Author&quot;</span>, <span class="hljs-type">Value</span> <span class="hljs-string">&quot;Jonh Doe&quot;</span>)]
           <span class="hljs-keyword">in</span> <span class="hljs-type">Document</span> {_title=title, _body=body, _metadata=metadata }

<span class="hljs-type">A</span>.<span class="hljs-type">Null</span>
<span class="hljs-type">A</span>.<span class="hljs-type">Bool</span> <span class="hljs-type">True</span>
<span class="hljs-type">A</span>.toJSON document
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">null</span>

<span class="hljs-title">true</span>

{
    <span class="hljs-string">&quot;body&quot;</span>: <span class="hljs-string">&quot;Lorem Ipsum&quot;</span>,
    <span class="hljs-string">&quot;metadata&quot;</span>: {
        <span class="hljs-string">&quot;Author&quot;</span>: <span class="hljs-string">&quot;Jonh Doe&quot;</span>,
        <span class="hljs-string">&quot;Encoding&quot;</span>: <span class="hljs-string">&quot;UTF-8&quot;</span>
    },
    <span class="hljs-string">&quot;title&quot;</span>: <span class="hljs-string">&quot;Foo Bar&quot;</span>
}
</code></pre>
</blockquote>
<h2>ihaskell-blaze</h2>
<p><a href="https://hackage.haskell.org/package/blaze-html" target="_blank" rel="noopener noreferrer">Blaze</a> is a fast combinator library used to assemble <em>HTML</em> documents directly in Haskell code <em>(<a href="https://wiki.haskell.org/Embedded_domain_specific_language" target="_blank" rel="noopener noreferrer">Embedded Domain Specific Language</a>)</em>. According to the official description, <em>“the project is aimed at those who seek to write web applications in Haskell – it integrates well with all Haskell web frameworks.”</em></p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This example if from the IHaskell official introduction</span>
:extension <span class="hljs-type">OverloadedStrings</span>

<span class="hljs-comment">-- import IHaskell.Display.Blaze</span>
<span class="hljs-keyword">import</span> Control.Monad
<span class="hljs-keyword">import</span> Prelude <span class="hljs-keyword">hiding</span> (<span class="hljs-title">div</span>, <span class="hljs-title">id</span>)
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Text.Blaze.Html4.Strict <span class="hljs-keyword">as</span> B
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Text.Blaze.Html4.Strict.Attributes <span class="hljs-keyword">as</span> A

<span class="hljs-title">forM</span> [<span class="hljs-number">1</span>..<span class="hljs-number">5</span>] $ \size -&gt; <span class="hljs-keyword">do</span>
  <span class="hljs-keyword">let</span> s = <span class="hljs-type">B</span>.toValue $ size * <span class="hljs-number">70</span>
  <span class="hljs-type">B</span>.img <span class="hljs-type">B</span>.! <span class="hljs-type">A</span>.src <span class="hljs-string">&quot;https://www.google.com/images/srpr/logo11w.png&quot;</span> <span class="hljs-type">B</span>.! <span class="hljs-type">A</span>.width s
</code></pre>
<img src="../images/google-logo.png" width="70">
<img src="../images/google-logo.png" width="140">
<img src="../images/google-logo.png" width="210">
<img src="../images/google-logo.png" width="280">
<img src="../images/google-logo.png" width="350">
<h2>ihaskell-charts</h2>
<p><a href="https://hackage.haskell.org/package/Chart" target="_blank" rel="noopener noreferrer">Charts</a> is a <em>“2D charting library for haskell”</em>. Here a two examples taken from the <a href="https://github.com/timbod7/haskell-chart/wiki" target="_blank" rel="noopener noreferrer">official wiki</a> on github. To adapt examples to notebooks, you must replace any reference of <code>toFile</code>, etc. by <code>toRenderable</code>.</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This example is taken from the wiki: https://github.com/timbod7/haskell-chart/wiki/example%205</span>
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Graphics.Rendering.Chart.Easy <span class="hljs-keyword">as</span> E

<span class="hljs-title">values</span> :: [(<span class="hljs-type">String</span>, <span class="hljs-type">Double</span>, <span class="hljs-type">Bool</span>)]
<span class="hljs-title">values</span> = [ (<span class="hljs-string">&quot;Mexico City&quot;</span>, <span class="hljs-number">19.2</span>, <span class="hljs-type">False</span>)
         , (<span class="hljs-string">&quot;Mumbai&quot;</span>, <span class="hljs-number">12.9</span>, <span class="hljs-type">False</span>)
         , (<span class="hljs-string">&quot;Sydney&quot;</span>, <span class="hljs-number">4.3</span>, <span class="hljs-type">False</span>)
         , (<span class="hljs-string">&quot;London&quot;</span>, <span class="hljs-number">8.3</span>, <span class="hljs-type">False</span>)
         , (<span class="hljs-string">&quot;New York&quot;</span>,<span class="hljs-number">8.2</span>,<span class="hljs-type">True</span>)]

<span class="hljs-title">pitem</span> (s, v, o) = <span class="hljs-type">E</span>.pitem_value <span class="hljs-type">E</span>..~ v
              $ <span class="hljs-type">E</span>.pitem_label <span class="hljs-type">E</span>..~ s
              $ <span class="hljs-type">E</span>.pitem_offset <span class="hljs-type">E</span>..~ (<span class="hljs-keyword">if</span> o <span class="hljs-keyword">then</span> <span class="hljs-number">25</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)
              $ <span class="hljs-type">E</span>.def

<span class="hljs-type">E</span>.toRenderable
  $ <span class="hljs-type">E</span>.pie_title <span class="hljs-type">E</span>..~ <span class="hljs-string">&quot;Relative Population&quot;</span>
  $ <span class="hljs-type">E</span>.pie_plot . <span class="hljs-type">E</span>.pie_data <span class="hljs-type">E</span>..~ map pitem values
  $ <span class="hljs-type">E</span>.def
</code></pre>
<figure><a href="../images/ihaskell-chart.svg" target="_blank" rel="noopener noreferrer"><img src="../images/ihaskell-chart.svg" alt=""></a><figcaption>pie chart</figcaption></figure>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This example is taken from the wiki: https://github.com/timbod7/haskell-chart/wiki/example%2012</span>
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Graphics.Rendering.Chart.Easy <span class="hljs-keyword">as</span> E

<span class="hljs-title">r&#x27;</span> x y z = sqrt $ x^<span class="hljs-number">2</span> + y^<span class="hljs-number">2</span> + z^<span class="hljs-number">2</span>
<span class="hljs-title">efield</span> sign x y = (sign * x / r, sign * y / r) <span class="hljs-keyword">where</span> r = r&#x27; x y <span class="hljs-number">10</span>
<span class="hljs-title">bfield</span> sign x y = (-sign * y / r^<span class="hljs-number">2</span>, sign * x / r^<span class="hljs-number">2</span>) <span class="hljs-keyword">where</span> r = r&#x27; x y <span class="hljs-number">10</span>
<span class="hljs-title">square</span> a s = [(x, y) | x &lt;- range, y &lt;- range] <span class="hljs-keyword">where</span> range = [-a, -a + s..a] :: [<span class="hljs-type">Double</span>]
<span class="hljs-title">add</span> (x1, y1) (x2, y2) = (x1 + x2, y1 + y2)

<span class="hljs-title">ef</span> (x, y) = efield <span class="hljs-number">1</span> (x - <span class="hljs-number">20</span>) y `add` efield (-<span class="hljs-number">1</span>) (x + <span class="hljs-number">20</span>) y
<span class="hljs-title">bf</span> (x, y) = bfield <span class="hljs-number">1</span> (x - <span class="hljs-number">20</span>) y `add` bfield (-<span class="hljs-number">1</span>) (x + <span class="hljs-number">20</span>) y
<span class="hljs-title">grid</span> = square <span class="hljs-number">30</span> <span class="hljs-number">3</span>

<span class="hljs-title">vectorField</span> title f grid = fmap <span class="hljs-type">E</span>.plotVectorField $ <span class="hljs-type">E</span>.liftEC $ <span class="hljs-keyword">do</span>
    c &lt;- <span class="hljs-type">E</span>.takeColor
    <span class="hljs-type">E</span>.plot_vectors_mapf <span class="hljs-type">E</span>..= f
    <span class="hljs-type">E</span>.plot_vectors_grid <span class="hljs-type">E</span>..= grid
    <span class="hljs-type">E</span>.plot_vectors_style . <span class="hljs-type">E</span>.vector_line_style . <span class="hljs-type">E</span>.line_color <span class="hljs-type">E</span>..= c
    <span class="hljs-type">E</span>.plot_vectors_style . <span class="hljs-type">E</span>.vector_head_style . <span class="hljs-type">E</span>.point_color <span class="hljs-type">E</span>..= c
    <span class="hljs-type">E</span>.plot_vectors_title <span class="hljs-type">E</span>..= title

<span class="hljs-title">main</span> = <span class="hljs-type">E</span>.toRenderable $ <span class="hljs-keyword">do</span>
    <span class="hljs-type">E</span>.setColors [<span class="hljs-type">E</span>.opaque <span class="hljs-type">E</span>.black, <span class="hljs-type">E</span>.opaque <span class="hljs-type">E</span>.blue]

    <span class="hljs-type">E</span>.layout_title <span class="hljs-type">E</span>..= <span class="hljs-string">&quot;Positive and Negative Charges&quot;</span>
    <span class="hljs-type">E</span>.plot $ vectorField <span class="hljs-string">&quot;Electric Field&quot;</span> ef grid
    <span class="hljs-type">E</span>.plot $ vectorField <span class="hljs-string">&quot;B-field&quot;</span> bf grid
<span class="hljs-title">main</span>
</code></pre>
<figure><a href="../images/ihaskell-field.svg" target="_blank" rel="noopener noreferrer"><img src="../images/ihaskell-field.svg" alt=""></a><figcaption>field</figcaption></figure>
<h2>ihaskell-diagrams</h2>
<p><a href="http://projects.haskell.org/diagrams/" target="_blank" rel="noopener noreferrer">Diagrams</a> is a <em>“powerful, flexible, declarative domain-specific language for creating vector graphics”</em>. That is, it provides a flexible embedded DSL used to describe vectorized figures that you can then render using different backends.</p>
<pre class="code" data-lang="haskell"><code>:extension <span class="hljs-type">NoMonomorphismRestriction</span>
:extension <span class="hljs-type">FlexibleContexts</span>
:extension <span class="hljs-type">GADTs</span>

<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Diagrams.Prelude <span class="hljs-keyword">as</span> D
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Diagrams.TwoD.Sunburst <span class="hljs-keyword">as</span> S
<span class="hljs-keyword">import</span> Data.Tree (<span class="hljs-title">unfoldTree</span>)

<span class="hljs-title">aTree</span> = unfoldTree (\n -&gt; (<span class="hljs-number">0</span>, replicate n (n - <span class="hljs-number">1</span>))) <span class="hljs-number">6</span>
<span class="hljs-title">diagram</span> $ <span class="hljs-type">S</span>.sunburst aTree <span class="hljs-type">D</span>.# <span class="hljs-type">D</span>.centerXY <span class="hljs-type">D</span>.# <span class="hljs-type">D</span>.pad <span class="hljs-number">1.1</span>
</code></pre>
<figure><a href="../images/ihaskell-diagram1.svg" target="_blank" rel="noopener noreferrer"><img src="../images/ihaskell-diagram1.svg" alt=""></a><figcaption>field</figcaption></figure>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- import Diagrams.Backend.SVG.CmdLine as</span>
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Diagrams.Prelude <span class="hljs-keyword">as</span> D
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Diagrams.TwoD.Factorization <span class="hljs-keyword">as</span> F

<span class="hljs-title">diagram</span> $ <span class="hljs-type">F</span>.fdGridList <span class="hljs-number">6</span> <span class="hljs-type">D</span>.# <span class="hljs-type">D</span>.center <span class="hljs-type">D</span>.# <span class="hljs-type">D</span>.pad <span class="hljs-number">1.05</span>
</code></pre>
<figure><a href="../images/ihaskell-diagram2.svg" target="_blank" rel="noopener noreferrer"><img src="../images/ihaskell-diagram2.svg" alt=""></a><figcaption>field</figcaption></figure>
<h2>ihaskell-magic</h2>
<p>In this case, libmagic is used to determine type of files using magic
values at the beginning, which allows us to display binary content in
notebooks, in the right way. For example, if we want to display an
image (png, jpeg, svg, etc.), we just have to read its content as a
<code>ByteString</code>, then <code>libmagic</code> is used behind the scene by <em>IHaskell</em> to
determine what kind of content it is, based on the magic bytes present
in the file, and then inline it in the notebook.</p>
<p>What is important to understand here, is that an instance of
IHaskellDisplay is defined for both <code>ByteString</code> and <code>Text</code>, in case
this strings represent something else than text (images, for example),
<em>IHaskell</em> is able to know it thanks to <code>libmagic</code> and display the content
accordingly, otherwise, it just displays the string.</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.ByteString <span class="hljs-keyword">as</span> B
<span class="hljs-type">B</span>.readFile <span class="hljs-string">&quot;./haskell-logo.png&quot;</span>
</code></pre>
<figure><a href="../images/output_25_0.png" target="_blank" rel="noopener noreferrer"><img src="../images/output_25_0.png" alt=""></a><figcaption>Haskell logo</figcaption></figure>
<pre class="code" data-lang="haskell"><code>:extension <span class="hljs-type">OverloadedStrings</span>
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.ByteString <span class="hljs-keyword">as</span> B
<span class="hljs-string">&quot;This is a string of type ByteString&quot;</span> :: <span class="hljs-type">B</span>.<span class="hljs-type">ByteString</span>
</code></pre>
<pre class="code" data-lang="sh"><code>This is a string of <span class="hljs-built_in">type</span> ByteString
</code></pre>
<pre class="code" data-lang="haskell"><code>:extension <span class="hljs-type">OverloadedStrings</span>
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.Text <span class="hljs-keyword">as</span> T
<span class="hljs-string">&quot;This is a string of type Text&quot;</span> :: <span class="hljs-type">T</span>.<span class="hljs-type">Text</span>
</code></pre>
<pre class="code" data-lang="sh"><code>This is a string of <span class="hljs-built_in">type</span> Text
</code></pre>
<h2>ihaskell-static-canvas</h2>
<p>Following on the <a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Static%20Canvas%20IHaskell%20Display.ipynb" target="_blank" rel="noopener noreferrer">excellent introduction</a>
from the author of <em>IHaskell</em>. Let’s try to use
<a href="https://github.com/jeffreyrosenbluth/static-canvas" target="_blank" rel="noopener noreferrer">static-canvas</a> to
create more elaborate inlings in notebooks! The github page is full
of <a href="" target="_blank" rel="noopener noreferrer">examples</a> that we can try out right now. But before that, we
must create an instance of <code>IHaskellDisplay</code> for <code>CanvasFree</code> (which
is taken directly from the mentionned tutorial (I hope it’s Ok, since
<code>ihaskell-static-canvas</code> doesn’t seem to be part of Stackage LTS at the
moment).</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-keyword">import</span> IHaskell.Display <span class="hljs-comment">-- From the &#x27;ihaskell&#x27; package.</span>
<span class="hljs-keyword">import</span> IHaskell.IPython.Types (<span class="hljs-type">MimeType(..)</span>)
<span class="hljs-keyword">import</span> Graphics.Static  <span class="hljs-comment">-- From the &#x27;static-canvas&#x27; package.</span>

<span class="hljs-comment">-- Text conversion functions.</span>
<span class="hljs-keyword">import</span> Data.Text.Lazy.Builder (<span class="hljs-title">toLazyText</span>)
<span class="hljs-keyword">import</span> Data.Text.Lazy (<span class="hljs-title">toStrict</span>)
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- Since CanvasFree is a type synonym, we need a language pragma.</span>
:extension <span class="hljs-type">TypeSynonymInstances</span>
:extension <span class="hljs-type">FlexibleInstances</span>
<span class="hljs-class">
<span class="hljs-keyword">instance</span> <span class="hljs-type">IHaskellDisplay</span> (<span class="hljs-type">CanvasFree</span> ()) <span class="hljs-keyword">where</span></span>
  <span class="hljs-comment">-- display :: CanvasFree () -&gt; IO Display</span>
  display canvas = return $
    <span class="hljs-keyword">let</span> src = toStrict
      $ toLazyText
      $ buildScript width height canvas
    <span class="hljs-keyword">in</span> <span class="hljs-type">Display</span> [<span class="hljs-type">DisplayData</span> <span class="hljs-type">MimeHtml</span> src]
    <span class="hljs-keyword">where</span> (height, width) = (<span class="hljs-number">200</span>, <span class="hljs-number">600</span>)
</code></pre>
<p>Now let’s try some example:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-keyword">import</span> Graphics.Static
<span class="hljs-keyword">import</span> Graphics.Static.ColorNames

<span class="hljs-title">text</span> :: <span class="hljs-type">CanvasFree</span> ()
<span class="hljs-title">text</span> = <span class="hljs-keyword">do</span>
  font <span class="hljs-string">&quot;italic 60pt Calibri&quot;</span>
  lineWidth <span class="hljs-number">6</span>
  strokeStyle blue
  fillStyle goldenrod
  textBaseline <span class="hljs-type">TextBaselineMiddle</span>
  strokeText <span class="hljs-string">&quot;Haskell&quot;</span> <span class="hljs-number">150</span> <span class="hljs-number">100</span>
  fillText <span class="hljs-string">&quot;Haskell!&quot;</span> <span class="hljs-number">150</span> <span class="hljs-number">100</span>

<span class="hljs-title">text</span>
</code></pre>
<figure><a href="../images/ihaskell-canvas.png" target="_blank" rel="noopener noreferrer"><img src="../images/ihaskell-canvas.png" alt=""></a></figure>
<h2>Conclusion</h2>
<p>This was a short introduction without much new stuff, but it gave me a
better understanding on how <em>IHaskell</em> (and in a way, <em>Jupyter</em>) works.
Thanks to the awesome work of some haskellers, we are able to benefit
from the great <em>Jupyter</em> ecosystem, and I think it can bring a lot to
<em>Haskell</em> itself. It’s easier to share code, easier to write about
<em>Haskell</em>-related stuff, easier to dig into a new projet.</p>
<p><em>IHaskell</em> is a solid foundation for more to come: more widgets, more
integrations with <em>Haskell</em> libraries, etc. I wonder if, for example, we
could use <em>Blaze</em> to generate <em>Display</em> on-the-fly? Could we reuse some
code from the <em>Python</em> Kernel of <em>Jupyter</em>? I’m also looking forward to
try the <code>ihaskell-widgets</code> extension.</p>
<p>That’s pretty much it, I’d like to say I’m very excited for Haskell,
because it becomes much more accessible for newcomers, thanks to (for
example) Stack, IHaskell, and lot of effort that is being made by the
community. I hope I can continue to contribute at my level to this
effort!</p>
<p>Thanks for reading!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Installing IHaskell on Ubuntu 14.04 with Stack]]></title>
            <link>https://remusao.github.io//posts/ihaskell-ubuntu-14-04-install.html</link>
            <guid>https://remusao.github.io//posts/ihaskell-ubuntu-14-04-install.html</guid>
            <pubDate>Thu, 07 Jan 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>In this post, we’re going through the installation of IHaskell on
GNU/Linux (Ubuntu 14.04 in my case, though it should be pretty similar
on other ditributions) step-by-step. We’ll see how the use of <em>Stack</em>
will simplify the whole process, and how to get all the dependencies
right!</p>
<h2>Install Stack</h2>
<p>From <em>Stack</em> official <a href="http://docs.haskellstack.org/en/stable/install_and_upgrade.html" target="_blank" rel="noopener noreferrer">documentation</a>, for Ubuntu 14.04:</p>
<pre class="code" data-lang="sh"><code>sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 575159689BEFB442
<span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;deb http://download.fpcomplete.com/ubuntu trusty main&#x27;</span> \
    |sudo <span class="hljs-built_in">tee</span> /etc/apt/sources.list.d/fpco.list
sudo apt-get update &amp;&amp; sudo apt-get install stack -y
</code></pre>
<p>You should now be able to run the <code>stack</code> executable in a shell:</p>
<pre class="code" data-lang="sh"><code>stack --<span class="hljs-built_in">help</span>
</code></pre>
<p>Being up-to-date is important, so setup your <em>Stack</em> global configuration <code>~/.stack/global/stack.yaml</code>:</p>
<pre class="code" data-lang="yaml"><code><span class="hljs-attr">flags:</span> {}
<span class="hljs-attr">resolver:</span> <span class="hljs-string">lts-4.0</span>
<span class="hljs-attr">packages:</span> []
<span class="hljs-attr">extra-deps:</span> []
</code></pre>
<p>Tell <em>Stack</em> to setup everything (download package list, install latest <em>GHC</em> release, etc.):</p>
<pre class="code" data-lang="sh"><code>stack setup
</code></pre>
<p>Note that you can lookup the latest release of stackage at anytime on this <a href="http://www.stackage.org/lts" target="_blank" rel="noopener noreferrer">page</a>.</p>
<h2>Install ZeroMQ latest version</h2>
<p>If you try to install IHaskell directly, you’ll get an error since Ubuntu 14.04 ships with an older version of ZeroMQ. We need a more recent release. There are several ways to install it:</p>
<ol>
<li>Compile it from source</li>
<li>Use Nix</li>
</ol>
<p>We’re going to compile it from source. I’ll follow the way of the official <a href="https://github.com/gibiansky/IHaskell#install-zeromq" target="_blank" rel="noopener noreferrer">README</a>:</p>
<pre class="code" data-lang="sh"><code><span class="hljs-comment"># Compiling from source:</span>
git <span class="hljs-built_in">clone</span> git@github.com:zeromq/zeromq4-x.git libzmq
<span class="hljs-built_in">cd</span> libzmq
./autogen.sh &amp;&amp; ./configure &amp;&amp; make
sudo make install
sudo ldconfig
</code></pre>
<p>That will do the trick! If you don’t like to install packages in global scope, feel free to install it in a user folder (Add the <code>--prefix=LOCATION</code> directive to <code>./configure</code>, and change <code>LD_LIBRARY_PATH</code> and <code>PATH</code> in your shell configuration accordingly).</p>
<h2>Install Jupyter</h2>
<p><strong>EDIT</strong>: Following Florian’s comment, it appears that <em>IPython</em> is now officialy named <em>Jupyter</em>, so we might as well install it in our virtualenv. The only change in the instructions is to replace <code>pip install ipython</code> by <code>pip install jupyter</code> (Note that <em>IPython</em> is a dependency of <em>Jupyter</em>).</p>
<p>IHaskell requires a recent version of <em>Jupyter</em>, so we need to install it ourselves. There are several options:</p>
<ol>
<li>Use pip and install it globaly (<code>pip install jupyter</code>)</li>
<li>Use pip and install it in a virtualenv (<strong>This is what we will do here</strong>)</li>
<li>Use <a href="https://nixos.org/nix/" target="_blank" rel="noopener noreferrer">nix</a> <em>(You’re on your own)</em></li>
<li>Use <a href="https://www.continuum.io/downloads" target="_blank" rel="noopener noreferrer">conda</a> (<code>conda update jupyter</code>)</li>
</ol>
<p>If you’re on a fresh install: <code>sudo apt-get install python-virtualenv python-dev ncurses-base</code></p>
<p>With <code>virtualenv</code>:</p>
<pre class="code" data-lang="sh"><code>virtualenv venv-ihaskell
<span class="hljs-built_in">source</span> venv-ihaskell/bin/activate
</code></pre>
<p>With <code>virtualenvwrapper</code>:</p>
<pre class="code" data-lang="sh"><code>mkvirtualenv ihaskell
workon ihaskell
</code></pre>
<p>Now we install <em>Jupyter</em>:</p>
<pre class="code" data-lang="sh"><code>pip install jupyter
</code></pre>
<h2>Install IHaskell</h2>
<p>Nothing simpler, just use <em>Stack</em>:</p>
<pre class="code" data-lang="sh"><code>stack build ihaskell
</code></pre>
<p>You may want to install extra packages to enhance <em>IHaskell</em> capabilities. Here are the ones supported by Stackage:</p>
<ul>
<li>ihaskell-aeson</li>
<li>ihaskell-blaze</li>
<li>ihaskell-charts</li>
<li>ihaskell-diagrams</li>
<li>ihaskell-rlangqq</li>
<li>ihaskell-magic</li>
<li>ihaskell-juicypixels</li>
<li>ihaskell-hatex</li>
<li>ihaskell-basic</li>
</ul>
<p>Some others are not in the LTS snapshot of Stackage, but could be useful in the future. I don’t know about the current maturity of these packages:</p>
<ul>
<li>ihaskell-widgets (conflict with current version of singletons)</li>
<li>ihaskell-parsec (conflict with current version of aeson)</li>
<li>ihaskell-plot</li>
</ul>
<h2>Setup IHaskell</h2>
<p>If everything went well, you should have <em>Jupyter</em> (latest version) and <em>ihaskell</em> installed properly. The last step is to install the <em>IHaskell Kernel</em> into <em>Jupyter</em>.</p>
<pre class="code" data-lang="sh"><code>stack <span class="hljs-built_in">exec</span> ihaskell -- install
</code></pre>
<p>Now run the notebook server and enjoy:</p>
<pre class="code" data-lang="sh"><code>stack <span class="hljs-built_in">exec</span> jupyter -- notebook
</code></pre>
<p>Open your browser and go to: <code>http://localhost:8000</code></p>
<h2>What’s next</h2>
<p>Thanks to Stack, the install process went very smoothely (appart from some dependency we had to install ourselves).
Using IPython with a Haskell Kernel I believe writing about Haskell will be a much pleasant experience since it’s really easy
to export a notebook either in HTML or Markdown.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pytest—Paramaterize tests with external data]]></title>
            <link>https://remusao.github.io//posts/pytest-param.html</link>
            <guid>https://remusao.github.io//posts/pytest-param.html</guid>
            <pubDate>Wed, 26 Nov 2014 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I recently began to make heavy use of <a href="http://pytest.org/latest/" target="_blank" rel="noopener noreferrer">pytest</a>
in my day-to-day Python development. It’s a wonderful tool, but I won’t
explain to you every features it provides and why it’s awesome. Instead,
I’ll explain how I managed to cleanly externalize the data used for my
tests in external files (that can be of any format: yaml, json, python
files). The idea here is to <em>separate the code that performs the test</em>,
from the <em>input data used to perform the test</em>.</p>
<ul>
<li><em>test_feature.py</em></li>
</ul>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_my_feature</span>(<span class="hljs-params">one_example</span>):
    <span class="hljs-keyword">assert</span> one_example
</code></pre>
<ul>
<li><em>data_feature.yaml</em></li>
</ul>
<pre class="code" data-lang="yaml"><code><span class="hljs-attr">tests:</span>
    <span class="hljs-attr">test1:</span>
        <span class="hljs-string">...</span>
    <span class="hljs-attr">test2:</span>
        <span class="hljs-string">...</span>
</code></pre>
<h2>First solution: yield</h2>
<p>The first solution would be to use <code>yield</code> to generate tests, as it’s supported
by <code>py.test</code> (as long as you don’t want to use fixtures in your test function…).</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">check</span>(<span class="hljs-params">example</span>):
    <span class="hljs-comment"># perform your test</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_feature</span>():
    <span class="hljs-keyword">for</span> test <span class="hljs-keyword">in</span> generate_tests():
        <span class="hljs-keyword">yield</span> check, test
</code></pre>
<p>Here, <code>py.test</code> will understand that <code>test_feature</code> will yield several tests and that
the <code>check</code> function must be used to perform the test, so it is almost equivalent to do:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_feature</span>():
    <span class="hljs-keyword">for</span> test <span class="hljs-keyword">in</span> generate_tests():
        check(test)
</code></pre>
<p>Except that in this last snippet of code, the tests will stop as soon as one fails.
With the <code>yield</code>-version, every tests will be ran even if some fail. This is useful
if you have lot of tests, and you want to know which ones fail (not just the first one).</p>
<p><strong>Problem</strong>: if you want to use fixtures with your <code>test_feature</code> functions, it breaks:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">check</span>(<span class="hljs-params">example</span>):
    <span class="hljs-comment"># perform your test</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_feature</span>(<span class="hljs-params">my_fixture</span>):
    <span class="hljs-keyword">for</span> test <span class="hljs-keyword">in</span> generate_tests():
        <span class="hljs-keyword">yield</span> check, test
</code></pre>
<p>This will tell you that <code>test_feature</code> expects one argument but that none are provided.</p>
<p>End of the story…
Wait, no, <code>py.test</code> is awesome remember? So there must be a solution!</p>
<h2>Parametrization</h2>
<p>One of the cool features of <code>py.test</code> is the ability to add parameters on our
tests or fixtures, so that a test is ran once for each parameter (from <a href="http://pytest.org/latest/parametrize.html" target="_blank" rel="noopener noreferrer">py.test doc</a>):</p>
<pre class="code" data-lang="python"><code><span class="hljs-comment"># content of test_expectation.py</span>
<span class="hljs-keyword">import</span> pytest
<span class="hljs-meta">@pytest.mark.parametrize(<span class="hljs-params"><span class="hljs-string">&quot;input,expected&quot;</span>, [
    (<span class="hljs-params"><span class="hljs-string">&quot;3+5&quot;</span>, <span class="hljs-number">8</span></span>),
    (<span class="hljs-params"><span class="hljs-string">&quot;2+4&quot;</span>, <span class="hljs-number">6</span></span>),
    (<span class="hljs-params"><span class="hljs-string">&quot;6*9&quot;</span>, <span class="hljs-number">42</span></span>),
]</span>)</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_eval</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, expected</span>):
    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">eval</span>(<span class="hljs-built_in">input</span>) == expected
</code></pre>
<pre class="code" data-lang="python"><code>$ py.test
=========================== test session starts ============================
platform linux -- Python <span class="hljs-number">3.4</span><span class="hljs-number">.0</span> -- py-<span class="hljs-number">1.4</span><span class="hljs-number">.26</span> -- pytest-<span class="hljs-number">2.6</span><span class="hljs-number">.4</span>
collected <span class="hljs-number">3</span> items

test_expectation.py ..F

================================= FAILURES =================================
____________________________ test_eval[<span class="hljs-number">6</span>*<span class="hljs-number">9</span>-<span class="hljs-number">42</span>] _____________________________

<span class="hljs-built_in">input</span> = <span class="hljs-string">&#x27;6*9&#x27;</span>, expected = <span class="hljs-number">42</span>

<span class="hljs-meta">    @pytest.mark.parametrize(<span class="hljs-params"><span class="hljs-string">&quot;input,expected&quot;</span>, [
        (<span class="hljs-params"><span class="hljs-string">&quot;3+5&quot;</span>, <span class="hljs-number">8</span></span>),
        (<span class="hljs-params"><span class="hljs-string">&quot;2+4&quot;</span>, <span class="hljs-number">6</span></span>),
        (<span class="hljs-params"><span class="hljs-string">&quot;6*9&quot;</span>, <span class="hljs-number">42</span></span>),
    ]</span>)</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_eval</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, expected</span>):
&gt;       <span class="hljs-keyword">assert</span> <span class="hljs-built_in">eval</span>(<span class="hljs-built_in">input</span>) == expected
E       <span class="hljs-keyword">assert</span> <span class="hljs-number">54</span> == <span class="hljs-number">42</span>
E        +  where <span class="hljs-number">54</span> = <span class="hljs-built_in">eval</span>(<span class="hljs-string">&#x27;6*9&#x27;</span>)

test_expectation.py:<span class="hljs-number">8</span>: AssertionError
==================== <span class="hljs-number">1</span> failed, <span class="hljs-number">2</span> passed <span class="hljs-keyword">in</span> <span class="hljs-number">0.01</span> seconds ====================
</code></pre>
<p>So here our <code>test_eval</code> function has been called <em>three times</em>. Once for each parameter.
Great! But what if you want your parameters to come from another file, or from a function.
In other words, what if you want to <em>dynamically parametrize</em> your function?</p>
<h2>Hooks at the rescue</h2>
<p><a href="http://pytest.org/latest/plugins.html#well-specified-hooks" target="_blank" rel="noopener noreferrer">Hooks</a> allow you to plug code into <code>py.test</code> at diffent stages of the test run.
The hook that can be useful for us is <code>pytest_generate_tests</code> that will allow
to generate several calls to the same test function, but with different arguments
(from <a href="http://pytest.org/latest/funcargs.html#basic-generated-test-example" target="_blank" rel="noopener noreferrer">py.test doc</a>):</p>
<pre class="code" data-lang="python"><code><span class="hljs-comment"># content of test_example.py</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">pytest_generate_tests</span>(<span class="hljs-params">metafunc</span>):
    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;numiter&quot;</span> <span class="hljs-keyword">in</span> metafunc.funcargnames:
        metafunc.parametrize(<span class="hljs-string">&quot;numiter&quot;</span>, <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))

<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_func</span>(<span class="hljs-params">numiter</span>):
    <span class="hljs-keyword">assert</span> numiter &lt; <span class="hljs-number">9</span>
</code></pre>
<pre class="code" data-lang="python"><code>$ py.test test_example.py
=========================== test session starts ============================
platform linux2 -- Python <span class="hljs-number">2.7</span><span class="hljs-number">.1</span> -- pytest-<span class="hljs-number">2.2</span><span class="hljs-number">.4</span>
collecting ... collected <span class="hljs-number">10</span> items

test_example.py .........F

================================= FAILURES =================================
_______________________________ test_func[<span class="hljs-number">9</span>] _______________________________

numiter = <span class="hljs-number">9</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_func</span>(<span class="hljs-params">numiter</span>):
&gt;       <span class="hljs-keyword">assert</span> numiter &lt; <span class="hljs-number">9</span>
E       <span class="hljs-keyword">assert</span> <span class="hljs-number">9</span> &lt; <span class="hljs-number">9</span>

test_example.py:<span class="hljs-number">6</span>: AssertionError
==================== <span class="hljs-number">1</span> failed, <span class="hljs-number">9</span> passed <span class="hljs-keyword">in</span> <span class="hljs-number">0.02</span> seconds ====================
</code></pre>
<p>Great, so the last things to do is:</p>
<ol>
<li>Detect functions that make use of a fixture whose name starts with <code>data_</code></li>
<li>Load the corresponding file or resource for the test source</li>
<li>Parametrize the function with each of the data</li>
</ol>
<p>For example, here is what you can do:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">pytest_generate_tests</span>(<span class="hljs-params">metafunc</span>):
    <span class="hljs-string">&quot;&quot;&quot; This allows us to load tests from external files by
    parametrizing tests with each test case found in a data_X
    file &quot;&quot;&quot;</span>
    <span class="hljs-keyword">for</span> fixture <span class="hljs-keyword">in</span> metafunc.fixturenames:
        <span class="hljs-keyword">if</span> fixture.startswith(<span class="hljs-string">&#x27;data_&#x27;</span>):
            <span class="hljs-comment"># Load associated test data</span>
            tests = load_tests(fixture)
            metafunc.parametrize(fixture, tests)
</code></pre>
<p>Here, the <code>load_tests</code> function takes as argument the name of the fixture <code>data_X</code>
and will:</p>
<ol>
<li>Load the corresponding file</li>
<li>Extract the different test-cases</li>
<li>Return a list of all the cases</li>
</ol>
<p>For example, if your tests are stored in a Python file:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> importlib


<span class="hljs-keyword">def</span> <span class="hljs-title function_">load_tests</span>(<span class="hljs-params">name</span>):
    <span class="hljs-comment"># Load module which contains test data</span>
    tests_module = importlib.import_module(name)
    <span class="hljs-comment"># Tests are to be found in the variable `tests` of the module</span>
    <span class="hljs-keyword">for</span> test <span class="hljs-keyword">in</span> tests_module.tests.iteritems():
        <span class="hljs-keyword">yield</span> test
</code></pre>
<p>The data file (<code>data_my_feature.py</code>) could look something like:</p>
<pre class="code" data-lang="python"><code>tests = [
    <span class="hljs-number">1</span>,
    <span class="hljs-number">2</span>,
    <span class="hljs-number">3</span>,
    <span class="hljs-number">4</span>,
    <span class="hljs-number">5</span>,
    <span class="hljs-number">6</span>,
    <span class="hljs-number">7</span>,
    <span class="hljs-number">8</span>,
    <span class="hljs-number">9</span>
]
</code></pre>
<p>The test function will then be invoked for each case.</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_feature</span>(<span class="hljs-params">data_my_feature</span>):
    <span class="hljs-keyword">assert</span> data_my_feature &lt; <span class="hljs-number">5</span>
</code></pre>
<h2>Conclusion</h2>
<p>Here it’s not really interesting, but the benefits are numerous:</p>
<ol>
<li>storing your data in a database, or in yaml/json formatted files, or whatever</li>
<li>other people can add tests to your project, without having to dig into the code</li>
<li>provide a common format to define tests in external files</li>
<li>reuse the same data for several tests</li>
<li>the data is not hard-coded in Python source-code</li>
</ol>
<p>TL;DR: <code>py.test</code> is awesome. Make tests. Get data for your tests from external sources.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Decompressing bzipped files with Julia]]></title>
            <link>https://remusao.github.io//posts/decompressing-bz2-files-with-julia.html</link>
            <guid>https://remusao.github.io//posts/decompressing-bz2-files-with-julia.html</guid>
            <pubDate>Tue, 22 Jul 2014 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I’m currently working with Wikipedia dumps, and to save space, it’s a
good thing to make scripts that read directly content from (and write
results to) BZipped files.</p>
<h2>Setup</h2>
<p>Tests where executed on my personal computer:</p>
<ul>
<li>i7</li>
<li>16GB of ram</li>
</ul>
<p>On a small Wikipedia dump of <em>407MB</em>. All timings are in <em>seconds</em>.</p>
<h2>bzcat alone</h2>
<p>To have a point of comparison, I decompressed the dump using <em>bzcat</em> alone. The timing is <em>64 seconds</em>.</p>
<pre class="code" data-lang="sh"><code>$ time 1&gt;/dev/null bzcat wikidump.xml.bz2
</code></pre>
<h2>Using Python</h2>
<p>It’s easy enough with <em>Python</em> thanks to the <code>bz2</code> module that allows to transparently manipulate a compressed file as if it were a normal opened file. Before jumping to Julia, let see how it is done in Python:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> bz2


<span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
    in_stream = bz2.BZ2File(sys.argv[<span class="hljs-number">1</span>])
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> in_stream:
        <span class="hljs-built_in">print</span>(line)
    in_stream.close()


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:
    main()
</code></pre>
<p>Nothing easier, it takes <em>85 seconds</em> to run.</p>
<h2>What about Julia?</h2>
<p>Since I really love <em>Julia</em> language, I was tempted to do the same with Julia. Here are the differents solutions that I went through, with their respective timings.</p>
<h3>Using bz2 Python module through PyCall</h3>
<p>The first naive option is to use the original module from Python. It’s easy enough using the <code>PyCall</code> module. We can install it like so:</p>
<pre class="code" data-lang="julia"><code>julia&gt; Pkg.add(<span class="hljs-string">&quot;PyCall&quot;</span>)
julia&gt; Pkg.update()
</code></pre>
<p>The script:</p>
<pre class="code" data-lang="julia"><code><span class="hljs-keyword">using</span> PyCall
<span class="hljs-meta">@pyimport</span> bz2

<span class="hljs-keyword">function</span> main()
    in_stream = bz2.BZ2File(<span class="hljs-literal">ARGS</span>[<span class="hljs-number">1</span>])
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> in_stream
        println(line)
    <span class="hljs-keyword">end</span>
    in_stream[:close]()
<span class="hljs-keyword">end</span>
</code></pre>
<p>But then we hit the wall… timing is: <em>1352 seconds</em>. This is likely due to the conversion between <em>Python</em> and <em>Julia</em> datatypes. So not the best option for a data-intensive usage.</p>
<h3>Piping result of bzcat to Julia</h3>
<p>The second option that came to my mind was: “why not using <em>bzcat</em>?”. It’s easy enough, we just have to read from <code>STDIN</code>:</p>
<pre class="code" data-lang="julia"><code><span class="hljs-keyword">function</span> main()
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> eachline(STDIN)
        print(line)
    <span class="hljs-keyword">end</span>
<span class="hljs-keyword">end</span>
</code></pre>
<p>Here is the invocation:</p>
<pre class="code" data-lang="sh"><code>$ bzcat wikidump.xml.bz2 | julia bz2_bench.jl
</code></pre>
<p>Timing is now a more reasonable <em>72 seconds</em>. So that is less than the <em>Python</em> version shown above. But this is not satisfactory enough. Why not use the wonderful capabilities of <em>Julia</em> to run external commands an pipe results?</p>
<h3>Invoking bzcat from Julia</h3>
<p>It is easy to invoke commands from inside <em>Julia</em> using backquotes: <code>run(`cmd`)</code> and <code>|&gt;</code> to pipe between commands and streams. Let’s do it:</p>
<pre class="code" data-lang="julia"><code><span class="hljs-keyword">function</span> main()
    file = <span class="hljs-literal">ARGS</span>[<span class="hljs-number">1</span>]
    run(<span class="hljs-string">`bzcat <span class="hljs-subst">$(file)</span>`</span> |&gt; STDOUT)
<span class="hljs-keyword">end</span>
</code></pre>
<p>The script is equivalent to: <code>bzcat wikidump.xml.bz2</code>, but it’s quite impressive to see how easy it is to do this inside a Julia script.
This time is about <em>66 seconds</em>, more or less the same than with the external piping from <code>bzcat</code>.</p>
<p>But it would be useful to get lines of contents from the stream, like it was in the original <em>Python</em> script. For this task, <em>Julia</em> standard library offers a multitudes of handy functions. The one we will use is <code>readsfrom</code> that returns two things: stdout of the given process, and the process itself. Here it is in action:</p>
<pre class="code" data-lang="julia"><code><span class="hljs-keyword">function</span> main()
    file = <span class="hljs-literal">ARGS</span>[<span class="hljs-number">1</span>]
    <span class="hljs-literal">stdout</span>, p = readsfrom(<span class="hljs-string">`bzcat <span class="hljs-subst">$(file)</span>`</span>)
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> eachline(<span class="hljs-literal">stdout</span>)
        print(line)
    <span class="hljs-keyword">end</span>
<span class="hljs-keyword">end</span>
</code></pre>
<p>Timing is now about <em>74 seconds</em>, this is <em>10 seconds</em> faster than the first <em>Python</em> version. But we don’t rely on a module. Instead, we make use of the ability to play with command invocations, stream pipings, and the like that <em>Julia</em> allows.</p>
<h2>Timings</h2>
<figure>
<a href="../images/bz2-julia-bench.png">
<img src="../images/bz2-julia-bench.png" alt="Bench">
</a>
<figcaption>Timings.</figcaption>
</figure>
<p>Timings are relatively close since the big work is done in the decompression, that’s why there isn’t much difference between <em>Julia</em> and <em>Python</em>.</p>
<h2>Conclusion</h2>
<p>I was first tempted to implement a <em>Julia</em> wrapper over <em>bzlib</em>, but what for? When it’s so easy to invoke external commands and manipulate their input and output streams.
<em>Julia</em> is a young language, but it’s so flexible and extensible, that often I forget about it!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Installation de Julia]]></title>
            <link>https://remusao.github.io//posts/julia-installation.html</link>
            <guid>https://remusao.github.io//posts/julia-installation.html</guid>
            <pubDate>Fri, 14 Feb 2014 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Suite au premier article sur le langage Julia, voici un guide rapide de mise en
route de votre environnement pour utiliser le langage.</p>
<p>Voici le plan :</p>
<ul>
<li>Compiler Julia depuis les sources</li>
<li>Coloration syntaxique et indentation sous vim</li>
<li>Environnement IJulia (équivalement de IPython)</li>
</ul>
<h2>Compilation</h2>
<p>Tout d’abord compiler l’interpréteur Julia depuis les sources. Notez que si
votre distribution <em>linux</em> dispose d’un paquet Julia dans ses dépôt ou si vous
ne désirez pas compiler Julia depuis les sources, il est toujours possible
d’installer une version pré-compilée depuis la
<a href="http://julialang.org/downloads/" target="_blank" rel="noopener noreferrer">page téléchargement</a> du site officiel.</p>
<p>Commençons tout d’abord par récupérer les sources de Julia :</p>
<pre class="code" data-lang="sh"><code>git <span class="hljs-built_in">clone</span> https://github.com/JuliaLang/julia.git
<span class="hljs-built_in">cd</span> julia
</code></pre>
<p>Ensuite, vérifiez que les dépendances suivantes sont bien disponibles sur votre
système :</p>
<ul>
<li><a href="http://www.gnu.org/software/make/" target="_blank" rel="noopener noreferrer">GNU make</a></li>
<li><a href="http://gcc.gnu.org/" target="_blank" rel="noopener noreferrer">gcc et g++</a> (ou <a href="http://clang.llvm.org/" target="_blank" rel="noopener noreferrer">Clang</a>)</li>
<li><a href="http://gcc.gnu.org/" target="_blank" rel="noopener noreferrer">gfortran</a></li>
<li><a href="http://git-scm.com/" target="_blank" rel="noopener noreferrer">git</a></li>
<li><a href="http://www.perl.org/" target="_blank" rel="noopener noreferrer">perl</a></li>
<li><a href="http://www.gnu.org/software/wget/" target="_blank" rel="noopener noreferrer">wget</a> (ou <a href="http://curl.haxx.se/" target="_blank" rel="noopener noreferrer">curl</a>, ou <em>fetch</em>)</li>
<li><a href="http://www.gnu.org/software/m4/" target="_blank" rel="noopener noreferrer">m4</a></li>
<li><a href="http://www.gnu.org/software/patch/" target="_blank" rel="noopener noreferrer">patch</a></li>
</ul>
<p>Si tout est installé, lancez la compilation (notez que <strong>N</strong> est à remplacer
par le nombre de cœurs dont dispose votre processeur, cela peut grandement
améliorer le temps de compilation) :</p>
<pre class="code" data-lang="sh"><code>make -j N
</code></pre>
<p>La première fois que vous compilez Julia, des dépendances vont être téléchargées
puis compilées, c’est pourquoi cela peut prendre un certains temps. La
compilation peut consommer jusqu’à <em>700 Mo de mémoire</em> et <em>1.5 Go d’espace
disque</em>. Les éventuelles compilations futures seront moins gourmandes.</p>
<p>Une fois la compilation terminée, vous disposez d’un
<a href="http://en.wikipedia.org/wiki/Symbolic_link" target="_blank" rel="noopener noreferrer">lien symbolique</a> vers l’exécutable
Julia. Afin qu’il soit accessible depuis n’importe quel endroit, vous pouvez
le rajouter à votre <code>PATH</code> (vous pouvez le rajouter dans le fichier de
configuration de votre Shell favori en remplaçant <code>$(pwd)</code> par le chemin
absolu vers le dossier julia dans lequel se trouve le lien symbolique) :</p>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">export</span> PATH=<span class="hljs-string">&quot;<span class="hljs-subst">$(pwd)</span>:<span class="hljs-variable">$PATH</span>&quot;</span>
</code></pre>
<p>Julia intègre tout le nécessaire pour gérer l’installation, la mise à jour
et la création de packages. Ces fonctionnalités sont disponibles depuis un
prompt Julia. La première fois que vous lancez Julia, il est nécessaire
d’initialiser les packages :</p>
<pre class="code" data-lang="sh"><code>$ julia
julia&gt; Pkg.update()
</code></pre>
<p>Les principales commandes disponibles sont :</p>
<ul>
<li><strong>Pkg.update()</strong> : met à jours les différents packages installés</li>
<li><strong>Pkg.add(“Package”)</strong> : installe le package <em>Package</em> ainsi que ses éventuelles dépendances</li>
<li><strong>Pkg.rm(“Package”)</strong> : supprime le package <em>Package</em></li>
</ul>
<h2>Coloration syntaxique et indentation</h2>
<p>Cette explication n’est valide que pour les utilisateurs de l’éditeur
<a href="http://www.vim.org/" target="_blank" rel="noopener noreferrer">Vim</a>. Voici des explications différentes en
fonction de la manière dont vous gérez les extensions.</p>
<h3>Pathogen</h3>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">cd</span> ~/.vim
<span class="hljs-built_in">mkdir</span> -p bundle &amp;&amp; <span class="hljs-built_in">cd</span> bundle
git <span class="hljs-built_in">clone</span> git://github.com/JuliaLang/julia-vim.git
</code></pre>
<h3>Vundle</h3>
<p>Ajouter un nouveau Bundle à votre <code>.vimrc</code> :</p>
<pre class="code" data-lang="sh"><code>Bundle <span class="hljs-string">&#x27;JuliaLang/julia-vim&#x27;</span>
</code></pre>
<p>Lancer Vim et mettre à jour vos Bundle :</p>
<pre class="code" data-lang="sh"><code>:BundleInstall!
</code></pre>
<h3>Manuel</h3>
<pre class="code" data-lang="sh"><code>git <span class="hljs-built_in">clone</span> git://github.com/JuliaLang/julia-vim.git
<span class="hljs-built_in">cd</span> julia-vim
<span class="hljs-built_in">cp</span> -R * ~/.vim
</code></pre>
<p>Voilà qui devrait vous fournir la coloration syntaxique ainsi que l’indentation
pour les fichier dont l’extension et <code>.jl</code>.</p>
<h2>IJulia</h2>
<p>IJulia permet d’interfacer Julia à l’environnement de développement interactif
<strong>IPython</strong>. Cela permet notamment d’utiliser le mode <strong>notebook</strong>, qui combine
du code, du texte, et des contenus multimédias (dessin, etc.) dans un même
environnement. Pour l’installer vous aurez besoin d’avoir sur votre système :</p>
<ul>
<li><strong>IPython</strong> en version <code>1.0</code> ou supérieure</li>
<li><a href="http://jinja.pocoo.org/docs/" target="_blank" rel="noopener noreferrer">Jinja2</a>, <a href="http://www.tornadoweb.org/en/stable/" target="_blank" rel="noopener noreferrer">Tornado</a>, et <a href="https://github.com/zeromq/pyzmq" target="_blank" rel="noopener noreferrer">pyzmq</a></li>
</ul>
<p>Ensuite il faut installer le package IJulia depuis un prompt julia :</p>
<pre class="code" data-lang="julia"><code>$ julia
julia&gt; Pkg.add(<span class="hljs-string">&quot;IJulia&quot;</span>)
julia&gt; Pkg.update()
</code></pre>
<p>Une fois ceci fait, vous n’avez plus qu’à lancer IPython de la manière
suivante. Pour le mode notebook :</p>
<pre class="code" data-lang="sh"><code>ipython notebook --profile julia
</code></pre>
<p>Et voilà, le tour est joué. C’est tout pour cet article. Vous devriez
normalement avoir de quoi démarrer à programmer en Julia et exécuter
vos programmes. A bientôt pour de nouvelles aventures !</p>
<p>Afin de réaliser cet articles je me suis inspiré de la documentation présente
sur les dépôts officiels de <a href="https://github.com/JuliaLang/julia" target="_blank" rel="noopener noreferrer">Julia</a>,
<a href="https://github.com/JuliaLang/julia-vim" target="_blank" rel="noopener noreferrer">julia-vim</a> et
<a href="https://github.com/JuliaLang/IJulia.jl" target="_blank" rel="noopener noreferrer">IJulia</a>.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Julia]]></title>
            <link>https://remusao.github.io//posts/julia-intro.html</link>
            <guid>https://remusao.github.io//posts/julia-intro.html</guid>
            <pubDate>Thu, 13 Feb 2014 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Aujourd’hui j’aimerais parler d’un langage de programmation que je viens de
découvrir : <strong>Julia</strong>. Je vais donc vous le présenter succinctement et donner
mon ressenti après quelques jours d’utilisation.</p>
<h2>Qu’est-ce que c’est ?</h2>
<p>Le Julia est un langage :</p>
<ul>
<li><strong>Haut niveau</strong> (<em>garbage collection</em>)</li>
<li><strong>Dynamique</strong></li>
<li><strong>Interprété</strong></li>
<li><strong>Disposant d’un compilateur JIT</strong> (<em>backend LLVM</em>)</li>
<li><strong>Performant</strong></li>
</ul>
<p>Il s’agit d’un subtile mélange entre les langage <strong>Python</strong>, <strong>R</strong> et
<strong>Matlab</strong>. Python pour une partie de la syntaxe et les constructions élégantes du
langage (<em>list comprehension</em>, boucles <em>for</em>, etc.), Matlab et R pour l’intégration
des vecteurs, matrices et opérations associées dans la bibliothèque standard,
en faisant un langage particulièrement adapté pour l’analyse numérique, le
<em>machine learning</em>, et toute autre application nécessitant des outils d’algèbre
linéaire, et des fonctions mathématiques diverses.</p>
<pre class="code" data-lang="julia"><code><span class="hljs-comment"># Dynamic type</span>
a = <span class="hljs-number">42</span>          <span class="hljs-comment"># Int</span>
a = <span class="hljs-string">&quot;toto&quot;</span>      <span class="hljs-comment"># String</span>
a = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]   <span class="hljs-comment"># Vector</span>
a = [<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>]     <span class="hljs-comment"># 1x3 Matrix</span>
a = [<span class="hljs-number">1</span>:<span class="hljs-number">3</span>]       <span class="hljs-comment"># same 1x3 Matrix</span>

<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> a
    println(test)
<span class="hljs-keyword">end</span>

<span class="hljs-comment"># Output</span>
<span class="hljs-comment"># 1</span>
<span class="hljs-comment"># 2</span>
<span class="hljs-comment"># 3</span>
</code></pre>
<p>Julia dispose également des atouts suivants :</p>
<ul>
<li><strong>Multi-méthode</strong> permettant un dispatch dynamique en fonction du type des arguments passés aux fonctions</li>
</ul>
<pre class="code" data-lang="julia"><code><span class="hljs-comment"># Method declaration</span>
<span class="hljs-comment"># foo is a function taking one argument of any type</span>
<span class="hljs-keyword">function</span> foo(bar)
    println(bar)
    <span class="hljs-keyword">end</span>

<span class="hljs-comment"># Shorter function declaration</span>
baz(x) = println(x)

<span class="hljs-comment"># Multimethod</span>
<span class="hljs-comment"># Takes an argument of type Int (Haskelish syntax)</span>
myprint(x::<span class="hljs-built_in">Int</span>) = println(<span class="hljs-string">&quot;Int&quot;</span>)
<span class="hljs-comment"># Takes an argument of type Matrix (of any type)</span>
myprint(x::<span class="hljs-built_in">Matrix</span>) = println(<span class="hljs-string">&quot;Matrix&quot;</span>)
<span class="hljs-comment"># Take an argument of type Matrix of Float64</span>
myprint(x::<span class="hljs-built_in">Matrix</span>{<span class="hljs-built_in">Float64</span>}) = println(<span class="hljs-string">&quot;Matrix of Float64&quot;</span>)

myprint(<span class="hljs-number">42</span>)         <span class="hljs-comment"># First one is called</span>
myprint([<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>])    <span class="hljs-comment"># Second one is called</span>
myprint([<span class="hljs-number">0.5</span> <span class="hljs-number">0.42</span>]) <span class="hljs-comment"># Third one is called</span>
</code></pre>
<ul>
<li>Un système de <strong>template</strong> pour créer du code générique</li>
</ul>
<pre class="code" data-lang="julia"><code><span class="hljs-keyword">function</span> printtype(m)
    println(<span class="hljs-string">&quot;Any type&quot;</span>)
<span class="hljs-keyword">end</span>

<span class="hljs-comment"># Takes argument of type T, in julia a type</span>
<span class="hljs-comment"># is an object, so you can print it</span>
<span class="hljs-keyword">function</span> printtype{T}(m::T)
    println(T)
<span class="hljs-keyword">end</span>

<span class="hljs-comment"># Takes an argument of type T, with the constraint FloatingPoint</span>
<span class="hljs-keyword">function</span> printtype{T &lt;: FloatingPoint}(m::T)
    println(<span class="hljs-string">&quot;Floating Point&quot;</span>)
<span class="hljs-keyword">end</span>

printtype(<span class="hljs-number">42</span>)
printtype(<span class="hljs-number">0.42</span>)
</code></pre>
<ul>
<li>Des <strong>expressions rationnelles</strong> compatible Perl</li>
<li>Des <strong>macros</strong> à la Lisp grâce à l’auto-iconicité du langage</li>
<li>La possibilité de lancer des <strong>commandes Shell</strong>, de piper, etc.</li>
<li><strong>Interfaçage avec le C</strong> sans bindings (simple utilisation de ccall comme une fonction)</li>
</ul>
<pre class="code" data-lang="julia"><code><span class="hljs-comment"># Simple function that wrap a call to libc clock function</span>
clock() = <span class="hljs-keyword">ccall</span>( (:clock, <span class="hljs-string">&quot;libc&quot;</span>), <span class="hljs-built_in">Int32</span>, ())

t = clock()

<span class="hljs-comment"># Do some stuff</span>

println(clock() - t)
</code></pre>
<ul>
<li><strong>Duck-typing</strong> mais possibilité de spécifier les types</li>
<li><strong>Parallélisation</strong> du code aisée en multithreading sur une unique machine ou sur un cluster (tasks, parallel for, etc.)</li>
</ul>
<p>Cet article n’a pas pour but d’être exhaustif à propos de Julia, pour plus
d’exemples je vous redirige vers le documentation officielle du langage :
<a href="http://docs.julialang.org/en/latest/manual/" target="_blank" rel="noopener noreferrer">Documentation</a>.</p>
<h2>Pourquoi l’utiliser ?</h2>
<p>Julia est un langage jeune mais dynamique. Il est pour le moment peu utilisé
mais il gagne à être connu. Grâce aux avantages cités ci-dessus, c’est un
parfait candidat pour tous les projets nécessitant :</p>
<ul>
<li><strong>Performances</strong> (compilation JIT),</li>
<li><strong>Bibliothèque standard</strong> très riche : <em>algèbre linéaire</em>, <em>fonctions mathématiques</em> diverses, etc.</li>
<li>Rassemble les qualités de plusieurs langages bien connus (Matlab, R, Python)</li>
</ul>
<p>Il est très aisé de convertir du code Matlab ou Python vers du Julia car les
différences sont assez peu nombreuses. La manipulation de matrice est très
similaire à celle de Matlab.</p>
<h2>Défauts de jeunesse</h2>
<p>Néanmoins le langage dispose de quelques points faibles, sans doute liés à sa
jeunesse et au manque de projets l’utilisant. Mis à part la richesse de sa
bibliothèque standard, les packages sont encore relativement peu nombreux et
donc selon le projet vous ne trouverez pas forcément les outils nécessaires
(par exemple pour du traitement d’image, il n’existe pas de binding ou
d’équivalent à OpenCV, des packages existent mais les fonctionnalités sont
encore limitées).</p>
<p>L’interpréteur met du temps à se lancer. Selon les ressources de la machine
que vous utilisez cela peut aller de 2-3 secondes à 30 secondes (sur mon
ordinateur portable peu puissant). Bien sûr il est possible de lancer une
session de l’interpréteur une bonne fois pour toutes et de travailler depuis
le prompt, mais cela reste gênant quand vous voulez simplement lancer un
script. Néanmoins, cela devrait s’améliorer à l’avenir, espérons-le, le
langage est encore en phase de release candidate.</p>
<p>Voilà pour cette rapide introduction du langage Julia, cet article n’avait
pas pour but d’être un tutoriel, mais juste de faire connaitre un projet qui
semble avoir de l’avenir. Il est possible que j’utilise ce langage dans mes
prochains articles pour les démonstrations de code.</p>
<p>Quelques ressources supplémentaires :</p>
<ul>
<li><a href="https://github.com/JuliaLang/julia" target="_blank" rel="noopener noreferrer">Github</a></li>
<li><a href="http://docs.julialang.org/en/latest/manual/" target="_blank" rel="noopener noreferrer">Documentation</a></li>
<li><a href="http://julialang.org/" target="_blank" rel="noopener noreferrer">Site officiel</a></li>
</ul>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[C++—Composition de fonctions]]></title>
            <link>https://remusao.github.io//posts/cpp-function-composition.html</link>
            <guid>https://remusao.github.io//posts/cpp-function-composition.html</guid>
            <pubDate>Thu, 30 May 2013 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Lorsque l’on a gouté aux joies des langages fonctionnels, ou que
l’on vient du monde des mathématiques, ou les deux, on est souvent
habitué à “chainer” des appels de fonctions entre eux. Par exemple, si
nous disposons de <code>n</code> fonctions de prototypes suivants :</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">f1</span> :: <span class="hljs-type">T1</span> -&gt; <span class="hljs-type">T2</span>
<span class="hljs-title">f2</span> :: <span class="hljs-type">T2</span> -&gt; <span class="hljs-type">T3</span>
...
<span class="hljs-title">fm</span> :: <span class="hljs-type">Tm</span> -&gt; <span class="hljs-type">Tn</span>
<span class="hljs-title">fn</span> :: <span class="hljs-type">Tn</span> -&gt; <span class="hljs-type">To</span>
</code></pre>
<p>Nous aimerions pouvoir les composer de la manière suivante :</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">fn</span> o fm o ... o f2 o f1
</code></pre>
<p>Ce qui dans un langage comme C++ nous obligerait à faire :</p>
<pre class="code" data-lang="c++"><code><span class="hljs-keyword">auto</span> res1 = <span class="hljs-built_in">f1</span>(arg);
<span class="hljs-keyword">auto</span> res2 = <span class="hljs-built_in">f2</span>(res1);
...
<span class="hljs-keyword">auto</span> resn = <span class="hljs-built_in">fn</span>(resm);
</code></pre>
<p>Ce qui est assez peu élégant. De plus, nous pourrions avoir envie
qu’il n’y ait pas de copie dans les différents passages de
paramètres (ce que nous pouvons faire en passant les arguments par
référence, ou en utilisant un <em>move semantic</em>). Puisque nous ne
faisons rien des résultats intermédiaires, nous aimerions disposer
d’une fonction, qui prendrait les fonctions en arguments, ainsi que
l’argument à donner à la première fonction, et s’occuperait de
faire les appels successifs, tout en passant les arguments par move
semantic ou référence. Une telle fonction peut-être créée en <code>c++11</code>,
voici une solution possible.</p>
<p>L’idée est assez simple, nous utilisons un template récursif qui
correspond a peu de choses près à la fonction suivante, le reste
n’est que du surplut visant à propager les types et déterminer le
type de retour des fonctions (avec <code>std::result_of</code>) :</p>
<pre class="code" data-lang="c++"><code><span class="hljs-built_in">pipeline</span>(arg, f1, f_suivantes) = <span class="hljs-built_in">pipeline</span>(<span class="hljs-built_in">f1</span>(arg), f_suivantes)
</code></pre>
<p>Et enfin voici le code C++ correspondant :</p>
<pre class="code" data-lang="c++"><code><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> PIPELINE_HH_</span>
<span class="hljs-meta"># <span class="hljs-keyword">define</span> PIPELINE_HH_</span>

<span class="hljs-keyword">namespace</span>
{
    <span class="hljs-comment">//</span>
    <span class="hljs-comment">// Extends the behavior of std::result_of for pipelines of function,</span>
    <span class="hljs-comment">// setting field type to the type returned by the last function of</span>
    <span class="hljs-comment">// the pipeline.</span>
    <span class="hljs-comment">//</span>
    <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> In, <span class="hljs-keyword">typename</span> F, <span class="hljs-keyword">typename</span> ...Args&gt;
    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">result_of</span> : <span class="hljs-keyword">public</span> result_of&lt;<span class="hljs-keyword">typename</span> std::result_of&lt;<span class="hljs-built_in">F</span>(In)&gt;::type, Args...&gt; {};

    <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> In, <span class="hljs-keyword">typename</span> F&gt;
    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">result_of</span>&lt;In, F&gt;
    {
        <span class="hljs-keyword">typedef</span> <span class="hljs-keyword">typename</span> std::result_of&lt;<span class="hljs-built_in">F</span>(In)&gt;::type type;
    };
}


<span class="hljs-comment">//</span>
<span class="hljs-comment">// Pipeline of function</span>
<span class="hljs-comment">// usage : pipeline(T arg, f1, f2, ..., fn) with:</span>
<span class="hljs-comment">// f1: T -&gt; T1</span>
<span class="hljs-comment">// f2: T1 -&gt; T2</span>
<span class="hljs-comment">// ...</span>
<span class="hljs-comment">// fn: Tn -&gt; Tm</span>
<span class="hljs-comment">// returns the result of fn(...f2(f1(arg)))</span>
<span class="hljs-comment">//</span>
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> In&gt;
<span class="hljs-function">In <span class="hljs-title">pipeline</span><span class="hljs-params">(In&amp;&amp; a)</span>
</span>{
    <span class="hljs-keyword">return</span> std::forward&lt;In&gt;(a);
}

<span class="hljs-keyword">template</span> &lt;
    <span class="hljs-keyword">typename</span> In,
    <span class="hljs-keyword">typename</span> Function&gt;
<span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">pipeline</span><span class="hljs-params">(In&amp;&amp; a, Function f)</span> -&gt; <span class="hljs-title">decltype</span> <span class="hljs-params">(f(std::forward&lt;In&gt;(a)))</span>
</span>{
    <span class="hljs-keyword">return</span> <span class="hljs-built_in">f</span>(std::forward&lt;In&gt;(a));
}

<span class="hljs-keyword">template</span> &lt;
    <span class="hljs-keyword">typename</span> In,
    <span class="hljs-keyword">typename</span> Function,
    <span class="hljs-keyword">typename</span> ...Args&gt;
<span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">pipeline</span><span class="hljs-params">(In&amp;&amp; a, Function f, Args... args)</span> -&gt; <span class="hljs-keyword">typename</span> result_of&lt;In, Function, Args...&gt;::type
</span>{
    <span class="hljs-keyword">return</span> pipeline&lt;<span class="hljs-keyword">decltype</span> (<span class="hljs-built_in">f</span>(std::forward&lt;In&gt;(a)))&gt;(<span class="hljs-built_in">f</span>(std::forward&lt;In&gt;(a)), args...);
}

<span class="hljs-meta">#<span class="hljs-keyword">endif</span> <span class="hljs-comment">/* !PIPELINE_HH_ */</span></span>
</code></pre>
<p>N’hésitez pas à me faire part de vos remarques.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[XMonad]]></title>
            <link>https://remusao.github.io//posts/xmonad.html</link>
            <guid>https://remusao.github.io//posts/xmonad.html</guid>
            <pubDate>Thu, 14 Feb 2013 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Étant utilisateur de GNU/Linux depuis quelques années maintenant,
j’ai eu l’occasion de tester quelques distributions et quelques
environnements de bureau. Parmi les distributions je suis passé par
Ubuntu, Debian, Fedora pour enfin essayer Archlinux, que je n’ai plus
quitté depuis. En terme d’environnement c’est un peu la même
chose, gnome, xfce, lxde, openbox puis Awesome que j’ai utilisé
pendant une année. Je n’ai jamais trop cherché à modifier la
configuration par défaut, qui me convenait plutôt bien. Puis je me
suis mis au Haskell, et avec lui des envies de refaire le monde, des
envies de pureté, des envies de paresse (enfin pas tant que ça !), et
j’ai ouï dire qu’il existait un gestionnaire de fenêtre écrit
avec ce fabuleux langage : XMonad !</p>
<h2>Présentation de XMonad</h2>
<p>XMonad est un gestionnaire de fenêtre de style « tiling » (c’est
à dire qu’il est capable de gérer tout seul la disposition des
fenêtres afin d’optimiser l’espace). Il est léger, épuré, très
minimaliste. En fait la première fois qu’on le lance il n’y a rien,
à part un curseur de souri ! C’est un bon début. A la différence
d’Awesome qui propose tout de même un minimum syndical (une barre de
tâches, une vue des différents tags, l’heure…). Sur XMonad rien
de tout ça. J’ai vraiment eu l’impression qu’on me fournissait
des briques de base, et qu’ensuite c’était à moi de jouer pour me
construire mon propre gestionnaire de fenêtre, et c’est en quelque
sorte ce que j’ai fait. Heureusement les ressources se trouvent assez
facilement sur internet, à partir de la documentation, d’articles et
d’exemples, on parvient à créer un petit environnement douillet en
quelques heures (à condition de connaitre quelques bribes de Haskell,
car oui, XMonad se configure en Haskell !). Au final, il n’y a pas à
dire, c’est un gestionnaire de fenêtre fonctionnel.</p>
<h2>Installation</h2>
<p>Pour les utilisateur de Archlinux il suffit d’exécuter la commande
suivante ! Pour les autres, un petit tour par la documentation de votre
distribution favorite devrait vous éguiller.</p>
<pre class="code" data-lang="sh"><code>$ pacman -S xmonad xmonad-contrib
</code></pre>
<h2>Configuration</h2>
<p>Venons-en aux sujets qui fâchent, à savoir, la configuration. Comme
dit un peu plus haut, ça se fait en utilisant le langage Haskell et
on place tout ça dans un fichier nommé xmonad.hs dans un dossier
~/.xmonad. Puisque c’est du Haskell, vous l’aurez deviné, ça
se compile. Heureusement cela se fait à chaud, sans avoir besoin de
quitter XMonad, ce qui est très appréciable. Grâce au raccourci Mod</p>
<ul>
<li>q le fichier de configuration est recompilé, si il est correct il
est appliqué à chaud, sinon une fenêtre s’ouvre vous indiquant les
éventuelles erreurs, et l’ancienne configuration est conservée.
Comme ça, pas de risque de casser votre environnement en le modifiant
en cours d’utilisation.</li>
</ul>
<p>Je vais vous présenter ma configuration actuelle, qui est assez
basique, mais comble amplement mes attentes. Ensuite je vais détailler
quelques points importants.</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">{- Config of berson_r -}</span>

<span class="hljs-keyword">import</span> System.Exit
<span class="hljs-keyword">import</span> System.IO
<span class="hljs-keyword">import</span> XMonad
<span class="hljs-keyword">import</span> XMonad.Actions.CycleWS
<span class="hljs-keyword">import</span> XMonad.Actions.GridSelect
<span class="hljs-keyword">import</span> XMonad.Hooks.DynamicLog
<span class="hljs-keyword">import</span> XMonad.Hooks.ManageDocks
<span class="hljs-keyword">import</span> XMonad.Layout.Fullscreen
<span class="hljs-keyword">import</span> XMonad.Layout.NoBorders
<span class="hljs-keyword">import</span> XMonad.Layout.Spiral
<span class="hljs-keyword">import</span> XMonad.Layout.Tabbed
<span class="hljs-keyword">import</span> XMonad.Util.EZConfig(<span class="hljs-title">additionalKeys</span>)
<span class="hljs-keyword">import</span> XMonad.Util.Run(<span class="hljs-title">spawnPipe</span>)
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.Map        <span class="hljs-keyword">as</span> M
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> XMonad.StackSet <span class="hljs-keyword">as</span> W


<span class="hljs-comment">-- Main</span>
<span class="hljs-title">main</span> = <span class="hljs-keyword">do</span>
    xmproc &lt;- spawnPipe <span class="hljs-string">&quot;xmobar /home/berson_r/.xmobarrc&quot;</span> <span class="hljs-comment">-- lance xmobar avec le bon fichier de config</span>
    spawn <span class="hljs-string">&quot;nitrogen --restore&quot;</span> <span class="hljs-comment">-- affiche le fond d&#x27;écran</span>
    xmonad $ defaultConfig { <span class="hljs-comment">-- redéfinition de certaines options de XMonad</span>
    <span class="hljs-comment">-- simple stuff</span>
    terminal           = myTerminal,
    modMask            = myModMask,
    workspaces         = myWorkspaces,
    normalBorderColor  = myNormalBorderColor,
    focusedBorderColor = myFocusedBorderColor,

    <span class="hljs-comment">-- key bindings</span>
    keys               = myKeys,
    <span class="hljs-comment">-- mouseBindings      = myMouseBindings,</span>

    <span class="hljs-comment">-- hooks, layouts</span>
    layoutHook         = smartBorders $ myLayout,
    manageHook         = myManageHook,
    logHook            = myLogHook xmproc,
    startupHook        = myStartupHook
    }


<span class="hljs-comment">-- Binding for the mod key</span>
<span class="hljs-title">myModMask</span> :: <span class="hljs-type">KeyMask</span>
<span class="hljs-title">myModMask</span> = mod4Mask

<span class="hljs-comment">-- Default terminal to use</span>
<span class="hljs-title">myTerminal</span> :: <span class="hljs-type">String</span>
<span class="hljs-title">myTerminal</span> = <span class="hljs-string">&quot;urxvt&quot;</span>

<span class="hljs-comment">-- Names of the workspaces</span>
<span class="hljs-title">myWorkspaces</span> :: [<span class="hljs-type">String</span>]
<span class="hljs-title">myWorkspaces</span> = [<span class="hljs-string">&quot;term&quot;</span>, <span class="hljs-string">&quot;web&quot;</span>, <span class="hljs-string">&quot;mail&quot;</span>, <span class="hljs-string">&quot;music&quot;</span>] ++ (map show [<span class="hljs-number">5</span>..<span class="hljs-number">9</span>])

<span class="hljs-comment">-- Color of normal borders</span>
<span class="hljs-title">myNormalBorderColor</span> :: <span class="hljs-type">String</span>
<span class="hljs-title">myNormalBorderColor</span>  = <span class="hljs-string">&quot;#7c7c7c&quot;</span>

<span class="hljs-comment">-- Color of the selected window&#x27;s borders</span>
<span class="hljs-title">myFocusedBorderColor</span> :: <span class="hljs-type">String</span>
<span class="hljs-title">myFocusedBorderColor</span> = <span class="hljs-string">&quot;#ffb6b0&quot;</span>

<span class="hljs-comment">-- Color of current window title in xmobar.</span>
<span class="hljs-title">xmobarTitleColor</span> :: <span class="hljs-type">String</span>
<span class="hljs-title">xmobarTitleColor</span> = <span class="hljs-string">&quot;#FFB6B0&quot;</span>

<span class="hljs-comment">-- -- Color of current workspace in xmobar.</span>
<span class="hljs-title">xmobarCurrentWorkspaceColor</span> :: <span class="hljs-type">String</span>
<span class="hljs-title">xmobarCurrentWorkspaceColor</span> = <span class="hljs-string">&quot;#CEFFAC&quot;</span>

<span class="hljs-comment">-- Custom layout</span>
<span class="hljs-title">myLayout</span> = avoidStruts (
    <span class="hljs-type">Tall</span> <span class="hljs-number">1</span> (<span class="hljs-number">3</span>/<span class="hljs-number">100</span>) (<span class="hljs-number">1</span>/<span class="hljs-number">2</span>) |||
    <span class="hljs-type">Mirror</span> (<span class="hljs-type">Tall</span> <span class="hljs-number">1</span> (<span class="hljs-number">3</span>/<span class="hljs-number">100</span>) (<span class="hljs-number">1</span>/<span class="hljs-number">2</span>)) |||
    tabbed shrinkText tabConfig |||
    <span class="hljs-type">Full</span> |||
    spiral (<span class="hljs-number">6</span>/<span class="hljs-number">7</span>)) |||
    noBorders (fullscreenFull <span class="hljs-type">Full</span>)

<span class="hljs-comment">-- Colors for text and backgrounds of each tab when in &quot;Tabbed&quot; layout.</span>
<span class="hljs-title">tabConfig</span> = defaultTheme {
    activeBorderColor = <span class="hljs-string">&quot;#7C7C7C&quot;</span>,
    activeTextColor = <span class="hljs-string">&quot;#CEFFAC&quot;</span>,
    activeColor = <span class="hljs-string">&quot;#000000&quot;</span>,
    inactiveBorderColor = <span class="hljs-string">&quot;#7C7C7C&quot;</span>,
    inactiveTextColor = <span class="hljs-string">&quot;#EEEEEE&quot;</span>,
    inactiveColor = <span class="hljs-string">&quot;#000000&quot;</span>
}


<span class="hljs-title">myStartupHook</span> = return ()

<span class="hljs-comment">-- Custom rules</span>
<span class="hljs-title">myManageHook</span> :: <span class="hljs-type">ManageHook</span>
<span class="hljs-title">myManageHook</span> = composeAll
    [ className =? <span class="hljs-string">&quot;Chromium&quot;</span>       --&gt; doShift <span class="hljs-string">&quot;web&quot;</span>
    , className =? <span class="hljs-string">&quot;Firefox&quot;</span>        --&gt; doShift <span class="hljs-string">&quot;web&quot;</span>
    , className =? <span class="hljs-string">&quot;Uzbl-core&quot;</span>      --&gt; doShift <span class="hljs-string">&quot;web&quot;</span>
    , className =? <span class="hljs-string">&quot;Thunderbird&quot;</span>    --&gt; doShift <span class="hljs-string">&quot;mail&quot;</span>
    , className =? <span class="hljs-string">&quot;Spotify&quot;</span>        --&gt; doShift <span class="hljs-string">&quot;music&quot;</span>
    , className =? <span class="hljs-string">&quot;Vlc&quot;</span>            --&gt; doFloat
    , className =? <span class="hljs-string">&quot;Steam&quot;</span>          --&gt; doFloat
    , className =? <span class="hljs-string">&quot;Gimp&quot;</span>           --&gt; doFloat
    , manageDocks]
<span class="hljs-comment">--    , isFullscreen --&gt; (doF W.focusDown &lt;+&gt; doFullFloat)]</span>

<span class="hljs-title">myLogHook</span> :: <span class="hljs-type">Handle</span> -&gt; <span class="hljs-type">X</span> ()
<span class="hljs-title">myLogHook</span> xmproc = dynamicLogWithPP xmobarPP {
    ppOutput = hPutStrLn xmproc,
    ppTitle = xmobarColor <span class="hljs-string">&quot;green&quot;</span> <span class="hljs-string">&quot;&quot;</span> . shorten <span class="hljs-number">50</span>
}


<span class="hljs-comment">-- Key bindings --</span>
<span class="hljs-title">myKeys</span> conf@(<span class="hljs-type">XConfig</span> {<span class="hljs-type">XMonad</span>.modMask = modMask}) = <span class="hljs-type">M</span>.fromList $

  <span class="hljs-comment">-- Custom key bindings</span>

  [ ((modMask .|. shiftMask, xK_Return), spawn $ <span class="hljs-type">XMonad</span>.terminal conf) <span class="hljs-comment">-- start term</span>
  , ((modMask, xK_r), spawn <span class="hljs-string">&quot;exe=`dmenu_path_c | yeganesh` &amp;&amp; eval \&quot;exec $exe\&quot;&quot;</span>) <span class="hljs-comment">-- dmenu</span>
  , ((modMask .|. controlMask, xK_m), spawn <span class="hljs-string">&quot;amixer -q set Master toggle&quot;</span>) <span class="hljs-comment">-- mute volume</span>
  , ((modMask .|. controlMask, xK_j), spawn <span class="hljs-string">&quot;amixer -q set Master 10%-&quot;</span>) <span class="hljs-comment">-- dec volume</span>
  , ((modMask .|. controlMask, xK_k), spawn <span class="hljs-string">&quot;amixer -q set Master 10%+&quot;</span>) <span class="hljs-comment">-- inc volume</span>
  , ((modMask, xK_g), goToSelected defaultGSConfig) <span class="hljs-comment">-- display selection grid</span>
  <span class="hljs-comment">-- workspaces</span>
  , ((modMask, xK_Right), nextWS)
  , ((modMask .|. shiftMask, xK_Right), shiftToNext)
  , ((modMask, xK_Left), prevWS)
  , ((modMask .|. shiftMask, xK_Left), shiftToPrev)

  <span class="hljs-comment">-- &quot;Standard&quot; xmonad key bindings</span>

  , ((modMask .|. shiftMask, xK_c), kill) <span class="hljs-comment">-- close selected window</span>
  , ((modMask, xK_space), sendMessage <span class="hljs-type">NextLayout</span>) <span class="hljs-comment">-- change layout</span>
  , ((modMask .|. shiftMask, xK_space), setLayout $ <span class="hljs-type">XMonad</span>.layoutHook conf) <span class="hljs-comment">-- reset layout</span>
  , ((modMask, xK_n), refresh) <span class="hljs-comment">-- resize windows to the correct size</span>
  , ((modMask, xK_Tab), windows <span class="hljs-type">W</span>.focusDown) <span class="hljs-comment">-- move focus to next window</span>
  , ((modMask, xK_j),   windows <span class="hljs-type">W</span>.focusDown) <span class="hljs-comment">-- move focus to next window</span>
  , ((modMask, xK_k),   windows <span class="hljs-type">W</span>.focusUp)   <span class="hljs-comment">-- move focus to previous window</span>
  , ((modMask, xK_m),   windows <span class="hljs-type">W</span>.focusMaster) <span class="hljs-comment">-- move focus to master window</span>
  , ((modMask, xK_Return), windows <span class="hljs-type">W</span>.swapMaster) <span class="hljs-comment">-- swap focused and master window</span>
  , ((modMask .|. shiftMask, xK_j), windows <span class="hljs-type">W</span>.swapDown) <span class="hljs-comment">-- swap focused and next window</span>
  , ((modMask .|. shiftMask, xK_k), windows <span class="hljs-type">W</span>.swapUp) <span class="hljs-comment">-- swap focused and previous window</span>

  <span class="hljs-comment">-- Shrink the master area.</span>
  , ((modMask, xK_h),
     sendMessage <span class="hljs-type">Shrink</span>)

  <span class="hljs-comment">-- Expand the master area.</span>
  , ((modMask, xK_l),
     sendMessage <span class="hljs-type">Expand</span>)

  <span class="hljs-comment">-- Push window back into tiling.</span>
  , ((modMask, xK_t),
     withFocused $ windows . <span class="hljs-type">W</span>.sink)

  <span class="hljs-comment">-- Increment the number of windows in the master area.</span>
  , ((modMask, xK_comma),
     sendMessage (<span class="hljs-type">IncMasterN</span> <span class="hljs-number">1</span>))

  <span class="hljs-comment">-- Decrement the number of windows in the master area.</span>
  , ((modMask, xK_period),
     sendMessage (<span class="hljs-type">IncMasterN</span> (-<span class="hljs-number">1</span>)))

  <span class="hljs-comment">-- Toggle the status bar gap.</span>
  <span class="hljs-comment">-- <span class="hljs-doctag">TODO:</span> update this binding with avoidStruts, ((modMask, xK_b),</span>

  <span class="hljs-comment">-- Quit xmonad.</span>
  , ((modMask .|. shiftMask, xK_q),
     io (exitWith <span class="hljs-type">ExitSuccess</span>))

  <span class="hljs-comment">-- Restart xmonad.</span>
  , ((modMask, xK_q),
     restart <span class="hljs-string">&quot;xmonad&quot;</span> <span class="hljs-type">True</span>)
  ]
  ++

  <span class="hljs-comment">-- mod-[1..9], Switch to workspace N</span>
  <span class="hljs-comment">-- mod-shift-[1..9], Move client to workspace N</span>
  [((m .|. modMask, k), windows $ f i)
      | (i, k) &lt;- zip (<span class="hljs-type">XMonad</span>.workspaces conf) [xK_1 .. xK_9]
      , (f, m) &lt;- [(<span class="hljs-type">W</span>.greedyView, <span class="hljs-number">0</span>), (<span class="hljs-type">W</span>.shift, shiftMask)]]
  ++

  <span class="hljs-comment">-- mod-{w,e,r}, Switch to physical/Xinerama screens 1, 2, or 3</span>
  <span class="hljs-comment">-- mod-shift-{w,e,r}, Move client to screen 1, 2, or 3</span>
  [((m .|. modMask, key), screenWorkspace sc &gt;&gt;= flip whenJust (windows . f))
      | (key, sc) &lt;- zip [xK_w, xK_e, xK_p] [<span class="hljs-number">0</span>..]
      , (f, m) &lt;- [(<span class="hljs-type">W</span>.view, <span class="hljs-number">0</span>), (<span class="hljs-type">W</span>.shift, shiftMask)]]
</code></pre>
<p>Globalement, on peut résumer l’organisation du fichier de configuration comme ceci :</p>
<ol>
<li>Les imports permettant de faire appel à des fonctionnalités de
XMonad, ou toute autre bibliothèque Haskell (car vous pouvez vraiment
mettre n’importe quoi dans votre fichier de configuration, si vous
le vouliez vous pourriez coder factorielle, Fibonacci et un crible
d’Ératosthène pour les afficher dans votre barre des tâches, aucun
problème !).</li>
<li>Des redéfinitions d’options ou de comportements sous forme de constantes.</li>
<li>Une fonction Main qui regroupe tout ceci et spécifie à XMonad
toutes les options, et les comportements que vous désirez. Globalement
vous pourrez quasiment tout modifier via un type enregistrement. Les
champs non spécifiés auront leur valeur par défaut, on se contente
donc de spécifier ce qui nous intéresse.</li>
</ol>
<h2>Barre d’état</h2>
<p>Par défaut, XMonad ne dispose pas d’une barre des tâches. Il en
existe une qui est également en Haskell et qui s’intègre très
simplement avec XMonad, il s’agit de XMobar. Elle est très légère
et permettra de répondre à la plupart des besoins. Il suffit pour la
mettre en place de :</p>
<ol>
<li>Disposer d’un fichier de configuration situé ici : <code>~/.xmobarrc</code>
(vous trouverez le mien un peu plus bas)</li>
<li>Rajouter la ligne : <code>xmproc &lt;- spawnPipe &quot;xmobar /home/berson_r/.xmobarrc</code>
en haut de votre fonction main (cf mon fichier de configuration ci-dessus).</li>
<li>Indiquer quelles informations XMonad doit transmettre à XMobar
lors de l’exécution (les workspaces par exemple). Pour ceci il faut
redéfinir le myLogHook dans le main, je vous invite encore une fois à
regarder mon exemple donné un peu plus haut.</li>
</ol>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Config</span> { font = <span class="hljs-string">&quot;-*-Fixed-Bold-R-Normal-*-13-*-*-*-*-*-*-*&quot;</span>
, bgColor = <span class="hljs-string">&quot;black&quot;</span>
, fgColor = <span class="hljs-string">&quot;grey&quot;</span>
, position = <span class="hljs-type">TopW</span> <span class="hljs-type">L</span> <span class="hljs-number">90</span>
, lowerOnStart = <span class="hljs-type">True</span>
, commands = [ <span class="hljs-type">Run</span> <span class="hljs-type">Date</span> <span class="hljs-string">&quot;%a %b %_d %H:%M&quot;</span> <span class="hljs-string">&quot;date&quot;</span> <span class="hljs-number">10</span>
, <span class="hljs-type">Run</span> <span class="hljs-type">StdinReader</span>
]
, sepChar = <span class="hljs-string">&quot;%&quot;</span>
, alignSep = <span class="hljs-string">&quot;}{&quot;</span>
, template = <span class="hljs-string">&quot;%StdinReader% }{ &lt;fc=#ee9a00&gt;%date%&lt;/fc&gt; =&lt;&lt;&quot;</span>
}
</code></pre>
<p>Attention, contrairement aux apparences, ce n’est pas du Haskell,
donc ne mettez pas de commentaires dans ce fichier. Une fois les deux
étapes décrites plus hauts effectuées, xmobar devrait s’afficher au
lancement de XMonad. Vous remarquerez qu’il affiche les workspaces,
l’application qui a le focus, l’heure, la date et … c’est tout.
En plus il y a un espace de 10% de la taille de l’écran sur la
droite. Il servira à mettre un trayer. C’est justement l’objet de
la section suivante.</p>
<h2>System Tray</h2>
<p>Par défaut, ni XMonad ni xmobar ne proposent un « trayer », où vous
pourriez voir les icônes des applications en cours d’exécution.
Pour cela j’utilise trayer, qui est très léger et facile à mettre
en place. En fait, une fois qu’on lui a réservé une petite place
(ce qui est notre cas), il suffit de le lancer avec les bonnes options
depuis notre .xinitrc (ou .Xsessions). Voici la commande telle que je
l’utilise :</p>
<pre class="code" data-lang="sh"><code>trayer --SetDockType <span class="hljs-literal">true</span>       \
       --SetPartialStrut <span class="hljs-literal">true</span>   \
       --align right            \
       --alpha 0                \
       --edge top               \
       --<span class="hljs-built_in">expand</span> <span class="hljs-literal">true</span>            \
       --height 12              \
       --heighttype pixel       \
       --tint 0x000000          \
       --transparent <span class="hljs-literal">true</span>       \
       --width 10 &amp;
</code></pre>
<h2>Fond d’écran</h2>
<p>Vous l’aurez compris, XMonad ne propose pas non plus par défaut
d’utilitaire pour changer l’image ou la couleur du fond d’écran.
Mais il est relativement simple d’en mettre un en place. J’ai
personnellement utilisé nitrogen. Il est très simple à utiliser, la
première fois il suffit de le lancer à la main et d’aller chercher
le fond d’écran désiré. Ensuite, il suffira de le relancer à
chaque démmarage avec la commande :</p>
<pre class="code" data-lang="sh"><code>nitrogen --restore &amp;
</code></pre>
<p>Et c’est exactement le rôle de la ligne 23 dans la fonction main du
fichier <code>xmonad.hs</code> :</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">spawn</span> <span class="hljs-string">&quot;nitrogen --restore&quot;</span>
</code></pre>
<h2>Raccourcies clavier utiles</h2>
<p>Le seul raccourci qu’il me manquait afin que ce soit parfait, était
le <code>« mod + flèche »</code> afin de se déplacer sur le workspace de droite
ou de gauche. Pour ce faire, il suffit de rajouter les lignes suivantes
dans le tableau des raccourcis personnalisés :</p>
<pre class="code" data-lang="haskell"><code>, ((modMask, xK_Right), nextWS)
, ((modMask .|. shiftMask, xK_Right), shiftToNext)
, ((modMask, xK_Left), prevWS)
, ((modMask .|. shiftMask, xK_Left), shiftToPrev)
</code></pre>
<p>Il y a d’autres options que je n’ai pas détaillées dans cet
article, mais j’ai laissé quelques commentaires dans le fichier de
configuration afin de guider la compréhension. Si jamais ils ne sont
pas suffisents, n’hésitez pas à laisser un commentaire pour poser
une question, ou faire une remarque.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Sciences et critique]]></title>
            <link>https://remusao.github.io//posts/science-et-critique.html</link>
            <guid>https://remusao.github.io//posts/science-et-critique.html</guid>
            <pubDate>Wed, 13 Feb 2013 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Une récente réflexion personnelle m’a amené à considérer
l’influence de l’étude des sciences (mathématiques, physiques,
etc.) sur la capacité à être critique, à faire preuve de
discernement dans la vie des tous les jours. Je prendrai ici appui sur
l’exemple des mathématiques afin d’étayer mon propos, mais le
parallèle avec d’autres sciences est possible.</p>
<p>Je vais donc essayer de présenter quelques traits de caractère, ou
habitudes et montrer en quoi ils peuvent être éveillés et entretenus
par les sciences, et encourager une vision critique et une prise de
recul par rapport aux informations glanées quotidiennement.</p>
<h2>Le doute</h2>
<p>Il est arrivé dans l’histoire des mathématiques que les
mathématiciens, parmi les plus talentueux, en se fiant à leur
instinct, à leur intuition, énoncent des vérités erronées. C’est
en particulier Bourbaki qui écrivit [1] (peut-être pas en premier)
que pour mener un travail rigoureux en mathématiques, il ne fallait
pas écouter son intuition, car celle-ci se trouve souvent impuissante
face à l’abstraction et l’inconnu, en revanche, il est en général
sûr de se fier à des axiomes et des raisonnements logiques rigoureux
afin de cheminer dans l’abstrait. Vous vous demandez peut-être le
lien entre ce que vous venez de lire et le « doute ». Je pense que
pour éviter les pièges, éviter de se tromper en croyant avoir affaire
à l’évidence, il faut tout remettre en doute, y compris sa propre
intuition. C’est ce que les sciences m’ont appris, et c’est ce
que j’ai pris le réflexe de mettre en pratique quotidiennement.
Si l’on commence à remettre en doute même ses intuitions, on est
capable de tout remettre en doute, y compris les autres. Attention,
remettre en doute ne signifie pas rejeter l’autre et son propos,
mais juste procéder à une mise à l’épreuve de l’information
que l’on reçoit. J’entends trop régulièrement des proches
m’énoncer des faits, sortis de nulle part, et qui en cherchant un
peu, se révèlent être faux, mais quand on a lu quelque chose, ou si
on l’a vu à la télévision, c’est que ça doit être vrai… Il
faut chercher l’argumentation, et se ramener à des bases solides,
à un raisonnement, à une logique, presqu’à une démonstration, et
c’est ce qui m’amène au point suivant, la rigueur.</p>
<h2>La rigueur</h2>
<p>La rigueur des sciences, la rigueur mathématique, est un allié
précieux lorsqu’il s’agit de traquer et de démasquer le faux,
déguisé en évidence. La pratique régulière des sciences, en
particulier des mathématiques, pousse à cette rigueur, et c’est
ce qui est reposant avec elles, c’est qu’une fois un théorème
prouvé rigoureusement, il est vrai. Modulo l’erreur inhérente
à l’être humain bien sûr. Mais des faits [2] énoncés par des
philosophes Grecs il y a plus de deux milles ans n’ont jamais été
autant d’actualité, ni autant enseignés dans nos écoles, c’est du
solide ! La rigueur, allié au raisonnement, mène à la preuve, à la
démonstration, et idéalement, nous devrions avoir ce réflexe d’une
analyse rigoureuse des informations qui nous parviennent, et pour cela,
les sciences aident.</p>
<p>De même, lorsqu’on a pris l’habitude de raisonner, de chercher la
preuve, de chercher l’argument pouvant servir à la démonstration,
on est plus enclin à détecter les failles, les erreurs dans les
démonstrations ou les argumentations des autres. Parfois, on peut avoir
cette intuition que quelque chose cloche (il arrive que les intuitions
soient bonnes, d’autres fois non, mais on peut leur laisser leur
chance, et les mettre à l’épreuve). Je pense que c’est ce qu’on
peut appeler du discernement. Capacité d’abstraction</p>
<p>Dernier point important, la capacité d’abstraction. Les
mathématiques enseignent l’art et la manière d’abstraire les
choses. Lorsqu’un problème se présente, le mathématicien exercé
aura plus de facilité à le dépouiller de toute information inutile,
le changer de contexte, le relier à d’autres faits, le regarder
sous un autre angle. Cette capacité à abstraire les choses de leur
contexte premier est essentielle, pour détecter des mécanismes
cachés, des liens masqués, des structures sous-jacentes, quel que soit
le problème considéré. Allié à une ouverture d’esprit et à une
vision globale, c’est à dire, parvenir à ne pas rester focaliser sur
l’information présente, mais arriver à voir toutes les autres en
même temps, prendre le recul nécessaire afin de traiter le problème
dans son ensemble, dans sa globalité et non localement, avec une vision
partielle du contexte, cette qualité permet également de ne pas
considérer qu’une seule version du problème, mais plusieurs. Il est
parfois utile de s’ouvrir à toutes les possibilités. Et encore une
fois, les sciences sont un excellent terrain de jeu pour s’entrainer !</p>
<h2>Contexte</h2>
<p>Dans un monde où il serait plus nécessaire que jamais de remettre en
doute la véracité de l’information à laquelle on peut accéder,
dans une société de l’ouverture, de l’internet et du partage des
données, il est vital de développer des outils nous permettant de
faire le tri dans les quantités astronomiques d’informations que nous
sommes amenés à traiter et assimiler quotidiennement. Le doute, la
rigueur, l’abstraction, l’ouverture d’esprit, la curiosité, sont
les germes de l’indépendance intellectuelle, qu’il est nécessaire
de cultiver continûment. Les sciences, qu’elles soient humaines ou
autres (mathématiques, physique, biologie, philosophies, sociologie,
géopolitique, etc.) sont plus que jamais nécessaires pour comprendre
le monde dans lequel nous vivons.</p>
<p><em>Références</em> :</p>
<ul>
<li>[1] <em>Nicolas Bourbaki – Éléments d’histoire des mathématiques</em></li>
<li>[2] <em>Euclide – Les éléments</em></li>
</ul>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ascii—Astuces]]></title>
            <link>https://remusao.github.io//posts/ascii-astuces.html</link>
            <guid>https://remusao.github.io//posts/ascii-astuces.html</guid>
            <pubDate>Tue, 25 Dec 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Voici quelques petites astuces afin de manipuler plus simplement des
caractères encodés en ASCII.</p>
<h2>Changer la casse</h2>
<p>Cette astuce est indiquée dans le page de <code>man(1)</code> ascii, mais je l’ai
découverte très récemment car je n’avais pas eu le réflexe de lire
les paragraphes se trouvant à la suite de la table ASCII sur cette
page. Afin de changer la casse d’une lettre (c’est à dire
passer de minuscule à majuscule, ou l’inverse), il suffit de changer
le 5ième bit. Celui-ci est à 1 pour les minuscules et à 0 pour les
majuscules. Donc en effectuant un <code>XOR 32</code> avec une lettre on change sa
casse. C’est tout de même pratique !</p>
<pre class="code" data-lang="c"><code><span class="hljs-string">&#x27;A&#x27;</span> ^ <span class="hljs-number">32</span> == <span class="hljs-string">&#x27;a&#x27;</span>
<span class="hljs-string">&#x27;a&#x27;</span> ^ <span class="hljs-number">32</span> == <span class="hljs-string">&#x27;A&#x27;</span>
</code></pre>
<h2>Manipuler les chiffres</h2>
<p>Afin de convertir un entier entre 0 et 9 en son équivalent en
caractère ASCII (‘0’ à ‘9’), on ajoute (ou soustrait selon le
sens de la conversion) la valeur de ‘0’. On peut aussi remarquer
qu’entre un entier et son équivalent en ASCII seuls 2 bits changent.
Il s’agit donc de mettre les 6ième et 5ième bits à 1 (ou 0 si on
désire passer d’un caractère à un entier). Il suffit donc d’un
simple <code>XOR 48</code>, comme ceci :</p>
<pre class="code" data-lang="c"><code><span class="hljs-string">&#x27;9&#x27;</span> ^ <span class="hljs-number">48</span> == <span class="hljs-number">9</span>
</code></pre>
<p>Ces deux astuces sont assez basiques, mais cela peut toujours servir !</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[C++—Taille d'un tableau static en temps constant]]></title>
            <link>https://remusao.github.io//posts/cpp-static-array-size.html</link>
            <guid>https://remusao.github.io//posts/cpp-static-array-size.html</guid>
            <pubDate>Tue, 25 Dec 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>J’ai découvert cette semaine une petite astuce que je trouve assez
élégante, même si son utilité est assez limitée. Il est possible
grâce à un template de garder la trace de la taille d’un tableau
static entre des appels de fonctions. Voyez plutôt :</p>
<pre class="code" data-lang="c++"><code><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T, <span class="hljs-type">int</span> N&gt;
<span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">size</span><span class="hljs-params">(T (&amp;)[N])</span>
</span>{
    <span class="hljs-keyword">return</span> N;
}

<span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>
</span>{
    <span class="hljs-type">int</span> tab[<span class="hljs-number">42</span>];
    cout &lt;&lt; <span class="hljs-built_in">size</span>(tab) &lt;&lt; endl;
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<p>Notre fonction size est une fonction template qui prend en paramètre
le type <code>T</code> des éléments stockés dans le tableau, ainsi que sa taille.
Ainsi lorsqu’on appelle notre fonction <code>size</code> sur un tableau, cette
fonction est spécialisée à la compilation avec la bonne valeur de <code>N</code>
et le bon type <code>T</code> et chaque appel sera remplacé par la valeur <code>N</code>, qui est
la taille du tableau.</p>
<p>Notez également que pour garder l’information de la taille du
tableau, il faut passer une référence sur le pointeur du tableau.
Si notre fonction <code>size</code> avait simplement pris un pointeur en argument
ça n’aurait pas marché puisque le compilateur ne garde pas
l’information de la taille, et considère l’argument comme un simple
pointeur.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ocaml—Hash table vs. pattern matching]]></title>
            <link>https://remusao.github.io//posts/ocaml-pattern-matching-vs-hashtable.html</link>
            <guid>https://remusao.github.io//posts/ocaml-pattern-matching-vs-hashtable.html</guid>
            <pubDate>Thu, 01 Nov 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><em>Disclaimer</em>: This is an old article and the information might be out-dated.</p>
<p>Dans le cadre d’un projet personnel j’en suis venu à réaliser un
lexer avec l’excellent Ocamllex. Afin de matcher les mots clés du
langage source (le langage Python), deux solutions se sont offertes à
moi afin d’associer un token à chaque string représentant un mot
clé :</p>
<ol>
<li>Utiliser une Hashtable dans laquelle chaque entrée (clé, valeur) représente un mot clé et son token associé.</li>
<li>Utiliser le pattern matching où chaque entrée correspond à un token.</li>
</ol>
<p>Les deux solutions ayant une « verbosité » équivalente (j’ai tout
de même une légère préférence pour le pattern matching, que je
trouve un peu plus lisible), je me suis demandé si les performances
étaient équivalentes. J’ai donc réalisé un petit benchmark afin de
comparer les deux solutions.</p>
<p>Les deux méthodes ont donc été testées avec une entrée de <code>3.000.000</code>
de chaines de caractères contenant, à fréquences d’apparition
égales, tous les mots clés possibles ainsi que des mots-clés non
existants.</p>
<p>Le programme a été compilé sans flag d’optimisation particulier. La
machine de test était équipée d’un processeur Atom 1,2 Ghz et 1 Go
de mémoire vive. Voici le résultat:</p>
<ul>
<li>Hashtable :  <code>1,259</code> secondes.</li>
<li>Pattern-matching : <code>2,265</code> secondes.</li>
</ul>
<p>Victoire pour les Hashtables. Dommage que le compilateur n’optimise
pas le pattern-matching en Hash table lorsque c’est possible.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ma vision des mathématiques]]></title>
            <link>https://remusao.github.io//posts/mathematiques-vision.html</link>
            <guid>https://remusao.github.io//posts/mathematiques-vision.html</guid>
            <pubDate>Tue, 31 Jul 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<h2>Socle axiomatique</h2>
<p>Imaginons un socle, les axiomes. En fait, les axiomes ce sont des
propositions, des choses admises en quelque sorte. Comme si on se
mettait d’accord sur certaines règles avant de commencer un jeu. On
admet qu’un certain nombre de propositions sont vraies. Par exemple,
si l’on prend les axiomes du philosophe et mathématicien grec Euclide
— qui sont à la base du monde mathématique classique aujourd’hui — :</p>
<ol>
<li>Il existe toujours une droite qui passe par deux points du plan.</li>
<li>Tout segment peut être étendu suivant sa direction en une droite (infinie).</li>
<li>A partir d’un segment, il existe un cercle dont le centre est un des points du segment et dont le rayon est la longueur du segment.</li>
<li>Tous les angles droits sont égaux entre eux.</li>
<li>Étant donné un point et une droite ne passant pas par ce point, il existe une seule droite passant par ce point et parallèle à la première.</li>
</ol>
<h2>Du socle naît la richesse et la diversité</h2>
<p>Une fois qu’on a ce socle, cette base, eh bien c’est un peu comme
le monde réel. Repensez un instant à la classification périodique de
Mendeleïev, qui répertorie tous les atomes connus, qui sont en nombre
fini. Maintenant ouvrez les yeux et regardez autour de vous, imaginez
que tout ce que vous voyez est composé de ces quelques éléments,
imaginez la richesse qui vous entoure, imaginez qu’à partir de ces
quelques briques de base une telle diversité, une telle richesse
ait pu émerger. Il en est de même avec les mathématiques et leurs
axiomes. Les axiomes sont comme une classification périodique qui
décrirait les éléments — d’ailleurs Euclide exposait les axiomes
dans une série d’ouvrages intitulés Les Éléments — de base du
monde mathématique, et à partir d’eux a pu émerger une diversité
fascinante.</p>
<h2>Un monde abstrait -</h2>
<p>Alors bien sûr ce n’est pas aussi simple d’observer le monde
mathématique pour se rendre compte de sa beauté et de sa richesse que
d’ouvrir les yeux et de regarder ce qui nous entoure. Même si bien
sûr nous avons trouvé des astuces pour essayer de visualiser ces «
choses » abstraites. Par exemple quand nous traçons une courbe sur
notre calculette, ou quand nous mettons des symboles sur des nombres.
Nous essayons de nous approprier ce monde abstrait en lui associant
des repères que nous sommes à même de comprendre. Que ce soient des
symboles ou des représentations graphiques. Lorsque nous écrivons
le symbole 2 ce n’est pas un nombre entier en lui-même, c’est un
symbole propre à notre langage qui désigne le nombre entier — qui
est un concept abstrait — situé entre les nombre entiers 1 et 3. On
voit ici une des limites de notre langage, nous ne pouvons évoquer les
mathématiques directement sans passer par lui, il est en quelque sorte
indissociable des mathématiques et c’est pour ça qu’en général
on considère que le symbole 2 n’est plus un symbole, mais le nombre
entier 2.</p>
<h2>Découverte ou invention ?</h2>
<p>Ce qu’il y a de plus fascinant encore, c’est qu’au delà du fait
qu’un monde d’une infinie richesse puisse exister à partir d’un
nombre fini de briques de base (le socle), que se passe-t-il si l’on
change ce socle ? Est-ce qu’il émerge un monde totalement différent
mais tout aussi riche ? Existe-t-il d’autres socles possibles pour
construire des mondes cohérents ? La réponse est oui, et cela nous
laisse entrevoir une richesse sans limite, c’est ça la puissances
de « mathématiques ». Mais c’est tout de même intriguant, si on
invente un nouveau « socle », est-ce que l’on crée automatiquement
un nouveau monde mathématique cohérent ? Ou est-ce que ce monde
existait déjà et nous venons de le découvrir, ou de prendre
conscience de son existence ? Ces questions sont philosophiques et sont
semblables à d’autres questions telles que : « Est-ce qu’une chose
qu’on ne peut pas voir existe ? » ou encore « Est-ce que quelque
chose qu’on a vu et qu’on ne voit plus existe encore ? ». Dans le
cas des mathématiques, on peut surement parler de vue de l’esprit,
mais existent-ils vraiment ? Ou sont-ils le fruit de l’imagination de
l’être humain ?</p>
<h2>Piste de réponse</h2>
<p>En fait, si l’on fait l’analogie d’un mathématicien avec un
bâtisseur, on peut se dire que lorsqu’on bâti un édifice dans le
monde réel, nous le faisons dans la limite de ce qu’il est possible
de faire avec les lois qui gouvernent notre monde et des outils dont
nous disposons. Et notre monde existait bien avant l’apparition de
l’homme, mais il était vierge. Peut-être en est-il de même avec les
mondes mathématiques. En posant une base axiomatique, un mathématicien
a créé un nouveau monde abstrait vierge et, grâce à des axiomes
et des outils plus avancés tels que des théorèmes et notre logique
les mathématiciens bâtissent des édifices dans ce monde — dans la
limite de ce qu’il est possible de faire en respectant les axiomes de
base —. Je pense qu’il est important de dissocier le monde en tant
que conteneur — dans le sens d’environnement — et le monde en tant
que tout — conteneur ainsi que contenu —.</p>
<h2>Capacité à expliquer des phénomènes réels</h2>
<p>Au delà de ces questionnements — qu’il est intéressant de se
poser —, nous nous rendons compte que les mathématiques sont de
formidables outils pour décrire et expliquer notre monde réel. Comme
si ce monde mathématique était une collection d’outils abstraits ou
un monde parallèle à notre réalité et disposant de caractéristiques
semblables. On peut se demander pourquoi il y a cette ressemblance entre
quelque chose d’apparemment très abstrait et notre monde réel.
C’est assez troublant. Une piste possible pour répondre à cette
question pourrait être la suivante ; nous venons d’évoquer le fait
qu’il existe d’autres « socles » possibles à partir desquels
bâtir les mathématiques, peut-être que Euclide — à qui l’on doit
les axiomes des mathématiques classiques — s’est inspiré du monde
qui l’entourait pour proposer ses axiomes. C’est peut-être parce
que ces axiomes sont logiques vis-à-vis du monde qui nous entoure que
le monde mathématique qui en découle est si proche de notre réalité.
Et pourtant, depuis on sait qu’un rayon lumineux peut se déplacer
de manière courbe dans l’espace-temps — En contradiction avec le
cinquième axiome d’Euclide —. On pourrait donc admettre un autre «
socle » qui dirait que par deux points dans l’espace peuvent passer
une infinité de droites parallèles entre elles — ce qui ne parait
pas naturel —. Et pourtant c’est ce à quoi avaient pensé Gauss et
d’autres mathématiciens après lui.</p>
<h2>Rigueur et perfection</h2>
<p>Une autre chose assez fascinante lorsque l’on pense aux
mathématiques, c’est leur pureté, leur perfection. Lorsque l’on
regarde l’évolution de la physique / chimie, nous voyons que nous
avons un univers (notre monde réel) et nous cherchons à en comprendre
les mécanismes, à en découvrir les briques élémentaires, …
En mathématiques c’est l’inverse, nous disposons des briques
élémentaires — nos axiomes — et nous cherchons à bâtir ou
découvrir l’univers qu’ils peuvent engendrer. Et pour cela nous
nous aidons de raisonnements logiques, d’axiomes, … Ceci est censé
ne laisser place à aucune incohérence ni aucune contradiction. C’est
pourquoi cette discipline dégage ce sentiment de sureté, de solidité
— Il n’en a pas toujours été ainsi. Notamment à l’époque où
Godël a livré son célèbre théorème d’incomplétude —.</p>
<h2>Pour conclure</h2>
<p>Finalement ce que l’on appelle les mathématiques, c’est l’art
d’évoluer dans ces univers abstraits, de visualiser et de comprendre
les œuvres laissées par d’illustres mathématiciens avant nous,
et de bâtir de nouveaux édifices avec les outils qu’ils nous ont
légués.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Compiler Mediatomb sur Arch Linux ARM]]></title>
            <link>https://remusao.github.io//posts/mediatomb-arm-archlinux.html</link>
            <guid>https://remusao.github.io//posts/mediatomb-arm-archlinux.html</guid>
            <pubDate>Tue, 31 Jul 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>En voulant installer le logiciel mediatomb sur le Raspberry Pi que
j’ai reçu récemment je me suis heurté à quelques problèmes
puisque la version dans les dépots de Archlinux ne compilait pas et
aucun paquet précompilé pour Arm n’était disponible. Je vais donc
exposer une solution pour pouvoir le compiler et l’installer. Mais
tout d’abord une petite description du logiciel trouvée sur le site
des créateurs :</p>
<blockquote>
<p>MediaTomb is an open source (GPL) UPnP MediaServer with a nice web user interface, it allows you to stream your digital media through your home network and listen to/watch it on a variety of UPnP compatible devices.</p>
</blockquote>
<p>La marche à suivre pour arriver à compiler le paquet est assez simple,
il suffit de télécharger un patch supplémentaire et de remplacer le
PKGBUILD fourni par un autre que je vais vous donner. Voici comment
faire :</p>
<ol>
<li>Premièrement vous devez télécharger le patch suivant : <a href="http://bugs.debian.org/cgi-bin/bugreport.cgi?msg=5;filename=libavformat_0.11_support.patch;att=1;bug=677959" target="_blank" rel="noopener noreferrer">patch</a>.</li>
<li>Téléchargez également le fichier PKGBUILD suivant : <a href="http://www.pythux.com/exemples/PKGBUILD" target="_blank" rel="noopener noreferrer">PKGBUILD</a>.</li>
<li>Exécutez les commandes suivantes :</li>
</ol>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">cd</span> /tmp
$ yaourt -G mediatomb
$ <span class="hljs-built_in">cd</span> mediatomb
[Copier le patch ici]
[Copier le fichier PKGBUILD ici]
$ makepkg -si
</code></pre>
<p>Sur le raspberry Pi la compilation prend un certain temps, mais ça
vaut le coup. J’espère que ça servira à certains le temps que les
paquets dans les dépôts d’archlinux soient de nouveau compilables
sans modification.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi]]></title>
            <link>https://remusao.github.io//posts/raspberry-pi.html</link>
            <guid>https://remusao.github.io//posts/raspberry-pi.html</guid>
            <pubDate>Tue, 31 Jul 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>J’ai reçu il y a quelques jours le Raspberry Pi que j’avais
commandé sur le site Element 14. Voici une description que j’ai
honteusement recopiée depuis le site d’archlinux pour architecture
arm :</p>
<blockquote>
<p>The Raspberry Pi is a credit-card sized computer that plugs into
your TV and a keyboard. It’s a capable little PC which can be used
for many of the things that your desktop PC does, like spreadsheets,
word-processing and games. It also plays high-definition video.</p>
</blockquote>
<blockquote>
<p>The Raspberry Pi measures 85.60mm x 53.98mm x 17mm, with a little
overlap for the SD card and connectors which project over the edges. The
SoC is a Broadcom BCM2835. This contains an ARM1176JZFS with floating
point running at 700Mhz, and a Videocore 4 GPU. The GPU is capable of
BluRay quality playback, using H.264 at 40MBits/s.</p>
</blockquote>
<p>C’est donc assez rigolo de bidouiller sur une ordinateur au format de
poche. Sa puissance limitée n’est pas faite pour tous les usages,
mais puisqu’il ne prend pas beaucoup de place, ne fait aucun bruit et
ne consomme pas beaucoup d’énergie, il est tout à fait adapté pour
servir de lecteur multimédia (avec mediatomb par exemple).</p>
<p>Comme vous vous en doutez j’ai installé archlinux (la version arm
dédiée au raspberry pi que vous pouvez télécharger gratuitement
ici : archlinux – arm). L’avantage c’est qu’ils fournissent
une image que vous avez juste à installer sur votre carte SD, et vous
n’avez pas à passer par la procédure d’installation classique des
distributions linux. J’ai donc pu me connecter directement en SSH
après avoir lancé mon raspberry Pi. Ce qui était plutôt pratique
puisque je n’avais pas de clavier usb sous la main.</p>
<p>Par contre, prévoyez au moins une carte SD de 4 Go pour faire tourner
votre système. J’en utilise une de 2 Go et en ayant installé
quelques paquets elle est pleine à 94%. Je l’utilise actuellement
pour streamer du contenu présent sur un de mes disques durs externe via
Mediatomb. Cela permet d’accéder à vos vidéos, photos, musiques
depuis n’importe quel périphérique supportant la technologie uPnP.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Visualiser la structure d’un projet python]]></title>
            <link>https://remusao.github.io//posts/visualize-project-structure-python.html</link>
            <guid>https://remusao.github.io//posts/visualize-project-structure-python.html</guid>
            <pubDate>Tue, 31 Jul 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Lors d’une de mes dernières contributions à un projet écrit en
Python, j’ai voulu trouver un moyen de rapidement pouvoir visualiser
la structure d’un projet selon plusieurs critères (dépendances
entres les modules, héritages entre les objets, etc.). J’ai donc
écris un script Python qui permet de générer un graphe à partir de
différentes données.</p>
<p><a href="https://github.com/remusao/PyProjectViewer" target="_blank" rel="noopener noreferrer">Project sur GitHub</a></p>
<p>J’ai essayé de faire en sorte de rentre le projet flexible afin de
pouvoir scanner d’autres types de données à l’avenir (et pourquoi
pas d’autres langages). Pour le moment on peut générer le graphe des
importations ainsi que le graphe de l’héritage.</p>
<p>Le projet est divisé en deux parties :</p>
<ol>
<li>Les fichiers Scan, qui doivent respecter l’interface d’un scanner.</li>
<li>Un objet modelViewer qui s’occupe de parcourir tout votre projet et d’appeler son scanner sur chaque fichier.</li>
</ol>
<p>Ainsi on peut tout à fait rajouter des Scanners à volonté. Pour
finir, voici un graphe de dépendance d’un de mes projets en Python.
Le graphe est coloré et chaque module (chaque dossier) possède sa
propre couleur.</p>
<p>N’hésitez pas à faire des remarques ou à proposer des améliorations !</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[10 bonnes raisons de coder en Python]]></title>
            <link>https://remusao.github.io//posts/10-reasons-to-use-python.html</link>
            <guid>https://remusao.github.io//posts/10-reasons-to-use-python.html</guid>
            <pubDate>Sun, 05 Feb 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Dans la continuité des articles ayant pour objet le langage Python, je
vais essayer de vous donner envie de l’utiliser en vous donnant 10
bonnes raison de le faire :</p>
<ol>
<li>Python est un langage haut niveau avec une syntaxe claire, concise et
lisible basée sur l’indentation. Le code résultant est souvent plus
lisible et plus compacte.</li>
<li>En Python, les types sont automatiquement déduis, ce qui permet de
ne pas avoir à spécifier le type de vos variables, ni les valeurs de
retour des fonctions d’ailleurs.</li>
<li>Python fourni de très nombreuses fonctions, structures de données,
etc… permettant d’augmenter de façon significative la productivité
des développeurs qui l’utilisent. On pourra notamment citer les liste
(qui servent de pile, file, tableau, liste), les dictionnaires, les set,
etc. Sa richesse ne s’arrête pas là puisque vous aurez accès a une
grande partie de la bibliothèque standard du C (module os).</li>
<li>Python est intuitif et accessible. En Python tout est simple, ou
presque. Il est possible d’acquérir les connaissances de base en
très peu de temps.</li>
<li>Python est un langage interprété, ce qui diminue grandement les
temps de développement (souvent au détriment des performances des
programmes, mais il existe des solutions à ce problème). Si vous
cherchez des performances, il est toujours possible de convertir votre
code Python en C++ (avec ShedSkin) ou de l’interpréter avec Pypy
(l’interpréteur doté d’un compilateur Just-in-Time).</li>
<li>Python dispose de fonctionnalités objet très avancées. Quasiment
tout est object en Python (les simples entiers ne sont pas des objets),
vous pouvez mettre n’importe quoi dans n’importe quoi (typage
dynamique). Les listes peuvent accueillir autant de variables de types
différents que vous le souhaitez. Malgré cette forte orientation
objet, il est tout à fait possible de coder en Python sans pour autant
créer de classes ou de se soucier de ce que sont les objets.</li>
<li>Le Python est un langage très utilisé et qui dispose d’une
communauté très active. Il existe d’ailleurs de nombreuses
implémentations du langage, avec chacune ses spécificités (Stackless
Python, Pypy, etc.)</li>
<li>Le Python est extrêmement flexible de part la richesse des modules
que vous pouvez utiliser (il en existe pour tout), et de part la
facilité de l’interfacer avec des modules écris en C ou C++. Que
vous souhaitiez faire du développement web avec Django ou du calcul
scientifique avec Numpy, toutes les portes sont ouvertes !</li>
<li>Malgré sa simplicité apparente, le Python dispose de constructions
extrêmement avancées et puissantes. Vous pouvez vous essayer à la
méta-programmation avec les décorateurs, ou modifier le langage
lui même à la volé en regardant du côté des méta-classes.
Multi-paradigme, vous pourrez aussi bien utiliser la POO, la
programmation fonctionnelle ou encore la programmation structurée.</li>
<li>Python fait tout, Python passe partout. Disponible sur un grand
nombre de plateforme, le Python est un langage portatif et libre.</li>
</ol>
<p><em>Bonus</em> Mais Python c’est aussi un langage de script :p Alors il fera
également très bien l’affaire pour jouer le rôle de « glus » dans
vos projets les plus fous.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Python—Le saviez-vous ?]]></title>
            <link>https://remusao.github.io//posts/python-did-you-know.html</link>
            <guid>https://remusao.github.io//posts/python-did-you-know.html</guid>
            <pubDate>Sun, 05 Feb 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>J’en apprends tous les jours sur le Python, et tous les jours je
suis émerveillé par la richesse de ce langage. Je fais actuellement
quelques recherches sur des utilisations avancées des décorateurs
(afin de faire de la méta-programmation par exemple), j’ai découvert
deux chose :</p>
<ol>
<li>Il est tout à fait possible en Python de déclarer des fonctions à
l’intérieur d’autres fonctions. Par exemple, le code suivant est
tout à fait valide :</li>
</ol>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">toto</span>():
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;toto&#x27;</span>)
    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>
  <span class="hljs-keyword">return</span> toto()
</code></pre>
<ol start="2">
<li>Il est également possible de créer des classes à l’intérieur de fonctions :</li>
</ol>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">dessine_moi_une_classe</span>():
  <span class="hljs-keyword">class</span> <span class="hljs-title class_">Classe</span>():
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">dessine</span>(<span class="hljs-params">self</span>):
      <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;classe&#x27;</span>)

  c = Classe()
  <span class="hljs-keyword">return</span> c
</code></pre>
<p>Bref, tout ceci pour dire que le Python est un langage d’une richesse
insoupçonnée :)</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Python—Construction des listes]]></title>
            <link>https://remusao.github.io//posts/python-list-comprehension.html</link>
            <guid>https://remusao.github.io//posts/python-list-comprehension.html</guid>
            <pubDate>Thu, 02 Feb 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Le type liste du langage python est une des structures les plus utiles
(et utilisées). Elles sont polyvalentes et efficaces. En effet, on
peut aussi bien s’en servir comme tableau, file, pile, listes, etc…
L’outil à tout faire en quelques sorte. Mais leur utilité et leur «
beauté » ne s’arrête pas là, car en plus de fournir de nombreuses
méthodes utiles, le programmeur a la possibilité de construire des
listes de manière très élégante. Voyons voir de plus près de quoi
il s’agit !</p>
<p>Les listes étant représentées entre crochet <code>[</code> et <code>]</code>, c’est
tout naturellement avec ce formalisme que nous allons les créer, en
plaçant entre les crochets des « motifs » décrivant les éléments
contenus dans la liste. Voyons sans plus tarder un exemple :</p>
<pre class="code" data-lang="python"><code>l = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)]
&gt;&gt; [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]
</code></pre>
<p>Nous pouvons bien sûr imaginer des exemples plus complexes comme la
génération de tous les couples de nombres <code>(x, y)</code> avec <code>x</code> et <code>y</code> compris
entre <code>1</code> et <code>9</code> :</p>
<pre class="code" data-lang="python"><code>l = [(x, y) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>) <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)]
</code></pre>
<p>Il est également possible de rajouter des conditions sur les éléments
avec lesquels nous construisons les listes :</p>
<pre class="code" data-lang="python"><code>l = [x*x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>) <span class="hljs-keyword">if</span> x % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>]
</code></pre>
<p>Ce dernier exemple génère la liste contenant les carrés de tous les
nombres pairs compris entre 1 et 10. Vous commencez à comprendre ? Ce
qui est drôle, c’est qu’on peut utiliser des constructions de liste
dans des constructions de liste. Ainsi on peut facilement générer des
matrice (listes de listes) :</p>
<pre class="code" data-lang="python"><code>l = [[x * y <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)] <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)]
</code></pre>
<p>Je vous laisse entrer cette ligne dans un interpréteur Python pour
voir ce que cela donne. On peut ainsi créer des listes contenant a
peu près n’importe quoi avec cette notation. Cette dernière étant
beaucoup plus compacte qu’une ou plusieurs boucles ‘for’, on gagne
beaucoup en lisibilité et compacité en les utilisant. Je précise
également que ce genre de constructions est également disponible pour
d’autres structures de données du Python (notamment les set et les
dictionnaires) :</p>
<pre class="code" data-lang="python"><code>s = {x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)}    <span class="hljs-comment"># crée un set</span>
d = {x : x * x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)}  <span class="hljs-comment"># crée un dictionnaire</span>
</code></pre>
<p>Il y a donc de quoi s’amuser :) Toutefois, attention à ne pas
les utiliser lorsque ce n’est pas nécessaire. Imaginons que vous
souhaitiez initialiser une liste avec 1M éléments ayant tous la même
valeur (disons True). Les deux manières suivantes sont équivalentes :</p>
<pre class="code" data-lang="python"><code>l = [<span class="hljs-literal">True</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">1000000</span>)]
l = [<span class="hljs-literal">True</span>] * <span class="hljs-number">100000</span>
</code></pre>
<p>Bien que produisant le même résultat, la deuxième méthode est
plus rapide que la première, attention donc de ne pas abuser des
constructions de liste :)</p>
<p><strong>Édition du 5 février 2012</strong> :</p>
<p>Dans tous les exemples précédents, c’est la fonction range qui a
été utilisée pour illustrer les constructions de listes. Sachez
qu’il est possible d’utiliser n’importe quel générateur à la
place, et même n’importe quelle structure de données itérable (par
exemple : une liste, un set, etc…).</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Python—Lister le contenu des répertoires]]></title>
            <link>https://remusao.github.io//posts/python-list-directories.html</link>
            <guid>https://remusao.github.io//posts/python-list-directories.html</guid>
            <pubDate>Thu, 02 Feb 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><strong>Disclaimer</strong> : Il est probablement plus simple d’utiliser la fonction
<a href="https://docs.python.org/2/library/os.html#os.walk" target="_blank" rel="noopener noreferrer">os.walk</a> pour lister
récursivement le contenu d’un dossier.</p>
<p>Python est un langage très haut niveau qui permet de faire beaucoup de
choses très facilement. Notamment, il est très facile de manipuler les
fichiers et les dossiers grâce au module os. Les lecteurs connaissant
le langage C remarqueront que les fonctions présentes dans ce module
sont les mêmes que celles de la bibliothèque standard du C (exceptées
certaines fonctions un peu plus « haut-niveau » qui sont seulement
disponibles dans le module os de Python).</p>
<p>Dans cet articles nous allons simplement voir comment lister
récursivement le contenu des dossiers à partir de la position
actuelle. Commençons tout d’abord par inclure le module os comme ceci :</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> os
</code></pre>
<p>Nous utiliserons ensuite les fonctions suivantes :</p>
<ul>
<li><code>os.listdir(dossier)</code> : Liste le contenu de <code>dossier</code> (fichiers et dossiers)</li>
<li><code>os.chdir(dossier)</code> : On se déplace dans <code>dossier</code>.</li>
<li><code>os.path.isdir(chemin)</code> : Détermine si le <code>chemin</code> donné en paramètre
pointe vers un dossier ou un simple fichier.</li>
<li><code>os.getcwd()</code> : Retourne une chaine de caractères représentant la
position actuelle dans le système de fichiers (sous forme de chemin
absolu).</li>
</ul>
<p>Avec ces quelques fonctions , on peu facilement lister le contenu des
sous-dossiers à partir de la position courante comme ceci :</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse</span>():
  <span class="hljs-string">&quot;&quot;&quot;
    Liste récursivement le contenu des sous-répertoires
  &quot;&quot;&quot;</span>
  <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> os.listdir(os.getcwd()):
      <span class="hljs-keyword">if</span> os.path.isdir(f): <span class="hljs-comment"># si f est un dossier</span>
        os.chdir(f) <span class="hljs-comment"># On va lister son contenu</span>
        parse()
        os.chdir(<span class="hljs-string">&#x27;../&#x27;</span>) <span class="hljs-comment"># On revient au répertoire précédent</span>
      <span class="hljs-keyword">else</span>:
        <span class="hljs-comment"># Traitement sur le fichier f</span>
</code></pre>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Arithmetic lexer]]></title>
            <link>https://remusao.github.io//posts/arithmetic-lexer.html</link>
            <guid>https://remusao.github.io//posts/arithmetic-lexer.html</guid>
            <pubDate>Tue, 27 Dec 2011 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>As part of a project dealing with implementing algorithm to do some
arithmetic on numbers of arbitrary size, arbitrary base and arbitrary
symbols, I had to think about how to write a flexible lexer, capable of
cutting very quickly stream of characters (an arithmetic expression) in
tokens understandable by a parser. So I will write some various articles
on the lexer, parser and evaluation of an arithmetic expression by
making it a point to highlight the various optimizations that I made in
the algorithms to make them as fast as possible. The language used is
C++, but since our priority is to reach the best performances possible,
we will avoid too costly features such as inheritance, virtual class,
etc. … This article will details the following points:</p>
<ol>
<li>Input and number representation.</li>
<li>Memory management.</li>
<li>The Lexer.</li>
</ol>
<h2>Input and number representation</h2>
<p>In order not to lose precious seconds in unnecessary operations such as
resizing of string, repeated IO operations, etc… An expression input
will consist of:</p>
<ol>
<li>Length of the base.</li>
<li>Symbols of the base.</li>
<li>Length of the arithmetic expression.</li>
<li>The arithmetic expression, without blank characters…</li>
</ol>
<p>A correct input could be:</p>
<pre class="code" data-lang="sh"><code>1 5 abcde 10 bc+bca+dec
</code></pre>
<p>So we can easily read the input data with the following code:</p>
<pre class="code" data-lang="c"><code><span class="hljs-type">char</span> newline;

<span class="hljs-comment">// Read the base size</span>
<span class="hljs-type">unsigned</span> base_size;
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span> &gt;&gt; base_size;
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span>.get(newline);

<span class="hljs-comment">// Read the base&#x27;s symbols</span>
<span class="hljs-type">char</span>* base = new <span class="hljs-type">char</span>[base_size + <span class="hljs-number">1</span>];
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span>.read (base, base_size + <span class="hljs-number">1</span>);
base[base_size] = <span class="hljs-string">&#x27;\0&#x27;</span>;

<span class="hljs-comment">// Read the expression&#x27;s size</span>
<span class="hljs-type">unsigned</span> expr_size;
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span> &gt;&gt; expr_size;
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span>.get(newline);

<span class="hljs-comment">// Read the expression</span>
<span class="hljs-type">char</span>* expr = new <span class="hljs-type">char</span>[expr_size + <span class="hljs-number">1</span>];
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span>.read (expr, expr_size + <span class="hljs-number">1</span>);
expr[expr_size] = <span class="hljs-string">&#x27;\0&#x27;</span>;
</code></pre>
<p>The variable named newline will only be used to « absorb » the \n at
the end of each line. Our expression is represented as a simple array
of characters (we could have done the same thing in C). If you want to
compile the code above, do not forget to add a #include <iostream> at
the top of your file.</p>
<p>Since the role of the lexer is to « cut » our expression into
tokens (numbers, operators, parentheses), we must ask ourself in what
form we will store our numbers, which tokens we will use, etc… It
would be tempting to create a string and to copy the number value
there, it would be the most intuitive. But since we are looking
for maximum performances, we will avoid as possible to use dynamic
memory allocation. Instead we will represent our number as a pair of
integers (offset, size) representing the beginning of the number in the
expression (i.e. the index of its first digit in the array representing
the expression) and its length. So we can work directly on the string
containing the arithmetic expression.</p>
<p>Concerning tokens, we can use a simple enumeration containing an entry for each symbol:</p>
<pre class="code" data-lang="c"><code><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span>
{</span>
  <span class="hljs-type">unsigned</span>  offset;
  <span class="hljs-type">unsigned</span>  size;
} s_number;

<span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">enum</span>
{</span>
  PLUS    = <span class="hljs-number">3</span>,
  MINUS   = <span class="hljs-number">4</span>,
  MULT    = <span class="hljs-number">5</span>,
  DIV     = <span class="hljs-number">6</span>,
  MOD     = <span class="hljs-number">7</span>,
  LPAR    = <span class="hljs-number">2</span>,
  RPAR    = <span class="hljs-number">8</span>,
  NUMBER  = <span class="hljs-number">1</span>
} e_token;
</code></pre>
<p>We will see later why each field of the list is associated with a number.</p>
<h2>Memory management</h2>
<p>We will try as much as possible to do it without dynamic memory
allocation. Our couples (offset, size) and our tokens are then stored
on the stack, using the static allocation, avoiding calls to new/delete
and malloc/free. As we are using the string containing the expression
to store our intermediate results, our memory consumption will be
optimized. We must therefore adapt our algorithms for arithmetic in
order to store the results directly in the string representing the
expression.</p>
<h2>The Lexer</h2>
<p>We will create a <code>Lexer class</code>, containing methods for lexing and some
private variables such as the string containing the expression, the
current offset, etc. …</p>
<p>The use of an object has several advantages in our case:</p>
<ol>
<li>This prevents parsing functions to take a lot of arguments (with
the object of type <code>Lexer</code>, we can afford to give a single argument to
functions).</li>
<li>To determine the next token, the lexer needs some informations,
including the expression, the offset, the variable used to return
the possible pair (offset, size) representing a number, etc. … All
variables can be stored in the object.</li>
<li>This makes the code more readable, without reducing the performances
of the program.</li>
</ol>
<p>Our <code>Lexer</code> will be defined as follows:</p>
<pre class="code" data-lang="c++"><code><span class="hljs-keyword">class</span> <span class="hljs-title class_">Lexer</span>
{
  <span class="hljs-keyword">public</span>:
    <span class="hljs-built_in">Lexer</span> (<span class="hljs-type">char</span>* expr, <span class="hljs-type">char</span>* table,
           <span class="hljs-type">unsigned</span> expr_size, <span class="hljs-type">char</span>* op)
      : <span class="hljs-built_in">num_</span> (<span class="hljs-built_in">s_number</span> ()),
        <span class="hljs-built_in">expr_</span> (expr),
        <span class="hljs-built_in">offset_</span> (<span class="hljs-number">0</span>),
        <span class="hljs-built_in">table_</span> (table),
        <span class="hljs-built_in">expr_size_</span> (expr_size),
        <span class="hljs-built_in">op_</span> (op) {}
    ~<span class="hljs-built_in">Lexer</span> () {}

    <span class="hljs-function"><span class="hljs-type">unsigned</span> <span class="hljs-title">get_token</span> <span class="hljs-params">()</span></span>;

    s_number num_;

  <span class="hljs-keyword">private</span>:

    <span class="hljs-function"><span class="hljs-type">int</span>
    <span class="hljs-title">get_op_</span> <span class="hljs-params">(<span class="hljs-type">char</span> c)</span>
    </span>{
      <span class="hljs-keyword">return</span> (<span class="hljs-type">int</span>)op_[(<span class="hljs-type">int</span>)c];
    }

    <span class="hljs-type">char</span>* expr_;
    <span class="hljs-type">unsigned</span> offset_;
    <span class="hljs-type">char</span>* table_;
    <span class="hljs-type">unsigned</span> expr_size_;
    <span class="hljs-type">char</span>* op_;
};
</code></pre>
<p>You have probably noticed that the constructor of our object <code>Lexer</code> takes
two string parameters named respectively, « table » and « op ». Why
are they useful ?</p>
<p><strong>Table</strong> - Since our program must be able to handle numbers represented
in an arbitrary base with a set of arbitrary symbols, it would be
very difficult to evaluate expressions without modification to make
them easier to compute. So we’re going (during lexing) to transform
numbers by changing the symbols which they are composed of by a set of
contiguous numbers starting from 0 and up to (base_size – 1). For
example:</p>
<pre class="code" data-lang="sh"><code>Old base : abcde
New base : 01234
</code></pre>
<p>It does not change the size of the base, but just the symbols, by this
wait it becomes easier to perform arithmetic operations on numbers.</p>
<p><strong>Op</strong> – The purpose of the variable op is different. During lexing,
we want to determine, for each symbol read, if it’s an operator or
not. We can imagine that for expressions of million of characters,
it makes us millions of tests just for the lexing. We will therefore
greatly reduce the number of tests by creating an array of 256
characters which associate, for each operator (using the ASCII code as
an index in the table) the number that corresponds (the one present
in the enumeration given above) and setting the value 0 to all other
characters. This allows us, first to test if a character is an operator,
and at the same time to know the value associated (to determine which
operator it is).</p>
<p>Finally, the public variable <code>num_</code> will allow the parser, when the lexer
will return a token of type NUMBER, to get the value of the number that
will be presented in this variable.</p>
<p>We code, we optimize a bit and here is the result:</p>
<pre class="code" data-lang="c++"><code><span class="hljs-function"><span class="hljs-type">unsigned</span>
<span class="hljs-title">Lexer::get_token</span> <span class="hljs-params">()</span>
</span>{
  <span class="hljs-keyword">if</span> (offset_ &gt;= expr_size_)
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;

  <span class="hljs-type">int</span> tok = <span class="hljs-built_in">get_op_</span> (expr_[offset_++]);

  <span class="hljs-keyword">if</span> (tok)
    <span class="hljs-keyword">return</span> tok;

  expr_[offset_ - <span class="hljs-number">1</span>] = table_[(<span class="hljs-type">int</span>)expr_[offset_ - <span class="hljs-number">1</span>]];

  num_.offset = offset_ - <span class="hljs-number">1</span>;
  <span class="hljs-type">unsigned</span> length = <span class="hljs-number">1</span>;

  <span class="hljs-keyword">while</span> (!op_[(<span class="hljs-type">int</span>)expr_[offset_]])
  {
    expr_[offset_] = table_[(<span class="hljs-type">int</span>)expr_[offset_++]];
    length++;
  }

  num_.size = length;

  <span class="hljs-keyword">return</span> NUMBER;
}
</code></pre>
<p>This code is not the most optimized but in this version of the program
we will use it like this. Later, during the profiling phase, if it turns
out that this is part of the program is the slowest, we could optimize
it.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Sieve—Even faster!]]></title>
            <link>https://remusao.github.io//posts/sieve-even-faster.html</link>
            <guid>https://remusao.github.io//posts/sieve-even-faster.html</guid>
            <pubDate>Tue, 27 Dec 2011 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><strong>Disclaimer</strong>: This is an old article and information may be out-dated. You can
find one of the (if not <em>the</em>) fastest implementation there: <a href="http://primesieve.org/" target="_blank" rel="noopener noreferrer">http://primesieve.org/</a></p>
<p>It has been a while since I posted my last article on the blog, my
studies didn’t leave me enough time for writing. But during Christmas
holidays I found some time to share with you some discoveries and
developments that I made recently on the Sieve of Eratosthenes.
This article follows the previous article on the Sieve and aim to
present some optimizations and an attempt to determine the complexity of
the algorithm.</p>
<h2>Last optimizations</h2>
<p>Optimizations that follow are the result of several comments on the
above implementations:</p>
<ul>
<li>Could we not reduce the memory footprint of the program by working
only on arrays of bits instead of chars ? (We could divide the memory
used by 8).</li>
<li>In the main loop, our variable i ranges from 1 in 1, and values
are not always prime numbers, so there is no need to eliminate their
multiples.</li>
</ul>
<p>For the second optimization, we just have to get the next number that
has not yet been eliminated. With a simple loop. We then gain precious
seconds at runtime.</p>
<p>Regarding the first optimization, it turns out that it’s not easy
to work directly on the bits in C, except with bit fields, but this
is complicated in the case of the Sieve of Eratosthenes. So I decided
to implement the algorithm in C++, which offers the type bool, which
takes only one bit in memory as well as Bitset, which are nothing more
than arrays of bits, provided with various operations. Thanks to a
std::vector (or a simple array) of bool the memory usage of the program
is reduced by 8, which is pretty good. But it’s possible to use a data
structure more efficient. You certainly heard about Boost, a library
which provide many very powerful tools for C++, and among this tools
is the Bitset (it also exists in STD, but it is less efficient). Using
Bitset, we gain a little in runtime.</p>
<p>Note that Boost Bitset are initialized to 0 by default, so we must
consider that a number is prime if the value associated in the array is
0 (and not 1 as in a previous implementations).</p>
<pre class="code" data-lang="c++"><code><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cmath&gt;</span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;boost/dynamic_bitset.hpp&gt;</span></span>

<span class="hljs-function"><span class="hljs-type">void</span>
<span class="hljs-title">print_tab</span> <span class="hljs-params">(boost::dynamic_bitset&lt;&gt;&amp; tab)</span>
</span>{
  std::cout &lt;&lt; <span class="hljs-number">2</span> &lt;&lt; std::endl;
  <span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> i = <span class="hljs-number">1</span>; i &lt; tab.<span class="hljs-built_in">size</span> (); i++)
    <span class="hljs-keyword">if</span> (!tab[i])
      std::cout &lt;&lt; <span class="hljs-number">2</span> * i + <span class="hljs-number">1</span> &lt;&lt; std::endl;
}

<span class="hljs-function"><span class="hljs-type">void</span>
<span class="hljs-title">erato</span> <span class="hljs-params">(boost::dynamic_bitset&lt;&gt;&amp; tab)</span>
</span>{
  <span class="hljs-type">unsigned</span> i = <span class="hljs-number">0</span>;
  <span class="hljs-type">unsigned</span> j, step, borne = <span class="hljs-built_in">sqrt</span> (tab.<span class="hljs-built_in">size</span> ());

  <span class="hljs-keyword">for</span> (i = <span class="hljs-number">1</span>; i &lt; borne; i++)
  {
    step = <span class="hljs-number">2</span> * i + <span class="hljs-number">1</span>;
    <span class="hljs-keyword">for</span> (j = i + step; j &lt; tab.<span class="hljs-built_in">size</span> (); j += step)
      tab[j] = <span class="hljs-number">1</span>;

    <span class="hljs-keyword">while</span> (tab[i])
      i++;
  }
}

<span class="hljs-function"><span class="hljs-type">int</span>
<span class="hljs-title">main</span> <span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> **argv)</span>
</span>{
  <span class="hljs-keyword">if</span> (argc != <span class="hljs-number">2</span>)
  {
    std::cout &lt;&lt; <span class="hljs-string">&quot;Please, you must give a number as argument.&quot;</span> &lt;&lt; std::endl;
    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;
  }

  <span class="hljs-type">unsigned</span> size = <span class="hljs-number">0</span>;
  <span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> i = <span class="hljs-number">0</span>; argv[<span class="hljs-number">1</span>][i]; i++)
    size = size * <span class="hljs-number">10</span> + (argv[<span class="hljs-number">1</span>][i] - <span class="hljs-string">&#x27;0&#x27;</span>);

  boost::dynamic_bitset&lt;&gt;* tab = <span class="hljs-keyword">new</span> boost::dynamic_bitset&lt;&gt; (size / <span class="hljs-number">2</span>);

  <span class="hljs-built_in">erato</span> (*tab);
  <span class="hljs-comment">//print_tab (*tab);</span>
}
</code></pre>
<p>With this algorithm we get much better performance than with the
previous implementation.</p>
<h2>Complexity approximation</h2>
<p>The complexity of an algorithm is used to express the number of
operations needed to execution depending on the size of the input (in
our case it will be the limit up to which we want to calculate the prime
numbers).</p>
<p>Soon I will post a more accurate approximation of the complexity of this
algorithm, but my initial investigations suggest that the complexity is
linear (3xN?).</p>
<h2>The last words</h2>
<p>After presenting a number of optimizations to the algorithm of the
Sieve of Eratosthenes, we saw that it is always possible to improve
a program, and this, in two lines of research. First, one can often
optimize the algorithm itself, by choosing appropriate data structures,
trying to reduce the memory footprint or by reducing the number of
calculations needed to compute the result, etc. … One can also optimize
the implementation of the algorithm, it’s often the last step, during
which we will try to find tips, related to language itself, that allow
us to make our program faster by changing the compiler flags (-O,
-march, etc. …), etc. …</p>
<p>The last implementation presented in this article is far from being the
most optimized, we could still find ways to improve performances, for
exemple by eliminating multiples of 3, 5 and 7 at the initialization
of the array or by using bit masks to eliminate several multiples at a
time. However, keep in mind that it is difficult to keep the compactness
and readability of our algorithm with such optimizations.</p>
<p>If you know other optimizations, or have any comments on this article,
feel free to contact me or leave a comment below.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Crible d'Ératosthène—Un algo pour les trouver tous]]></title>
            <link>https://remusao.github.io//posts/eratosthene-algo-to-find-them-all.html</link>
            <guid>https://remusao.github.io//posts/eratosthene-algo-to-find-them-all.html</guid>
            <pubDate>Tue, 15 Nov 2011 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Il y a quelques temps je me suis intéressé au crible
d’Ératosthène, qui permet de trouver l’ensemble des nombres
premiers inférieurs à une borne donnée. L’application naïve
de l’algorithme dans sa version originale n’étant pas très
performante, j’ai cherché à l’optimiser afin d’obtenir des
performances correctes. Voici donc les différents moyens de rendre cet
algorithme plus efficace. Des fichiers sources en C ou en Python seront
fournis tout au long de l’article.</p>
<ol>
<li>Qu’est-ce qu’un nombre premier ?</li>
<li>Le crible d’Ératosthène.</li>
<li>Optimisations.</li>
<li>Performances.</li>
<li>Conclusion.</li>
</ol>
<p><em>Qu’est-ce qu’un nombre premier</em> – Un nombre premier est un entier
naturel qui n’admet que deux diviseurs, 1 et lui-même. Ce qui exclut
tous les autres entiers naturels (c’est sur cette remarque qu’est
basé le crible d’Ératosthène). Il existe une infinité de nombre
premiers.</p>
<p><em>Le crible d’Ératosthène</em> – L’algorithme du crible
d’Ératosthène est très simple. Prenons un tableau contenant les
entiers de 2 a n (si l’on désire connaitre tous les nombres premiers
inférieurs à n) que l’on suppose tous premiers. Ensuite il suffit,
pour chaque élément du tableau, de supprimer tous ses multiples. Le
pseudo code pourrait donc être le suivant :</p>
<pre class="code" data-lang="python"><code>Crible(entier n):
  Tableau = entiers de <span class="hljs-number">2</span> a n
  Pour chaque i dans Tableau
    supprimer_multiples de i dans Tableau
  Fin Pour Fin Crible
</code></pre>
<p>Le pseudo-code suivant peut aisément être implémenté en Python :</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">Supprimer_multiples</span>(<span class="hljs-params">i, tableau</span>):
  <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> tableau:
    <span class="hljs-keyword">if</span> x &gt; i <span class="hljs-keyword">and</span> x % i == <span class="hljs-number">0</span>:
      tableau.remove(x)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">Crible</span>(<span class="hljs-params">n</span>):
  tableau = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, n)]
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tableau:
    Supprimer_multiples(i, tableau)
  <span class="hljs-keyword">return</span> tableau

<span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
  tableau = Crible(<span class="hljs-number">100</span>)
  <span class="hljs-built_in">print</span> tableau

main()
</code></pre>
<p>On remarque que la complexité de cette implémentation n’est pas
du tout adaptée à des <code>n</code> très grands (essayez avec <code>n &gt; 10000</code>, le
résultat va commencer à mettre un certain temps à être calculé).
Voyons comment l’optimiser.</p>
<h2>Optimisations</h2>
<p><em>Première remarque</em>, si le fait de stocker tous les nombres dans un
tableau puis de les supprimer au fur et à mesure peut sembler plus
lisible, ce n’est pas une bonne méthode si l’on recherche les
performances. Une première optimisation est de déclarer un tableau
de n cases qui peuvent chacune contenir soit 1 soit 0 en fonction de
la primalité (ou non-primalité) du nombre correspondant à l’index
considéré dans le tableau. Nous allons voir qu’avec cette technique
nous allons pouvoir nous passer complètement de comparaisons et de
tests (sauf pour les cas d’arrêt des boucles bien évidemment), ce
qui va diminuer grandement le temps de calcul.</p>
<p><em>Deuxièmement</em>, on remarque que pour obtenir tous les multiples d’un
nombre i dans notre tableau dont les index correspondent aux nombres
dont on veut connaitre la primalité, il n’est pas nécessaire de
parcourir tout le tableau en testant à chaque fois le modulo. Pour cela
il suffit de partir de l’index i puis d’aller de i en i dans le
tableau, nous sommes ainsi assurés de passer sur tous les multiples de
i (y compris lui-même). Ceci va grandement améliorer notre algorithme.</p>
<p>Une autre remarque que l’on peut faire est que pour tester la
primalité d’un nombre n, il n’est pas nécessaire de tester la
division par tous les nombres de <code>2</code> a <code>n</code>, il suffit d’aller jusqu’à
la racine carrée de n (au delà on ne peut pas trouver de diviseur
entier).</p>
<p>Enfin, une petite amélioration liée à l’implémentation en C de
l’algorithme, puisqu’on va devoir initialiser notre tableau avec
toutes les cases à 1, autant éliminer tous les nombres pairs (qui ne
sont pas premier puisque divisibles par <code>2</code>). On peut donc initialiser
notre tableau avec deux boucles distinctes, une qui part de 3 et
qui va jusqu’à n de deux en deux en initialisant à 1 les cases
visitées et une autre qui part de 4 et qui va jusqu’à n de deux
en deux en initialisant à 0 les cases parcourues. Voici ce que donne
l’algorithme implémenté en C avec les optimisations précédentes
(sources : <a href="http://www.pythux.com/exemples/erato/crible_1.c" target="_blank" rel="noopener noreferrer">http://www.pythux.com/exemples/erato/crible_1.c</a>). Pour compiler le
fichier source, vous pouvez utiliser soit clang soit gcc (ou un autre
compilateur C) comme ceci :</p>
<pre class="code" data-lang="sh"><code>clang -lm -O3 crible_1.c
gcc -lm -o3 crible_1.c
</code></pre>
<p>Nous pourrions nous arrêter là, puisque les performances sont déjà
très bonnes (11 ms pour un crible jusqu’à 1.000.000 et 40-45
secondes jusqu’à 1.000.000.000), mais nous allons voir qu’il est
encore possible de diminuer drastiquement le temps de calcul. En effet,
nous savons qu’à part le nombre 2, aucun nombre pair n’est premier.
Nous pourrions donc chercher un moyen de ne pas les stocker dans le
tableau, afin de ne garder que les nombres impairs. Nous diviserions
donc dans un premier temps l’espace mémoire occupé par deux. Pour
un crible jusqu’à n = 30, nous aurions à stocker les éléments
suivants :</p>
<pre class="code" data-lang="sh"><code>Les nombres -&gt; [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]
Les index   -&gt; [0, 1, 2, 3, 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]
</code></pre>
<p>Hors, nous ne pouvons plus simplement utiliser les index dans le tableau
pour connaitre les nombres associés. En fait, on peut remarquer que
pour retrouver le nombre associé a chaque case du tableau, il nous
suffit de calculer : <code>index * 2 + 1</code> . Deuxièmement, pour retrouver
les multiples d’un nombre N dans le tableau, il nous suffit d’aller
de N en N dans le tableau en partant de la case <code>N / 2</code>. Enfin, on
remarque qu’avec cette technique, l’algorithme est plus compact
et nous pouvons nous contenter d’initialiser toutes les cases du
tableau à 1 (avec la fonction memset de la bibliothèque <code>&lt;string&gt;</code> du
langage C). Voici le code source de cette implémentation (sources :
<a href="http://www.pythux.com/exemples/erato/crible.c" target="_blank" rel="noopener noreferrer">http://www.pythux.com/exemples/erato/crible.c</a>) :</p>
<pre class="code" data-lang="c"><code><span class="hljs-type">char</span> *<span class="hljs-title function_">erato_opti</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span>
{
  <span class="hljs-type">char</span>  *tab = <span class="hljs-built_in">malloc</span>(n / <span class="hljs-number">2</span>);
  <span class="hljs-type">int</span>   i = <span class="hljs-number">1</span>, j, borne = <span class="hljs-built_in">sqrt</span>(n / <span class="hljs-number">2</span>), step;

  tab = <span class="hljs-built_in">memset</span>(tab, <span class="hljs-number">1</span>, n / <span class="hljs-number">2</span>);

  <span class="hljs-keyword">for</span> (; i &lt;= borne; i++)
  {
    step = <span class="hljs-number">2</span> * i + <span class="hljs-number">1</span>;
    <span class="hljs-keyword">for</span> (j = i + step; j &lt; n / <span class="hljs-number">2</span>; j += step)
      tab[j] = <span class="hljs-number">0</span>;
  }

  <span class="hljs-keyword">return</span> (tab);
}
</code></pre>
<p>Si nous voulons afficher les nombres premiers produits par la fonction
erato_opti il nous suffit d’utiliser l’astuce du <code>nombre = index * 2 + 1</code> et de ne pas oublier d’afficher le nombre 2 (qui n’est pas
contenu dans le tableau) :</p>
<pre class="code" data-lang="c"><code><span class="hljs-type">void</span> <span class="hljs-title function_">print_erato_space</span><span class="hljs-params">(<span class="hljs-type">char</span> *tab, <span class="hljs-type">int</span> n)</span>
{
  <span class="hljs-type">int</span> i = <span class="hljs-number">1</span>;

  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;2\n&quot;</span>);
  <span class="hljs-keyword">for</span> (; i &lt; n / <span class="hljs-number">2</span>; i++)
    <span class="hljs-keyword">if</span> (tab[i])
      <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%i\n&quot;</span>, i * <span class="hljs-number">2</span> + <span class="hljs-number">1</span>);
}
</code></pre>
<p>Vous pouvez compiler les sources précédentes avec l’une ou l’autre
des commandes suivantes :</p>
<pre class="code" data-lang="sh"><code>clang -lm -O3 crible.c
gcc -lm -O3 crible.c
</code></pre>
<h2>Performances</h2>
<p>Voici un récapitulatif des performances obtenues avec les différentes
implémentations :</p>
<table>
<thead>
<tr>
<th>Valeur de N</th>
<th style="text-align:center">1000</th>
<th style="text-align:center">10.000</th>
<th style="text-align:center">1.000.000</th>
<th style="text-align:center">1.000.000.000</th>
</tr>
</thead>
<tbody>
<tr>
<td>Version Python (Pypy)</td>
<td style="text-align:center">30ms</td>
<td style="text-align:center">370ms</td>
<td style="text-align:center">/</td>
<td style="text-align:center">/</td>
</tr>
<tr>
<td>Version Python (CPython)</td>
<td style="text-align:center">42ms</td>
<td style="text-align:center">710ms</td>
<td style="text-align:center">/</td>
<td style="text-align:center">/</td>
</tr>
<tr>
<td>Version C intermédiaire</td>
<td style="text-align:center">1ms</td>
<td style="text-align:center">1ms</td>
<td style="text-align:center">7ms</td>
<td style="text-align:center">40s</td>
</tr>
<tr>
<td>Version C opti</td>
<td style="text-align:center">1ms</td>
<td style="text-align:center">1ms</td>
<td style="text-align:center">6ms</td>
<td style="text-align:center">32s</td>
</tr>
</tbody>
</table>
<h2>Conclusion</h2>
<p>Nous avons vu quelques optimisations possibles sur l’algorithme du
crible d’Ératosthène. Cet article est loin d’être exhaustif,
vous pourrez trouver d’autres optimisations plus ou moins efficaces.
Néanmoins, la plupart des implémentations trouvables sur internet et
qui sont plus performante que celle proposée ici sont moins lisibles et
plus complexes que celle-ci (qui ne fait qu’une dizaine de ligne). Si
vous connaissez d’autres optimisations, n’hésitez pas a poster un
commentaire :)</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pypy—Make Python faster!]]></title>
            <link>https://remusao.github.io//posts/pypy-makes-python-faster.html</link>
            <guid>https://remusao.github.io//posts/pypy-makes-python-faster.html</guid>
            <pubDate>Thu, 10 Nov 2011 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>J’inaugure ce blog avec un article sur <a href="https://pypy.org/" target="_blank" rel="noopener noreferrer">Pypy</a>, une implémentation de
Python très intéressante du point de vue des performances puisque,
comme nous le verrons un peu plus bas, il est possible de rivaliser avec
des langages compilés statiquement tels que le C ou le C++. L’article
se décomposera de la façon suivante :</p>
<ol>
<li>Qu’est-ce que Python.</li>
<li>Quelles sont les différentes implémentation ?</li>
<li>Qu’est-ce qui caractérise Pypy ?</li>
<li>La compilation JIT (Just-In-Time).</li>
<li>Compiler et utiliser Pypy.</li>
<li>Bref aperçu des performances.</li>
</ol>
<h2>Qu’est ce que Python</h2>
<p>Python est un langage de programmation moderne classé dans la
catégorie des langages de scripts (il est interprété, du moins dans
son implémentation officielle, CPython). Étant très haut niveau, il
permet aux développeurs de gagner en productivité en leur permettant
de se détacher au maximum des contraintes bas niveaux que l’on peut
retrouver sur d’autres langages tels que le C, ce qui en fait un
langage adapté pour l’apprentissage de la programmation. En effet,
il est facile d’accès et rapide à apprendre. Sa syntaxe, basée
sur l’indentation (pas d’accolades ni de mot-clé pour séparer
les « blocs » d’instruction) le rend plus lisible que la plupart
des langages. Pour terminer, voici quelques spécificités du langage
: Inférence de type, fonctionnalités objet avancées, type entier de
taille arbitraire, compréhension de listes permettant de créer des
listes de manière élégante, etc …</p>
<h2>Quelles sont les différentes implémentations</h2>
<p>Le langage Python étant placé sous licence libre, il en existe de
nombreuses implémentations ayant chacune leurs spécificités. En voici
quelques-unes :</p>
<ol>
<li><em>CPython</em> : Implémentation officielle (la plus connue) écrite en C.</li>
<li><em>Pypy</em> : Implémentation disposant d’un compilateur JIT (Just-In-Time).</li>
<li><em>ShedSkin</em> : Implémentation disposant d’un compilateur
Python-to-C++ et offrant des performances très intéressantes du point
de vu du temps d’exécution.</li>
<li><em>Stackless</em> : Implémentation qui se passe de la pile d’appels du
C en la remplaçant par une structure de données propre au Python.
Cette implémentation est grandement basée sur le paradigme de la
concurrence, faisant appel à des Tasklets (sorte de micro-threads)
afin de simuler une exécution parallèle des programmes. Les Tasklets
peuvent être créées par centaines (voire milliers), communiquer entre
elles facilement, être mise en pause ou réveillées instantanément,
etc …</li>
<li><em>Jython</em> : Implémentation écrite en Java.</li>
<li><em>Iron Python</em> : Implémentation écrite en C#.</li>
</ol>
<h2>Qu’est-ce qui caractérise Pypy</h2>
<p>Pypy est une implémentation de Python, écrite en Python, et proposant
(entre autres), un compilateur JIT (cf paragraphe suivant) lui
permettant de délivrer des performances dignes de la plupart des
langages compilés statiquement (C, C++, etc…). Pypy offre également
une consommation mémoire réduite par rapport à CPython, et supporte
la plupart des bibliothèques disponibles avec l’implémentation
officielle.</p>
<p>Il est également possible de compiler Pypy pour obtenir une version
SandBox ou Stackless de Python. D’autres langages sont également
supportés par Pypy (Javascript, Scheme, etc…) puisque ce dernier
utilise une chaine de traitement qui peut analyser des programmes
écrits en RPython (un subset réduit du langage Python), les
traduire en code C puis les compiler en code machine, ce qui permet
à n’importe quel langage d’être utilisé avec Pypy à condition
qu’ils puissent être traduit en RPython. Pour plus d’informations,
je vous invite à consulter le site officiel de Pypy dont le lien est
communiqué en fin d’article.</p>
<h2>La compilation JIT (Just-In-Time)</h2>
<p>Le langage Python offrant des outils très haut niveau (tels que des
fonctionnalités Objet avancées), il est difficile et globalement
inefficace (comparativement à des langages plus bas niveaux tels que le
C) de le compiler statiquement, on ne se tournera donc pas vers de la
compilation statique si l’on recherche des performances honorables. Il
existe heureusement une alternative très performante à la compilation
statique, il s’agit de la compilation JIT (Just-In-Time, ou « à la
volée »). C’est cette technologie qui est utilisée dans le projet
Pypy, ce qui permet d’offrir au langage Python des performances dignes
de langages compilés statiquement tels que le C ou le C++. Voyons de
quoi il s’agit.</p>
<p>La compilation Just-In-Time (ou dynamique) représente une approche
hybride entre la compilation statique et l’interprétation, elle a
pour but d’obtenir des performance égales, voire supérieures, à la
compilation statique classique. Les compilateurs JIT convertissent du
Bytecode en code machine à la volée (au moment de l’exécution).
Mais pour limiter la dégradation des performances, plusieurs techniques
sont utilisées. Premièrement, il est possible de mettre en cache
certaines parties d’un programme afin de ne pas avoir à les
retraduire inutilement lors d’exécutions ultérieures si leur code
source n’a pas été modifié entre temps. Deuxièmement, grâce à
un système de détection des points chauds (parties d’un programmes
étant très sollicitées lors de l’exécution), le compilateur peut
décider de traduire une partie du programme en code machine si cela
s’avère plus intéressant qu’une simple interprétation en terme de
temps d’exécution.</p>
<p>De plus, de nombreuses optimisations ne sont possibles qu’au moment
de l’exécution du programme. Un compilateur JIT peut donc utiliser
les informations du contexte d’exécution afin d’améliorer les
performance d’un programme. Notamment, il est possible d’adapter le
code machine produit en fonction de l’architecture du processeur ou
encore d’effectuer de l’inlining de bibliothèques dynamiques, sans
perdre pour autant les avantages du linkage dynamique.</p>
<p>La compilation JIT est utilisée par la machine virtuelle du Java ou
encore le C#.</p>
<h2>Compiler et utiliser Pypy</h2>
<p>Il existe deux solutions pour utiliser Pypy. Soit votre distribution
Linux favorite vous le propose directement depuis ses dépôts, auquel
cas il vous suffit de l’installer, soit vous pouvez télécharger
les sources depuis le mercurial de Pypy. Attention néanmoins, si
vous installez Pypy depuis les dépôts de votre distribution, il est
possible qu’il remplace une version existante de Python sur votre
ordinateur.</p>
<p><em>Building from sources</em> : Nous allons voir ici comment télécharger les
sources de Pypy, les compiler puis utiliser le binaire produit. Avant
toute chose, il faut savoir que la compilation de Pypy est extrêmement
gourmande en ressources (mémoire vive et CPU), si vous n’avez pas
4 Go de RAM sur votre PC, il faudra passer par les dépôts de votre
distribution, sans quoi vous risquez de partir en Swap infini …</p>
<p><em>Liste des dépendances</em> : <a href="http://pypy.readthedocs.org/en/latest/getting-started-python.html#translating-the-pypy-python-interpreter" target="_blank" rel="noopener noreferrer">http://pypy.readthedocs.org/en/latest/getting-started-python.html#translating-the-pypy-python-interpreter</a></p>
<p>Une fois toutes les dépendances installées, récupérez les sources de
Pypy en lançant la commande suivant :</p>
<pre class="code" data-lang="sh"><code>$ hg <span class="hljs-built_in">clone</span> https://bitbucket.org/pypy/pypy
</code></pre>
<p>Rendez-vous ensuite dans le répertoire goal :</p>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">cd</span> pypy/pypy/translator/goal
</code></pre>
<p>Lancez enfin le script avec Python (ou avec Pypy lui-même si vous
l’avez déjà installé, ce qui vous fera économiser du temps et de
la mémoire) :</p>
<pre class="code" data-lang="sh"><code>$ python2 translate.py -Ojit
</code></pre>
<p>Vous apprécierez au passage les fractales de Mandelbrot qui seront
dessinées dans votre terminal pendant la compilation.</p>
<p>Une fois le long processus terminé, un binaire nommé pypy-c est
normalement présent dans le répertoire. Vous pouvez le renommer et/ou
le déplacer afin de l’utiliser comme bon vous semble. Il remplace le
binaire Python traditionnel, vous pouvez donc l’utiliser de la façon
suivante :</p>
<pre class="code" data-lang="sh"><code>$ ./pypy mon_script.py <span class="hljs-comment"># votre script python</span>
</code></pre>
<h2>Bref aperçu des performances</h2>
<p>Pour terminer, voici un bref aperçu des performances de Pypy
comparativement à d’autres implémentations/langages disponible sur
la page Performance officielle du site de Pypy : <a href="http://speed.pypy.org/" target="_blank" rel="noopener noreferrer">http://speed.pypy.org/</a></p>
<h2>Bibliographie</h2>
<ul>
<li><a href="http://pypy.org/index.html" target="_blank" rel="noopener noreferrer">http://pypy.org/index.html</a></li>
<li><a href="http://fr.wikipedia.org/wiki/PyPy" target="_blank" rel="noopener noreferrer">http://fr.wikipedia.org/wiki/PyPy</a></li>
<li><a href="http://en.wikipedia.org/wiki/PyPy" target="_blank" rel="noopener noreferrer">http://en.wikipedia.org/wiki/PyPy</a></li>
<li><a href="http://en.wikipedia.org/wiki/Just-in-time_compilation" target="_blank" rel="noopener noreferrer">http://en.wikipedia.org/wiki/Just-in-time_compilation</a></li>
<li><a href="http://www.python.org/" target="_blank" rel="noopener noreferrer">http://www.python.org/</a></li>
<li><a href="http://fr.wikibooks.org/wiki/Python" target="_blank" rel="noopener noreferrer">http://fr.wikibooks.org/wiki/Python</a></li>
</ul>
<p>Le mot de la fin—Toutes les propositions et remarques sont bien
évidemment les bienvenues :)</p>
]]></content:encoded>
        </item>
    </channel>
</rss>