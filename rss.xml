<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Simplex Sigillum Veri</title>
        <link>https://remusao.github.io</link>
        <description>Simplex Sigillum Veri</description>
        <lastBuildDate>Thu, 12 Sep 2024 14:00:57 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <copyright>All rights reserved 2023, Rémi Berson</copyright>
        <atom:link href="https://remusao.github.io/rss.xml" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[A more efficient matching engine for HTTPS Everywhere RuleSets]]></title>
            <link>https://remusao.github.io//posts/efficient-https-everywhere-engine.html</link>
            <guid>https://remusao.github.io//posts/efficient-https-everywhere-engine.html</guid>
            <pubDate>Sat, 30 May 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><strong>TL;DR:</strong> <em>In this post I describe the results of an experiment showing
how matching of HTTPS Everywhere rules can be made <strong>between 4x and
10x more memory-efficient</strong>, initialization of the matching engine
reduced to less than <strong>25 milliseconds</strong>, and HTTPS upgrades performed
in <strong>0.0029</strong> to <strong>0.0073 milliseconds</strong>, using a different design
inspired by modern adblockers, without relying on the Rust/WebAssembly
combo (i.e. pure JavaScript).</em></p>
<p><strong>Disclaimer:</strong> <em>This work was <em>not</em> conducted as part of the HTTPS
Everywhere project. My intent when experimenting with rulesets matching
was to explore new ways to implement an efficient engine and document
my findings. I would of course love it if some of these ideas are used
upstream.</em></p>
<p>Over the last few years, the adoption of HTTPS has continuously increased,
reaching 50% of the Web traffic for the <a href="https://letsencrypt.org/stats/#percent-pageloads" target="_blank" rel="noopener noreferrer">first time in 2017</a>
and up to <a href="https://almanac.httparchive.org/en/2019/security#transport-layer-security" target="_blank" rel="noopener noreferrer">80% in 2019</a>.
Yet, <a href="https://www.eff.org/https-everywhere" target="_blank" rel="noopener noreferrer">according to the EFF</a>:
<em>“Many sites on the web [still] offer some limited support for
encryption over HTTPS, but make it difficult to use. For instance, they
may default to unencrypted HTTP, or fill encrypted pages with links that
go back to the unencrypted site.”</em></p>
<p>For this reason, the EFF started the HTTPS Everywhere project in 2014,
providing users with a browser extension able to automatically upgrade
connections to HTTPS whenever possible.</p>
<p>To decide when an upgrade is feasible, the extension relies on a database of
<em>rulesets</em> allowing it to know for a given URL if HTTPS is supported. These
rules are <a href="https://github.com/EFForg/https-everywhere/commits/master/src/chrome/content/rules" target="_blank" rel="noopener noreferrer">continuously updated</a>
to limit breakage and maximize coverage.</p>
<p>Having spent a fair amount of my time working on <a href="https://github.com/cliqz-oss/adblocker" target="_blank" rel="noopener noreferrer">content blockers</a> in the last
few years—especially on the <a href="https://whotracks.me/blog/adblockers_performance_study.html" target="_blank" rel="noopener noreferrer">performance aspect</a>—, I have always been curious
about how the rule-matching logic was implemented in HTTPS Everywhere, since the
task shares many similarities with adblocking. More recently, I stumbled
upon two tickets mentioning <a href="https://github.com/EFForg/https-everywhere/issues/12232" target="_blank" rel="noopener noreferrer">high memory usage</a> and <a href="https://trac.torproject.org/projects/tor/ticket/23719" target="_blank" rel="noopener noreferrer">slow initialization of the extension</a> and decided to have a closer look.</p>
<p>High memory and CPU usage are problematic for multiple reasons. As HTTPS
Everywhere is running in various environments—including potentially
low-end mobile phones—it has to perform decently even under
limited IO performance, slow CPUs and low amount of memory. Moreover,
HTTPS is included in Tor (on both desktop and mobile) where the JIT
can be disabled when security settings are maxed out, further degrading
performance. Also consider that while loading a
page, many components of the browser are competing for resources:
parsing HTML, evaluating JavaScript, rendering the page, but also
privacy protections such as adblockers, and of course, HTTPS
Everywhere. Last but not the least, energy consumption (especially on
mobile devices), is not to be ignored: A higher CPU usage means reduced
battery life.</p>
<p>While experimenting, I was wondering if some of the optimizations implemented
as part of modern content blockers would make sense in HTTPS Everywhere
and if they would improve the overall efficiency. This blog post presents some
of the results of this investigation. The following contributions and
improvements are presented:</p>
<ul>
<li>A new design, inspired by some of the same optimizations implemented
in the fastest content blockers, leading to an increased efficiency:
<ul>
<li><strong>~4.7MB</strong> of memory usage (<strong>4x less than the current HTTPS Everywhere</strong>
Rust/WebAssembly implementation), further reduced to <strong>~2.1MB</strong> when using an
experimental statistical data structure (with ideas to reduce it even more).</li>
<li>Decision time between <strong>0.0029</strong> and <strong>0.0073 milliseconds</strong> when
querying the rulesets with a URL to be upgraded to HTTPS.</li>
<li>Serialization to and deserialization from a compact binary representation
in under <strong>25 milliseconds</strong> and no memory copy.</li>
</ul>
</li>
<li>Design and implementation of a compact index data structure allowing to
efficiently retrieve a small subset of rules likely to apply to a given input
URL.</li>
<li>A built-in small string compression implementation inspired by SMAZ which
allows to reduce memory usage by up to 60%.</li>
<li>An experimental statistical data structure allowing an even lower
memory usage, at the risk of unlikely collisions.</li>
<li>An experimentation with a compact trie data structure to attempt reducing
memory usage further.</li>
</ul>
<h2>The Rules</h2>
<p>Before digging deeper into the design of the matching engine, let’s briefly
describe <a href="https://www.eff.org/https-everywhere/rulesets" target="_blank" rel="noopener noreferrer">HTTPS Everwhere rulesets</a>.</p>
<p>The database of rules is made of <em>thousands of rulesets</em> (currently
about 25k). Each <em>ruleset</em> is an XML file containing information about
upgrading requests to HTTPS for a domain or group of domains (e.g.
for an organization like Bitly). The file can contain the following
entities:</p>
<ul>
<li><strong>Targets</strong>—define which domains are targeted by this ruleset (e.g.
<code>example.com</code>). They can also make use of wildcards, either to target all
subdomains, or multiple top-level domains.</li>
<li><strong>Exclusions</strong>—are regular expressions allowing to prevent some specific domains or URLs from
being upgraded to HTTPS (e.g. to prevent breakage).</li>
<li><strong>Rules</strong>—define how insecure requests should be upgraded <em>from</em>
insecure <em>to</em> secure (i.e. they encode the URL rewriting logic).
They define a <code>from</code> regular expression which the input URL should match,
associated with a <code>to</code> attribute describing how the upgraded URL should look like.
The most common case being to simply transform <code>^http:</code> into <code>https:</code>.</li>
<li><strong>Secure Cookies</strong>—Optionally defined if cookies from one of the targeted
domains should be secured as well using hardened flags.</li>
</ul>
<p>Here is a simple example of how such a ruleset could look like:</p>
<pre class="code" data-lang="xml"><code><span class="hljs-tag">&lt;<span class="hljs-name">ruleset</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;example.com&quot;</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">target</span> <span class="hljs-attr">host</span>=<span class="hljs-string">&quot;example.com&quot;</span> /&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">target</span> <span class="hljs-attr">host</span>=<span class="hljs-string">&quot;*.example.com&quot;</span> /&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span> <span class="hljs-attr">pattern</span>=<span class="hljs-string">&quot;^http://unsecure\.example\.com/&quot;</span> /&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">rule</span> <span class="hljs-attr">from</span>=<span class="hljs-string">&quot;^http:&quot;</span> <span class="hljs-attr">to</span>=<span class="hljs-string">&quot;https:&quot;</span> /&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">securecookie</span> <span class="hljs-attr">host</span>=<span class="hljs-string">&quot;.+&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;.+&quot;</span> /&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">ruleset</span>&gt;</span>
</code></pre>
<h2>Matching Algorithm</h2>
<p>Given a collection of rulesets, the decision of upgrading an insecure request
to a secure one relies on the following steps:</p>
<ol>
<li>Identifying the subset of rulesets <em>targeting</em> the URL’s domain.</li>
<li>Eliminating rulesets having at least one matching <em>exclusion</em> rule.</li>
<li>Evaluating the <em>rules</em> from the candidate rulesets until one matches.</li>
</ol>
<p>If a matching <code>rule</code> is found following the previous steps, then the URL is
rewritten to a secure version using the rewriting logic defined by
this <code>rule</code>. For more information about the exact semantic of matching
rulesets, check <a href="https://www.eff.org/https-everywhere/rulesets" target="_blank" rel="noopener noreferrer">this page</a> of the official documentation.</p>
<h2>Efficient Matching</h2>
<p>The naive approach to writing a matching algorithm would be to iteratively inspect
all rulesets for each input URL, checking their <em>targets</em>, <em>exclusions</em> and
<em>rules</em> until a match is found. This would not be very efficient and
we can do better (to be clear, this is <em>not</em> the approach taken by HTTPS
Everywhere and I only describe it to get a sense of the most naive solution).</p>
<p>In the following few sections we are going to explore some of the
biggest ideas contributing to the speed and memory efficiency of the
new matching engine. Firstly, I will present the central <em>indexing
data structure which allows to drastically reduce the amount of work
required</em> to find relevant rulesets. Secondly, I will walk you through
<em>how this index can be represented in a very compact way</em>, as a single
typed array. Thirdly, we will see how we can further reduce the memory
usage by implementing a built-in string compression capability to this
compact index. Lastly I will briefly describe two other attempts at
reducing the size of the index using a trie data structure and an
experimental probabilistic data structure based on hashing.</p>
<h3>Reverse Index</h3>
<p>Instead of iterating through all rulesets for each input URL, we
want to quickly identify a small subset of candidates which will be
evaluated against the input URL. To achieve this goal, we rely on
a <a href="https://github.com/remusao/https-everywhere-core/blob/master/src/reverse-index.ts" target="_blank" rel="noopener noreferrer">reverse index</a>
which groups <em>targets</em>, <em>exclusions</em> and <em>rules</em> into buckets indexed
by a common substring (or <em>token</em>) that they contain. This allows us to
collect candidates for a given URL by querying the index with tokens
found in the URL. Each candidate retrieved is thus guaranteed to share
at least a common substring with the URL. In practice, this drastically
reduces the amount of work required to take a decision. This technique is
<a href="https://0x65.dev/blog/2019-12-20/not-all-adblockers-are-born-equal.html#CurrentApproach" target="_blank" rel="noopener noreferrer">used as part of content blockers</a>
to identify lists of filters indicating that a network request should be
canceled.</p>
<p>We create a separate index for <em>targets</em>, <em>exclusions</em>, <em>rules</em> and
<em>secure cookies</em>. To minimize the number of candidates retrieved for
each URL, we make sure that each <em>target</em> and <em>secure cookie</em> is indexed using <em>its rarest
token</em>, whereas <em>exclusions</em> and <em>rules</em> are indexed only using the ID
of the ruleset they belong to. In practice, each index is created
using the following algorithm:</p>
<ol>
<li>Each element is tokenized using <code>\w+</code> (alpha-numeric characters) or
the ruleset ID is used as a token. For example <em>target</em> <code>example.com</code>
would be tokenized into <code>['example', 'com']</code>.</li>
<li>We keep track of the number of occurrences of each token with a global
counter.</li>
<li>We then select the <em>best</em> (i.e. least seen) token for each element, and use
it as a key in the reverse index.</li>
</ol>
<p>As a result, most <em>buckets</em> of the index will contain a single element
(meaning that we found a token which is unique globally to index the
element). To get a better idea of the dispatching capabilities brought by this
technique, consider the following statistics collected by matching <a href="https://cdn.cliqz.com/adblocking/requests_top500.json.gz" target="_blank" rel="noopener noreferrer">a
datasets</a>
containing 240k URLs from the most popular domains against the HTTPS
Everywhere rulesets:</p>
<ul>
<li>The median number of <em>targets</em> candidates evaluated for a given URL
is: <strong>7</strong>—from a total of 163k; which means we only need to look at
0.004% of all <em>targets</em> on average. And out of these targets, most
only cost a look-up in a <code>Set</code> since we often get multiple candidates from
the same ruleset. By keeping track of which rulesets we are already
considering, we only need to evaluate the first target from a given ruleset. The
median number of <em>targets</em> candidates requiring a string comparison is: <strong>5</strong>.</li>
<li>The median number of <em>rulesets</em> considered is: <strong>1</strong>, with a maximum of:
<strong>2</strong> in the rare case where a given domain is targeted by more than one
ruleset (from a total of 25k).</li>
<li>For each ruleset, we then retrieve a combined exclusion (all regular
expressions aggregated into one, joined with <code>|</code> characters), resulting in one
or two <code>RegExp</code> evaluations (from the one or two rulesets considered).</li>
<li>Finally, we inspect the <em>rules</em> from each ruleset not already excluded, until we find a
match. The median number of <em>rules</em> considered is <strong>2</strong>.</li>
</ul>
<figure><a href="../images/posts/efficient-https-everywhere-engine/speed.svg" target="_blank" rel="noopener noreferrer"><img src="../images/posts/efficient-https-everywhere-engine/speed.svg" alt="" loading="lazy"></a><figcaption>Average decision time per URL.</figcaption></figure>
<p>This graph depicts the average time it takes to rewrite a request to
HTTPS, based on the latest snapshots of rulesets, evaluated against the
dataset of 240k URLs mentioned above. Please note that internal caching
of HTTPS Everywhere <em>was disabled</em> for these measurements, to only take
into account the raw speed of the engine.</p>
<p>It is surprising to observe that the Rust/WebAssembly version is slower
than the JavaScript implementation. Although both are really fast since
even the “slowest” result is of <strong>0.028 milliseconds</strong> on average.
It could very well be that the overhead of transferring data from
JavaScript to WebAssembly is responsible for this result. On the other
hand, we see that our reverse index implementation is faster than both,
with an average time between <strong>0.0046</strong> and <strong>0.0073 milliseconds</strong>. Note
that running the same benchmark in Node.js results in an even faster
decision time of <strong>0.0029 milliseconds</strong>—this might be explained by
the fact that browsers are less friendly to benchmarking due to the many
components potentially competing for CPU resources, but this is just
speculation on my part.</p>
<h3>Binary Representation</h3>
<p>While the indexing technique described in the previous section
speeds-up matching drastically, it is not optimal in terms of memory
usage and initialization time. If the index is represented as a <code>Map</code>,
it means that on each initialization (when the extension starts) we need
to either re-create the index from scratch (using the raw XML rulesets or a JSON
version of it), or load it from a textual representation of the <code>Map</code>
(i.e. from cache), like an array of <em>key</em>, <em>value</em> pairs.</p>
<p>Instead, the reverse index described above is implemented as a compact binary
data structure stored in a single <code>Uint8Array</code> (typed array), where the data is
organized in a way that allows for efficient look-ups. In-memory
instances of <em>targets</em>, <em>exclusions</em>, <em>rules</em> and <em>secure cookies</em>
along with the instances of <code>RegExp</code> required to match against input
URLs and domains are only lazily loaded and compiled from their binary
representation stored in the typed array, when there is a chance they will match, thanks to the
reverse index. These instances can also be (optionally) cached into a
<code>Map</code> so that subsequent look-ups do not need to hit the binary index
(which is a bit slower than <code>Map.get</code>).</p>
<p>Since the number of rulesets really considered in practice is more or less
proportional to the number of unique domains visited by a user during a browsing
session, the additional memory usage required for the caching mechanism is
fairly small.</p>
<p>More implementation details are given in the section “Going low-level with typed arrays” from <a href="https://0x65.dev/blog/2019-12-20/not-all-adblockers-are-born-equal.html" target="_blank" rel="noopener noreferrer">this other article</a>. To summarize the benefits of this data structure:</p>
<ul>
<li>It allows to encode all rulesets into a very compact, binary format, stored
in a single <code>Uint8Array</code>. The total memory usage of the extension using such
an engine is therefore fairly predictable, and close to the size of this typed array.</li>
<li>Serialization and deserialization are extremely efficient since the
look-ups can be performed directly on this <code>Uint8Array</code> instance without
the need to first copy the data into a more convenient data structure
such as a <code>Map</code>. Serialization thus consists in storing the same typed
array locally (e.g. in IndexedDB), and deserialization consists in
reading it back.</li>
<li>This binary data structure can be created once on the server-side and hosted
on a CDN, so that clients can fetch it directly, speeding-up initialization
further (The following <a href="https://github.com/remusao/https-everywhere-core/blob/master/engine.bin" target="_blank" rel="noopener noreferrer">binary file</a> is updated automatically using a GitHub Workflow triggered using <code>cron</code>).</li>
<li>In-memory instances of <em>targets</em>, <em>exclusions</em>, <em>rules</em> and <em>secure
cookies</em> along with the instances of <code>RegExp</code> required to match against
input URLs and domains are only lazily loaded and compiled from the
binary representation, when there is a chance they will match, thanks to
the reverse index.</li>
</ul>
<p>The drawback of this approach, though, is that updating (adding or deleting
elements from the index), currently requires to recreate the index completely,
which is relatively costly (it takes around <em>500 milliseconds</em>). But since
updates can be performed backend-side, and are relatively infrequent,
this is not a road-blocker.</p>
<figure><a href="../images/posts/efficient-https-everywhere-engine/init.svg" target="_blank" rel="noopener noreferrer"><img src="../images/posts/efficient-https-everywhere-engine/init.svg" alt="" loading="lazy"></a><figcaption>Average initialization time for rulesets.</figcaption></figure>
<p>These measurements offer some fairly surprising results. On the one hand
we see that Chrome seems to struggle with the WebAssembly version compared to
Firefox. Once again the JavaScript implementation outperforms the
Rust/WebAssembly combo, though. Again, my best guess is that the amount of
data transfered to WebAssembly context might be partly responsible for that, but
I would love to get more insights from core developers on this. We also see that
our binary index is extremely fast to initialize, between <strong>12</strong> and <strong>45
milliseconds</strong>. We could reduce it further by disabling the built-in <em>CRC-32</em> checksum
mechanism which ensures that the buffer is not corruption before deserializing
it, but this does not seem necessary.</p>
<h3>String Compression</h3>
<p>Up to this point, we have shown how we can efficiently query rulesets and how the
indexing data structures can be represented in a compact way, friendly to
serialization and deserialization to allow faster initializations. The size of
the final typed array is roughly of <strong>7MB</strong>. When looking closer, it appears that a
big proportion of this data consists of the raw strings from <em>targets</em> (<code>host</code>),
<em>exclusions</em> (<code>pattern</code>), <em>rules</em> (<code>from</code> and <code>to</code>), as well as <em>secure cookies</em>
(<code>host</code> and <code>name</code>): about <strong>3MB</strong>, or a bit more than 40% of the total size.</p>
<p>Looking at these strings, it does not take long to notice that some values are
very frequent, like <code>.+</code> in <em>secure cookies</em>, or <code>^http:</code> and <code>https:</code> in
<em>rules</em>. One way to take advantage of these patterns would be to hard-code the
detection of some of the common strings and replace them by
opcodes, or perform some kind of <a href="https://en.wikipedia.org/wiki/String_interning" target="_blank" rel="noopener noreferrer">string interning</a>,
to avoid having many times the same data in memory (or in the compact reverse
index).</p>
<p>Another way to look at the problem, which could also be seen as a string
interning mechanism, is to rely on a codebook-based compression algorithm to
reduce the size of strings. It so happens that I had already experimented with
such techniques in the past (e.g. using <a href="https://github.com/antirez/smaz" target="_blank" rel="noopener noreferrer">SMAZ</a> or
<a href="https://ed-von-schleck.github.io/shoco/" target="_blank" rel="noopener noreferrer">shoco</a>). I ended up implementing a
custom variant of SMAZ in pure-JavaScript to integrate into the <a href="https://github.com/cliqz-oss/adblocker" target="_blank" rel="noopener noreferrer">adblocker</a>
I was working on. The library offers an <a href="https://github.com/remusao/mono/tree/master/packages/smaz-generate#remusaosmaz-generate" target="_blank" rel="noopener noreferrer">automatic codebook-generation
function</a>
that tries to find optimal codebooks based on a list of input strings.</p>
<p>Applying this codebook compression idea to rulesets, we are able to compress
strings by 40 to 60%, further reducing the total size of the serialized engine to
<strong>5MB</strong> (i.e. a <em>2MB</em>, or <em>30%</em>, reduction). Applying this optimization can be
done transparently in the custom DataView-like <a href="https://github.com/remusao/https-everywhere-core/blob/master/src/data-view.ts" target="_blank" rel="noopener noreferrer">abstraction</a>
used to serialize data to the binary representation and back.</p>
<p>A drawback of relying on codebooks is that they need to be re-generated when the
rulesets are updated so that they remain relevant. The <a href="https://github.com/remusao/https-everywhere-core/blob/master/.github/workflows/rulesets.yml" target="_blank" rel="noopener noreferrer">prototype hosted on
GitHub</a>
is relying on a GitHub Workflow to update the codebooks based on the latest
snapshot of the rules and open a PR with the updated assets. The codebooks are
also shipped as part of the binary representation of the matching engine, which
means that clients downloading a new version from the CDN (i.e. GitHub) always
get the best compression, without needing to update the source code.</p>
<figure><a href="../images/posts/efficient-https-everywhere-engine/memory.svg" target="_blank" rel="noopener noreferrer"><img src="../images/posts/efficient-https-everywhere-engine/memory.svg" alt="" loading="lazy"></a><figcaption>Memory usage with strings compression.</figcaption></figure>
<p>This plot shows the size occupied by rulesets as reported by the Chrome
Memory Dev Tool with a snapshot. We see that the memory usage went down
with WebAssembly compared to the initial JavaScript implementation of
HTTPS Everywhere. On the other hand, our binary index uses less memory,
and the difference is even bigger when using string compression as well.</p>
<h3>Do. Or do not. There is no Trie.</h3>
<p>Although the codebook-based compression is very effective at reducing the memory usage
of raw strings needed for matching rulesets, there might be more efficient
approaches depending on the nature of the data. In particular, <em>targets</em> are
domain names, most of which are not using wildcards at all; they also represent the bulk of the strings. A <a href="https://en.wikipedia.org/wiki/Trie" target="_blank" rel="noopener noreferrer">trie</a>
is commonly used to represent this kind of data. We expect suffixes of domains
to be repeated among many targets (some top-level domains are very common).</p>
<p>I already knew it was possible to encode a trie in a very compact
way—using only one 32-bit number to represent each node when storing ASCII
strings. Before putting the work to implement this new data structure, I started
by estimating the expected final size to make sure it was worth it.</p>
<p>I constructed the trie in-memory using a more naive representation based
on JavaScript objects and an instance of <code>Map</code> in each node to link
a parent to its children. Storing all <em>targets</em> resulted in a trie of
<code>1,654,430</code> nodes, which would result in about <strong>6.6MB</strong> of memory with our
compact representation. Not very encouraging…</p>
<p>I then realized that it would probably make more sense to store the domains in
reverse, to benefit from compression of top-level domains. After reversing the
order of <em>targets</em> on insertion, the number of nodes went down to <code>878,251</code>,
which would result in <strong>3.5MB</strong> of memory. This already seemed more reasonable.
But we also need to factor-in the extra information about which ruleset each
<em>target</em> belongs to (information needed when matching). Given that we have <code>163,486</code>
<em>targets</em>, and assuming we find a way to encode the ruleset membership with an
extra 32-bit number for each target, a back-of-the-envelope calculation tells us
that we would need an extra <em>650KB</em>, resulting in a total of <strong>4.1MB</strong> memory
usage. Even assuming a very optimistic 16-bit overhead per target, we would
still need more memory to store <em>targets</em> than with the codebook-compression
approach described above.</p>
<p>This concluded the experimentation with tries. Unfortunately, it does not seem
like using a trie would yield any significant savings compared to the string
compression method already implemented. It might be a viable option if string
compression is not to be implemented at all. Also, it could be that better
results can be obtained using a more advanced trie structure such as a <a href="https://en.wikipedia.org/wiki/Radix_tree" target="_blank" rel="noopener noreferrer">patricia</a>
or <a href="https://db.in.tum.de/~leis/papers/ART.pdf" target="_blank" rel="noopener noreferrer">adaptive (ART)</a> trie, which
would allow to store multiple characters into a single node.</p>
<h3>Compact Hashes</h3>
<p>At this point it seemed like the different new ideas to improve the memory
representation of rulesets were hitting diminishing returns. As a last trick, I
thought of implementing a data structure which allows to trade space for
uncertainty (a.k.a. probabilistic data structure). I had already experimented
with a similar approach when working on the <a href="https://github.com/remusao/tldts#tldts---blazing-fast-url-parsing" target="_blank" rel="noopener noreferrer"><code>tldts-experiment</code></a> package.
You are probably familiar with <a href="https://en.wikipedia.org/wiki/Bloom_filter" target="_blank" rel="noopener noreferrer">Bloom filters</a>,
which allow to perform membership tests on a potentially large collection of
elements, while keeping the memory usage under control (by adjusting the
probability of false positives).</p>
<p>Instead of going for full-blown Bloom filters, I decided to experiment with a
simpler method, also based on hashing. The idea is fairly simple, each domain
in the collection is stored in a bucket alongside domains having
the same number of labels. Each bucket is a sorted array of 32-bit hashes of
these domains. We could also store all hashes in a single array regardless of
the number of labels, but this increases the probability of collisions by a
<em>factor of 2</em>. Each bucket is followed by a second array of same size,
containing ids of rulesets to which the targets belong. The final data structure
is then composed of all buckets concatenated into a single <code>Uint32Array</code>.</p>
<p>Using <a href="https://github.com/remusao/https-everywhere-core/blob/master/src/hashes.ts" target="_blank" rel="noopener noreferrer">this trick</a>
allows to reduce the size of the final serialized engine to <strong>2.1MB</strong> (i.e. a
<em>2MB</em>, or <em>40%</em>, reduction). This comes at the cost of a <code>0.000017</code> probability of
collision when looking-up <em>targets</em> in the index (estimated using <a href="https://github.com/duckduckgo/smarter-encryption/blob/master/README.md#just-want-the-list" target="_blank" rel="noopener noreferrer">a list of 20M
popular domains</a>).
For this reason, this feature is turned-off by default but can be enabled
using a config flag when building the binary engine.</p>
<p>Note that an extra <em>320KB</em> of memory could be saved by
using a 16-bit identifier for ruleset IDs instead of the current 32-bit
identifier (which could work because we only have 25k rulesets at the
moment and this can be represented using 16-bit numbers). This would reduce
the total memory usage to <strong>1.8MB</strong> of memory (i.e. a 10x improvement over the
memory usage of the current HTTPS Everywhere implementation in Rust compiled to
WebAssembly).</p>
<h2>Conclusion and Future Work</h2>
<p>In this article I have presented the current state of an experiment
aiming at implementing a more efficient matching engine for HTTPS
Everywhere rulesets. Using a radically different design, matching can
be made <strong>between 4x and 10x more memory-efficient</strong>, initialization of
the engine reduced to less than <strong>25 milliseconds</strong>, and HTTPS upgrades
performed in <strong>0.0029</strong> to <strong>0.0073 milliseconds</strong>, without relying on
the Rust/WebAssembly combo.</p>
<p>The source code can be <a href="https://github.com/remusao/https-everywhere-core" target="_blank" rel="noopener noreferrer">found on
GitHub</a>. You can also
install a simple WebExtension and try out the new engine locally in
Firefox or Chromium.</p>
<p>There are currently a few known limitations compared to the official
HTTPS Everywhere:</p>
<ul>
<li>No way for users to add custom rules. This can be implemented
as a second, smaller engine which would be stored separately from the
main rulesets.</li>
<li>Rulesets need to have a unique 32-bit identifier known when creating
the index. For built-in rules, this ID is determined whenever the engine
is created. To handle user-defined rules, we could either rely on a counter
maintained client-side, or a 32-bit hash of the ruleset name.</li>
<li>Metadata for rulesets (i.e. the name and default state) are currently
discarded at build-time. It would be fairly easy to include them in the engine
for an estimated overhead of <em>350KB</em> in the final size. It should be noted,
though, that the <code>name</code> information is currently not needed in the prototype.</li>
<li>Rulesets marked as <em>mixedcontent</em>—only supported in the Tor browser—are
discarded at build time. They could easily be included, either enabled
by default (if we ship two different engines, fetched by clients
depending on their browser support), or side-by-side with the
other rules and enabled dynamically.</li>
</ul>
<p>Lastly, I was surprised to observe that the Rust/WebAssembly version of
the engine as currently shipped in HTTPS Everywhere seems to be slower at both
initialization and operating than the previous JavaScript implementation. This
seems to contradict the <a href="https://twitter.com/eff/status/1172622942158479360" target="_blank" rel="noopener noreferrer">previous claims</a>
when this was <a href="https://twitter.com/HTTPSEverywhere/status/1144375820334424064" target="_blank" rel="noopener noreferrer">first released</a>.
I’d love to get some feedback from core developers about this potential
issue and more insights from them to understand why I got these results.</p>
<p>I hope this work will be helpful to the community and I would be glad to
discuss these findings in more details with people directly working on
the HTTPS Everywhere extension.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Parsing Thunderbird filtering rules]]></title>
            <link>https://remusao.github.io//posts/parsing-thunderbird-msg-filters.html</link>
            <guid>https://remusao.github.io//posts/parsing-thunderbird-msg-filters.html</guid>
            <pubDate>Sun, 24 Nov 2019 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p><a href="https://www.thunderbird.net/" target="_blank" rel="noopener noreferrer">Thunderbird</a> is a free email application that’s
easy to set up and customize - and it’s loaded with great features!</p>
</blockquote>
<p>I have been using Thunderbird as my email client of choice for many years, it
is the hub which allows me to manage all the emails I get: work, multiple
personal addresses, etc. As of today my combined mail folders are about <code>30GB</code>
and counting. Still, Thunderbird has been running rock solid and I had no issue
so far.</p>
<p>I have to say that I make extensive use of folders, labels and <em>message
filters</em>. These features combined allow to effortlessly manage a high volume of
emails by filtering, sorting, tagging, dispatching emails; greatly reducing the
amount of manual work needed to process then read them.</p>
<p>As an example, I receive a lot of emails notifications from GitHub, both for work and personal
OSS projects. I also tend to follow activity of repositories which I find
interesting; but I do not want to have to go through all these notifications
myself. A few years ago I adopted the following strategy:</p>
<ol>
<li>Create folders or subfolders for each repository:</li>
</ol>
<ul>
<li><code>github/work/repo1</code>,</li>
<li><code>github/work/repo2</code>,</li>
<li><code>github/perso/repo3</code>,</li>
<li>etc.</li>
</ul>
<ol start="2">
<li>Create a first filter rule <em>for each repository</em> to automatically move
GitHub notifications to their respective folders. This can be achieve by
detecting <code>notifications@github.com</code> using a condition of the form <code>From is notifications@github.com</code> and adding a <code>Move Message to</code> action.</li>
<li>Optionally, I create rules to automatically mark as read any
message which is not directed to me specifically (e.g.: via direct mention
of my GitHub handler, PR request, issue assigned, etc.); especially on very
active repositories. This can be achieved by detecting things like
<code>mention@noreply.github.com</code> or <code>assign@noreply.github.com</code> in the <code>Cc</code>
field.</li>
</ol>
<p>GitHub has a <a href="https://help.github.com/en/github/receiving-notifications-about-activity-on-github/about-email-notifications" target="_blank" rel="noopener noreferrer">full page of documentation</a>
describing all the values you can use to filter email notifications. This is
<em>really useful</em>. For example I tag emails where I am directly mentioned in
<strong>red</strong> but notifications about discussions that I was involved in but not
directly mentioned with <strong>blue</strong>. This allows to filter at a glance what I
really need to check, versus what I can check later. In practice, more than 90%
of notifications do not need to be checked manually. This is huge!</p>
<p>Unfortunately, as the number of filters grows, I found the built-in interface
to not be very convenient. Finding or editing rules can become a pain.
Fortunately, Thunderbird stores all the filters for a given account in a
single, plain text file named: <code>msgFilterRules.dat</code>, located in your
Thunderbird profile folder. So I decided to write <a href="https://github.com/remusao/thunderbird-msg-filters" target="_blank" rel="noopener noreferrer">a
library</a> which allows to
manipulate these rules through a minimal and type-safe API; in <em>TypeScript</em>.</p>
<p>The goal of the project is to allow developing more high-level tooling to
read, transform, extend, update the rules while not having to worry about the
low-level parsing details. It would also be possible to store the rules in a
nicer format then use the library to produce the final file which can be
consumed by Thunderbird.</p>
<p>To install the library: <code>npm install --save thunderbird-msg-filters</code>.</p>
<p>You can then use it to parse a <code>msgFilterRules.dat</code> file which you can find in
your Thunderbird folder (one per email account configured):</p>
<pre class="code" data-lang="typescript"><code><span class="hljs-keyword">import</span> { parse } <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;thunderbird-msg-filters&#x27;</span>;

<span class="hljs-comment">// A typical `msgFilterRules.dat` could contain this raw value.</span>
<span class="hljs-keyword">const</span> rules = <span class="hljs-title function_">parse</span>(<span class="hljs-string">`
version=&quot;9&quot;
logging=&quot;no&quot;
name=&quot;rule 1&quot;
enabled=&quot;yes&quot;
type=&quot;17&quot;
action=&quot;Mark flagged&quot;
condition=&quot;OR (subject,contains,foo) OR (subject,contains,bar)&quot;
name=&quot;rule 2&quot;
enabled=&quot;yes&quot;
type=&quot;17&quot;
action=&quot;Mark read&quot;
action=&quot;JunkScore&quot;
actionValue=&quot;100&quot;
condition=&quot;ALL&quot;
`</span>);
</code></pre>
<p>You can also format rules to the same original format:</p>
<pre class="code" data-lang="typescript"><code><span class="hljs-keyword">import</span> { format } <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;thunderbird-msg-filters&#x27;</span>;

<span class="hljs-keyword">const</span> rules = <span class="hljs-title function_">format</span>({
  <span class="hljs-attr">version</span>: <span class="hljs-string">&#x27;9&#x27;</span>,
  <span class="hljs-attr">logging</span>: <span class="hljs-string">&#x27;no&#x27;</span>,
  <span class="hljs-attr">rules</span>: [
    {
      <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;rule 1&#x27;</span>,
      <span class="hljs-attr">enabled</span>: <span class="hljs-string">&#x27;yes&#x27;</span>,
      <span class="hljs-attr">type</span>: <span class="hljs-string">&#x27;17&#x27;</span>,
      <span class="hljs-attr">actions</span>: [{ <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;Mark flagged&#x27;</span>}],
      <span class="hljs-attr">condition</span>: <span class="hljs-string">&#x27;OR (subject,contains,foo) OR (subject,contains,bar)&#x27;</span>
    },
    {
      <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;rule 2&#x27;</span>,
      <span class="hljs-attr">enabled</span>: <span class="hljs-string">&#x27;yes&#x27;</span>,
      <span class="hljs-attr">type</span>: <span class="hljs-string">&#x27;17&#x27;</span>,
      <span class="hljs-attr">actions</span>: [
        { <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;Mark read&#x27;</span> }
        { <span class="hljs-attr">name</span>: <span class="hljs-string">&#x27;JunkScore&#x27;</span>, <span class="hljs-attr">value</span>: <span class="hljs-string">&#x27;100&#x27;</span> }
      ],
      <span class="hljs-attr">condition</span>: <span class="hljs-string">&#x27;ALL&#x27;</span>
    },
  ]
});
</code></pre>
<p>The library is currently very young and will probably contain bugs, so use at
your own risks. Feel free to use it and <a href="https://github.com/remusao/thunderbird-msg-filters/issues/new" target="_blank" rel="noopener noreferrer">open an issue</a>
for any feedback!</p>
<p><strong>What’s next?</strong> I plan to use this library to store the message filters rules
in a separate location and synchronize it potentially between multiple
computers. The nice thing is that the rules can now be expressed in a typed
language (TypeScript) which will give me more confidence about their validity.
It is also much easier to manipulate them from a single file, in a familiar
developer environment (i.e.: your editor of choice) than through the
Thunderbird interface.</p>
<p>GitHub repository: <a href="https://github.com/remusao/thunderbird-msg-filters/" target="_blank" rel="noopener noreferrer">https://github.com/remusao/thunderbird-msg-filters/</a></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Installing Diablo II]]></title>
            <link>https://remusao.github.io//posts/installing-diablo2-ubuntu-sandboxing.html</link>
            <guid>https://remusao.github.io//posts/installing-diablo2-ubuntu-sandboxing.html</guid>
            <pubDate>Sat, 02 Nov 2019 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<picture>
  <source srcset="../images/diablo2-banner.webp" type="image/webp">
  <source srcset="../images/diablo2-banner.png" type="image/png">
  <img src="../images/diablo2-banner.png" alt="Diablo II banner" style="width:100%">
</picture>
<p>You might have heard the news: <em>Diablo IV</em> has been announced yesterday with a
<a href="https://www.youtube.com/watch?v=9bRWIdOMfro" target="_blank" rel="noopener noreferrer">great cinematic</a>. What better
time to install <s>Diablo III</s> <em>Diablo II</em> again and have some fun while
waiting for the latest iteration of the franchise?</p>
<p>But… it’s 2019 and it is not always easy to install a game first released
back in June 2000 (yes, that’s 19 years ago. Yes, you’re old)! In this post I
will show you how to install <em>Diablo II</em> with its extension <em>Lord of
Destruction</em> on Windows, MacOS and Linux (Ubuntu in this case), using
<a href="https://www.winehq.org" target="_blank" rel="noopener noreferrer"><em>Wine</em></a> as well as optional sandboxing using
<a href="https://github.com/netblue30/firejail" target="_blank" rel="noopener noreferrer"><em>firejail</em></a>! Let’s get to it…</p>
<p>If you are running <em>MacOS</em> or <em>Windows</em>, you’re in luck! The official game
launcher already supports those platforms natively so you can install it and
play straight away without extra hassle! Here are the links:</p>
<ul>
<li><a href="https://eu.battle.net/download/getLegacy?product=D2DV&amp;locale=enUS&amp;os=WIN" target="_blank" rel="noopener noreferrer">Windows – Diablo II</a>.</li>
<li><a href="https://eu.battle.net/download/getLegacy?product=D2XP&amp;locale=enUS&amp;os=WIN" target="_blank" rel="noopener noreferrer">Windows – Lord of Destruction</a>.</li>
<li><a href="https://eu.battle.net/download/getLegacy?product=D2DV&amp;locale=enUS&amp;os=MAC" target="_blank" rel="noopener noreferrer">MacOS – Diablo II</a>.</li>
<li><a href="https://eu.battle.net/download/getLegacy?product=D2XP&amp;locale=enUS&amp;os=MAC" target="_blank" rel="noopener noreferrer">MacOS – Lord of Destruction</a>.</li>
</ul>
<h2>Get a License Key</h2>
<p>First of, you will need a valid CD-Key for the game (both <em>Diablo II</em> and its
extension <em>LOD</em>). You can get them on the <a href="https://www.blizzard.com" target="_blank" rel="noopener noreferrer">official website</a>
for about <em>20 euros</em> from Blizzard (yes, that’s a shame, the game used to cost
<em>15.99</em> euros a few years ago!), or by registering your old keys if you still
have the box version (which is what I did).</p>
<h2>Get the Launcher</h2>
<p>The second step is to download the Windows launcher of the game which we will
use in conjunction with Wine to make it work on Linux. You can find the links
on <a href="https://www.blizzard.com/en-us/download/" target="_blank" rel="noopener noreferrer">Blizzard’s website</a>. Here they
are if you want to save some time:</p>
<ul>
<li><a href="https://eu.battle.net/download/getLegacy?product=D2DV&amp;locale=enUS&amp;os=WIN" target="_blank" rel="noopener noreferrer">Downloader_Diablo2_enUS.exe</a></li>
<li><a href="https://eu.battle.net/download/getLegacy?product=D2XP&amp;locale=enUS&amp;os=WIN" target="_blank" rel="noopener noreferrer">Downloader_Diablo2_Lord_of_Destruction_enUS.exe</a></li>
</ul>
<h2>Installing Latest Wine</h2>
<p>You could probably use the stock version of wine which ships with your Linux
distribution but I always like to get the latest shiny version so here we go.
If you use another distribution than Ubuntu, you can <em>skip this section
completely</em>. From the <a href="https://wiki.winehq.org/Ubuntu" target="_blank" rel="noopener noreferrer">official wiki</a>:</p>
<blockquote>
<p>If your system is 64 bit, enable 32 bit architecture (if you haven’t already):</p>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">sudo</span> dpkg --add-architecture i386
</code></pre>
<p>Download and add the repository key:</p>
<pre class="code" data-lang="sh"><code>wget -nc https://dl.winehq.org/wine-builds/winehq.key
<span class="hljs-built_in">sudo</span> apt-key add winehq.key
</code></pre>
</blockquote>
<p>Now you need to get the repository matching your release of Ubuntu. For me it
was <code>bionic</code> (you can get yours using command <code>lsb_release -cs</code>), but check
official instructions if that does not correspond to yours.</p>
<blockquote>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">sudo</span> apt-add-repository <span class="hljs-string">&#x27;deb https://dl.winehq.org/wine-builds/ubuntu/ bionic main&#x27;</span>
<span class="hljs-built_in">sudo</span> apt install --install-recommends winehq-stable
</code></pre>
</blockquote>
<p>Note that I could not install <code>winehq-stable</code> directly and had to first install
one of its dependencies manually. If you encounter an error, then try to run
the following command before installing <code>winehq-stable</code> again:</p>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">sudo</span> apt install libasound2-plugins:i386
</code></pre>
<p>I am using <strong>version 4.0.2</strong> of <code>wine</code>.</p>
<h2>[Optional] Installing Firejail</h2>
<p>Firejail has a special place in my heart. It allows to sandbox any program
running on Linux using kernel capabilities (some of them you might already know
from Docker world). From the <a href="https://github.com/netblue30/firejail" target="_blank" rel="noopener noreferrer">official repository</a>:</p>
<blockquote>
<p>Firejail is a SUID sandbox program that reduces the risk of security breaches
by restricting the running environment of untrusted applications using Linux
namespaces, seccomp-bpf and Linux capabilities. It allows a process and all
its descendants to have their own private view of the globally shared kernel
resources, such as the network stack, process table, mount table. Firejail
can work in a SELinux or AppArmor environment, and it is integrated with
Linux Control Groups.</p>
</blockquote>
<p>There is an extra benefit in my opinion. You can specify a different directory
to be used as the <code>~/</code> (home) folder of each program you run in a sandbox
instead of your real home. This is great because it allows to keep files and
folders of each app nicely isolated. For example I run <code>thunderbird</code>, <code>cliqz</code>
and other programs in sandboxes and assign them different homes like
<code>~/.sandboxes/thunderbird</code>, <code>~/.sandboxed/cliqz</code>, etc. This means that I can
clean-up all files for each program by simply deleting their respective
folders! That’s super convenient.</p>
<p>Let’s get back to <em>Diablo II</em>! Install Firejail from your official Linux
repositories (or <a href="https://github.com/netblue30/firejail#compile-and-install" target="_blank" rel="noopener noreferrer">compile it yourself</a> if that’s
your thing… that’s what I did). I am currently running <strong>version 0.9.61</strong> but I
assume this should work with other versions as well.</p>
<p>Firejail comes with a preset for sandboxing wine which you can find at
<code>/etc/firejail/wine.profile</code>. That’s the one we will be using!</p>
<h2>Preparing Wine Home Folder</h2>
<p>Let’s now prepare the <code>wine</code> folder that we will use in our Firejail sandbox:</p>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">mkdir</span> -p ~/.sandboxes/wine
</code></pre>
<p>Copy the two downloaders into <code>~/.sandboxes/wine/</code>:</p>
<ul>
<li><code>~/.sandboxes/wine/Downloader_Diablo2_enUS.exe</code></li>
<li><code>~/.sandboxes/wine/Downloader_Diablo2_Lord_of_Destruction_enUS.exe</code></li>
</ul>
<h2>Installing Diablo II</h2>
<p>We can now proceed and install <em>Diablo II</em> base game:</p>
<pre class="code" data-lang="sh"><code>firejail \
  --profile=/etc/firejail/wine.profile \
  --private=~/.sandboxes/wine \
  wine ~/Downloader_Diablo2_enUS.exe
</code></pre>
<p>Here are screenshots for each step of the installation process:</p>
<figure>
  <a href="../images/diablo2-install-1.png">
    <picture>
      <source srcset="../images/diablo2-install-1.webp" type="image/webp">
      <source srcset="../images/diablo2-install-1.png" type="image/png">
      <img loading="lazy" src="../images/diablo2-install-1.png" alt="Press 'OK' to select default download folder." style="width:100%">
    </picture>
  </a>
  <figcaption>Press 'OK' to select default download folder.</figcaption>
</figure>
<figure>
  <a href="../images/diablo2-install-2.png">
    <picture>
      <source srcset="../images/diablo2-install-2.webp" type="image/webp">
      <source srcset="../images/diablo2-install-2.png" type="image/png">
      <img loading="lazy" src="../images/diablo2-install-2.png" alt="Enjoy the murloc view while downloading the game..." style="width:100%">
    </picture>
  </a>
  <figcaption>Enjoy the murloc view while downloading the game...</figcaption>
</figure>
<figure>
  <a href="../images/diablo2-install-3.png">
    <picture>
      <source srcset="../images/diablo2-install-3.webp" type="image/webp">
      <source srcset="../images/diablo2-install-3.png" type="image/png">
      <img loading="lazy" src="../images/diablo2-install-3.png" alt="Press 'Install Diablo II'." style="width:100%">
    </picture>
  </a>
  <figcaption>Press 'Install Diablo II'.</figcaption>
</figure>
<figure>
  <a href="../images/diablo2-install-7.png">
    <picture>
      <source srcset="../images/diablo2-install-7.webp" type="image/webp">
      <source srcset="../images/diablo2-install-7.png" type="image/png">
      <img loading="lazy" src="../images/diablo2-install-7.png" alt="Accept license." style="width:100%">
    </picture>
  </a>
  <figcaption>Accept license.</figcaption>
</figure>
<figure>
  <a href="../images/diablo2-install-6.png">
    <picture>
      <source srcset="../images/diablo2-install-6.webp" type="image/webp">
      <source srcset="../images/diablo2-install-6.png" type="image/png">
      <img loading="lazy" src="../images/diablo2-install-6.png" alt="Enter you CD-Key." style="width:100%">
    </picture>
  </a>
  <figcaption>Enter you CD-Key.</figcaption>
</figure>
<figure>
  <a href="../images/diablo2-install-5.png">
    <picture>
      <source srcset="../images/diablo2-install-5.webp" type="image/webp">
      <source srcset="../images/diablo2-install-5.png" type="image/png">
      <img loading="lazy" src="../images/diablo2-install-5.png" alt="Press 'OK' to select default destination directory." style="width:100%">
    </picture>
  </a>
  <figcaption>Press 'OK' to select default destination directory.</figcaption>
</figure>
<figure>
  <a href="../images/diablo2-install-4.png">
    <picture>
      <source srcset="../images/diablo2-install-4.webp" type="image/webp">
      <source srcset="../images/diablo2-install-4.png" type="image/png">
      <img loading="lazy" src="../images/diablo2-install-4.png" alt="It's so fast that I don't know how I managed to make a screenshot!" style="width:100%">
    </picture>
  </a>
  <figcaption>It's so fast that I don't know how I managed to make a screenshot!</figcaption>
</figure>
<p>Press <strong>Back</strong> then <strong>Exit Installer</strong>. Time to install the extension!</p>
<h2>Installing Lord of Destruction</h2>
<pre class="code" data-lang="sh"><code>firejail \
  --profile=/etc/firejail/wine.profile \
  --private=~/.sandboxes/wine \
  wine ~/Downloader_Diablo2_Lord_of_Destruction_enUS.exe
</code></pre>
<p>I will spare you all the screenshots since the procedure is identical to the
base version of the game. When you are done, resist the damning temptation and
<strong>exit the installer</strong>; there is one last thing we have to take care of…</p>
<h2>Install Latest Patch</h2>
<p>Before starting the game and finally start playing, you will want to install
the latest patch for Diablo II: <strong>1.14d</strong>. Usually it can be done by accessing
<a href="http://Battle.net" target="_blank" rel="noopener noreferrer">Battle.net</a> in-game but for some reason it failed in my case because of a corrupted
file… Luckily, it’s possible to download and install the update manually. Get
it from the following link:</p>
<ul>
<li><a href="http://ftp.blizzard.com/pub/diablo2exp/patches/PC/LODPatch_114d.exe" target="_blank" rel="noopener noreferrer">LODPatch_114d.exe</a></li>
</ul>
<p>Copy it into your <code>wine</code> home folder: <code>~/.sandboxes/wine/LODPatch_114d.exe</code>.
Then start the update with:</p>
<pre class="code" data-lang="sh"><code>firejail \
  --profile=/etc/firejail/wine.profile \
  --private=~/.sandboxes/wine \
  wine ~/LODPatch_114d.exe
</code></pre>
<h2>Let’s Play!</h2>
<p>Finally, to launch the game you can use the following command:</p>
<pre class="code" data-lang="sh"><code>firejail \
  --profile=/etc/firejail/wine.profile \
  --private=~/.sandboxes/wine \
  wine ~/.wine/drive_c/Program\ Files\ \(x86\)/Diablo\ II/Diablo\ II.exe
</code></pre>
<p>Have fun!</p>
<figure>
  <a href="../images/diablo2-cows.jpg">
    <picture>
      <source srcset="../images/diablo2-cows.webp" type="image/webp">
      <source srcset="../images/diablo2-cows.jpg" type="image/jpeg">
      <img loading="lazy" src="../images/diablo2-cows.jpg" alt="There is no such thing as the 'Cow Level'." style="width:100%">
    </picture>
  </a>
  <figcaption>There is no such thing as the 'Cow Level'.</figcaption>
</figure>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Thoughts about unit and integration tests]]></title>
            <link>https://remusao.github.io//posts/unit-integration-tests.html</link>
            <guid>https://remusao.github.io//posts/unit-integration-tests.html</guid>
            <pubDate>Sat, 26 Oct 2019 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p>Do not feed the anti-patterns!</p>
</blockquote>
<p>I recently found myself working with tests—integration and unit—. This
experience led to some frustration, which got me thinking… Where did the
frustration come from? How could it be done differently? And ultimately, what
makes a good test? This post is a collection of thoughts about testing, not an
exhaustive guide.</p>
<h2>Unit vs. Integration?</h2>
<blockquote>
<p>It does not matter which one you pick first, you might need both eventually…</p>
</blockquote>
<p>Before writing any test, you might be wondering <em>which kind of test</em> makes
sense. Would it be better to cover your new feature with unit or integration
tests? You might want to pause for a moment and think about the trade-offs of
the different options.</p>
<p>Often, <em>unit tests</em> will run in a more controlled environment, maybe with some
dependencies <a href="https://en.wikipedia.org/wiki/Mock_object" target="_blank" rel="noopener noreferrer">mocked</a>, so that you
can focus on a specific file, class or function. This means that unit tests are
more targeted than integration tests. It also means that they might be easier
to reason about, and quicker to iterate with. As an example, imagine testing a
JavaScript library; unit tests could be running in Node.js instead of a
full-blown browser.</p>
<p>On the other hand, <em>integration tests</em> will potentially target multiple systems
interacting with each other, running in an environment which is much closer to
production conditions. Using the same example, your JavaScript library might now be tested
in a handful of browsers (e.g.: Firefox, Chromium and Safari, with different
versions of each), while interacting with other libraries. This means that you
will most likely gain more confidence that the code works in production
environment, at the cost of a more complex setup.</p>
<h2>Non-regression Tests</h2>
<blockquote>
<p>Non-regression is not the same as <em>non-evolution</em>.</p>
</blockquote>
<p>It is desirable to consolidate APIs or components with non-regression tests,
but be careful not to prevent future evolution! This might happen if you take
the current production system and generate test-cases by feeding inputs,
getting the results and writing high-level tests which ensure that the output
is always the one that was expected <em>at the time test-cases were generated</em>.</p>
<p>Although this might feel good at first—we have great test coverage after
all!—, this approach has at least one major short-coming: <em>it’s very hard to
make the tests evolve in the future</em>. It’s nice to “freeze” the capabilities of
your system with numerous tests, but unless said system is not meant to evolve
in the future, the assumptions about expected results will most likely evolve
over time. This means that when writing tests you probably need to think not
only about coverage and the expected behavior <em>right now</em>, but also how easy it
will be to make the tests evolve in the future.</p>
<p>Tests are tightly related to the code being tested and, if you are not careful,
rigid tests might make changing the source code much more painful than it
should be.</p>
<h2>Your Tests are Code</h2>
<blockquote>
<p>Tests are not the destination, they are the starting point and the path.</p>
</blockquote>
<p>There is a misunderstanding at the root of all evils: you shall not <em>treat
your tests differently than your source code</em>. Tests <strong>are</strong> code! To make
things a bit more concrete, here is a list of assumptions which I think are
reasonable when it comes to source code but are rarely accepted for tests:</p>
<ul>
<li>You expect to be able to <em>build</em> and <em>run</em> your code easily.</li>
<li>You expect your code to be <em>efficient</em>.</li>
<li>You expect your code to be <em>understandable</em>.</li>
<li>You expect your code to be <em>documented</em>.</li>
<li>You expect your code to be <em>cross-platform</em>.</li>
<li>You expect your code to be <em>easy to delete</em>!</li>
<li>You expect your code to <em>not be redundant and use abstractions</em>.</li>
</ul>
<p>Whenever one of the expectations holds for your code, try replacing <code>code</code> with
<code>tests</code> and ask yourself if it is still true. Your code and the tests you write
to ensure it behaves in a correct way will have to evolve side-by-side in the
future. You do not want your tests to become a <em>liability</em>.</p>
<h2>Future-Proof Tests?</h2>
<blockquote>
<p>No developer ever reads the same code twice. — Heraclitus</p>
</blockquote>
<p>When writing tests, try to express your intent and give cues to the future
reader —that might be you in a few months!— regarding why a given assertion was
needed, what behavior is being tested, etc. Alongside the usual features of a
language such as <em>comments</em>, <em>good names</em> for variables and functions, etc.
modern testing frameworks give many tools to ease this process: use things like
<code>describe(...)</code>, <code>it(...)</code> and explicit assertions <code>expect(...).to.be</code>.</p>
<p>Additionally, as a contributor to a project which has tests, it should be
reasonnably straightforward to answer the following questions:</p>
<ul>
<li>when looking at code, where can I find the existing tests?</li>
<li>when looking at tests, which code is being tested?</li>
</ul>
<p>There should be a clear path to modify both code and tests:</p>
<ul>
<li>when changing code, which tests need to be changed?</li>
<li>when deleting code, which tests need to be deleted?</li>
</ul>
<p>A few tips can ease this process. <em>Naming conventions</em> for test files should be
consistent and finding the tests for a given file or component should not
involve any interpretation, it should be mechanical (e.g.: tests for <code>module.js</code>
are always to be found in <code>tests/module.test.js</code>).</p>
<p>Tests should be organized in a way that follows the code structure closely so
that changes in the source can be reflected to the tests and <em>vice versa</em>. This
also applies to the internal structure of the tests. It can be helpful to group
assertions by behavior or assumptions. It is also helpful to be explicit about
both success and failure of an assertion!</p>
<p>This last point is important because if you can quickly grasp the intent while
reading a test; it allows to decide if an assertion still holds after a change
in the code, or if it should go away completely.</p>
<p>Last but not least, avoid repetition in tests. If you see yourself writing the
same assertions over and over again to tests similar components, it might be
worth abstracting these away. You will thank yourself in the future when you
need to amend the tests!</p>
<h2>By Way of Conclusion</h2>
<blockquote>
<p>Always pick the right hammer for your nails…</p>
</blockquote>
<p>As mentioned previously, this is not about picking unit tests over integration
tests. You will likely need both eventually because they are often
complementary and give you a different kind of confidence in the correctness of
your code (although some <a href="https://blog.thecodewhisperer.com/permalink/integrated-tests-are-a-scam" target="_blank" rel="noopener noreferrer">argue against integration tests</a>).</p>
<p>As a take-away, treat your tests the same way you treat your source code and
hold them both to high standards. Not doing so might lead to a situation where
your tests become a liability and slow you down instead of empowering you to
write better and more robust features.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A static blog generator in TypeScript]]></title>
            <link>https://remusao.github.io//posts/typescript-blog-generator.html</link>
            <guid>https://remusao.github.io//posts/typescript-blog-generator.html</guid>
            <pubDate>Fri, 19 Jul 2019 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p>Oups, I did it again…</p>
</blockquote>
<p>A while ago I was joking with <a href="https://twitter.com/sebadzia" target="_blank" rel="noopener noreferrer">@sebadzia</a> about
the fact that if you are not re-writting your blog generation mechanism from
scratch every <em>N</em> posts, then you’re doing it wrong. It appears that I’m
actually living by these words and have been re-implementing my own blog over
and over again; maybe in the hope that it would motivate me to write more. This
blog <em>became an end instead of a mean</em> to communicate things.</p>
<p>Here are the 6 engines I’ve used over the years (and this does not even account
for the different themes that I used with each of them):</p>
<ul>
<li><a href="https://wordpress.org/" target="_blank" rel="noopener noreferrer">WordPress</a></li>
<li><a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a></li>
<li><a href="https://blog.getpelican.com/" target="_blank" rel="noopener noreferrer">Pelican</a></li>
<li><a href="https://jaspervdj.be/hakyll/" target="_blank" rel="noopener noreferrer">Hakyll</a></li>
<li><a href="https://github.com/remusao/remusao.github.io/tree/diy" target="_blank" rel="noopener noreferrer">Custom generator in Haskell</a></li>
<li><a href="https://github.com/remusao/remusao.github.io/tree/diy-ts" target="_blank" rel="noopener noreferrer"><strong>Custom generator in TypeScript</strong></a></li>
</ul>
<p>This means that the blog engine has been changed on average every <em>8.5</em> posts.
Not too bad! Maybe the next one will be in Rust?</p>
<p>I think what made me switch this time is the fact that I’m actually enjoying
TypeScript very much lately (I find the type system super neat, and already
liked JavaScript tooling a lot); and I was a bit fed up by the build time of
the Haskell version. The way I did it was most probably sub-optimal as I am by
no mean an experienced Haskell developer. Last but not least, I was on vacation
and had some time to waste…</p>
<p>The TypeScript generator is still rough around the edges but it’s working and
allows me to build the site, watch changes, and serve locally in development
mode.</p>
<p>I rely on the following packages to do the heavy lifting:</p>
<ul>
<li><a href="https://www.npmjs.com/package/@octokit/rest" target="_blank" rel="noopener noreferrer">@octokit/rest</a> to interact with GitHub APIs (used to fetch static comments)</li>
<li><a href="https://www.npmjs.com/package/chokidar" target="_blank" rel="noopener noreferrer">chokidar</a> to watch for files changes</li>
<li><a href="https://www.npmjs.com/package/express" target="_blank" rel="noopener noreferrer">express</a> to serve blog locally</li>
<li><a href="https://www.npmjs.com/package/dompurify" target="_blank" rel="noopener noreferrer">dompurify</a> to sanitize final HTML</li>
<li><a href="https://www.npmjs.com/package/highlight.js" target="_blank" rel="noopener noreferrer">highlight.js</a> to provide syntactic coloration for code blocks in posts</li>
<li><a href="https://www.npmjs.com/package/html-minifier" target="_blank" rel="noopener noreferrer">html-minifier</a> to minimize HTML</li>
<li><a href="https://www.npmjs.com/package/marked" target="_blank" rel="noopener noreferrer">marked</a> to convert markdown to HTML</li>
</ul>
<p>Overall I’m fairly happy with this setup. The generator currently fits into a
single source file (which should probably be split at some point) and generation
is pretty fast: <em>~50</em> seconds from scratch (which includes installing all npm
dependencies, generating posts and fetching comments from GitHub). Generating
posts only takes less than 10 seconds, and most of the time is spent waiting
for comments to be fetched from GitHub issues.</p>
<p>There are a few things I’d like to try or investigate in the future to improve:</p>
<ul>
<li>consider using JSX (with React in pure server-side rendering mode)</li>
<li>consider writing CSS in TypeScript as well with typing</li>
<li>add support for inlined math using KaTex (which I do not need at the moment)</li>
<li>improve comments display with better rendering and support for reactions and emojis</li>
</ul>
<p>And of course, I will try my best to write more content here in the future!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[What's exciting in Cliqz 1.35]]></title>
            <link>https://remusao.github.io//posts/cliqz-1.35-notes.html</link>
            <guid>https://remusao.github.io//posts/cliqz-1.35-notes.html</guid>
            <pubDate>Fri, 22 Mar 2019 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><a href="https://cliqz.com/en/download" target="_blank" rel="noopener noreferrer">Cliqz 1.35</a> is just being released as I write
these lines and there is a lot to talk about in there: performance, more
privacy, more polish. Let me share a few of the things that make me excited!</p>
<h2>Privacy</h2>
<p>There is continuous work to make sure Cliqz users always get the best privacy
protection. In this release, there were three major improvements when it comes
to privacy: human proxy network, a more efficient adblocker and better cookie
retention policies.</p>
<ul>
<li>
<p><strong>Human Proxy Network</strong> (or, HPN), allows our users to stay anonymous when
the browser contacts our backend (e.g.: for search or telemetry). This is the
heart of our <em>privacy by design approach</em>, where you don’t even need to trust
us to not do bad things: we simply don’t know anything personal about you. In
this case, we now use a <em>third-party VPN provider to also hide any
network-level identifiers like IPs</em>. We were already providing this
protection before but we were operating the network of proxies ourselves.
What I’m especially excited about is that now, there is <em>no way Cliqz can
learn anything about who you are using your IP</em> (because of the third-party
VPN relaying the messages); and there is also no way the third-party VPN
provider can learn anything about you, because all messages are encrypted
client-side!</p>
</li>
<li>
<p><strong>Adblocker</strong>. We wrote about it recently in our <a href="https://whotracks.me/blog/adblockers_performance_study.html" target="_blank" rel="noopener noreferrer">performance study</a>
in the context of Manifest v3; <em>Cliqz has the fastest and most memory
efficient adblocker around</em> and we are very proud of it. In this release we
made sure that the latest improvements are included in the browser: blocking ads
was never faster!</p>
</li>
</ul>
<figure>
<a href="../images/cliqz_1.35/adblockerSpeed.png">
<img src="../images/cliqz_1.35/adblockerSpeed.png" alt="Adblock Speed" style="width:100.0%">
</a>
<figcaption>Adblocker Speed</figcaption>
</figure>
<ul>
<li><strong>Better cookies retention policies</strong>. We’re constantly fine-tuning our
Anti-tracking as well as cookies retention policies. In a nutshell, we make
sure that cookies cannot be used to track you by limiting their life-time
depending on if they are needed for a service/website you are using or not.</li>
</ul>
<figure>
<a href="../images/cliqz_1.35/cookies.jpg">
<img src="../images/cliqz_1.35/cookies.jpg" alt="Cookies Retention" style="width:70.0%">
</a>
<figcaption>Cookies Retention</figcaption>
</figure>
<h2>Performance</h2>
<p>We’re pushing super hard for our mobile products to offer the best possible
experience even on slow devices. This means that usability, privacy protection
and performance need to be great. There was a lot of work on these aspects in
the last few months and because most of our core features share the same
codebase across products, this impacts positively Cliqz desktop browser as
well.</p>
<ul>
<li>
<p><strong>Faster URL parsing</strong>. To make sure no identifiers or ads slip through when
you browser the web, Cliqz needs to analyze and filter <em>a lot</em> of URLs (to
load a single page, it can go up to hundreds of network requests). Because
this represents a lot of work, it was a good candidate for optimization. My
co-worker <a href="https://twitter.com/sammacbeth" target="_blank" rel="noopener noreferrer">sammacbeth</a> did a fantastic job
and was able to replicate the API of the native URL parser provided by the
browser: except it’s now <em>4-5x faster</em>. This means users get the same great
privacy protection, but the browser sweats less for it!</p>
</li>
<li>
<p>Along those lines, we made sure that the processing of requests in the
extension (not just parsing the URLs) is as fast as possible. We removed lots
of friction so that <em>when an ad needs to get blocked, or a fingerprint needs
to be removed, it happens as fast as possible</em> and more resources can be
dedicated to load pages faster. This also greatly improves the experience on
mobile!</p>
</li>
</ul>
<h2>What Else?</h2>
<p>There were a lot of other changes to polish the overall Cliqz experience. For
example: the weather smart Cliqz is now… much smarter and will display very
detailed information about the forcasts (temperatures, wind, etc.)!</p>
<figure>
<a href="../images/cliqz_1.35/weather.png">
<img src="../images/cliqz_1.35/weather.png" alt="Weather Smart Cliqz" style="width:100.0%">
</a>
<figcaption>Advanced Weather Smart Cliqz</figcaption>
</figure>
<p>The estimation of time saved on Freshtab now takes into account the time saved
when using Cliqz results directly in the dropdown instead of going to a search
result page. This comes as an addition to the time saved by blocking ads or
trackers.</p>
<figure>
<a href="../images/cliqz_1.35/timeSaved.png">
<img src="../images/cliqz_1.35/timeSaved.png" alt="Time Saved by Cliqz" style="width:100.0%">
</a>
<figcaption>Updated Time Saved on Freshtab</figcaption>
</figure>
<h2>What’s Next?</h2>
<p>I am also super excited with the changes coming to mobile. We’ve been doing <em>a
lot</em> of performance work to ensure that our mobile browser can run at full
speed while enabling all privacy protections, even on very slow devices (in
fact, we’re even more aggressive when blocking ads and trackers!).</p>
<p>In the next release, we have more coming: the infrastructure distributing
adblocker rules has been revamped and allows most of the heavy lifting of
parsing the rules and initializing the engine to be performed on the backend,
which means much faster updates for clients as well as drastically reduced data
usage (we’re talking of at least one order of magnitude less)! Stay tuned.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Adblockers performance study]]></title>
            <link>https://remusao.github.io//posts/adblockers_performance_study.html</link>
            <guid>https://remusao.github.io//posts/adblockers_performance_study.html</guid>
            <pubDate>Fri, 15 Feb 2019 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><strong>Disclaimer</strong>: This study was originally posted on <a href="https://whotracks.me/blog/adblockers_performance_study.html" target="_blank" rel="noopener noreferrer">WhoTracks.me</a>.</p>
<p>Summary: <em>In this study we show</em></p>
<ul>
<li><em>That all popular content-blockers are very efficient, having sub-millisecond
median decision time per request</em></li>
<li><em>That the manifest v3 performance claim does not hold based on our
measurements</em></li>
<li><em>That the adblocker used by Cliqz and Ghostery consistently performs as well
or better than other popular content-blockers.</em></li>
</ul>
<hr>
<p>Here we present a detailed analysis of the performance of some of the
most popular content-blocker engines: <em>uBlock Origin</em>, <em>Adblock Plus</em>,
<em>Brave</em>, <em>DuckDuckGo</em> and <em>Cliqz/Ghostery’s</em> advanced adblocker (shipped
since Ghostery 8), which we will refer to as <em>Ghostery</em> for the rest of
the article.</p>
<p>This study was motivated by the recent <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=896897" target="_blank" rel="noopener noreferrer">Manifest V3
controversy</a>.
One of the proposed changes involves crippling the WebRequest APIs to
limit their blocking abilities. Two justifications were put forth:
one related to <em>performance</em> and another related to privacy. The
privacy argument deserves its own separate analysis and will not be
covered here. In this study, we show that the <em>performance</em> argument
does not hold. Our comparison demonstrates that the most popular
content-blockers are already very efficient (having a sub-millisecond
median decision time per request) and should not result in any
over-head noticeable by users. We showed in another study <a href="https://www.ghostery.com/lp/trackertax/" target="_blank" rel="noopener noreferrer">The Tracker
Tax</a> that blocking ads and
trackers actually reduces the loading time of websites by <strong>up to
a factor of 2</strong>. Besides, efficiency is continuously improved and
technologies such as WebAssembly will allow to go even further.</p>
<p>This comparison does not involve full extensions, but instead <strong>focuses
on network request blocking engines</strong>, which is the most CPU intensive
task performed by content-blockers (in particular, this does not account
for cosmetics engines or subscription management). Here are the home
pages for all content-blockers compared:</p>
<ul>
<li>Ghostery and Cliqz’s adblocker: <a href="https://github.com/cliqz-oss/adblocker" target="_blank" rel="noopener noreferrer">https://github.com/cliqz-oss/adblocker</a></li>
<li>Brave’s adblocker: <a href="https://github.com/brave/ad-block" target="_blank" rel="noopener noreferrer">https://github.com/brave/ad-block</a></li>
<li>DuckDuckGo’s adblocker: <a href="https://github.com/duckduckgo/abp-filter-parser" target="_blank" rel="noopener noreferrer">https://github.com/duckduckgo/abp-filter-parser</a></li>
<li>uBlock Origin: <a href="https://github.com/gorhill/uBlock" target="_blank" rel="noopener noreferrer">https://github.com/gorhill/uBlock</a></li>
<li>Adblock Plus: <a href="https://github.com/adblockplus/adblockpluscore" target="_blank" rel="noopener noreferrer">https://github.com/adblockplus/adblockpluscore</a></li>
</ul>
<p>We did not include native blockers from Chromium and Safari projects
as this would require some significant effort to package them in a way
that allows benchmarking against the other libraries. We leave this for
future work.</p>
<p>All blockers except <em>uBlock Origin</em> are available as JavaScript libraries which
can be loaded in Node.js. To allow comparing <em>uBlock Origin</em> as well, we had to
extract the static network filtering engine <a href="https://github.com/cliqz-oss/adblocker/blob/master/bench/comparison/ublock.js" target="_blank" rel="noopener noreferrer">out of the
extension</a>.
The version of <em>uBlock Origin</em> running in this benchmark <em>does not make
use of the Webassembly</em> version of domain matching.</p>
<p>All benchmarks were ran on an X1 Carbon 2016 (i7 U6600 + 16 GB) in
Node.js 11.9.0. Memory measurements were performed in Google Chrome version
72.0.3626.96 using the memory snapshot tool.</p>
<h2>Results</h2>
<p>Before presenting the detailed analysis of the results, let us highlight
our findings in a nutshell:</p>
<ul>
<li>
<p>All content-blockers except <em>DuckDuckGo</em> have <strong>sub-millisecond median decision
time</strong> per request.</p>
</li>
<li>
<p><strong>Time to Process a Request in Ghostery</strong> (median): <strong>0.007 ms</strong></p>
<ul>
<li>2.7x faster than <em>uBlock Origin</em></li>
<li>2.9x faster than <em>Adblock Plus</em></li>
<li>6.3x faster than <em>Brave</em>’s Adblocker</li>
<li>1258.4x faster than <em>DuckDuckGo</em>’s adblocker</li>
</ul>
</li>
<li>
<p><strong>Loading Ghostery’s Blocking Engine</strong> (from cache): <strong>0.03 ms</strong></p>
<ul>
<li>368x faster than <em>Brave</em>’s Adblocker</li>
<li>588x faster than <em>uBlock Origin</em></li>
<li>3575x faster than <em>Adblock Plus</em></li>
<li><em>DuckDuckGo</em>’s adblocker does not offer serialization, so the loading cost is always the one from parsing the lists.</li>
</ul>
</li>
<li>
<p><strong>Memory Consumption of Ghostery’s Blocking Engine</strong> (at startup, in Chrome): <strong>1.8 MB</strong></p>
<ul>
<li>1.6x less memory than <em>uBlock Origin</em></li>
<li>8.4x less memory than <em>Adblock Plus</em></li>
<li>8.8x less memory than <em>DuckDuckGo</em>’s adblocker</li>
<li>The memory usage of <em>Brave</em> could not be evaluated using the devtools
and thus is not included in this section.</li>
</ul>
</li>
</ul>
<h3>About the Dataset</h3>
<p>To measure the performance of each content-blocker, we replayed requests
from popular domains <em>once</em> and kept track of the time it took to decide
if they should be blocked or not. We then analyzed the results in three
different ways: all requests, blocked only and not blocked (taken from
the same run).</p>
<p>This requests dataset was created using a pool of Chrome
headless browsers (driven by the <a href="https://github.com/GoogleChrome/puppeteer" target="_blank" rel="noopener noreferrer"><code>puppeteer</code> library</a>)
to visit home pages of the <em>top 500 domains</em> (as reported by Cliqz
Search), as well as up to 3 pages of each domain (picked randomly from
the home page) and collecting all the network requests seen (URL, frame
URL and type). The dataset was shuffled in such a way that the different
pages were visited in a random order, but requests seen on each page
were replayed as they were recorded initially.</p>
<p>The dataset is composed of 242944 requests. We released the data publicly at
this URL: <a href="https://cdn.cliqz.com/adblocking/requests_top500.json.gz" target="_blank" rel="noopener noreferrer">requests_top500.json.gz</a>.
The script to create the dataset is also available:
<a href="https://github.com/cliqz-oss/adblocker/blob/master/bench/comparison/create_dataset.js" target="_blank" rel="noopener noreferrer">create_dataset.js</a> and
<a href="https://github.com/cliqz-oss/adblocker/blob/master/bench/comparison/shuffle_dataset.js" target="_blank" rel="noopener noreferrer">shuffle_dataset.js</a> was used to shuffle the
requests to produce the final data.</p>
<h3>Composition of Requests</h3>
<p>For the purpose of this comparison, we consider that each network
request can be either blocked or allowed by the content-blocker; we call
the process of deciding whether a request should be blocked or not:
<em>matching</em>. We observed that from our dataset, only ~19.2% are blocked
(average across all content-blockers).</p>
<figure>
<a href="../images/adblockers_performance_study/requests-composition.svg">
<img src="../images/adblockers_performance_study/requests-composition.svg" alt="Proportion of requests blocked">
</a>
</figure>
<p>It results from this observation that content-blockers will perform better on
average if they can efficiently decide which requests to <em>not block</em>.</p>
<p>The filters used to determine whether or not a request is to be blocked
are the ones from <a href="https://easylist-downloads.adblockplus.org/easylist.txt" target="_blank" rel="noopener noreferrer">Easylist</a>,
where we removed all the cosmetic rules before running the benchmarks.
The final list contains <em>38978 network filters</em> and is available here:
<a href="https://github.com/cliqz-oss/adblocker/blob/master/bench/comparison/easylist.txt" target="_blank" rel="noopener noreferrer">easylist.txt</a>.</p>
<p>It should be noted at this point that a larger proportion of requests
would be blocked by enabling extra filters lists such as <em>EasyPrivacy</em>.</p>
<h3>Time To Match All Requests</h3>
<p>We first look at all of the requests (whether they will eventually
be blocked or not). We use a log-scale for the x-axis (time in
milliseconds) to facilitate the comparison of the cumulative
distribution of the time it takes for content-blockers to decide whether
or not a request should be blocked.</p>
<p>Here is a break-down of the 99th percentile and median times for each
content-blocker:</p>
<table>
<thead>
<tr>
<th></th>
<th>99% OF REQUESTS</th>
<th>MEDIAN</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ghostery</strong></td>
<td><strong>0.050ms</strong></td>
<td><strong>0.007ms</strong></td>
</tr>
<tr>
<td>uBlock Origin</td>
<td>0.124ms (<strong>2.5x slower</strong>)</td>
<td>0.017ms (<strong>2.7x slower</strong>)</td>
</tr>
<tr>
<td>Adblock Plus</td>
<td>0.103ms (<strong>2.1x slower</strong>)</td>
<td>0.019ms (<strong>2.9x slower</strong>)</td>
</tr>
<tr>
<td>Brave</td>
<td>1.288ms (<strong>25.9x slower</strong>)</td>
<td>0.041ms (<strong>6.3x slower</strong>)</td>
</tr>
<tr>
<td>DuckDuckGo</td>
<td>12.085ms (<strong>242.5x slower</strong>)</td>
<td>8.270ms (<strong>1258.4x slower</strong>)</td>
</tr>
</tbody>
</table>
<p>Below you can find the cumulative distribution plots of these timings:</p>
<figure>
<a href="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-all.svg">
<img src="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-all.svg" alt="Time to match all requests">
</a>
</figure>
<h3>Time To Match Requests Which Are Not Blocked</h3>
<p>The following table details 99th percentile and median timings for requests not
blocked:</p>
<table>
<thead>
<tr>
<th></th>
<th>99% OF REQUESTS</th>
<th>MEDIAN</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ghostery</strong></td>
<td><strong>0.049ms</strong></td>
<td><strong>0.006ms</strong></td>
</tr>
<tr>
<td>uBlock Origin</td>
<td>0.112ms (<strong>2.3x slower</strong>)</td>
<td>0.018ms (<strong>2.8x slower</strong>)</td>
</tr>
<tr>
<td>Adblock Plus</td>
<td>0.105ms (<strong>2.2x slower</strong>)</td>
<td>0.020ms (<strong>3.1x slower</strong>)</td>
</tr>
<tr>
<td>Brave</td>
<td>1.270ms (<strong>26.2x slower</strong>)</td>
<td>0.038ms (<strong>5.9x slower</strong>)</td>
</tr>
<tr>
<td>DuckDuckGo</td>
<td>11.190ms (<strong>230.5x slower</strong>)</td>
<td>6.781ms (<strong>1060.5x slower</strong>)</td>
</tr>
</tbody>
</table>
<figure>
<a href="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-not-blocked.svg">
<img src="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-not-blocked.svg" alt="Time to match requests which are not blocked">
</a>
</figure>
<h3>Time To Match Requests Which Are Blocked</h3>
<p>The following table details 99th percentile and median timings for requests blocked:</p>
<table>
<thead>
<tr>
<th></th>
<th>99% OF REQUESTS</th>
<th>MEDIAN</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ghostery</strong></td>
<td><strong>0.052ms</strong></td>
<td><strong>0.007ms</strong></td>
</tr>
<tr>
<td>uBlock Origin</td>
<td>0.165ms (<strong>3.1x slower</strong>)</td>
<td>0.016ms (<strong>2.2x slower</strong>)</td>
</tr>
<tr>
<td>Adblock Plus</td>
<td>0.099ms (<strong>1.9x slower</strong>)</td>
<td>0.014ms (<strong>1.9x slower</strong>)</td>
</tr>
<tr>
<td>Brave</td>
<td>1.468ms (<strong>28.0x slower</strong>)</td>
<td>0.062ms (<strong>8.5x slower</strong>)</td>
</tr>
<tr>
<td>DuckDuckGo</td>
<td>13.025ms (<strong>248.5x slower</strong>)</td>
<td>8.31ms (<strong>1130.6x slower</strong>)</td>
</tr>
</tbody>
</table>
<figure>
<a href="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-blocked.svg">
<img src="../images/adblockers_performance_study/ghostery-ublock-origin-brave-duckduckgo-adblock-plus-blocked.svg" alt="Time to match requests which are blocked">
</a>
</figure>
<p>On these graphs we observe a plateau for <em>Adblock Plus</em>, <em>Brave</em> and
<em>Duckduckgo</em>. This can be explained by the fact that these engines
implement some form of caching internally, thus having a very fast
response time for some requests which were already seen (redundancy in
requests comes from both common third-parties seen on multiple websites
as well as the fact that we load several pages for each domain). This
caching can be implemented on top of any content-blocker and does not
tell much about the efficiency of each; we can see this as a means to
trade <em>memory</em> against <em>CPU usage</em>.</p>
<p>From the previous measurements we see that Ghostery out-performs other
libraries in terms of matching speed. Without going into too many
details, here are some of the optimizations which can explain these
results:</p>
<ul>
<li>Ghostery makes use of a reverse index associating tokens to filters. Contrary
to other libraries, we make sure that we pick <em>the best</em> token for each filter
at construction time (best being defined as the <em>least seen token</em>). This incurs
a one-time extra cost but results in maximized dispatching capabilities.</li>
<li>Filters are stored in a very compact form, in typed arrays, and only loaded in
memory lazily, when there is a chance they will be blocked (if we encounter
identical tokens in URLs).</li>
<li>Filters loaded in memory are optimized on-the-fly and multiple filters can be
combined for increased efficiency. The optimizations were carefully crafted
based on common cases observed in Easylist.</li>
</ul>
<h3>Serialization And Deserialization</h3>
<p>In this section we have a look at the performance of content-blockers
when it comes to serializing their internal representation for faster
subsequent loading. Only <em>DuckDuckGo</em>’s engine does not provide this
feature. <em>uBlock Origin</em>, <em>Ghostery</em>, <em>Adblock Plus</em> and <em>Brave</em> all allow to
serialize or cache (<em>uBlock Origin</em>’s terminology is: <em>selfies</em>) the
entire blocking engine to either a string or a buffer, which can then be
used to speed-up subsequent loads.</p>
<p>Because this is a one-time operation, having a higher loading-time does not
impact significantly desktop users. On the other hand, the ability to quickly
initialize the content-blocker is critical on mobile.</p>
<p>Another use-case allowed by such capability is to perform the parsing
of the lists on the backend and ship the serialized form of the
content-blocker to clients directly, which removes the cost of
initialization completely.</p>
<p>We performed 100 serializations for each content-blocker and display the
results below:</p>
<figure>
<a href="../images/adblockers_performance_study/ghostery-ublock-origin-brave-adblock-plus-serializationtimings.svg">
<img src="../images/adblockers_performance_study/ghostery-ublock-origin-brave-adblock-plus-serializationtimings.svg" alt="Serialization timings">
</a>
</figure>
<p>This bar plot contains the median time taken to serialize the engine for each
content-blocker:</p>
<figure>
<a href="../images/adblockers_performance_study/serializationtimings.svg">
<img src="../images/adblockers_performance_study/serializationtimings.svg" alt="Serialization timings">
</a>
</figure>
<p>Similarly, we measure the time it takes to restore the content-blocker from its
serialized form:</p>
<figure>
<a href="../images/adblockers_performance_study/ghostery-ublock-origin-brave-adblock-plus-deserializationtimings.svg">
<img src="../images/adblockers_performance_study/ghostery-ublock-origin-brave-adblock-plus-deserializationtimings.svg" alt="Deserialization timings">
</a>
</figure>
<p>And here is the median time:</p>
<figure>
<a href="../images/adblockers_performance_study/deserializationtimings.svg">
<img src="../images/adblockers_performance_study/deserializationtimings.svg" alt="Deserialization timings">
</a>
</figure>
<p>Last but not least, we measured the size of the serialized buffer for each
content-blocker:</p>
<figure>
<a href="../images/adblockers_performance_study/cache-size.svg">
<img src="../images/adblockers_performance_study/cache-size.svg" alt="Cache size">
</a>
</figure>
<p>From these measurements we see that <em>Ghostery</em> offers both significantly
faster serialization and deserialization times as well as a smaller
cache size.</p>
<p>The reason is the following: the internal representation is already
mostly stored in a compact form (using typed arrays); this means that
serialization only consists in adding a small amount of metadata
along-side the already available arrays and deserialization is
<em>essentially instantaneous</em> since it’s enough to create some typed array
views on top of the serialized buffer (think of <code>mmap</code> but using typed
arrays). This also explains the very low memory consumption: after
initialization, the memory usage is only slightly higher than the size
of the serialized form.</p>
<h3>Memory Consumption at Start-up</h3>
<p>Here we consider the memory usage of each content-blocker, initialized
from lists (not from cache) after one full garbage collection. The
measurements were performed using Chrome’s devtools memory snapshot. We
did not measure Brave here since the memory used from C++ side does not
seem to be taken into account in the snapshot. Also keep in mind that
this memory usage can vary at run-time as content-blockers might cache
frequently used resources, etc.</p>
<figure>
<a href="../images/adblockers_performance_study/memory-usage-at-startup.svg">
<img src="../images/adblockers_performance_study/memory-usage-at-startup.svg" alt="Memory usage at start-up">
</a>
</figure>
<p>As mentioned in the previous section on serialization, the very low
memory usage of <em>Ghostery</em> can be explained by the fact that the
internal representation mostly consists of very compact typed arrays
with some small over-head for extra meta-data. Again, we need to stress
here that this measures the network filtering engine of Ghostery only,
not the full extension, as described in the introduction.</p>
<h3>Parsing Lists</h3>
<p>In this graph, we present the time it takes for each content-blocker to
be initialized from the lists (without any prior caching, which means
initializing all internal resources by parsing the raw list). We see
that only Brave seems to be significantly slower and that <em>uBlock Origin</em>,
<em>Ghostery</em>, <em>Adblock Plus</em> and <em>DuckDuckGo</em> all perform well.</p>
<figure>
<a href="../images/adblockers_performance_study/time-to-parse-easylist-all.svg">
<img src="../images/adblockers_performance_study/time-to-parse-easylist-all.svg" alt="Time to parse Easylist">
</a>
</figure>
<p>It seems that the long parsing time for Brave is a <a href="https://github.com/brave/ad-block/issues/158" target="_blank" rel="noopener noreferrer">known
issue</a> tracked on their
GitHub repository.</p>
<p>Now if we remove Brave, we see that there are still differences between
<em>uBlock Origin</em>, <em>Ghostery</em>, <em>Adblock Plus</em> and <em>DuckDuckGo</em>. One reason
<em>Ghostery</em> is slower than <em>uBlock Origin</em> and <em>AdblockPlus</em> here is that to
achieve maximum performance while matching as well as minimize memory
usage, there is a bit more work to do up-front. In practice this does
not matter so much since it is a one-time operation and that subsequent
loads are performed from cache, and this is really fast (in fact, we
can even perform the parsing backend-side and just ship the serialized
version of the blocker, which removes this step completely).</p>
<figure>
<a href="../images/adblockers_performance_study/time-to-parse-easylist-without-brave.svg">
<img src="../images/adblockers_performance_study/time-to-parse-easylist-without-brave.svg" alt="Time to parse Easylist without Brave">
</a>
</figure>
<h3>Conclusion</h3>
<p>In this study we looked closely at the performance of some of the most
popular content-blockers in use today. In particular, we focused on the
efficiency of their network filtering engines, which is the most CPU
intensive task they perform.</p>
<p>This work was motivated by one of the claims formulated in the <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=896897" target="_blank" rel="noopener noreferrer">Manifest V3
proposal</a>
of the Chromium project: <em>“the extension then performs arbitrary (and
potentially very slow) JavaScript”</em>, talking about content-blockers’
ability to process all network requests. From the measurements, we do
not think this claim holds, as all popular content-blockers are already
very efficient and should not incur any noticeable slow-down for users.
Moreover, the efficiency of content-blockers is <em>continuously improving</em>,
either thanks to more innovative approaches or using technologies like
WebAssembly to reach native performance.</p>
<p>While most content-blockers are indeed efficient, they are not
equivalent and we observed that <em>Ghostery</em> performs consistently as well
or better across all dimensions, often surpassing other libraries.</p>
<p>We hope that these benchmarks will give an opportunity for content-blockers
developers to measure their own progress against other popular libraries;
benefiting all users, no matter which extension they use, as the efficiency of
content-blockers improves.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fast domains and URLs parsing with tldts]]></title>
            <link>https://remusao.github.io//posts/tldts-benchmarks.html</link>
            <guid>https://remusao.github.io//posts/tldts-benchmarks.html</guid>
            <pubDate>Sat, 02 Feb 2019 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>For quite some time now I’ve been working on
<a href="https://github.com/remusao/tldts/" target="_blank" rel="noopener noreferrer"><strong>tldts</strong></a> (<a href="https://www.npmjs.com/package/tldts" target="_blank" rel="noopener noreferrer"><strong>npm</strong></a>), an <em>extemely fast</em>,
<em>feature-full</em>, <em>battle-tested</em> JavaScript library for domain parsing. It
allows to answer questions such has:</p>
<ul>
<li>What’s the hostname of an URL?</li>
<li>What’s the registrable domain of an URL, a hostname or an email address?</li>
<li>What’s the sub-domain of a domain?</li>
<li>etc.</li>
</ul>
<p>What puts <a href="https://github.com/remusao/tldts/" target="_blank" rel="noopener noreferrer"><strong>tldts</strong></a> appart from other libraries is:</p>
<ul>
<li>It is <strong>much faster</strong> than alternatives, allowing to parse between
<strong>1 and 2 million</strong> domains per second (that’s <strong>up to 1000 times</strong> faster
than other popular libraries).</li>
<li>It is more feature-full, supporting <em>IPs detection</em>, <em>domain validation</em> and <em>complex URLs parsing</em>.</li>
<li>It offers the smallest bundles, in both <code>cjs</code>, <code>esm</code> and <code>umd</code> formats; it runs <em>anywhere</em>.</li>
<li>It is written in <em>TypeScript</em> and benefits from 100% test coverage.</li>
</ul>
<p>Most of the features are made possible by the <a href="https://publicsuffix.org/" target="_blank" rel="noopener noreferrer">public suffix
list</a> project. But
<a href="https://github.com/remusao/tldts/" target="_blank" rel="noopener noreferrer"><strong>tldts</strong></a> offers some bells and whistles on
top. One of the goals is to be <em>conveniant</em> to use and as fast as it gets. Some
libraries require you to provide already-valid hostnames, but
<a href="https://github.com/remusao/tldts/" target="_blank" rel="noopener noreferrer"><strong>tldts</strong></a> has no such constraints and will
happily parse complex URLs, as well as already-extracted hostnames. The best
part is that this does not come with any over-head!</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">const</span> tldts = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;tldts&#x27;</span>);

<span class="hljs-comment">// Retrieving hostname related informations of a given URL</span>
tldts.<span class="hljs-title function_">parse</span>(<span class="hljs-string">&#x27;https://remusao.github.io/posts/tldts-benchmarks.html&#x27;</span>);
<span class="hljs-comment">// { domain: &#x27;github.io&#x27;,</span>
<span class="hljs-comment">//   hostname: &#x27;remusao.github.io&#x27;,</span>
<span class="hljs-comment">//   isIcann: true,</span>
<span class="hljs-comment">//   isIp: false,</span>
<span class="hljs-comment">//   isPrivate: false,</span>
<span class="hljs-comment">//   publicSuffix: &#x27;io&#x27;,</span>
<span class="hljs-comment">//   subdomain: &#x27;remusao&#x27; }</span>
</code></pre>
<p>In this post I’d like to share some results of a performance comparison against
other available JavaScript libraries offering the same kind of features. We
will see that they vary greatly in terms of performance, ease of use or
features. In fact, we observed that <code>tldts</code> is up to <strong>1000 times</strong> faster than
some of the other libraries!</p>
<p>Before presenting the results, a few words about the instrumentation and what
was measured. We aim at comparing the libraries in the following aspects:</p>
<ol>
<li>Features</li>
<li>Performance (in terms of operations per second)</li>
<li>Loading time (time it took V8 to load the bundle)</li>
<li>Memory used</li>
</ol>
<p>All the measurements were performed in the following environment:</p>
<ul>
<li><code>Node.js</code> version <strong>11.6.0</strong></li>
<li>Hardware: X1 Carbon 4th with i7-6600U CPU and 16GB of RAM</li>
</ul>
<p>And now the list of the contenders:</p>
<ul>
<li><a href="https://www.npmjs.com/package/tldts" target="_blank" rel="noopener noreferrer"><strong>tldts</strong></a></li>
<li><a href="https://www.npmjs.com/package/psl" target="_blank" rel="noopener noreferrer">psl</a></li>
<li><a href="https://www.npmjs.com/package/tldjs" target="_blank" rel="noopener noreferrer">tld.js</a></li>
<li><a href="https://www.npmjs.com/package/parse-domain" target="_blank" rel="noopener noreferrer">parse-domain</a></li>
<li><a href="https://www.npmjs.com/package/haraka-tld" target="_blank" rel="noopener noreferrer">haraka-tld</a></li>
<li><a href="https://github.com/gorhill/uBlock/blob/master/src/lib/publicsuffixlist.js" target="_blank" rel="noopener noreferrer">uBlock’s publicsuffixlist.js</a></li>
</ul>
<p>In the results you will also see <code>tldts-experimental</code> mentioned. It is a
probabilistic data-structure implementing the exact same features as <code>tldts</code>
but using <em>much less memory</em>, <em>loading instantly</em> and offering <em>even higher
performances</em>. It can be used in contexts with very constrained hardware
capabilities such as mobiles.</p>
<p>Now let’s now dig into the results!</p>
<h2>Feature Matrix</h2>
<p>The following features are considered:</p>
<ul>
<li>Is there <code>IDNA</code> support? Does the library support inputs with unicode such as <em>中国</em>?</li>
<li>Does the library accept complex <code>URLs</code> as input, or is it necessary to extract the hostname before-hand?</li>
<li>Is the library able to detect if the given input is an <code>IP</code> address? This is important, otherwise <code>getPublicSuffix('192.168.0.1')</code> would return <code>1</code>!</li>
<li>Does the library allow you to extract <code>domain</code> and <code>public suffix</code>?</li>
<li>Does the library support ICANN/Private sections of the public suffix list? Can they be disabled individually?</li>
<li>Will the public suffix rules be <code>shipped</code> with the library, or do they need to be fetched separately?</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">Library</th>
<th style="text-align:center">IDNA</th>
<th style="text-align:center">URLs</th>
<th style="text-align:center">IPs</th>
<th style="text-align:center">getDomain</th>
<th style="text-align:center">getPublicSuffix</th>
<th style="text-align:center">ICANN/Private</th>
<th style="text-align:center">Ships lists</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>tldts</strong></td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
</tr>
<tr>
<td style="text-align:center">tld.js</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
</tr>
<tr>
<td style="text-align:center">psl</td>
<td style="text-align:center">X</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center"></td>
<td style="text-align:center">X</td>
</tr>
<tr>
<td style="text-align:center">parse-domain</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center"></td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
</tr>
<tr>
<td style="text-align:center">haraka-tld</td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center"></td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center"></td>
<td style="text-align:center">X</td>
</tr>
<tr>
<td style="text-align:center">uBlock publicsuffixlist</td>
<td style="text-align:center">?</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">X</td>
<td style="text-align:center">X</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<h1>Performance</h1>
<p>Here we measure the performance of three common operations offered by domain
parsing library: <em>getting the public suffix</em> of a hostname, <em>getting the
domain</em> (tld + sld) and <em>getting the subdomain</em>.</p>
<p>A few notes about this benchmark:</p>
<ul>
<li>The inputs used are always already valid hostnames (no URLs, although some
libraries like tldts support it). You can find the list of inputs there:</li>
<li>The selection of hostnames can be seen in <a href="https://github.com/remusao/tldts/blob/master/comparison/bench_performance.js#L12" target="_blank" rel="noopener noreferrer">bench_performance.js</a>
and was selected to contain a mix of non-existing suffixes, ICANN rules,
private rules as well as wildcards and exceptions.</li>
<li>All hostnames were ASCII (puny-encoded if needed before-hand)</li>
<li>All libraries were used in their default setup (no option given, with the
exception of <code>tldts-no-parse</code> which runs <code>tldts</code> disabling the parsing phase
and assuming that the input is already a valid hostname, to match the
behavior of other libraries).</li>
</ul>
<p>The results are expressed in terms of operations per second (where each
operation is calling the function once on a hostname).</p>
<table>
<thead>
<tr>
<th style="text-align:left">Library</th>
<th style="text-align:right">getPublicSuffix</th>
<th style="text-align:right">getDomain</th>
<th style="text-align:right">getSubdomain</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>tldts-experimental</strong></td>
<td style="text-align:right">1 898 446</td>
<td style="text-align:right">1 690 572</td>
<td style="text-align:right">1 615 166</td>
</tr>
<tr>
<td style="text-align:left">tldts no parsing</td>
<td style="text-align:right">1 780 469</td>
<td style="text-align:right">1 515 703</td>
<td style="text-align:right">1 502 692</td>
</tr>
<tr>
<td style="text-align:left"><strong>tldts</strong></td>
<td style="text-align:right"><strong>1 280 063</strong></td>
<td style="text-align:right"><strong>1 134 956</strong></td>
<td style="text-align:right">1 125 362</td>
</tr>
<tr>
<td style="text-align:left">tld.js</td>
<td style="text-align:right">1 141 414</td>
<td style="text-align:right">1 049 180</td>
<td style="text-align:right">1 125 362</td>
</tr>
<tr>
<td style="text-align:left">ublock publicsuffix</td>
<td style="text-align:right">620 816</td>
<td style="text-align:right">567 664</td>
<td style="text-align:right">?</td>
</tr>
<tr>
<td style="text-align:left">parse-domain</td>
<td style="text-align:right">554 355</td>
<td style="text-align:right">528 217</td>
<td style="text-align:right">551 008</td>
</tr>
<tr>
<td style="text-align:left">haraka-tld</td>
<td style="text-align:right">?</td>
<td style="text-align:right">105 321</td>
<td style="text-align:right">?</td>
</tr>
<tr>
<td style="text-align:left">psl</td>
<td style="text-align:right">1 654</td>
<td style="text-align:right">1 693</td>
<td style="text-align:right">1 673</td>
</tr>
</tbody>
</table>
<p>Here we see that the performance varies a lot between libraries, for the same
operations. <code>tldts</code> is <strong>1000</strong> faster than <code>psl</code>, which is the most popular
library.</p>
<h1>Memory Usage</h1>
<p>Here we estimate the memory used by each library. The measurements are done
using the <a href="https://github.com/remusao/tldts/blob/master/comparison/bench_memory.js" target="_blank" rel="noopener noreferrer">bench_memory.js</a>
script, which loads each file ten times and measure the average memory usage
before and after GC using <code>process.memoryUsage()</code>. The result are then compared
to a reference memory usage computed in the same way using <code>noop_test.js</code> which
does not import anything.</p>
<table>
<thead>
<tr>
<th style="text-align:left">Library</th>
<th style="text-align:right">Before GC</th>
<th style="text-align:right">After GC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>tldts-experimental</strong></td>
<td style="text-align:right"><strong>461KB</strong></td>
<td style="text-align:right"><strong>229 KB</strong></td>
</tr>
<tr>
<td style="text-align:left">parse-domain</td>
<td style="text-align:right">2.579 MB</td>
<td style="text-align:right">1.310MB</td>
</tr>
<tr>
<td style="text-align:left">psl</td>
<td style="text-align:right">2.199 MB</td>
<td style="text-align:right">1.537MB</td>
</tr>
<tr>
<td style="text-align:left">tldjs</td>
<td style="text-align:right">2.621 MB</td>
<td style="text-align:right">1.714MB</td>
</tr>
<tr>
<td style="text-align:left">tldts</td>
<td style="text-align:right">3.094 MB</td>
<td style="text-align:right">1.792MB</td>
</tr>
<tr>
<td style="text-align:left">UBlock publicsuffix</td>
<td style="text-align:right">4.529 MB*</td>
<td style="text-align:right">2.399MB</td>
</tr>
<tr>
<td style="text-align:left">haraka-tld</td>
<td style="text-align:right">4.405 MB</td>
<td style="text-align:right">2.595MB</td>
</tr>
</tbody>
</table>
<p>(*) The memory of uBlock cannot be estimated correctly as for this
benchmarks the lists were inlined in the source code, which is not how
it’s used in production.</p>
<h1>Loading Time</h1>
<p>One point of comparison which can make a difference in some contexts (e.g.:
mobile or if the library is embedded in a website) is the loading time of the
bundle itself (or time it takes to parse the code and initialize it). It can
have a big impact if you use the library on very slow devices (like mobiles)
and here again, not all the libraries are equal.</p>
<p>The benchmark code can be found in <a href="https://github.com/remusao/tldts/blob/master/comparison/bench_startup.sh" target="_blank" rel="noopener noreferrer">bench_startup.sh</a>.
It measures the time it takes to import each of the libraries. The measurements
are performed using the <a href="https://hackage.haskell.org/package/bench" target="_blank" rel="noopener noreferrer">bench</a> CLI,
looking at the <code>mean</code> time returned for each.</p>
<p>Note that this benchmark was performed using the cjs bundle. The performance
might be different in another environment or different bundle (e.g.: UMD in a
browser).</p>
<table>
<thead>
<tr>
<th style="text-align:left">Library</th>
<th style="text-align:right">Mean (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Ref (no <code>require</code>)</td>
<td style="text-align:right">48.21</td>
</tr>
<tr>
<td style="text-align:left"><strong>tldts-experimental</strong></td>
<td style="text-align:right"><strong>47.93</strong></td>
</tr>
<tr>
<td style="text-align:left">psl</td>
<td style="text-align:right">53.77</td>
</tr>
<tr>
<td style="text-align:left">tld.js</td>
<td style="text-align:right">58.74</td>
</tr>
<tr>
<td style="text-align:left">parse-domain</td>
<td style="text-align:right">61.96</td>
</tr>
<tr>
<td style="text-align:left">tldts</td>
<td style="text-align:right">64.48</td>
</tr>
<tr>
<td style="text-align:left">ublock</td>
<td style="text-align:right">78.05</td>
</tr>
<tr>
<td style="text-align:left">haraka-tld</td>
<td style="text-align:right">84.93</td>
</tr>
</tbody>
</table>
<p>Note that some libraries like <code>ublock</code> or <code>haraka-tld</code> perform some form of parsing
of the rules at loading-time, which incurs an initial cost when importing the
library.</p>
<h1>Bundles</h1>
<p>Comparison of bundle sizes, when applicable (not all libraries provide bundles):</p>
<table>
<thead>
<tr>
<th style="text-align:left">Library</th>
<th style="text-align:right">Normal</th>
<th style="text-align:right">Minified</th>
<th style="text-align:right">Gzipped</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>tldts-experimental</strong></td>
<td style="text-align:right"><strong>100KB</strong></td>
<td style="text-align:right"><strong>94KB</strong></td>
<td style="text-align:right">38KB</td>
</tr>
<tr>
<td style="text-align:left">tldts</td>
<td style="text-align:right">140KB</td>
<td style="text-align:right"><strong>95KB</strong></td>
<td style="text-align:right">37KB</td>
</tr>
<tr>
<td style="text-align:left">psl</td>
<td style="text-align:right">138KB</td>
<td style="text-align:right">122KB</td>
<td style="text-align:right">39KB</td>
</tr>
<tr>
<td style="text-align:left">tld.js</td>
<td style="text-align:right">209KB</td>
<td style="text-align:right">141KB</td>
<td style="text-align:right">40KB</td>
</tr>
<tr>
<td style="text-align:left">parse-domain</td>
<td style="text-align:right">?</td>
<td style="text-align:right">?</td>
<td style="text-align:right">?</td>
</tr>
<tr>
<td style="text-align:left">ublock</td>
<td style="text-align:right">?</td>
<td style="text-align:right">?</td>
<td style="text-align:right">?</td>
</tr>
<tr>
<td style="text-align:left">haraka-tld</td>
<td style="text-align:right">?</td>
<td style="text-align:right">?</td>
<td style="text-align:right">?</td>
</tr>
</tbody>
</table>
<h1>Dependencies</h1>
<p>Here is a comparison of dependencies for each library:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Library</th>
<th style="text-align:left">Dependencies</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>tldts</strong></td>
<td style="text-align:left"><strong>(none)</strong></td>
</tr>
<tr>
<td style="text-align:left">psl</td>
<td style="text-align:left">punycode</td>
</tr>
<tr>
<td style="text-align:left">tld.js</td>
<td style="text-align:left">punycode</td>
</tr>
<tr>
<td style="text-align:left">ublock</td>
<td style="text-align:left">punycode</td>
</tr>
<tr>
<td style="text-align:left">haraka-tld</td>
<td style="text-align:left">punycode</td>
</tr>
<tr>
<td style="text-align:left">parse-domain</td>
<td style="text-align:left">?</td>
</tr>
</tbody>
</table>
<h1>Conclusion</h1>
<p>=&gt; <a href="https://github.com/remusao/tldts" target="_blank" rel="noopener noreferrer"><strong>Tldts GitHub repository</strong></a></p>
<p>=&gt; <a href="https://www.npmjs.com/package/tldts" target="_blank" rel="noopener noreferrer"><strong>Tldts on NPM</strong></a></p>
<pre class="code" data-lang="sh"><code>npm install tldts
</code></pre>
<p>If that sounds appealing to you, give it a shot and do not hesite to open
issues for any feedback you might have!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Debugging iptables rules]]></title>
            <link>https://remusao.github.io//posts/test-iptables-rules.html</link>
            <guid>https://remusao.github.io//posts/test-iptables-rules.html</guid>
            <pubDate>Wed, 24 Oct 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>A very quick one! I’ve been playing with <code>iptables</code> rules lately and was
wondering: “How do I debug these things?”. How can I know if the rule is
matching what I want, or if it’s doing something at all? I found <em>one way</em> to do
so, and it’s probably not the only one (or the best one), but I thought I’d
share it anyway. Feel free to send me your tips and tricks!</p>
<p>Using the <code>LOG</code> action and optionally specifying a custom log prefix, it’s
relatively easy to see what packets are targeted by a rule. For example:</p>
<pre class="code" data-lang="sh"><code>iptables -A FORWARD -p tcp -j LOG --log-prefix=<span class="hljs-string">&#x27;[netfilter] &#x27;</span>
</code></pre>
<p>Will then write logs into <code>/var/log/kern.log</code>, which you can monitor using <code>tail</code>:</p>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">tail</span> -f /var/log/kern.log
</code></pre>
<p>I found this to be pretty convenient!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[TypeScript performance tip—Escaping partial]]></title>
            <link>https://remusao.github.io//posts/typescript-escaping-optional.html</link>
            <guid>https://remusao.github.io//posts/typescript-escaping-optional.html</guid>
            <pubDate>Tue, 25 Sep 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>A common pattern in JavaScript or TypeScript is to pass options to
a function or constructor as an object with optional attributes
(meaning, only a subset of the attributes can be specified). Since v2.1,
TypeScript offers a great way to make this type-safe in the form of
<code>Partial&lt;T&gt;</code> which allows to specify a type for exactly this pattern. In
practice this looks like:</p>
<pre class="code" data-lang="javascript"><code>interface <span class="hljs-title class_">IOptions</span> {
  <span class="hljs-attr">option1</span>: boolean;
  <span class="hljs-attr">option2</span>: string;
}

<span class="hljs-keyword">function</span> <span class="hljs-title function_">doSomething</span>(<span class="hljs-params">options: Partial&lt;IOptions&gt; = {}</span>): <span class="hljs-keyword">void</span> {
  ...
}
</code></pre>
<p>This definition allows to give a subset of the options to the function,
or all of them, or no argument at all!</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-title function_">doSomething</span>(); <span class="hljs-comment">// OK</span>
<span class="hljs-title function_">doSomething</span>({ <span class="hljs-attr">option1</span>: <span class="hljs-literal">true</span> }); <span class="hljs-comment">// OK</span>
<span class="hljs-title function_">doSomething</span>({ <span class="hljs-attr">option1</span>: <span class="hljs-literal">true</span>, <span class="hljs-attr">option2</span>: <span class="hljs-string">&#x27;foo&#x27;</span> }); <span class="hljs-comment">// OK</span>

<span class="hljs-title function_">doSomething</span>({ <span class="hljs-attr">option3</span>: <span class="hljs-number">42</span> }); <span class="hljs-comment">// NOT OK</span>
</code></pre>
<p>Now, something you might want to do is to provide a set of default
values for each attribute of your <code>IOptions</code> passed as argument. One
way this could be done is to use <code>Object.assign</code> to merge the partial
options given as argument with a set of default values:</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">options: Partial&lt;IOptions&gt; = {}</span>): <span class="hljs-title class_">IOptions</span> {
  <span class="hljs-keyword">return</span> <span class="hljs-title class_">Object</span>.<span class="hljs-title function_">assign</span>({
    <span class="hljs-attr">option1</span>: <span class="hljs-literal">true</span>,
    <span class="hljs-attr">option2</span>: <span class="hljs-string">&#x27;bar&#x27;</span>,
  }, options);
}
</code></pre>
<p>This is elegant and it works. However, this is not the optimal solution
in terms of performance. There is still some overhead in the call
to <code>assign</code>, and although it might not matter most of the time,
sometimes you just want to make things go as fast as possible. As a
baseline, let’s measure the performance of this solution using the
<a href="https://www.npmjs.com/package/benchmark" target="_blank" rel="noopener noreferrer">benchmark</a> library:</p>
<blockquote>
<p><strong>14M</strong> calls/second</p>
</blockquote>
<p>To by-pass the use of <code>Object.assign</code>, we could try to use the spread operator:</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">options: Partial&lt;IOptions&gt; = {}</span>): <span class="hljs-title class_">IOptions</span> {
  <span class="hljs-keyword">return</span> {
    <span class="hljs-attr">option1</span>: <span class="hljs-literal">true</span>,
    <span class="hljs-attr">option2</span>: <span class="hljs-string">&#x27;bar&#x27;</span>,
    ...options,
  };
}
</code></pre>
<p>This is even terser, but unfortunately it’s not as fast, at least when
<code>esnext</code> is targeted. For <code>ES6</code> or lower, a call to <code>Object.assign</code> will
be made, which makes this solution equivalent to the first one.</p>
<blockquote>
<p><strong>7M</strong> calls/second (<strong>x0.6</strong>)</p>
</blockquote>
<p>Another solution would be to hard-code the creation of the object
with the existence of each attribute checked:</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">options?: Partial&lt;IOptions&gt;</span>): <span class="hljs-title class_">IOptions</span> {
  <span class="hljs-keyword">return</span> {
    <span class="hljs-attr">option1</span>: options.<span class="hljs-property">option1</span> !=== <span class="hljs-literal">undefined</span> ? options.<span class="hljs-property">options1</span> : <span class="hljs-literal">true</span>,
    <span class="hljs-attr">option2</span>: options.<span class="hljs-property">option2</span> !=== <span class="hljs-literal">undefined</span> ? options.<span class="hljs-property">options2</span> : <span class="hljs-string">&#x27;bar&#x27;</span>,
  };
}
</code></pre>
<p>This does the job, but is much more verbose, and you will have to write the name
of each attribute several times. It does not get better as your option type
grows. The performance is much better though:</p>
<blockquote>
<p><strong>215M</strong> calls/second (<strong>x15</strong>)</p>
</blockquote>
<p>If you already looked at the code generated by Babel or TypeScript to
transpile arguments destructuring, this should look familiar. We could
try to make TypeScript generate the boilerplate code for us by targeting
an older version of ECMAScript (which does not support destructuring).
On top of that, destructuring allows to specify default values for some
(or all) of the attributes. Let’s combine these two ideas to create a
fourth version of our <code>setDefaults</code> function:</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">{
  option1 = <span class="hljs-literal">true</span>,
  option2 = <span class="hljs-string">&#x27;bar&#x27;</span>,
}: Partial&lt;IOptions&gt; = {}</span>): <span class="hljs-title class_">IOptions</span> {
  <span class="hljs-keyword">return</span> { option1, option2 };
}
</code></pre>
<p>This is almost as terse as the first version based on <code>Object.assign</code>
and much better than the second version. It is also the fastest version:</p>
<blockquote>
<p><strong>230M</strong> calls/second (<strong>x16</strong>)</p>
</blockquote>
<p>Out of curiosity, we can check the code generated by TypeScript
depending on the <code>target</code> you specify. Keep in mind that the performance
seen above corresponds to the <code>ES3</code> target.</p>
<ul>
<li><strong>ES3 and ES5</strong></li>
</ul>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">_a</span>) {
  <span class="hljs-keyword">var</span> _b = _a === <span class="hljs-keyword">void</span> <span class="hljs-number">0</span> ? {} : _a, _c = _b.<span class="hljs-property">option1</span>, option1 = _c === <span class="hljs-keyword">void</span> <span class="hljs-number">0</span> ? <span class="hljs-literal">true</span> : _c, _d = _b.<span class="hljs-property">option2</span>, option2 = _d === <span class="hljs-keyword">void</span> <span class="hljs-number">0</span> ? <span class="hljs-string">&#x27;bar&#x27;</span> : _d;
  <span class="hljs-keyword">return</span> { <span class="hljs-attr">option1</span>: option1, <span class="hljs-attr">option2</span>: option2 };
}
</code></pre>
<p>Yey, fast and ugly!</p>
<blockquote>
<p><strong>230M</strong> calls/second (<strong>x16</strong>)</p>
</blockquote>
<ul>
<li><strong>ES6</strong></li>
</ul>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">setDefaults</span>(<span class="hljs-params">{ option1 = <span class="hljs-literal">true</span>, option2 = <span class="hljs-string">&#x27;bar&#x27;</span>, } = {}</span>) {
  <span class="hljs-keyword">return</span> { option1, option2 };
}
</code></pre>
<p>Yey, nice and not as fast…</p>
<blockquote>
<p><strong>170M</strong> calls/second (<strong>x12</strong>)</p>
</blockquote>
<p>Here we can see that the implementation of <code>ES6</code> destructuring with
defaults is not yet as fast as the transpiled version, at least on V8
(Node.js 10.11.0). In practice that is not an issue as TypeScript will
allow you to write high-level, type-safe code, while still giving you
the best performance by targeting low-level JavaScript (e.g.: <code>ES3</code>!).</p>
<p>The full source-code for benchmarks can be found there: <a href="../snippets/typescript-options-bench.ts" target="_blank" rel="noopener noreferrer">typescript-options-bench.ts</a>.
All the results were obtained using Node.js v10.11.0 on an Intel
i7-6600U (2,60-3,40 GHz) with 16GB of Ram, running Ubuntu 18.04.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Exploring etymology using Wiktionary data]]></title>
            <link>https://remusao.github.io//posts/wiktionary-etymology-exploration.html</link>
            <guid>https://remusao.github.io//posts/wiktionary-etymology-exploration.html</guid>
            <pubDate>Sat, 14 Jul 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Etymology is a fascinating topic. Looking closer at the origin of words often
yields surprising and interesting connections between languages and countries,
forgotten stories or fun anecdotes. There are multiple sources for etymological
data, and most of the time, using specialized books is a safe bet. The issue is
that they are usually dedicated to one language, and it’s close to impossible to
extract the data in a format which allows manipulation by programs.</p>
<p>There is an alternative though: <a href="https://www.wiktionary.org/" target="_blank" rel="noopener noreferrer"><strong>Wiktionary</strong></a>. It is not perfect and suffers from the following drawbacks:</p>
<ul>
<li>Information about some words can be missing or incomplete</li>
<li>Different editions offer various degrees of exhaustiveness</li>
<li>It is still not trivial to extract the data in a nice format (more on that
later)</li>
</ul>
<p>But it offers very nice benefits as well:</p>
<ul>
<li>It is possible to parse the dumps (although not as easy as it could)</li>
<li>It is possible to combine multiple editions to get more complete etymological data (e.g.: French and English dumps)</li>
<li>It is constantly evolving and freely accessible</li>
</ul>
<p>I often use Wiktinary from the website to get more insight about some words, but
it is not always optimal: it can be time-consuming to follow the links,
difficult to know if you missed anything, and hard to answer some questions. In
particular:</p>
<ol>
<li>What is the “etymological” distance between two words, and how are they connected? (according to
Wiktionary data)</li>
<li>Given a word in a source language (e.g.: <code>Buch</code> from <em>German</em>), what is the
closest word in another target language (e.g.: in <em>English</em> it would be <code>book</code>.)</li>
<li>Can we identify the subset of words from a source language which is very
closely connected to words from a target language? (e.g. by direct
inheritance)?</li>
<li>Could we visualize the graph of etymological connections from a source <em>word</em>
until a given <em>distance</em>?</li>
<li>etc.</li>
</ol>
<p>In the rest of this article, I’d like to present a work-in-progress project
called <a href="https://github.com/remusao/wgraph" target="_blank" rel="noopener noreferrer"><em>wgraph</em></a>, which I have been
developing recently. It allows to parse the content of Wiktionary dumps in
multiple languages (currently French and English are well supported and more are
on the way), to extract a graph of etymological relationships between words. Here
are a few examples of possible connections:</p>
<ul>
<li>German word ‘Buch’ <em>cognates</em> with English word ‘book’</li>
<li>English word ‘table’ <em>inherits</em> from Middle English words ‘table’, ‘tabel’,
‘tabil’ and ‘tabul’</li>
<li>French word ‘chaise’ is <em>borrowed</em> from Old French ‘chaiere’, and <em>cognates</em>
with English word ‘chair’</li>
</ul>
<h2>Parsing the data</h2>
<p>The parsing stage takes as input one or multiple
<a href="https://dumps.wikimedia.org/backup-index.html" target="_blank" rel="noopener noreferrer">dumps</a>, and produces a
mapping between <code>source</code> words, and multiple references as found in the
specific pages from Wiktionary, in the <code>etymology</code> section. Using
<code>wgraph</code>, this can be performed as follows:</p>
<pre class="code" data-lang="sh"><code>$ parse enwiki-articles/enwiktionary-latest-pages-articles.xml
</code></pre>
<p>(Note that you can input a compressed version of the dumps as well, either in
<code>.gz</code> or <code>.bz2</code> format)</p>
<p>This will produce a file named <code>graph.tsv</code> containing one word per line,
alongside its references. The first few lines look like:</p>
<pre class="code" data-lang="sh"><code>lire  lira|etyl|  lira|borrowed|it  *lekʷs-|mention|ine-pro  lies|cognate|<span class="hljs-built_in">nl</span> ...
encyclopédie  encyclique|lien|  encyclopaedia|etyl|  encyclopaedia|mention|la ...
manga  漫|mention|ltc  manga|mention|pt  漫画|borrowed|ja  man + -ga|suffix|zza ...
</code></pre>
<p>Each line starts with the word (e.g.: <code>manga</code>) and then follows a tab-separated
list of references. Each reference is a tuple of <code>word</code>, <code>kind</code> (kind of
relationship with the origin word, e.g.: borrowed from, inherited from, etc.)
and <code>origin</code> (optional, since not all origins are specified in the data).</p>
<p>And this is all we need start exploring the data and answer interesting
questions!</p>
<h2>Etymological summary visualization</h2>
<p>Once we have a graph of “etymological” connections between words, one of the
simplest things we can do is to visualize the neighborhood of a given word. This
can be performed using the <code>summary</code> command provided by <code>wgraph</code>:</p>
<pre class="code" data-lang="sh"><code>$ summary graph.tsv Buch
Graph written into: wgraph_Buch
</code></pre>
<figure>
<a href="../images/wgraph_Buch_1.svg">
<img src="../images/wgraph_Buch_1.svg" alt="Etymological neighborhood of 'Buch'" style="width:100.0%">
</a>
<figcaption>Etymological neighborhood of *Buch*</figcaption>
</figure>
<p>We can also look deeper in the graph:</p>
<pre class="code" data-lang="sh"><code>$ summary graph.tsv candidate --max-depth 2
Graph written into: wgraph_Buch
</code></pre>
<figure>
<a href="../images/wgraph_candidate.svg">
<img src="../images/wgraph_candidate.svg" alt="Etymological neighborhood of 'candidate'" style="width:100.0%">
</a>
<figcaption>Etymological neighborhood of *candidate*</figcaption>
</figure>
<p>Interestingly enough, the ‘candidates’ referred to
the “Roman candidates wearing bleached white togas
as a symbol of purity at a public forum” (source:
<a href="https://en.wiktionary.org/wiki/candidate#Etymology" target="_blank" rel="noopener noreferrer">Wiktionary</a>). This
explains why the word ‘candidate’ is related to ‘white’, ‘candide’,
‘blank’ and even the ‘elves’.</p>
<p>Note that by default, up to 50 words will be included in the graph, to not
overload it too much.</p>
<p>It is also possible to group the nodes by origin using the <code>--group-by-origin</code>
argument:</p>
<pre class="code" data-lang="sh"><code>$ summary graph.tsv petrol --max-depth 2 --group-by-origin
Graph written into: wgraph_Buch
</code></pre>
<figure>
<a href="../images/wgraph_petrol_2_groupped.svg">
<img src="../images/wgraph_petrol_2_groupped.svg" alt="Etymological neighborhood of 'petrol'" style="width:100.0%">
</a>
<figcaption>Etymological neighborhood of *petrol*</figcaption>
</figure>
<p>Now we know that <em>pretrol</em> literally means “oil from stones”: <em>ol</em> + <em>petra</em>
(the stone).</p>
<p>As a last example, let’s explore the neighborhood of ‘truie’ a French word used
to designate the female of the pork. This word has a curious origin…</p>
<pre class="code" data-lang="sh"><code>$ summary graph.tsv truie --max-depth 2 --group-by-origin
Graph written into: wgraph_Buch
</code></pre>
<figure>
<a href="../images/wgraph_truie.svg">
<img src="../images/wgraph_truie.svg" alt="Etymological neighborhood of 'truie'" style="width:100.0%">
</a>
<figcaption>Etymological neighborhood of *truie*</figcaption>
</figure>
<p>You can see mentions of the word “Troja”, the famous city, where the
“Trojan Horse” was used as a subterfuge that the Greeks used to enter
the city of Troy during the war. And this is where we think this ‘truie’
comes from. The “Trojan Horse” gave its name to a way to prepare (or
grill) the pork called: “Porka de Troja”, and they ‘truie’ in French.</p>
<h2>Distance between two words</h2>
<p>Another simple application of the graph is to compute the size of
the shortest path between two words. This can be achieved using the
<code>distance</code> command provided by <code>wgraph</code>:</p>
<figure>
<a href="../images/wgraph_distance_Buch_beech.svg">
<img src="../images/wgraph_distance_Buch_beech.svg" alt="Etymological distance between 'Buch' and 'beech'" style="width:20.0%">
</a>
<figcaption>Etymological distance between *Buch* and *beech*</figcaption>
</figure>
<pre class="code" data-lang="sh"><code>$ distance graph.tsv Buch book
Distance: 1
Start: Buch
&gt; Cognates with book (English)
</code></pre>
<pre class="code" data-lang="sh"><code>$ distance graph.tsv Buch beech
Distance: 5
Start: Buch
&gt; Cognates with book (English)
&gt; Cognates with boek (Dutch)
&gt; Cognates with bog (Danish)
&gt; Inherited from boc (Old Irish (to 900))
&gt; Mention beech (English)
</code></pre>
<pre class="code" data-lang="sh"><code>$ distance graph.tsv camaraderie chambre
Distance: 3
Start: camaraderie
&gt; Mention comrade (English)
&gt; Mention chamber (English)
&gt; Inherited from chambre (Middle English (1100-1500))
</code></pre>
<pre class="code" data-lang="sh"><code>$ distance graph.tsv camarade chambre
Distance: 2
Start: camarade
&gt; None chambrée (French)
&gt; None chambre (French)
</code></pre>
<p>You probably noticed that <code>origin</code> or <code>kind</code> are not always available. This is
mainly caused by:</p>
<ol>
<li>Data in French dumps are not formatted in an easily parsable format, and most
information needs to be extracted from links (e.g.: <code>''[[word]]''''</code>) as well
as the context, and the parser from <code>wgraph</code> is not yet smart enough to do
this in a lot of cases.</li>
<li>Sometimes the information is not available at all.</li>
</ol>
<p>Also note that this command only finds <em>one possible path</em>, but it happens
that multiple paths of the same length link two words of the graph. A possible
improvement would be to find all possible paths between two words, which would
probably gives some nice insight! (It could also be visualized as a graph!)</p>
<h2>Closest word in a target language</h2>
<p>Let’s say you are learning a new language (e.g.: German) and while learning a
new word, you are looking for a way to “connect” it to some words you already
know. One way we could leverage our graph of words is to find a close word in a
language you already know! This is what the command <code>closest</code> is doing:</p>
<pre class="code" data-lang="sh"><code>$ closest graph.tsv buchstabieren en
Start: buchstabieren
&gt; None Buchstabe (unknown origin)
&gt; Mention bookstaff (English)
</code></pre>
<p>The German word “buchstabieren” (or “to spell” in English) literally
means “to stab the letters on the Buch/book/beech”. The connection with
“beech” comes from the fact that people used to use “beech” tree as a
material to create the tablets to write.</p>
<pre class="code" data-lang="sh"><code>$ closest graph.tsv hospital fr
Start: hospital
&gt; Cognates with hôpital (French)
</code></pre>
<p>This one was pretty easy…</p>
<pre class="code" data-lang="sh"><code>$ closest graph.tsv therme en
Start: therme
&gt; Etymology θερμός (unknown origin)
&gt; Cognates with wearm (Old English (ca. 450-1100))
&gt; Cognates with formus (Latin)
&gt; Cognates with warm (English)
</code></pre>
<p>Interesting to know that “therme” (name given to the ancient Roman baths)
connects to “warm” in English (very indirectly, but we find this idea of “warm
water”).</p>
<pre class="code" data-lang="sh"><code>$ closest graph.tsv schön en
Start: schön
&gt; None sheen (unknown origin)
&gt; Cognates with show (English)
</code></pre>
<pre class="code" data-lang="sh"><code>$ closest graph.tsv Welt fr
Start: Welt
&gt; Inherited from weralt (Old High German (ca. 750-1050))
&gt; Mention world (English)
&gt; Cognates with verd (Norwegian Nynorsk)
&gt; Cognates with vert (French)
</code></pre>
<p>Some connections are pretty far-fetched, and we would need to dig in the
original data to understand why! And this is where it can get exciting to do
some manual research!</p>
<h2>What are the easiest words to learn in a language?</h2>
<p>As a final application, and as a result of our ability to compute the minimum
distance between two words in different languages, we can try to identify the
easiest sub-set of a language you can learn! This works as follows:</p>
<ol>
<li>Specify the target language (e.g.: German)</li>
<li>Specify languages you already know (e.g.: French and English)</li>
</ol>
<p>Then the <code>easiest</code> command will try to find a set of German words which
is very close from words in either English or French. These words should
be easier to memorize because they will probably resemble words you
already know.</p>
<pre class="code" data-lang="sh"><code>$ easiest graph.tsv
========================================
&gt; 1
========================================
  * personell
  * Republik
  * munizipal
  * Provokateur
  * Strauß
  * Beispiel
  * Tupperware
  * Karosserie
  * maritim
  * hypoallergen
  * Etappe
  * Finanzier
  * Pansen
  * bekommen
  * Feuer
  * blockieren
  * robbe
  * kidnappen
  * Flakon
  * lukrativ
  * eskortieren
  * universell
  * Bravour
  * Mittwoch
  * grotesk
  * jetzt
  * positiv
  ...
</code></pre>
<p>At the moment it is not possible to specify other languages than French, English
and German, but it will probably be in the future.</p>
<h2>Closing remarks</h2>
<p>There is probably much more we can do using this data, and this is only
the beginning, I already find the project useful to get insight about
the origin of some words, but it is still rough around the edges. In the
following weeks I intend to improve <code>wgraph</code> in the following ways:</p>
<ol>
<li>Improve information extraction from Wiktionary dumps (especially for the
French edition), this should have a direct impact on the results of all
sub-commands presented above.</li>
<li>Support more editions to make the dataset more complete (German is next)</li>
<li>Find more interesting applications and visualizations ideas!</li>
</ol>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Synacor—Down the rabbit hole]]></title>
            <link>https://remusao.github.io//posts/synacor-down-the-rabbit-hole.html</link>
            <guid>https://remusao.github.io//posts/synacor-down-the-rabbit-hole.html</guid>
            <pubDate>Sun, 10 Jun 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Last year I had the chance to participate in the 2017 edition of <a href="https://adventofcode.com/" target="_blank" rel="noopener noreferrer">Advent
of Code</a>. That was the first time and I
<em>really</em> enjoyed it. Having to solve an interesting problem, every
day, made me learn a lot! It’s also a good occasion to practice some
skills that might not be otherwise useful in your daily job (and more
importantly: have fun!).</p>
<p>While skimming through the discussions on Reddit about possible
solutions to one of the AoC’s problems, someone mentioned “Synacor”… I
never heard of it before, but from what I understood it was some kind of
programming challenge. I did not need more to have a look:
<a href="https://challenge.synacor.com" target="_blank" rel="noopener noreferrer">challenge.synacor.com</a>.</p>
<h1>The Challenge</h1>
<p>The challenge is briefly introduced, the competition took place during
two conferences in the past and is now over. But you can still download
the material of the challenge and try to solve it.</p>
<p>After registering an email address and a password, I could download an
archive <code>synacor-challenge.tgz</code>. Uncompressed, it contains two files :</p>
<ol>
<li><code>arch-spec</code></li>
<li><code>challenge.bin</code></li>
</ol>
<p>The first one describes the challenge. It is about creating “a virtual
machine capable of running the included binary [challenge.bin]”. It also
mentions that some “codes” are to be found along the way. The rest of
the document describes the architecture of the virtual machine:</p>
<ul>
<li>16 bits integers stored in little-endian format</li>
<li>16 bits addressable memory (the program starts at address <code>0</code>)</li>
<li>8 registers</li>
<li>1 stack containing 16 bits numbers</li>
<li>22 instructions: <code>halt</code>, <code>noop</code>, <code>set</code>, <code>push</code>, <code>jpm</code>, <code>add</code>, <code>mult</code>, etc.</li>
</ul>
<p>Each instruction is described in details: opcode, number of expected
arguments and behavior when executed by the virtual machine. So
far so good, this looks pretty classic. The implementation of such
virtual machine is pretty straight forward. I choose <code>Haskell</code> for
the implementation (because why not, and I already implemented some
<a href="https://github.com/remusao/Hodor" target="_blank" rel="noopener noreferrer">Brainfuck interpreter/transpiler</a>
before, so I thought I could reuse some learnings from there). Without
going into too much details, I used the following data structures to
represent the state of the VM:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">Synacor</span> = <span class="hljs-type">Synacor</span></span>
  { pos :: <span class="hljs-type">Int</span>
  , mem :: <span class="hljs-type">Map</span> <span class="hljs-type">Register</span> <span class="hljs-type">Word16</span>
  , stack :: [<span class="hljs-type">Word16</span>]
  , program :: <span class="hljs-type">Vector</span> <span class="hljs-type">Word16</span>
  }
</code></pre>
<h1>First Results</h1>
<p>After implementing most of the instructions, I tried to run the program:</p>
<blockquote>
<p>Welcome to the Synacor Challenge! Please record your progress by
putting codes like this one into the challenge website: XXXXXXXXXXX</p>
<p>Executing self-test…</p>
</blockquote>
<p>Nice, so the program actually starts by <em>testing the virtual machine</em>,
to make sure all instructions are implemented properly. It’s pretty
cool. It means that you cannot proceed until your VM is fully functional
(Using Haskell is a good start for that…). After a few iterations of
trial, error, fix, I completed my implementation until…</p>
<blockquote>
<p>self-test complete, all tests pass
The self-test completion code is: XXXXXXXXXXXX</p>
</blockquote>
<p>Youpi! All good… but, wait, something else was displayed on the terminal:</p>
<p><strong>DISCLAIMER</strong>: The next section of this post contains spoilers and
parts of solutions for the Synacor challenge. Please only proceed if you
already solved the challenge, or do not intend to do so.</p>
<p>…</p>
<h1>Riddles in the Dark</h1>
<blockquote>
<p>== Foothills ==
You find yourself standing at the base of an enormous mountain. At its
base to the north, there is a massive doorway. A sign nearby reads
“Keep out! Definitely no treasure within!”</p>
<p>Things of interest here:</p>
<ul>
<li>tablet</li>
</ul>
<p>There are 2 exits:</p>
<ul>
<li>doorway</li>
<li>south</li>
</ul>
<p>What do you do?</p>
</blockquote>
<p><em>Mind blown</em>. The program you are running is actually a terminal-based
RPG! How cool is that? Well, very cool, and very smart. I clearly did
not expect that from the challenge. It’s a bit like trying to open a
chess (the chess is a program and the virtual machine is the key) and
then you discover there is another riddle in the chess. So what’s next?
Well play the game I guess…</p>
<p>I played for a bit, and discovered one more code in the game (Did I
already mention how cool all this is?). Which means some (all?) codes
can be found by playing the game. But then, how do I know if all codes
are in the game? How deep and rich can this game be? What if it takes 10
hours to find the codes? I already under-estimated the challenge once,
let’s not do the same mistake again.</p>
<p>At this point I thought of two things that could be done:</p>
<ol>
<li>Try to extract all text from the file <code>challenge.bin</code> and see if it contains
any code.</li>
<li>Modify the VM so that it can play the game by itself, and explore all
possible paths possible, some kind of depth-first search on the game itself
in a way.</li>
<li>Disassemble the program and try to understand its structure. The codes must
be stored somewhere (or generated somehow), by understanding (and maybe
changing a bit) the code, it must be possible to bypass the game completely.</li>
</ol>
<p>The first approach did not yield any result, which means that codes are
probably encoded in some way to not be readable. I did not have too much hope
anyways, but we never know.</p>
<p>The second approach was the most promising and allowed me to discover a few more
codes. Here is how it worked:</p>
<p><strong>First step</strong> – I modified the virtual machine implementation so that it’s 100%
pure code with no side-effect. The execution now consists in a function
<code>execNextOpCode</code> which takes as input the state of the program, runs the
next opcode of the program, then returns a “continuation” which can be
one of:</p>
<ul>
<li><code>Halt</code> - program terminated successfully.</li>
<li><code>Error String</code> - there was an exception while running the opcode (should
never happen).</li>
<li><code>PutChar Char</code> - we should print a character in the terminal.</li>
<li><code>GetChar (Char -&gt; s)</code> - we should ask some user input, then continue the
execution of the opcode using the function returned (<code>Char -&gt; s</code>).</li>
<li><code>Ok</code> - opcode was executed correctly and we can continue running the program.</li>
</ul>
<p>The nice thing with this model, is that running an opcode does not alter
the state of the virtual machine, but instead returns a new virtual
machine (copy of the initial state). This might seem crazy, but it’s not as
inefficient as it sounds (and pretty common in an immutable language like
Haskell). This allows us to parallelize the execution of different branches of a
program without having to care about controlling side-effects.</p>
<p><strong>Second step</strong> – write a depth-first search for the game by changing the VM
execution model in two ways:</p>
<ol>
<li>Each output <code>PutChar</code> from the program is stored in an accumulator so that we
can inspect it later.</li>
<li>Each time a user input is required by the <code>GetChar</code> continuation code, we
<em>fork</em> our execution of the program and perform all possible user actions
concurrently: <em>picking up objects</em>, <em>using objects</em>, <em>visit available
places</em>.</li>
<li>We need to detect loops to not explore forever (e.g.: when we come back to an
already visited location). This is done by comparing the output (accumulated
<code>PutChar</code> from the program) of a given branch to all previously explored
branches. If we already generated the same output once, no need to do it
again.</li>
</ol>
<p>This approach allowed me to discover a few more codes, <em>but not all</em>!
This can mean two things: either not all codes can be discovered through
the game (likely), or my exploration method is not working as well as it
should! In both cases, it means I’m not done exploring the rabbit hole…</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[TIL—Python has a built-in persistent key-value store]]></title>
            <link>https://remusao.github.io//posts/python-dbm-module.html</link>
            <guid>https://remusao.github.io//posts/python-dbm-module.html</guid>
            <pubDate>Sun, 10 Jun 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Python is, in a lot of ways, a very rich language. After years of using
it, I still regularly discover new parts of the ecosystem, even in the
standard library. In particular, there are a few modules which are not
very well-known, but can be very useful in some situations. Today I
discovered <code>dbm</code> a persistent key/value store:</p>
<p>Quick start:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> dbm

<span class="hljs-keyword">with</span> dbm.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;my_store&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>) <span class="hljs-keyword">as</span> db:
  db[<span class="hljs-string">&#x27;key&#x27;</span>] = <span class="hljs-string">&#x27;value&#x27;</span>
  <span class="hljs-built_in">print</span>(db.keys()) <span class="hljs-comment"># [&#x27;key&#x27;]</span>
  <span class="hljs-built_in">print</span>(db[<span class="hljs-string">&#x27;key&#x27;</span>]) <span class="hljs-comment"># &#x27;value&#x27;</span>
  <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;key&#x27;</span> <span class="hljs-keyword">in</span> db) <span class="hljs-comment"># True</span>
</code></pre>
<p>It behaves a lot like a <code>dict</code> except:</p>
<ul>
<li>It persists its values on disk</li>
<li>You can only use <code>str</code> or <code>bytes</code> as key and values</li>
</ul>
<p>The performance is also slower than a dictionary, but faster than <code>sqlite3</code>.</p>
<p>The benchmark consists in performing <em>10k</em> writes and <em>10k</em> random reads:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> time

operations = <span class="hljs-number">10000</span>
writes = [<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(operations)]
reads = [<span class="hljs-built_in">str</span>(<span class="hljs-built_in">int</span>(random() * operations)) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(operations)]

<span class="hljs-comment"># Create some records</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> writes:
    db[i] = <span class="hljs-string">&#x27;x&#x27;</span>

<span class="hljs-comment"># Read values in random order</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> reads:
    x = db[i]
</code></pre>
<p>Here are the results:</p>
<ul>
<li><code>dict</code> – total: <em>0.002 seconds</em>, 0.23398 μs/record <strong>x 1</strong></li>
<li><code>dbm</code> – total: 0.054 seconds, 5.35984 μs/record <strong>x 27</strong></li>
<li><code>sqlite3</code> in-memory: total: 2.468 seconds, 246.84346 μs/record <strong>x 1234</strong></li>
<li><code>sqlite3</code> file: total 42.407 seconds, 4240.69593 μs/record <strong>x 21207</strong></li>
</ul>
<p>Why is <code>sqlite3</code> so slow? Well, the benchmark is probably not representative of
the typical workload for sqlite (lots of individual insertions and selections).
If we perform the same operations using <code>executemany</code> and one <code>select</code> of all
the keys at once, we get:</p>
<ul>
<li><code>:memory:</code> – total: 0.038 seconds, 3.81415 μs/record <strong>x 19</strong></li>
<li><code>file</code> – total 0.071 seconds, 7.07369 μs/record <strong>x 35</strong></li>
</ul>
<p>It’s much better, but still not as fast as <code>dbm</code> (when we persist to
a file). So, if you have a workload where keys and values are added
and retrieved very often, are always <code>str</code> or <code>bytes</code> and need to be
persisted on disk, <code>dbm</code> is a serious contender!</p>
<p><em>The code used to benchmark can be found here:
<a href="https://github.com/remusao/remusao.github.io/blob/d9b5a3088e4cae8452eabf90371f582c81569d88/snippets/dbm_bench.py" target="_blank" rel="noopener noreferrer">dbm_bench.py</a></em></p>
<hr>
<p><strong>Edit 06-11-2022</strong>: There was some great feedback on <a href="https://news.ycombinator.com/item?id=32849592" target="_blank" rel="noopener noreferrer">Hacker News</a> yesterday. I’d like to address some of it.</p>
<ul>
<li><em>Using a primary key</em>—It was suggested that adding a <code>PRIMARY KEY</code> when
creating the table improves performance of SQLite3, so I’ve updated the
benchmark accordingly. It does help with performance indeed (see below).</li>
<li><em>Using WAL pragma</em>—It was suggested that using WAL journaling instead of
default mode would also make more sense. I have updated the <a href="https://github.com/remusao/remusao.github.io/blob/42743be91b5ec4bf4233ffe25c3c7c90cf515627/snippets/dbm_bench.py" target="_blank" rel="noopener noreferrer">benchmarking
script</a> accordingly.</li>
<li><em>Using one INSERT at a time vs. <code>executemany</code></em>—It was called out that
executing one INSERT command per key instead of batching the operations
is less efficient. The benchmark measures both scenarios: one where single
INSERTs are made (“sqlite3 (:memory:)” and “sqlite3 (file)”) and one where
<code>executemany</code> is used to insert and read everything in one batch (“sqlite3
(executemany)”). I’ve added one more benchmark for the use of <code>executemany</code>
on a <code>:memory</code> SQLite3 database. The bottomline is that in all these cases,
SQLite3 is still slower than DBM.</li>
<li><em>Using an index with SQLite3</em>—In order to improve performances of SQLite3
operations, creating an index can also be benefitial, and this was suggested
in the comments. I’ve added two new entries to the <a href="https://github.com/remusao/remusao.github.io/blob/42743be91b5ec4bf4233ffe25c3c7c90cf515627/snippets/dbm_bench.py" target="_blank" rel="noopener noreferrer">benchmark</a> to show the
performance when creating an index before insertions and also after
insertions but before reading the values back.</li>
<li><em>Which DBM implementation is used</em>—This is something that the initial
blogpost missed. The results are about the GNU implementation of DBM, which
the new benchmarking code now explicitely imports. The performance might vary
vastely between implementations (worst case being if the <a href="https://docs.python.org/3/library/dbm.html#module-dbm.dumb" target="_blank" rel="noopener noreferrer">dbm.dumb</a> module is used).</li>
</ul>
<p>With all the above, I have updated the <a href="https://github.com/remusao/remusao.github.io/blob/42743be91b5ec4bf4233ffe25c3c7c90cf515627/snippets/dbm_bench.py" target="_blank" rel="noopener noreferrer">benchmarks</a> and here are the new results obtained with CPython 3.11.0, best of 5 runs:</p>
<ul>
<li><code>dict</code>—took 0.001 seconds, 0.11792 microseconds / record</li>
<li><code>dbm</code>—took 0.009 seconds, 0.88954 microseconds / record</li>
<li><code>sqlite3, executemany, :memory:</code>—took 0.029 seconds, 2.86062 microseconds / record</li>
<li><code>sqlite3, executemany, file</code>—took 0.045 seconds, 4.52690 microseconds / record</li>
<li><code>sqlite3, executemany, index after insertions</code>—took 0.044 seconds, 4.37975 microseconds / record</li>
<li><code>sqlite3, executemany, index before insertions</code>—took 0.048 seconds, 4.84734 microseconds / record</li>
<li><code>sqlite3, :memory:</code>—took 0.082 seconds, 8.19964 microseconds / record</li>
<li><code>sqlite3, file</code> —took 4.661 seconds, 466.07621 microseconds / record</li>
</ul>
<p>With all optimizations brought to the SQLite3 version, <code>dbm.gnu</code> still has an
edge on this very <em>synthetic benchmark</em>. And that is, I think, the bottom line
of this article. It is only that, a synthetic benchmark and you should probably
not read too much into it, unless  your particular use-case involves writing
10,000 random values then reading them back and nothing else. As everything,
you should first perform your own measurements based on your own use-case and
constraints, then make a decision about what technology best serves your need.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Copy anything to clipboard in HTML and JavaScript]]></title>
            <link>https://remusao.github.io//posts/javascript-html-copy-anything-to-clipboard.html</link>
            <guid>https://remusao.github.io//posts/javascript-html-copy-anything-to-clipboard.html</guid>
            <pubDate>Sat, 09 Jun 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Not long ago, I was looking for a way to copy the content of any HTML element on
a page to clipboard. What I thought would be an easy task turned out to be more
complicated than expected. In the end I had to use some trick which I will show
here.</p>
<p>The way this will work is as follows: when clicking an element on the page, its
<code>innerText</code> will be copied to Clipboard. To achieve this we will need to:</p>
<ul>
<li>Attach an <code>onclick</code> event listener to our element (or to several elements)</li>
<li>When a <code>click</code> event is received, emit a fake <code>copy</code> event</li>
</ul>
<pre class="code" data-lang="javascript"><code>  <span class="hljs-comment">// This variable will be used to store a reference to the</span>
  <span class="hljs-comment">// latest element clicked.</span>
  <span class="hljs-keyword">let</span> selected = <span class="hljs-literal">null</span>;

  <span class="hljs-comment">// Attach our custom copy-to-clipboard-on-click trick to `elt`</span>
  <span class="hljs-keyword">const</span> elt = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">querySelector</span>(<span class="hljs-string">&#x27;...&#x27;</span>);
  elt.<span class="hljs-property">onclick</span> = <span class="hljs-function">() =&gt;</span> {
    <span class="hljs-comment">// Store reference to this element in the global `selected`</span>
    selected = elt;
    <span class="hljs-comment">// Emit fake `copy` event</span>
    <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">execCommand</span>(<span class="hljs-string">&#x27;copy&#x27;</span>);
    <span class="hljs-comment">// Remove reference from `selected` to allow normal copies</span>
    <span class="hljs-comment">// to be performed on the page.</span>
    <span class="hljs-built_in">setTimeout</span>(<span class="hljs-function">() =&gt;</span> { selected = <span class="hljs-literal">null</span>; }, <span class="hljs-number">1000</span>);
  };
</code></pre>
<ul>
<li>Listen to this <code>copy</code> event and copy the content of the latest element
clicked to clipboard.</li>
</ul>
<pre class="code" data-lang="javascript"><code>  <span class="hljs-comment">// Intercept copy events</span>
  <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">addEventListener</span>(<span class="hljs-string">&#x27;copy&#x27;</span>, <span class="hljs-function">(<span class="hljs-params">e</span>) =&gt;</span> {
    <span class="hljs-keyword">if</span> (selected === <span class="hljs-literal">null</span>) {
      <span class="hljs-comment">// No element was clicked</span>
      <span class="hljs-keyword">return</span>;
    }

    <span class="hljs-comment">// Copy content of clicked element to clipboard</span>
    e.<span class="hljs-property">clipboardData</span>.<span class="hljs-title function_">setData</span>(
      <span class="hljs-string">&#x27;text/plain&#x27;</span>,
      selected.<span class="hljs-property">innerText</span>,
    );

    <span class="hljs-comment">// We want our data, not data from any selection,</span>
    <span class="hljs-comment">// to be written to the clipboard</span>
    e.<span class="hljs-title function_">preventDefault</span>();
  });

</code></pre>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Packaging Node.js apps the easy way]]></title>
            <link>https://remusao.github.io//posts/packaging-nodejs-apps.html</link>
            <guid>https://remusao.github.io//posts/packaging-nodejs-apps.html</guid>
            <pubDate>Sun, 04 Mar 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><em>TL;DR</em> in this article we demonstrate how to:</p>
<ul>
<li>Create a minified bundle for a Node.js application (using Webpack 4).</li>
<li>Create a self-contained executable (using Nexe).</li>
<li>Create a Docker containers to run the application.</li>
</ul>
<p>…without any configuration file!</p>
<p>Packaging, bundling, deploying Node.js applications can get very tricky
when you are faced with the diversity of tools that can be used. Even
when tools have been chosen, configuration is often non-trivial.</p>
<p>In this post we will see that packaging a Node.js application does not have to
be difficult or confusing. By sticking to a minimal set of tools and using just
the necessary configuration, we will be able to create the following artifacts:
minified bundle, self-contained executable, Docker image.</p>
<p>All the code from this article can be found <a href="https://github.com/remusao/node-app-packaging-template" target="_blank" rel="noopener noreferrer">on GitHub</a>.</p>
<h2>The Application</h2>
<p>Our demonstration application is performing a bandwidth test with
<code>fast.com</code>, using <code>jsdom</code> to avoid having to resort to a headless
browser. The output looks like the following:</p>
<pre class="code" data-lang="js"><code>$ node index.<span class="hljs-property">js</span>
<span class="hljs-title class_">Starting</span> bandwidth test...
~ <span class="hljs-title class_">Speed</span> <span class="hljs-number">0</span>
~ <span class="hljs-title class_">Speed</span> <span class="hljs-number">7.9</span> <span class="hljs-title class_">Mbps</span>
~ <span class="hljs-title class_">Speed</span> <span class="hljs-number">35</span> <span class="hljs-title class_">Mbps</span>
~ <span class="hljs-title class_">Speed</span> <span class="hljs-number">60</span> <span class="hljs-title class_">Mbps</span>
~ <span class="hljs-title class_">Speed</span> <span class="hljs-number">60</span> <span class="hljs-title class_">Mbps</span>
~ <span class="hljs-title class_">Speed</span> <span class="hljs-number">64</span> <span class="hljs-title class_">Mbps</span>
~ <span class="hljs-title class_">Speed</span> <span class="hljs-number">65</span> <span class="hljs-title class_">Mbps</span>
~ <span class="hljs-title class_">Speed</span> <span class="hljs-number">67</span> <span class="hljs-title class_">Mbps</span>

= <span class="hljs-title class_">Speed</span> <span class="hljs-number">66</span> <span class="hljs-title class_">Mbps</span>
</code></pre>
<p>The implementation details are not really relevant, but long story
short; <code>jsdom</code> is loading the URL <code>https://fast.com</code>. We then display the
bandwidth estimation every second until the test is completed.</p>
<h2>Bundling with Webpack</h2>
<p>In the past, I found Webpack to be a bit cumbersome to use, even for
simple use-cases. With version 4, I was delighted to see that they now
provide meaningful defaults and simple options. In our case, it is not
even necessary to have a configuration file, which is great!</p>
<p>Producing a minified bundle is as simple as:</p>
<pre class="code" data-lang="sh"><code>$ webpack index.js --output bundle.min.js --mode production --target node
</code></pre>
<p>That’s it! This command will create a new file: <code>bundle.min.js</code> in the
current directory. Since the <code>--target</code> is Node.js, we can invoke it
directly: <code>node bundle.min.js</code>.</p>
<p>If you want faster builds as well as a watch-mode, you can use the following
variations of the previous command:</p>
<pre class="code" data-lang="sh"><code>$ webpack index.js --output bundle.min.js --mode development --target node
$ webpack index.js --output bundle.min.js --mode development --watch --target node
</code></pre>
<p>Yes, it’s <em>that easy</em>!</p>
<h2>Compiling into a Single Executable</h2>
<p>We could have stopped at our minified bundle, but what if we could get
a self-contained executable packaging our application as well as all
dependencies? And by dependencies, we really mean: Node.js itself and
everything needed for the runtime.</p>
<p>It’s possible thanks to <a href="https://github.com/nexe/nexe" target="_blank" rel="noopener noreferrer">Nexe</a>, which
provides a way to <em>compile</em> your Javascript application along with a
Node.js runtime in a single executable. Neat.</p>
<p>With our already existing bundle <code>bundle.min.js</code>, a single command is needed to
create the executable:</p>
<pre class="code" data-lang="sh"><code>$ nexe bundle.min.js -t alpine-x64-8.9.3 -o app
</code></pre>
<p>What we’re saying here is that our <code>bundle.min.js</code> should be compiled with a
Node.js runtime version 8.9.3 compiled for Alpine Linux x64 (which will be
useful in a moment to create a Docker image). You can also check the <a href="https://github.com/nexe/nexe/releases/tag/v2.0.0-rc.17" target="_blank" rel="noopener noreferrer">exhaustive list of all
possible targets</a></p>
<p>You should now have a new executable in your current folder: <code>app</code>. It
can be started by invoking it like any other command:</p>
<pre class="code" data-lang="sh"><code>$ ./app
</code></pre>
<h2>Building Docker Images</h2>
<p>And now the cherry on the cake! Although you can already easily ship your
self-contained application created using Nexe, why not create a Docker
container out of it? This can be achieved with the following <code>Dockerfile</code>:</p>
<pre class="code" data-lang="sh"><code>FROM alpine:3.7
COPY ./app .
</code></pre>
<p>Building:</p>
<pre class="code" data-lang="sh"><code>$ docker build -t app .
</code></pre>
<p>The resulting image should weigh around 44MB. And here is how to run the
application:</p>
<pre class="code" data-lang="sh"><code>$ docker run app ./app
Starting bandwidth <span class="hljs-built_in">test</span>...
...

= Speed 66 Mbps
</code></pre>
<h2>Final Thoughts</h2>
<p>I will not pretend that the tools described here are able to handle
all use-cases (or that they are the only possible tools; there are a
plethora!), far from it. It is mostly restricted to simple Node.js
applications (with dependencies). But this is probably a nice starting
point for more complex situations, for which you might need to create a
proper configuration file with more bells and whistles.</p>
<p>The ease with which complex tasks can be handled with simple commands and
almost no configuration also shows that the Node.js/Javascript ecosystem is
maturing! Although there is still a lot of fragmentation, it’s really nice to
observe and benefit from all these improvements.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Monitoring your Internet bandwidth with a Raspberry Pi]]></title>
            <link>https://remusao.github.io//posts/raspberrypi-home-network-monitoring.html</link>
            <guid>https://remusao.github.io//posts/raspberrypi-home-network-monitoring.html</guid>
            <pubDate>Sat, 13 Jan 2018 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>After having switched to a new Internet Provider a few months ago, I
was often disappointed by the bandwidth I got (or perceived). It’s not
always easy to know if your connection is the problem, or is it Wi-Fi
connectivity? Or the website you are trying to connect to, etc. So to
get a better idea, I decided to create a simple setup to continuously
monitor my connection, using two independent methods that I will
describe below. Before digging into the details, here is how it currently looks
like:</p>
<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  }
</script>
<iframe
  frameborder="0"
  onload="resizeIframe(this)"
  scrolling="no"
  style="width:100%;height:100%;overflow:hidden;display:block"
  src='../images/bandwidth.html'>
</iframe>
<h2>Setup</h2>
<ul>
<li>RaspberryPi 3.</li>
<li>Latest version of Raspbian.</li>
<li>Direct Ethernet connection to the router.</li>
</ul>
<h2>Measurements</h2>
<p>To get a better idea of the bandwidth (I also measure upload and ping, but that
is not the most important for me, and I’m not sure how robust the measurements
are), I decided to implement two separate methods:</p>
<ol>
<li>The first one is using <a href="https://github.com/sivel/speedtest-cli" target="_blank" rel="noopener noreferrer">speedtest-cli</a>,
a Python project which allows you to measure you connection using servers from
<a href="http://www.speedtest.net/" target="_blank" rel="noopener noreferrer">speedtest.net</a>. It is very simple to use and the
project seems to be pretty mature.</li>
<li>For the second measurement, I wanted to use <a href="https://fast.com/" target="_blank" rel="noopener noreferrer">fast.com</a>, a
service provided by Netflix. I could not find a way to use it easily
from the command line (and I could not find an easy way to get a
driver for Selenium for either Firefox or Chromium), but I managed
to get the measurements using <code>chromium</code> headless mode, which is
available on <code>raspbian</code>, so no extra dependency is required!</li>
</ol>
<p>Here is the current way measurements are performed:</p>
<ol>
<li>The script <code>speed.py</code> is triggered from a <code>watch</code> command every 30 minutes (it
runs in a detached <code>screen</code>).</li>
<li><code>speedtest-cli</code> measurement is triggered.</li>
<li>Then we wait for 15 seconds.</li>
<li><code>fast.com</code> measurement is triggered.</li>
<li>Results are persisted into a local sqlite3 database.</li>
</ol>
<p>In parallel, the <code>app.py</code> runs in another <code>screen</code> to allow visualizing
the results stored in the database. This is not mandatory, but it’s nice
to see the bandwidth over time (the fluctuations reminds me of Bitcoin
pricing…).</p>
<h2>Results</h2>
<p>I have uploaded the scripts I’m using on <a href="https://github.com/remusao/bandwidth-monitor" target="_blank" rel="noopener noreferrer">GitHub</a>
so that it can be re-used or modified.</p>
<p>It should be noted that I now have more measurements and that both
methods (speedtest and <a href="http://fast.com" target="_blank" rel="noopener noreferrer">fast.com</a>) yield similar results. Another
interesting thing is that the bandwidth is usually higher than what I
perceive in normal usage. I have currently two hypotheses:</p>
<ol>
<li>It could be that the provider is playing nice with servers used to measure
bandwidth and artificially increases the bandwidth for those?</li>
<li>My Wi-Fi setup might not be optimal, and I need to investigate if changing
the channel or other settings would improve the situation.</li>
</ol>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[People in Cuba built their own Internet]]></title>
            <link>https://remusao.github.io//posts/cuba-internet.html</link>
            <guid>https://remusao.github.io//posts/cuba-internet.html</guid>
            <pubDate>Sat, 30 Dec 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Today is the last day of 34c3 and this year was amazing. There is a
lot to talk about, a lot of information to digest, and so many new
ideas to experiment with. I plan on writing a review of the talks I
preferred and outline the take aways in a future post, but for now
I’d like to talk about one presentation in particular: “The Internet in Cuba:
A Story of Community Resilience”. You can find the <a href="https://media.ccc.de/v/34c3-8740-the_internet_in_cuba_a_story_of_community_resilience" target="_blank" rel="noopener noreferrer">full video online</a>.
This talk gave me a lot of hope, and I will tell you why, but
first, let’s quickly summarize the situation in Cuba, regarding access
to the Internet (most of the information is from the actual talk).</p>
<p>The only way to access the Internet in Cuba is through hotspots accessible in
each city. This is not ideal for several reasons:</p>
<ol>
<li>There are not so many hotspots (~500 in the country, according to a recent
estimation), which means that you need to go there to get an access and it’s
shared with many people: bandwidth is not great! (maximum 1 MB/s).</li>
<li>It’s expansive, about 1 CUC/hour (~1 euro per hour).</li>
</ol>
<p>There are some alternatives, not sanctioned by the government:</p>
<ol>
<li><em>El Paquete</em>, which is basically an external drive you can buy once a week,
containing data dumped from the internet: TV shows, movies, etc. You can
check this website to know more about what it contains:
<a href="http://paquetedecuba.com" target="_blank" rel="noopener noreferrer">paquetedecuba.com</a> (in <em>http</em> only!)</li>
<li><em>WiFi sharing</em>, where someone shares his connection to a hotspot with other
people and make them pay a smaller fee (e.g.: using Connectify).</li>
<li>Isolated networks.</li>
</ol>
<p>This last point is the amazing one. There are multiple isolated networks such as
Universities (and inter-Universities networks), but the most interesting are the
ones called <em>SNET</em>, which stands for Street Network. In Havana alone, one such
network connects more than 100k people. And it’s not something provided by an
FAI, it has been built from the ground up by people! And multiple other cities
have it too, except they are not connected with each other. And they are not
connected to the Internet either. In fact, this is forbidden, as it would be
illegal.</p>
<p>It’s hard to imagine how it got to that scale, but it has not always
been that way. In fact, it all started as a multitude of much smaller
gaming LAN networks used to play multiplayer games. They then realized
that they could connect with each other, across streets, allowing
neighborhoods to play or communicate.</p>
<p>Nowadays the organization is slightly more complex and is composed of different
levels. For more details you can read directly the <a href="https://conferences.sigcomm.org/imc/2017/papers/imc17-final186.pdf" target="_blank" rel="noopener noreferrer">paper published at
the Internet Measurement Conference</a>, November 2017 in London. But to
put it simply, there are local <em>nodes</em> at the scale of neighborhoods,
connecting up to 200 people. The connection at this scale is made of a
mix of WiFi connections and Ethernet wires. Nodes are then connected to
regional <em>pillars</em>, which in turn are connected to a few other pillars. In
short, <em>SNET</em> is literally an Internet on its own.</p>
<p>And what do people do on this SNET? Well, basically the same thing people do on
the Internet:</p>
<ul>
<li>They have HTTP websites to serve content.</li>
<li>Portals to discover more content.</li>
<li>Gaming (the most popular usage).</li>
<li>Forums (<em>WifiNet</em>, the biggest one, has 56k active users).</li>
<li>Real time communications.</li>
<li>Mirrors of Internet websites such as Wikipedia.</li>
<li>Sub-communities, one of which is mostly working on open-source stuff; they
setup their own instance of Gitlab and built their own search engine for
<em>SNET</em>.</li>
</ul>
<p>Of course there are some pain points such as cost of the equipment, lack of
emails, out-dated software, etc. But overall they are doing a fantastic job
developing and maintaining such an infrastructure on their own.</p>
<p>This seriously gives me hope for the future. Because it shows that it
is possible to build alternative networks or internets at a large scale
without multi-billion international companies. Of course it’s a lot of
work, but it’s possible, with hardware that you can buy online today.</p>
<p>This gives a bit of perspective after net neutrality was killed in the US a few
days ago. The Cuba situation shows that starting from scratch, with no private
support, people were able to invent and build the tools they needed to connect
and communicate with each other.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS NVMe storage optimized instances]]></title>
            <link>https://remusao.github.io//posts/aws-nvme-storage-instance.html</link>
            <guid>https://remusao.github.io//posts/aws-nvme-storage-instance.html</guid>
            <pubDate>Wed, 27 Dec 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I recently had the need for very fast storage on an Amazon AWS machine. I gave a
try to their “NVMe Storage Optimized” instances. I was a bit surprised though
that the drive was not accessible straight away. To make it work, you need to
format and mount it manually.</p>
<p>Formatting the drive found at <code>/dev/nvme0n1</code>:</p>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">sudo</span> mkfs -t ext4 /dev/nvme0n1
</code></pre>
<p>Mounting to <code>/ebs/</code>:</p>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">sudo</span> <span class="hljs-built_in">mkdir</span> /ebs
$ <span class="hljs-built_in">sudo</span> mount -o rw /dev/nvme0n1 /ebs/
$ <span class="hljs-built_in">cd</span> /ebs/
</code></pre>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[simple-sanic—A blazing fast HTTP server using Sanic]]></title>
            <link>https://remusao.github.io//posts/faster-http-server-sanic.html</link>
            <guid>https://remusao.github.io//posts/faster-http-server-sanic.html</guid>
            <pubDate>Sun, 26 Nov 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I recently <a href="/posts/simple-http-server-haskell.html" target="_blank" rel="noopener noreferrer">showed how</a> one can
implement something equivalent to <code>http.server</code> from <code>Python</code> in <code>Haskell</code>. The
solution turned out to be reasonably simple, and <em>surprisingly fast</em>.</p>
<p>Unfortunately, we cannot say that <code>http.server</code> is fast… It works fine
to serve simple files and is very convenient to use, but will quickly
reach its limit when more files need to be served. To be clear, <em>you should not
use</em> <code>sanic</code> or <code>http.server</code> in production to serve static files; <a href="https://www.nginx.com/resources/admin-guide/serving-static-content/" target="_blank" rel="noopener noreferrer">nginx</a>
is a much more robust solution for that. But sometimes you need to work
locally on some static files, and it makes sense to have a reasonably fast and
easy way to achieve that!</p>
<p>I decided to go with <a href="https://github.com/channelcat/sanic" target="_blank" rel="noopener noreferrer">sanic</a>, an “Async
Python 3.5+ web server that’s written to go fast”. It can be configured to
behave like <code>http.server</code>, except much faster…</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">from</span> sanic <span class="hljs-keyword">import</span> Sanic

<span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
    app = Sanic(__name__, log_config=<span class="hljs-literal">None</span>)
    app.static(<span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-string">&#x27;./index.html&#x27;</span>)
    app.static(<span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-string">&#x27;./&#x27;</span>)
    app.run(host=<span class="hljs-string">&quot;0.0.0.0&quot;</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:
    main()
</code></pre>
<p>To make it even easier to use, I bundled this code into a package: <a href="https://github.com/remusao/simple-sanic" target="_blank" rel="noopener noreferrer">simple-sanic</a>,
which is a drop-in replacement for <code>http.server</code>. It allows to serve the content
of the current directory over http with a single command:</p>
<pre class="code" data-lang="sh"><code>$ python -m simple-sanic
</code></pre>
<p>The package is available on <a href="https://pypi.python.org/pypi/simple-sanic" target="_blank" rel="noopener noreferrer">Pypi</a>
and <a href="https://github.com/remusao/simple-sanic" target="_blank" rel="noopener noreferrer">Github</a>. To install:</p>
<pre class="code" data-lang="sh"><code>$ pip install simple-sanic
</code></pre>
<p>You can customize the <code>host</code> and <code>port</code> as well:</p>
<pre class="code" data-lang="sh"><code>$ python -m simple-sanic --<span class="hljs-built_in">help</span>
Usage:
    simple-sanic [options]
    simple-sanic -h | --<span class="hljs-built_in">help</span>

Options:
    -p --port PORT      Specify alternate port [default: 8000]
    -b --<span class="hljs-built_in">bind</span> ADDRESS   Specify alternate <span class="hljs-built_in">bind</span> address [default: 0.0.0.0]
    -h, --<span class="hljs-built_in">help</span>          Show this <span class="hljs-built_in">help</span> message and <span class="hljs-built_in">exit</span>.
</code></pre>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Compiling V8 on Ubuntu 16.04]]></title>
            <link>https://remusao.github.io//posts/compiling-v8-ubuntu-16-04.html</link>
            <guid>https://remusao.github.io//posts/compiling-v8-ubuntu-16-04.html</guid>
            <pubDate>Sat, 25 Nov 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>While preparing another article about fast hashing and how to use it for very
fast fuzzy matching and approximate set membership tests, I found myself in a
situation where I needed more insight about what optimizations <code>V8</code> was
performing under the hood. I wanted to see what <code>d8</code> offers in this regard so I
compiled <code>v8</code> from source. It was relatively easy, but there are a few things to
consider!</p>
<p>This article assumes you’re using
<code>Ubuntu</code>, but it should work as well for other platforms. You can check for any
extra steps from the <a href="https://github.com/v8/v8/wiki/Building-from-Source" target="_blank" rel="noopener noreferrer">official wiki</a>.
During the redaction of this article, I also found this <a href="http://www.mattzeunert.com/2015/08/19/viewing-assembly-code-generated-by-v8.html" target="_blank" rel="noopener noreferrer">other blog post</a>
very useful!</p>
<h1>Building V8 From Source</h1>
<h2>Installing depot_tools</h2>
<p>The <code>V8</code> toolchain requires scripts from <a href="https://www.chromium.org/developers/how-tos/install-depot-tools" target="_blank" rel="noopener noreferrer">depot_tools</a>.</p>
<pre class="code" data-lang="sh"><code>$ git <span class="hljs-built_in">clone</span> https://chromium.googlesource.com/chromium/tools/depot_tools.git
$ <span class="hljs-built_in">export</span> PATH=`<span class="hljs-built_in">pwd</span>`/depot_tools:<span class="hljs-string">&quot;<span class="hljs-variable">$PATH</span>&quot;</span>
</code></pre>
<h2>Compiling V8</h2>
<p>Now that everything is available in <code>PATH</code>, let’s clone and compile <code>V8</code>:</p>
<pre class="code" data-lang="sh"><code>$ fetch v8
</code></pre>
<p>This might take a while. It will create a new <code>v8</code> folder containing the latest
version of the sources. It will also configure everything needed for the build.</p>
<pre class="code" data-lang="sh"><code>$ ./tools/dev/v8gen.py x64.release
$ ninja -C out.gn/x64.release
</code></pre>
<p>Have a tea or a coffee, then come back and check if the compiled <code>v8</code> works as
intended by running the tests:</p>
<pre class="code" data-lang="sh"><code>$ tools/run-tests.py --gn
</code></pre>
<p>If everything went well, this file should exist: <code>./out.gn/x64.release/d8</code>.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The wrong way of benchmarking integer comparison functions]]></title>
            <link>https://remusao.github.io//posts/wrong-way-benchmarking-integer-comparison.html</link>
            <guid>https://remusao.github.io//posts/wrong-way-benchmarking-integer-comparison.html</guid>
            <pubDate>Sat, 25 Nov 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><em>TL;DR</em>: Naive code can sometimes run faster than “clever” code. Compilers are
usually designed to optimize for the most common code, and common code is not
clever. Lessons learned; if you try to write clever code, benchmark it to make
sure there is a benefit.</p>
<p>I recently stumbled upon <a href="https://blogs.msdn.microsoft.com/oldnewthing/20171117-00/?p=97416" target="_blank" rel="noopener noreferrer">an article</a>,
describing how trying to out-smart the compiler can result in bad
performances compared to more naive code. The benchmark is about finding
the most efficient way to write a comparison function between integers,
to be used in conjunction with <code>sort</code> or binary search for example. The
original post being about <code>c++</code>, I was curious to know if the results
would transfer to JavaScript (in particular <code>V8</code>, using <code>Node.js</code>). This
is what this post is about.</p>
<p>Let see the contenders:</p>
<ul>
<li><em>Naive</em></li>
</ul>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">compare1</span>(<span class="hljs-params">a, b</span>) {
    <span class="hljs-keyword">if</span> (a &lt; b) <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;
    <span class="hljs-keyword">if</span> (a &gt; b) <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<ul>
<li><em>Clever</em></li>
</ul>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">compare2</span>(<span class="hljs-params">a, b</span>) {
    <span class="hljs-keyword">return</span> a - b;
}
</code></pre>
<h2>Benchmarks</h2>
<p>The original article has a very good point saying that to benchmark this
code realistically, you need a real use-case. Just sorting the array and
summing the numbers does not make any sense, no one would do it. But if
instead you perform a binary search on the sorted array, it gets closer
to something one might do in a real code-base.</p>
<p>I took the liberty of converting the original <code>C++</code> implementation of the binary
search into JavaScript, to stick closely to the article:</p>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">binarySearch</span>(<span class="hljs-params">array, first, last, key, compare</span>) {
  <span class="hljs-keyword">var</span> length = last - first;
  <span class="hljs-keyword">while</span> (length &gt; <span class="hljs-number">0</span>) {
    <span class="hljs-keyword">var</span> step = (length / <span class="hljs-number">2</span>) | <span class="hljs-number">0</span>;
    <span class="hljs-keyword">var</span> middle = first + step;
    <span class="hljs-keyword">var</span> result = <span class="hljs-title function_">compare</span>(array[middle], key);
    <span class="hljs-keyword">if</span> (result &lt; <span class="hljs-number">0</span>) {
      first = middle + <span class="hljs-number">1</span>;
      length -= step + <span class="hljs-number">1</span>;
    } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (result === <span class="hljs-number">0</span>) {
      <span class="hljs-keyword">return</span> middle;
    } <span class="hljs-keyword">else</span> {
      length = step;
    }
  }

  <span class="hljs-keyword">return</span> last;
}
</code></pre>
<p>Using the great <a href="https://www.npmjs.com/package/benchmark" target="_blank" rel="noopener noreferrer">benchmark</a>
library, let’s evaluate the performance of each compare function:</p>
<ul>
<li><em>Setup</em></li>
</ul>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">compare</span>) {
  <span class="hljs-comment">// Create a sorted array</span>
  <span class="hljs-keyword">var</span> array = [];
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">8192</span>; ++i) {
    array.<span class="hljs-title function_">push</span>(i * <span class="hljs-number">2</span>);
  }

  <span class="hljs-keyword">var</span> found = <span class="hljs-number">0</span>;

  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">var</span> j = -<span class="hljs-number">1</span>; j &lt; <span class="hljs-number">16383</span>; ++j) {
    <span class="hljs-keyword">var</span> index = <span class="hljs-title function_">binarySearch</span>(
      array,              <span class="hljs-comment">// sorted array</span>
      <span class="hljs-number">0</span>,                  <span class="hljs-comment">// start index</span>
      array.<span class="hljs-property">length</span> - <span class="hljs-number">1</span>,   <span class="hljs-comment">// end index</span>
      j,                  <span class="hljs-comment">// element we are looking for</span>
      compare);           <span class="hljs-comment">// comparison function</span>

    <span class="hljs-keyword">if</span> (index !== -<span class="hljs-number">1</span> &amp;&amp; array[index] === j) {
      found += <span class="hljs-number">1</span>;
    }
  }

  <span class="hljs-keyword">if</span> (found !== <span class="hljs-number">8191</span>) {
    <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">error</span>(<span class="hljs-string">&#x27;Found bug&#x27;</span>, found);
  }
}
</code></pre>
<ul>
<li><em>Benchmark</em></li>
</ul>
<pre class="code" data-lang="javascript"><code><span class="hljs-keyword">function</span> <span class="hljs-title function_">bench</span>(<span class="hljs-params"></span>) {
  <span class="hljs-keyword">var</span> <span class="hljs-title class_">Benchmark</span> = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;benchmark&#x27;</span>);
  <span class="hljs-keyword">var</span> suite = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Benchmark</span>.<span class="hljs-title class_">Suite</span>();

  suite
    .<span class="hljs-title function_">add</span>(<span class="hljs-string">&#x27;compare1&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) {
      <span class="hljs-title function_">run</span>(compare1);
    })
    .<span class="hljs-title function_">add</span>(<span class="hljs-string">&#x27;compare2&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) {
      <span class="hljs-title function_">run</span>(compare2);
    })
    .<span class="hljs-title function_">on</span>(<span class="hljs-string">&#x27;cycle&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params">event</span>) {
      <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-title class_">String</span>(event.<span class="hljs-property">target</span>));
    })
    .<span class="hljs-title function_">on</span>(<span class="hljs-string">&#x27;complete&#x27;</span>, <span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) {
      <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">&#x27;Fastest is &#x27;</span> + <span class="hljs-variable language_">this</span>.<span class="hljs-title function_">filter</span>(<span class="hljs-string">&#x27;fastest&#x27;</span>).<span class="hljs-title function_">map</span>(<span class="hljs-string">&#x27;name&#x27;</span>));
    })
    .<span class="hljs-title function_">run</span>({});
}

<span class="hljs-title function_">bench</span>();
</code></pre>
<p>And…</p>
<blockquote>
<pre class="code" data-lang="sh"><code>compare1 x 421 ops/sec ±0.51% (91 runs sampled)
compare2 x 394 ops/sec ±0.39% (89 runs sampled)
</code></pre>
</blockquote>
<p>It happens that the naive <code>compare1</code> is a bit faster than <code>compare2</code>.
It’s not day and night, but the <em>naive</em>, more readable code is more
efficient on V8 than the clever one.</p>
<p>The complete version of the code used in this <a href="/snippets/compare-benchmark.js" target="_blank" rel="noopener noreferrer">available
there</a></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Generating Ad-Blocker filters from whotracks.me data]]></title>
            <link>https://remusao.github.io//posts/whotracksme-generate-adb-filters.html</link>
            <guid>https://remusao.github.io//posts/whotracksme-generate-adb-filters.html</guid>
            <pubDate>Wed, 22 Nov 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><strong>Disclaimer</strong>: This article has originally been written for, and published on
<a href="https://whotracks.me/blog/generating_adblocker_filters.html" target="_blank" rel="noopener noreferrer">whotracks.me</a>.</p>
<p><em>TL;DR</em>  In this post we see how to:</p>
<ol>
<li>Load the data from <a href="https://github.com/cliqz-oss/whotracks.me" target="_blank" rel="noopener noreferrer">whotracks.me</a> to get access to trackers’ information</li>
<li>Create a mapping from tracking categories to list of domains</li>
<li>Filter each domain based on the amount of tracking of each <em>app</em></li>
<li>Generate a filter list for each category</li>
</ol>
<p>The full source code used in this article can be found on the <a href="https://github.com/cliqz-oss/whotracks.me/blob/master/contrib/generating_adblocker_filters.py" target="_blank" rel="noopener noreferrer">Github repository</a>.</p>
<p>Most popular content blockers are using filter lists to decide what requests
leaving the browser should be blocked. In this regard, filter lists act as a
privacy <em>ground truth</em>: deciding what is safe, and what is not safe for users.
It means that your privacy protection is only as good as the filters your are
using. The community is doing an amazing job, but still there can be gaps in
your protection; one such situation is when a new tracker appears.</p>
<p>With the right data, updated regularly, we believe it is possible to
build powerful tools to help increase users’ privacy. Knowing more about
trackers, in real time, allows to provide better anti-tracking but can also
<em>help</em> the tedious process of curating the filter lists.</p>
<p>In this post we’d like to demonstrate how we can make use of the
open-sourced <a href="https://whotracks.me" target="_blank" rel="noopener noreferrer">whotracks.me</a> data to automatically
generate <em>up-to-date</em>, <em>per-category</em>, filter lists supported by the
most popular ad-blockers out there. Leveraging this data can improve
user experience and make maintaining the lists easier.</p>
<p>In the future, we can imagine generating per-country lists as well,
in the spirit of the different <a href="https://easylist.to/" target="_blank" rel="noopener noreferrer">easylists</a> already
in existence:</p>
<ul>
<li><code>DEU: Pornvertising blocking Germany</code></li>
<li><code>DEU: Site_Analytics blocking Germany</code></li>
<li>…</li>
<li><code>FR: Site_Analytics blocking France</code></li>
</ul>
<p>They could also be dispatched in the already existing lists such as
<code>advertising</code>, <code>privacy</code>, etc. Another option could be to use this as a
tool to assist maintainers to keep an eye on the ecosystem; allowing to
learn about new trackers in real time.</p>
<p>Let’s get started!</p>
<h2>Loading the data</h2>
<p>The first step is to install the <code>whotracksme</code> package, available on <a href="https://pypi.python.org/pypi/whotracksme" target="_blank" rel="noopener noreferrer">PyPI</a>
and <a href="https://github.com/cliqz-oss/whotracks.me" target="_blank" rel="noopener noreferrer">Github</a>. You can get started by
installing <code>whotracksme</code> with <code>pip</code>:</p>
<pre class="code" data-lang="sh"><code>$ pip install whotracksme
</code></pre>
<p>We start by loading the tracker-related data from <a href="https://github.com/cliqz-oss/whotracks.me/blob/master/whotracksme/data/assets/trackerdb.sql" target="_blank" rel="noopener noreferrer">trackerdb.sql</a>, using the
helper function found in the <code>whotracksme.data</code> module:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict
<span class="hljs-keyword">from</span> whotracksme.data <span class="hljs-keyword">import</span> load_tracker_db

<span class="hljs-comment"># Categories to tracker domains</span>
tracker_domains_per_category = defaultdict(<span class="hljs-built_in">list</span>)

<span class="hljs-comment"># Keep track of normalized &quot;app&quot; name for each tracker domain. A given &quot;app&quot;</span>
<span class="hljs-comment"># such as &quot;doubleclick&quot; can use several domains: 2mdn.net, doubleclick.net, etc.</span>
tracker_domains_to_app = {}

<span class="hljs-comment"># Load trackers and group them by category</span>
sql_query = <span class="hljs-string">&quot;&quot;&quot;
  SELECT categories.name, tracker, domain FROM tracker_domains
  INNER JOIN trackers ON trackers.id = tracker_domains.tracker
  INNER JOIN categories ON categories.id = trackers.category_id;
&quot;&quot;&quot;</span>
<span class="hljs-keyword">with</span> load_tracker_db() <span class="hljs-keyword">as</span> connection:
    <span class="hljs-keyword">for</span> (category, tracker, domain) <span class="hljs-keyword">in</span> connection.execute(sql_query):
        tracker_domains_per_category[category].append(domain)
        tracker_domains_to_app[domain] = tracker
</code></pre>
<p>Here is a sample of what we get in <code>tracker_domains_per_category</code>. Note that if
you run the same script, you might get slightly different results as the
data is being constantly updated:</p>
<blockquote>
<pre class="code" data-lang="python"><code>defaultdict(<span class="hljs-built_in">list</span>, {
  <span class="hljs-string">&#x27;advertising&#x27;</span>: [
    <span class="hljs-string">&#x27;doubleclick.net&#x27;</span>,
    ...
  ],
  <span class="hljs-string">&#x27;audio_video_player&#x27;</span>: [
    <span class="hljs-string">&#x27;soundcloud.com&#x27;</span>
    ...
  ],
  <span class="hljs-string">&#x27;cdn&#x27;</span>: [
    <span class="hljs-string">&#x27;googleapis.com&#x27;</span>,
    ...
  ],
  <span class="hljs-string">&#x27;comments&#x27;</span>: [
    <span class="hljs-string">&#x27;disqus.com&#x27;</span>,
    ...
  ],
  <span class="hljs-string">&#x27;customer_interaction&#x27;</span>: [
    <span class="hljs-string">&#x27;zendesk.com&#x27;</span>,
    ...
  ],
  <span class="hljs-string">&#x27;essential&#x27;</span>: [
    <span class="hljs-string">&#x27;googletagmanager.com&#x27;</span>,
    ...
  ],
  <span class="hljs-string">&#x27;extensions&#x27;</span>: [
    <span class="hljs-string">&#x27;kaspersky-labs.com&#x27;</span>,
    ...
  ],
  <span class="hljs-string">&#x27;hosting&#x27;</span>: [
    <span class="hljs-string">&#x27;amazonaws.com&#x27;</span>,
    ...
  ],
  <span class="hljs-string">&#x27;misc&#x27;</span>: [
    <span class="hljs-string">&#x27;linkedin.com&#x27;</span>,
    ...
  ],
  <span class="hljs-string">&#x27;pornvertising&#x27;</span>: [
    <span class="hljs-string">&#x27;pornhub.com&#x27;</span>,
    ...
  ],
  <span class="hljs-string">&#x27;site_analytics&#x27;</span>: [
    <span class="hljs-string">&#x27;google-analytics.com&#x27;</span>,
    ...
  ],
  <span class="hljs-string">&#x27;social_media&#x27;</span>: [
    <span class="hljs-string">&#x27;twitter.com&#x27;</span>,
    ...
  ]
]})
</code></pre>
</blockquote>
<h2>Filtering based on tracking behavior</h2>
<p>It is tempting to generate filters for each domain loaded so far, but it
would be very aggressive. Indeed, some domains identified as potential
trackers might in fact not send <a href="https://whotracks.me/blog/what_is_a_tracker.html" target="_blank" rel="noopener noreferrer">unsafe identifiers</a> (or not a lot). For example
<a href="https://whotracks.me/trackers/createjs.html" target="_blank" rel="noopener noreferrer">createjs</a> is not using any
<em>fingerprinting</em> and does not seem to be doing tracking via <em>cookies</em>,
hence, it should not be blocked systematically.</p>
<p>Fortunately, we can make use of the data from <a href="https://github.com/cliqz-oss/whotracks.me/blob/master/whotracksme/data/assets/apps.json" target="_blank" rel="noopener noreferrer">apps.json</a> to learn
more about each tracker. An <em>app</em> is an entity which can contain several
domains (e.g.: <em>doubleclick</em> is an <em>app</em> for which we identified three
domains: <code>2mdn.net</code>, <code>invitemedia.com</code> and <code>doubleclick.net</code>). We also
provide information about companies to which each app belongs, but we
will leave the exploration of this data for another article.</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> json
<span class="hljs-keyword">from</span> whotracksme.data <span class="hljs-keyword">import</span> load_apps

apps = load_apps()
</code></pre>
<p><code>apps</code> is a dictionary with keys being <em>app ids</em> (e.g.: <code>google_analytics</code>)
and values containing all we know about each <em>app</em>. Let’s take an example:</p>
<pre class="code" data-lang="json"><code>apps<span class="hljs-punctuation">[</span><span class="hljs-string">&quot;google_analytics&quot;</span><span class="hljs-punctuation">]</span>

<span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;overview&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
        <span class="hljs-attr">&quot;bad_qs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.4377430033329568</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;content_length&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">14771.492718357234</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;cookies&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.0015869678941083753</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;https&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7507222054912428</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;google_analytics&quot;</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;reach&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.44292899275150094</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;requests&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3.834100333790446</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;requests_tracking&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1.202157901660253</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;site_reach&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.616005569531587</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;tracked&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.4383474801843971</span>
    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;history&quot;</span><span class="hljs-punctuation">:</span> ...<span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;rank&quot;</span><span class="hljs-punctuation">:</span> ...<span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;sites&quot;</span><span class="hljs-punctuation">:</span> ...
<span class="hljs-punctuation">}</span>
</code></pre>
<p>That’s a lot of data, and we plan to release a more complete
documentation about what all this is about soon. For now let’s just say
that everything is already made accessible on the website, in form of
nice graphs and aggregations!</p>
<p>For our use-case, we will only consider the field: <code>tracked</code>. It
represents the proportion of page loads including <em>app</em>, identified as
performing some form of tracking (using either identifying <em>cookies</em>
or <em>fingerprinting</em>). In the case of <code>google_analytics</code>, it means that
out of 100 page loads where <code>google_analytics</code> was present, tracking
occurred 44 times.</p>
<p>Before generating the filter list, let’s keep only <em>apps</em> tracking
users more than <code>10%</code> of the time. Please note that finding the right
threshold would require some finer analysis, and could depend on the
application.</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_domains</span>(<span class="hljs-params">domains</span>):
    <span class="hljs-keyword">for</span> domain <span class="hljs-keyword">in</span> domains:
        app_name = tracker_domains_to_app[domain]
        <span class="hljs-keyword">if</span> app_name <span class="hljs-keyword">in</span> apps:
            app = apps[tracker_domains_to_app[domain]]
            tracked = app[<span class="hljs-string">&#x27;overview&#x27;</span>][<span class="hljs-string">&#x27;tracked&#x27;</span>]
            <span class="hljs-keyword">if</span> tracked &gt;= <span class="hljs-number">0.1</span>:
                <span class="hljs-keyword">yield</span> domain
</code></pre>
<p>We need to check if the <em>app</em> exists first because we currently only have the
top 500 hosted on Github. We will host more in the future.</p>
<h2>Generating the lists</h2>
<p>We now proceed to generate the filter lists from these domains. They can take
two forms:</p>
<ul>
<li>ADB compatible syntax: <code>||{domain}$third-party</code></li>
<li>Hostname syntax: <code>127.0.0.1 {domain}</code></li>
</ul>
<p>Note that the second option will probably be too aggressive in a lot of
cases, as it will also block the domain even if they are first-party (e.g.,
<code>google.com</code> might get blocked by these rules).</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_adb_filters</span>(<span class="hljs-params">domains</span>):
    <span class="hljs-string">&quot;&quot;&quot;Given a list of domains, generate filters using the
    ADB syntax to be used in an adblocker&quot;&quot;&quot;</span>
    <span class="hljs-keyword">for</span> domain <span class="hljs-keyword">in</span> domains:
        <span class="hljs-keyword">yield</span> <span class="hljs-string">f&quot;||<span class="hljs-subst">{domain}</span>$third-party&quot;</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_hostname_filters</span>(<span class="hljs-params">domains</span>):
    <span class="hljs-string">&quot;&quot;&quot;Given a list of domains, generate filters using
    the hostname syntax&quot;&quot;&quot;</span>
    <span class="hljs-keyword">for</span> domain <span class="hljs-keyword">in</span> domains:
        <span class="hljs-keyword">yield</span> <span class="hljs-string">f&quot;127.0.0.1 <span class="hljs-subst">{domain}</span>&quot;</span>

<span class="hljs-comment"># Generate filters with *ADB* syntax</span>
adb_filters = {
    category: <span class="hljs-string">&#x27;\n&#x27;</span>.join(generate_adb_filters(filter_domains(domains)))
    <span class="hljs-keyword">for</span> (category, domains) <span class="hljs-keyword">in</span> tracker_domains_per_category.items()
}

<span class="hljs-comment"># Generate filters with *hostname* syntax</span>
hostname_filters = {
    category: <span class="hljs-string">&#x27;\n&#x27;</span>.join(generate_hostname_filters(filter_domains(domains)))
    <span class="hljs-keyword">for</span> (category, domains) <span class="hljs-keyword">in</span> tracker_domains_per_category.items()
}
</code></pre>
<p>Each dictionary now contains a valid adblocking list for each category:</p>
<pre class="code" data-lang="python"><code>hostname_filters.keys()
</code></pre>
<blockquote>
<pre class="code" data-lang="python"><code>dict_keys([
  <span class="hljs-string">&#x27;advertising&#x27;</span>,
  <span class="hljs-string">&#x27;audio_video_player&#x27;</span>,
  <span class="hljs-string">&#x27;cdn&#x27;</span>,
  <span class="hljs-string">&#x27;comments&#x27;</span>,
  <span class="hljs-string">&#x27;customer_interaction&#x27;</span>,
  <span class="hljs-string">&#x27;essential&#x27;</span>,
  <span class="hljs-string">&#x27;extensions&#x27;</span>,
  <span class="hljs-string">&#x27;hosting&#x27;</span>,
  <span class="hljs-string">&#x27;misc&#x27;</span>,
  <span class="hljs-string">&#x27;pornvertising&#x27;</span>,
  <span class="hljs-string">&#x27;site_analytics&#x27;</span>,
  <span class="hljs-string">&#x27;social_media&#x27;</span>,
  <span class="hljs-string">&#x27;unknown&#x27;</span>
])
</code></pre>
</blockquote>
<p>And here is what we get for example in the <code>advertising</code> category:</p>
<pre class="code" data-lang="python"><code><span class="hljs-built_in">print</span>(adb_filters[<span class="hljs-string">&#x27;advertising&#x27;</span>])
</code></pre>
<blockquote>
<pre class="code" data-lang="sh"><code>||doubleclick.com<span class="hljs-variable">$third</span>-party
||criteo.com<span class="hljs-variable">$third</span>-party
...
</code></pre>
</blockquote>
<p>And the same domains but as <code>hostname</code> filters:</p>
<pre class="code" data-lang="python"><code><span class="hljs-built_in">print</span>(hostname_filters[<span class="hljs-string">&#x27;advertising&#x27;</span>])
</code></pre>
<blockquote>
<pre class="code" data-lang="sh"><code>127.0.0.1 doubleclick.com
127.0.0.1 criteo.com
...
</code></pre>
</blockquote>
<p>To put it in a nutshell, here is what we just did:</p>
<ol>
<li>Load the data from <a href="https://github.com/cliqz-oss/whotracks.me" target="_blank" rel="noopener noreferrer">whotracks.me</a> to get access to trackers’ information</li>
<li>Create a mapping from tracking categories to list of domains</li>
<li>Filter each domain based on the amount of tracking of each <em>app</em></li>
<li>Generate a filter list for each category</li>
</ol>
<p>There is so much more we can do with this database. At the moment the
API to load the data is pretty-low level, but it will be improved over
time.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fully static comments]]></title>
            <link>https://remusao.github.io//posts/static-comments.html</link>
            <guid>https://remusao.github.io//posts/static-comments.html</guid>
            <pubDate>Sun, 19 Nov 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I’d like to give a quick update about the comments
on this blog. I already mentioned in a <a href="/posts/state-of-static-blogs.html" target="_blank" rel="noopener noreferrer">previous post</a>
that I wanted to experiment with fully static comments for my blog. By
fully static I mean that comments are directly integrated in the HTML of
each page, at generation time. It requires to generate pages with new
comments regularly but I think it’s a good trade-off.</p>
<p>I’d like to give an overview of how it works, and how it looks in practice.</p>
<h2>How does it Work?</h2>
<ol>
<li>Comments will be posted and hosted on <em>Github Issues</em>.</li>
<li>Each <code>post</code>’s original <code>Markdown</code> document has an optional <code>issue</code>
attribute in its metadata; when it is specified, the static blog
generator will fetch the comments of the specified issue every time we
build the site.</li>
<li>Issues are directly integrated in the HTML of the page (at the bottom) and
are collapsed by default.</li>
</ol>
<h2>Pros</h2>
<p>I see several advantages with this system:</p>
<ol>
<li>It’s fast because it’s part of the page’s HTML.</li>
<li>The look and feel of the page is consistent.</li>
<li>It does not require any third-party Javascript to work (so no tracking…).</li>
<li>It leverages Github, which is already used to host the blog anyway, so why
not use the <code>issues</code> as well.</li>
</ol>
<h2>Cons</h2>
<p>Obviously it’s not perfect because:</p>
<ol>
<li>People need a Github account to post comments: but I expect a lot of people
do, and if they don’t, there are a lot of ways to discuss blog posts on the
Internet: Reddit, HackerNews, Twitter; and they all have their sharing button
at the bottom of the page!</li>
<li>It takes a bit of time to refresh the comments (currently <code>Travis</code> will
deploy the posts at least once a day + every time I do a commit), but they
can always be seen in real time on the <code>issue</code> itself.</li>
<li>It might not scale very well with a lot of comments, but I will be happy to
figure out a solution for this problem when it happens with this blog!</li>
</ol>
<h2>How it Looks</h2>
<p>This post is already equipped with the static comments. I created a few of them
to demonstrate the look and feel. You can expend the comments by
clicking the first link on the left <code>N comments</code>, or post a new one by clicking
on <code>Leave a comment on Github</code> (you will be redirected on the correct <code>issue</code>).</p>
<p>Feel free to add more! I’d love to get some feedback on this.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A simple HTTP server in Haskell]]></title>
            <link>https://remusao.github.io//posts/simple-http-server-haskell.html</link>
            <guid>https://remusao.github.io//posts/simple-http-server-haskell.html</guid>
            <pubDate>Sun, 12 Nov 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I was recently looking for a way to create a very simple <code>HTTP</code> Server to serve
static files in the current directory, in Haskell. The way we would do it in
Python:</p>
<pre class="code" data-lang="sh"><code>$ python -m SimpleHTTPServer 8000
</code></pre>
<p>That’s dead simple, exactly what I needed. It took me some time, but I finally
found a very simple (and efficient) solution:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-meta">#! /usr/bin/env stack</span>
<span class="hljs-comment">{-
  stack --resolver lts-9.12
        --install-ghc runghc
        --package wai-app-static
-}</span>
<span class="hljs-keyword">import</span> Network.Wai.Handler.Warp (<span class="hljs-title">run</span>)
<span class="hljs-keyword">import</span> Network.Wai.Application.Static

<span class="hljs-title">main</span> :: <span class="hljs-type">IO</span> ()
<span class="hljs-title">main</span> = run <span class="hljs-number">8000</span> (staticApp (defaultFileServerSettings <span class="hljs-string">&quot;.&quot;</span>))
</code></pre>
<p>That’s it! And it’s using the super efficient <a href="http://www.aosabook.org/en/posa/warp.html" target="_blank" rel="noopener noreferrer">warp</a>
HTTP server.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Getting the most out of SQLite3 with Python]]></title>
            <link>https://remusao.github.io//posts/few-tips-sqlite-perf.html</link>
            <guid>https://remusao.github.io//posts/few-tips-sqlite-perf.html</guid>
            <pubDate>Sat, 21 Oct 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I’ve recently made heavy use of <code>sqlite3</code> for a project involving a lot of data
and processing. My first attempt involved no database at all, and all data would
be kept in memory and queries would consist in a mix of dictionary lookups,
iteration, conditions, etc. This was nice, but there is only so much you can fit
in memory, and re-generating/loading the data from disk to memory became a tedious
and time consuming process.</p>
<p>I decided to give <code>sqlite3</code> a try. This allowed an increase in the amount of
data that could be processed, and reduced the loading time of the application to
nothing, since only opening a connection to the database was needed. Moreover,
I could replace a lot of Python logic by SQL queries.</p>
<p>I’d like to share a few learnings and findings about this experience.</p>
<p><strong>TL;DR</strong>:</p>
<ol>
<li>Use bulk operations (<em>a.k.a.</em> <code>executemany</code>).</li>
<li>You don’t need <code>cursors</code> (most of the time).</li>
<li>Cursors can be iterated upon.</li>
<li>Use context managers.</li>
<li>Use pragmas (when it makes sense).</li>
<li>Postpone index creation.</li>
<li>Use placeholders to interpolate python values.</li>
</ol>
<h2>Use Bulk Operations</h2>
<p>If you need to insert a lot of rows at once in your database, you really
should not use <code>execute</code>. The <code>sqlite3</code> module provides a way to bulk
insertions: <code>executemany</code>.</p>
<p>Instead of doing something like:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> iter_data():
    connection.execute(<span class="hljs-string">&#x27;INSERT INTO my_table VALUES (?)&#x27;</span>, row)
</code></pre>
<p>You can leverage the fact that <code>executemany</code> accepts as argument a generator of
<code>tuples</code>:</p>
<pre class="code" data-lang="python"><code>connection.executemany(
    <span class="hljs-string">&#x27;INSERT INTO my_table VALUE (?)&#x27;</span>,
    iter_data()
)
</code></pre>
<p>This is not only more concise, it’s also much more efficient. In fact, <code>sqlite3</code>
implements <code>execute</code> using <code>executemany</code> behind the scene, but the former
inserts a single row instead of many.</p>
<p>I wrote a small benchmark which consists in inserting a million rows into an
empty table (the database lives in memory):</p>
<ul>
<li><code>executemany</code>: <strong>1.6</strong> seconds</li>
<li><code>execute</code>: 2.7 seconds</li>
</ul>
<h2>You Don’t Need Cursors</h2>
<p>…<em>most of the time</em>.</p>
<p>One thing I often found confusing at the beginning, was <code>cursor</code> management.
Examples online and in the documentation often look like:</p>
<pre class="code" data-lang="python"><code>connection = sqlite3.connect(<span class="hljs-string">&#x27;:memory:&#x27;</span>)
cursor = connection.cursor()
<span class="hljs-comment"># Do something with cursor</span>
</code></pre>
<p>But most of the time you don’t need a cursor at all, and you can directly use
the <code>connection</code> object (it is mentioned at the
<a href="https://docs.python.org/3.6/library/sqlite3.html#using-shortcut-methods" target="_blank" rel="noopener noreferrer">end of the documentation</a>).</p>
<p>Operations such as <code>execute</code> and <code>executemany</code> can be called directly on the
connection and <em>will return a cursor</em>. Here is an example to demonstrate that:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> sqlite3

connection = sqlite3.connect(<span class="hljs-string">&#x27;:memory:&#x27;</span>)

<span class="hljs-comment"># Create a table</span>
connection.execute(<span class="hljs-string">&#x27;CREATE TABLE events(ts, msg)&#x27;</span>)

<span class="hljs-comment"># Insert values</span>
connection.executemany(
    <span class="hljs-string">&#x27;INSERT INTO events VALUES (?,?)&#x27;</span>,
    [
        (<span class="hljs-number">1</span>, <span class="hljs-string">&#x27;foo&#x27;</span>),
        (<span class="hljs-number">2</span>, <span class="hljs-string">&#x27;bar&#x27;</span>),
        (<span class="hljs-number">3</span>, <span class="hljs-string">&#x27;baz&#x27;</span>)
    ]
)

<span class="hljs-comment"># Print inserted rows</span>
<span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> connection.execute(<span class="hljs-string">&#x27;SELECT * FROM events&#x27;</span>):
    <span class="hljs-built_in">print</span>(row)
</code></pre>
<h2>Cursors Can Be Iterated Upon</h2>
<p>You might often see examples making use of <code>fetchone</code> or <code>fetchall</code> on
the result of a <code>SELECT</code> query. But I find that the most natural way to
consume the results is to actually iterate on the cursor directly:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> connection.execute(<span class="hljs-string">&#x27;SELECT * FROM events&#x27;</span>):
    <span class="hljs-built_in">print</span>(row)
</code></pre>
<p>This way, you can stop as soon as you got enough results and not waste
resources. Of course, if you know beforehand how many results you want, you can
use the <code>LIMIT</code> SQL statement instead, but Python generators are very handy and
allow you to decouple data generation from data consumption.</p>
<h2>Use Context Managers</h2>
<p>Shit happens, even in the middle of a SQL transaction. To avoid having
to deal manually with <code>rollback</code> or <code>commit</code>, you can simply use the
<code>connection</code> object as a context manager. In the following example we
create a table, and insert <em>by mistake</em> duplicated values:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> sqlite3
connection = sqlite3.connect(<span class="hljs-string">&#x27;:memory:&#x27;</span>)

<span class="hljs-keyword">with</span> connection:
    connection.execute(
        <span class="hljs-string">&#x27;CREATE TABLE events(ts, msg, PRIMARY KEY(ts, msg))&#x27;</span>)

<span class="hljs-keyword">try</span>:
    <span class="hljs-keyword">with</span> connection:
        connection.executemany(<span class="hljs-string">&#x27;INSERT INTO events VALUES (?, ?)&#x27;</span>, [
            (<span class="hljs-number">1</span>, <span class="hljs-string">&#x27;foo&#x27;</span>),
            (<span class="hljs-number">2</span>, <span class="hljs-string">&#x27;bar&#x27;</span>),
            (<span class="hljs-number">3</span>, <span class="hljs-string">&#x27;baz&#x27;</span>),
            (<span class="hljs-number">1</span>, <span class="hljs-string">&#x27;foo&#x27;</span>),
        ])
<span class="hljs-keyword">except</span> (sqlite3.OperationalError, sqlite3.IntegrityError) <span class="hljs-keyword">as</span> e:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Could not complete operation:&#x27;</span>, e)

<span class="hljs-comment"># No row was inserted because transaction failed</span>
<span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> connection.execute(<span class="hljs-string">&#x27;SELECT * FROM events&#x27;</span>):
    <span class="hljs-built_in">print</span>(row)

connection.close()
</code></pre>
<h2>Use Pragmas</h2>
<p>…<em>when it makes sense</em></p>
<p>There are a few <em>pragmas</em> you can use to tweak the behavior of <code>sqlite3</code> in your
program. In particular, one that could improve the performance is <code>synchronous</code>:</p>
<pre class="code" data-lang="python"><code>connection.execute(<span class="hljs-string">&#x27;PRAGMA synchronous = OFF&#x27;</span>)
</code></pre>
<p>You should be aware though that this can <em>be dangerous</em>. If the application
crashes unexpectedly in the middle of a transaction, the database will probably
be left in an inconsistent state. So use with care! But if you want to insert a
lot of rows faster, that can be an option. A safer option is to use the
<a href="https://www.sqlite.org/draft/wal.html" target="_blank" rel="noopener noreferrer"><code>WAL</code></a> option instead of disabling
<code>synchronous</code> completely.</p>
<pre class="code" data-lang="python"><code>connection.execute(<span class="hljs-string">&#x27;PRAGMA journal_mode = WAL&#x27;</span>)
</code></pre>
<h2>Postpone Index Creation</h2>
<p>Let’s say you need a few indices on your database, and you also need to
insert a lot of rows while creating them. Postponing the creation of the indices
to after all rows have been inserted could result in a substantial performance
improvement.</p>
<h2>Use Placeholders to Interpolate Python Values</h2>
<p>It is tempting to use Python string operations to include values into
queries. <em>Do not</em>! This is highly insecure, and <code>sqlite3</code> gives you a
better way to do it:</p>
<pre class="code" data-lang="python"><code><span class="hljs-comment"># Do not do this!</span>
my_timestamp = <span class="hljs-number">1</span>
c.execute(<span class="hljs-string">&quot;SELECT * FROM events WHERE ts = &#x27;%s&#x27;&quot;</span> % my_timestamp)

<span class="hljs-comment"># Do this instead</span>
my_timestamp = (<span class="hljs-number">1</span>,)
c.execute(<span class="hljs-string">&#x27;SELECT * FROM events WHERE ts = ?&#x27;</span>, my_timestamp)
</code></pre>
<p>Also, string interpolation using Python <code>%s</code> (or format, or formatted string
literals) does not go well with <code>executemany</code>. So there is really no point in
trying!</p>
<hr>
<p>Keep in mind though that these tips might or might not give you a benefit,
depending on your specific use-case. You should always try for yourself and
decide if it’s worth it or not.</p>
<p><em>Edit 28-12-2017</em>: Thanks for all the great feedback from <a href="https://www.reddit.com/r/Python/comments/781q18/getting_the_most_out_of_sqlite3_with_python/" target="_blank" rel="noopener noreferrer">Reddit</a>
and <a href="https://news.ycombinator.com/item?id=15525715" target="_blank" rel="noopener noreferrer">Hacker News</a>.
I took the liberty to amend the original article with a few of the suggestions.</p>
<p>There are a few topics that were not mentioned in this article but are
definitely worth reading:</p>
<ul>
<li><a href="https://docs.python.org/3.6/library/sqlite3.html#controlling-transactions" target="_blank" rel="noopener noreferrer">Using transactions</a>
can dramatically improve the speed of your code if you need to run several
SQL statements in a row (it should not be needed if you use <code>executemany</code>).</li>
<li>If you don’t need to re-use your database across sessions, you can use an
<a href="https://sqlite.org/inmemorydb.html" target="_blank" rel="noopener noreferrer"><em>in-memory</em></a> database by specifying
<code>:memory:</code> as a location, which should give you a nice speed-up.</li>
<li>You can <a href="https://docs.python.org/3.6/library/sqlite3.html#sqlite3.Connection.row_factory" target="_blank" rel="noopener noreferrer">customize <code>row_factory</code></a>
to get something more useful than <code>tuple</code>s as results from <code>SELECT</code> queries.</li>
<li>Consider changing <code>isolation_level</code> to <code>DEFERRED</code> or <code>IMMEDIATE</code>.</li>
</ul>
<p><em>Edit 30-05-2021</em>: Fixed a missing <code>.connect</code> in the “You Don’t Need Cursors” section. Thanks to <a href="https://github.com/Gelma" target="_blank" rel="noopener noreferrer">Gelma</a> for noticing.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[State of privacy in statically generated blogs]]></title>
            <link>https://remusao.github.io//posts/state-of-static-blogs.html</link>
            <guid>https://remusao.github.io//posts/state-of-static-blogs.html</guid>
            <pubDate>Sun, 08 Oct 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I woke up one morning and realized that my “static blog” (hosted on
Github pages), contained around <strong>14 trackers</strong> on every page. By
tracker I mean a third-party company having some piece of <code>javascript</code>
injected on the page. Each tracker would also try to send unsafe data
to their backend (You can observe this behavior using any privacy
extension: Ghostery or Cliqz for example).</p>
<p>The truth is, most static blog embed <em>Google</em> for analytics, <em>Disqus</em>
for comments, <em>Mathjax</em> for Latex rendering, extra fonts, CSS, etc.</p>
<p>This is nice, and it brings many benefits to your blog, but people are
probably not aware of what the consequences are for their readers.
Instead of having a nice static html page containing only the content
you’d like to read, you get third-party scripts tracking you on every
page you visit (my content blocker extension even blocked a few advertising
requests).</p>
<figure>
<a href="../images/static-site-ghostery-trackers.png">
<img src="../images/static-site-ghostery-trackers.png" alt="Ghostery Trackers">
</a>
<figcaption>Advertisers joined the party...</figcaption>
</figure>
<p>If you wonder why there are so many, let’s just say that once you allow
a third-party script to execute on your page, you loose control over what
happens next. It might be that any script you include on your page,
will also inject a script from another company, which might make a few
requests as well, etc. If you want to see for yourself, go on a random site
having Disqus and Google Analytics (or your own blog if you have one), and open
the <em>Network Monitor</em> while loading the page. You will see all the resources
fetched (which can be scary…).</p>
<figure>
<a href="../images/network-monitor-tracking.png">
<img src="../images/network-monitor-tracking.png" alt="Network Monitor">
</a>
<figcaption>74 requests seems like a lot for a static page.</figcaption>
</figure>
<p>And they all send unsafe data (unique identifiers) back! I agree that
features like comments and math rendering are sometimes unavoidable, but
there should be a way to do it without all the tracking.</p>
<p>Unfortunately, the alternatives (if there is one at all), represent more
work to integrate and use.</p>
<p>For my own blog I decided to first strip all superfluous external
dependencies (meaning basically anything but the content of the blog),
and then find a way to introduce extra features one by one if needed.</p>
<p>It means that currently, there are no comments and no analytics report
on the number of readers/visits. But there are some promising solutions.</p>
<h2>Comments</h2>
<p>That is one of the most wanted features on a blog, and yet it requires having a
central server to store the comments. <em>Disqus</em> comes pretty handy here, with
only one small line of javascript to include on the page to load the entire
commenting system (but it comes with a high price, as we saw above).</p>
<p>Some possible alternatives are:</p>
<ul>
<li>Using <em>Github Issues</em> to host the comments. Here are a few posts about how that
can work for you:
<ul>
<li><a href="https://mademistakes.com/articles/jekyll-static-comments/" target="_blank" rel="noopener noreferrer">Going Static: Episode II — Attack of the Comments</a></li>
<li><a href="http://ivanzuzak.info/2011/02/18/github-hosted-comments-for-github-hosted-blogs.html" target="_blank" rel="noopener noreferrer">GitHub hosted comments for GitHub hosted blogs</a></li>
<li><a href="http://artsy.github.io/blog/2017/07/15/Comments-are-on/" target="_blank" rel="noopener noreferrer">Using GitHub Issues for Blog Comments</a></li>
<li><a href="http://sean.lane.sh/blog/2016/Hosting_comments_within_issues_on_Github_Pages" target="_blank" rel="noopener noreferrer">Hosting comments within issues on Github Pages</a></li>
<li>Last but not least, I seriously consider <em>embedding the comments
statically in the page</em> (since Github’s API returns the markdown, it
would allow to style the comments like the rest of your blog). That
would require you to fetch all the comments when you generate your
page (yes it takes extra time, but I would rather pay this price
once, instead of making users do it at every page load). Then there
could be some automated task scheduled using Travis to re-generate
the blog (or only the pages with new comments) every time there is a
new comment. I admit that this does not scale for a popular blog
with a lot of comments, but most of the times comments are scarce,
so this solution would work pretty well!</li>
</ul>
</li>
<li><a href="https://posativ.org/isso/" target="_blank" rel="noopener noreferrer">Isso</a>, which requires self-hosting.</li>
<li>There is also <em>Talk</em>, from the <a href="https://coralproject.net/about.html" target="_blank" rel="noopener noreferrer">Mozilla Coral Project</a>. I’m not sure if it can be used on any static website, but it might be something worth investigating.</li>
</ul>
<p>That does not seem to exist yet, but a totally distributed
commenting system would be an ideal fit here (using something like
<a href="https://ipfs.io/" target="_blank" rel="noopener noreferrer">IPFS</a>). There are some discussions about that on this
<a href="https://www.reddit.com/r/ipfs/comments/4om8c0/how_to_create_a_fairly_decentralized_commenting/" target="_blank" rel="noopener noreferrer">reddit thread</a>.</p>
<p>I’m not sure yet if I will add one of those on this blog, since I don’t
really have enough readers to justify the extra complexity (and it’s
still possible to leave some feedback on Github or Twitter if you really
want to). But if I were to choose one solution, I would probably go for
the Github Issues solution, which seems to fit nicely with a blog hosted
on Github Pages.</p>
<h2>Math Rendering</h2>
<p>One solution for privacy-preserving math rendering is to render the
equations at build-time and then embed them in the html as data urls.
That might not be the perfect solution, but it actually works pretty
well, and does not require any third-party resource. I used the
<a href="https://github.com/liamoc/latex-formulae" target="_blank" rel="noopener noreferrer">latex-formulae</a> plugin of
Hakyll, which worked pretty smoothly!</p>
<p>For example:</p>
<p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mn>42</mn></munderover><msup><mi>i</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sum^{42}_{i=0} i^2 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0788em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8011em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">42</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>But it can also be inlined like that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mn>42</mn></msubsup><msup><mi>i</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sum^{42}_{i=0} i^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2537em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.954em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">42</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>.</p>
<h2>Analytics</h2>
<p>I have to admit that I totally dropped this feature for now. Ideally,
Github would provide a very basic visit counter for each page of your
blog by default.</p>
<p>Otherwise, there are some nicer alternatives to <em>Google Analytics</em> such as:</p>
<ul>
<li><a href="https://piwik.org/" target="_blank" rel="noopener noreferrer">Piwik</a> – probably the most serious alternative.</li>
<li><a href="https://github.com/cliqz-oss/green-analytics" target="_blank" rel="noopener noreferrer">Green Tracker</a> – still experimental but demonstrates some very promising capabilities, and it requires self-hosting as well.</li>
</ul>
<p>And probably more, although none of them will be as convenient/powerful as
Google Analytics (for now at least…), but do you need as much?</p>
<h2>Fonts and styling</h2>
<p>This is obviously a very personal choice here, and most people will go with
pre-existing templates or frameworks such as <em>Bootstrap</em>.</p>
<p>I took the path of more simplicity and tried to roll-out my own super minimal
template. I also tried to use only fonts available widely (and provide
fall-backs in case a font is not present on the system).</p>
<h2>Social sharing</h2>
<p>It’s nice to have a few buttons to share an article quickly on Twitter,
Facebook or other social network using the social sharing widgets. The
downside is that most of the time, you’re also including trackers on
your page! (e.g.: Facebook will be able to track users reading your
page).</p>
<p>One option is to insert static buttons on your page, instead of the official
widgets. More information can be found there:</p>
<ul>
<li><a href="https://www.savjee.be/2015/01/Creating-static-social-share-buttons/" target="_blank" rel="noopener noreferrer">Creating static social share buttons</a></li>
</ul>
<p>Check them out at the bottom of the page!</p>
<h2>Conclusion</h2>
<p>The main down-side of this path, is that most of the time you will be on your
own. You might get lucky and find a plugin for your favorite static blog
generator (Jekyll, Pelican, Hugo, Hakyll), but if there is nothing, you will
have to come up with a solution from scratch.</p>
<p>At the end, I think it’s possible to get a mostly static site, with
no or very few external dependencies. This post was probably loaded
using only one request (the main document + the example images), which
includes everything needed. Yes it’s super minimal, and it could look
better, and it could use some comments, but most personal static
blogs don’t need as much, and if they do, and you’re willing to spend
the extra time – having totally private analytics, comments or math
rendering, could make for a very interesting and rewarding side-project!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Installing IHaskell on Ubuntu 16.04 with Stack]]></title>
            <link>https://remusao.github.io//posts/ihaskell-ubuntu-16-04-install.html</link>
            <guid>https://remusao.github.io//posts/ihaskell-ubuntu-16-04-install.html</guid>
            <pubDate>Sat, 07 Oct 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Last year I wrote a tutorial to install iHaskell on Ubuntu 14.04. Since it’s a
bit out-dated now, but I still think iHaskell can be super useful, I decided to
update it for Ubuntu 16.04.</p>
<p>Before we start, please be aware that you can use IHaskell directly in your
browser by visiting this website: <a href="https://try.jupyter.org/" target="_blank" rel="noopener noreferrer">try.jupyter.org</a>.
The following tutorial is only meant for those who want IHaskell to run locally.</p>
<h2>Install Stack</h2>
<p>Compared to Ubuntu 14.04, it is now easier to install <code>stack</code> thanks to the
<code>haskell-stack</code> package:</p>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">sudo</span> apt-get install haskell-stack
</code></pre>
<p>Now let’s make sure we have the latest version of stack, as well as the latest
snapshot from <a href="stackage.org/lts" target="_blank" rel="noopener noreferrer">stackage</a>:</p>
<pre class="code" data-lang="sh"><code>$ stack upgrade
$ stack update
$ stack setup
</code></pre>
<h2>Dependencies</h2>
<p>Some <a href="https://github.com/gibiansky/IHaskell#linux" target="_blank" rel="noopener noreferrer">dependencies</a> are
required before building the IHaskell kernel, let’s install them:</p>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">sudo</span> apt-get install -y   \
    git                     \
    libtinfo-dev            \
    libzmq3-dev             \
    libcairo2-dev           \
    libpango1.0-dev         \
    libmagic-dev            \
    libblas-dev             \
    liblapack-dev
</code></pre>
<h2>Install Jupyter</h2>
<p>IHaskell requires a recent version of <em>Jupyter</em>, so we need to install
it ourselves. There are several options:</p>
<ol>
<li>Use pip and install it globally (<code>pip install jupyter</code>)</li>
<li><strong>Use pip and install it in a <a href="https://virtualenv.pypa.io/en/stable/" target="_blank" rel="noopener noreferrer"><code>virtualenv</code></a></strong></li>
<li>Use <a href="https://nixos.org/nix/" target="_blank" rel="noopener noreferrer">nix</a> <em>(You’re on your own)</em></li>
<li>Use <a href="https://www.continuum.io/downloads" target="_blank" rel="noopener noreferrer">conda</a> (<code>conda update jupyter</code>)</li>
</ol>
<p>Let’s go with option <code>2.</code>. I usually never install python packages globally
using <code>sudo pip</code>, and prefer to create a fresh <a href="https://virtualenv.pypa.io/en/stable/" target="_blank" rel="noopener noreferrer"><code>virtualenv</code></a> for each project.
Let’s proceed!</p>
<p>If you’re on a fresh install, we need to install virtualenv first:</p>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">sudo</span> apt-get install virtualenv python3-dev ncurses-base
</code></pre>
<p>Then let’s install <code>jupyter</code> inside of our virtualenv <code>virtualenv</code>:</p>
<pre class="code" data-lang="sh"><code>$ virtualenv venv-ihaskell -p /usr/bin/python3 <span class="hljs-comment"># Create a virtualenv</span>
$ <span class="hljs-built_in">source</span> venv-ihaskell/bin/activate <span class="hljs-comment"># Active it</span>
$ pip install                                   \
    jupyter==1.0.0                              \
    jupyter-contrib-core==0.3.3                 \
    jupyter-contrib-nbextensions==0.3.1         \
    jupyter-highlight-selected-word==0.0.11     \
    jupyter-latex-envs==1.3.8.4                 \
    jupyter-nbextensions-configurator==0.2.8
</code></pre>
<h2>Install IHaskell</h2>
<p>Since IHaskell is not available in the latest stackage LTS snapshot, we have two
options to install it:</p>
<ul>
<li>Compile from source</li>
<li>Use the latest snapshot supporting IHaskell (<code>lts-6.35</code>)</li>
</ul>
<p>I will present both methods.</p>
<h3>From source</h3>
<p>The instructions can be found in the github <a href="https://github.com/gibiansky/IHaskell#linux" target="_blank" rel="noopener noreferrer">repository</a>:</p>
<blockquote>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">source</span> ihaskell-venv/bin/activate
$ git <span class="hljs-built_in">clone</span> git@github.com:gibiansky/IHaskell.git
$ <span class="hljs-built_in">cd</span> IHaskell
$ pip install -r requirements.txt
$ stack setup
$ stack install gtk2hs-buildtools
$ stack install --fast
$ stack <span class="hljs-built_in">exec</span> ihaskell -- install --stack
</code></pre>
</blockquote>
<p>Then it can be started using:</p>
<pre class="code" data-lang="sh"><code>$ stack <span class="hljs-built_in">exec</span> jupyter -- notebook
</code></pre>
<h3>From stackage lts-6.35</h3>
<p>Unfortunately, it is not possible to build IHaskell using the latest snapshot,
as it does not seem to work with GHC 8.x. The latest supported LTS snapshot is
<code>6.35</code>, so we will have to specify it explicitly:</p>
<pre class="code" data-lang="sh"><code>$ stack --resolver lts-6.35 setup --install-ghc
$ stack --resolver lts-6.35 install ihaskell
$ stack --resolver lts-6.35 <span class="hljs-built_in">exec</span> ihaskell -- install --stack
</code></pre>
<p>You may want to install extra packages to enhance <em>IHaskell</em>’s capabilities. Here are the ones supported by stackage:</p>
<ul>
<li><code>ihaskell-aeson</code></li>
<li><code>ihaskell-basic</code></li>
<li><code>ihaskell-blaze</code></li>
<li><code>ihaskell-charts</code></li>
<li><code>ihaskell-diagrams</code></li>
<li><code>ihaskell-hatex</code></li>
<li><code>ihaskell-inline-r</code></li>
<li><code>ihaskell-juicypixels</code></li>
<li><code>ihaskell-magic</code></li>
<li><code>ihaskell-rlangqq</code></li>
</ul>
<p>Some others are not in the snapshot, but could be very useful and can probably
be installed from source:</p>
<ul>
<li><code>ihaskell-widgets</code></li>
<li><code>ihaskell-parsec</code></li>
<li><code>ihaskell-plot</code></li>
</ul>
<h2>What’s next</h2>
<p>The installation of IHaskell on Ubuntu 16.04 is a bit easier than on 14.04
thanks to more up-to-date dependencies. Unfortunately, the latest IHaskell is
not available on stackage LTS, which requires to use an older snapshot (<code>6.35</code>).
It is still possible to build IHaskell from source, which allows you to
run the latest version of the code! It’s up to you to choose the method you prefer.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[What's in a parser combinator?]]></title>
            <link>https://remusao.github.io//posts/whats-in-a-parser-combinator.html</link>
            <guid>https://remusao.github.io//posts/whats-in-a-parser-combinator.html</guid>
            <pubDate>Tue, 23 Feb 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>As part of my ongoing effort to make progress in Haskell (that’s
one of my goals for 2016!), I’m following the <a href="https://courses.edx.org/courses/course-v1:DelftX+FP101x+3T2015/info" target="_blank" rel="noopener noreferrer">MOOC on functionnal programming</a>
by <a href="https://twitter.com/headinthebox" target="_blank" rel="noopener noreferrer">Erik Meijer</a> on <em>edX</em>.</p>
<p>The first lessons were pretty basic stuff, and I got through
them quickly. Lesson 7 is about <em>Functional parsers</em> and
M***** (scary). This is where I encountered my first
difficulties, and I thought it would be an interesting writing.
I already used parser combinators in Haskell before (mainly
<a href="https://hackage.haskell.org/package/parsec" target="_blank" rel="noopener noreferrer">Parsec</a> and
<a href="http://hackage.haskell.org/package/attoparsec" target="_blank" rel="noopener noreferrer">Attoparsec</a>), but never
really understood how they worked, or at least not enough to implement
one myself. So here is my take on the subject. Don’t expect really
advanced stuff! It’s just an introduction to the basic concepts, on
which we could build more complex and useful tools. In particular, <strong>I
won’t talk about</strong>:</p>
<ol>
<li>How to report errors.</li>
<li>How to recover from errors.</li>
<li>How to write a parser for a concrete grammar.</li>
</ol>
<p>Instead <strong>I’ll focus on</strong>:</p>
<ol>
<li>What a parser <em>is</em>.</li>
<li>How to make parsers <em>compose</em>.</li>
<li>How to use <em>do notation</em> to implement more complex parsers.</li>
</ol>
<p>One of the interesting facts about writing your own parser combinators
library, is that you will learn (or consolidate) other knowledges in
the process, like: <em>Functors</em>, <em>Applicatives</em> and, of course, <em>Monads</em>,
and more generaly, how to <em>design DSL in Haskell</em>. I already knew about
this concepts (at least, that’s what I thought…), but knowing what
something is from a high level of abstraction, <em>is not the same as
knowing how to implement it on a concrete type</em> (like a Parser)!</p>
<h3>So what’s a parser?</h3>
<p>We can view a <em>Parser</em> as <em>something</em> that consumes some input, and
outputs a structured representation of what was consumed. For the sake
of simplicity, we’ll only consume strings (Haskell type <code>String</code>). So
that would be something like:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-type">Parser</span> a = <span class="hljs-type">String</span> -&gt; a</span>
</code></pre>
<p>Here <code>a</code> represents the type of what is <em>built</em> from the stream of
characters (<code>String</code>). This could be a syntactic tree, or a list
of numbers, or anything else. For example a parser that is able to
recognize a string like <code>&quot;[1, 2, 3, 4]&quot;</code> could have the type: <code>Parser [Int]</code>
(expended to <code>String -&gt; [Int]</code>), which means it takes a <code>String</code>
and output a <code>list</code> of integers.</p>
<p>But we’re missing two important properties of a <em>Parser</em>:</p>
<ol>
<li>It can <strong>fail to parse</strong> something.</li>
<li>It can <strong>partially consume</strong> its input.</li>
</ol>
<p>To take into account the first point, we could return <code>Maybe a</code> instead
of <code>a</code> (resulting in <code>Nothing</code> in case of failure). Note that we could
also use a richer type like <code>Either</code> to handle parsing errors. And for
the second point, we can return a tuple of a <code>a</code> and a <code>String</code>, which
represents the part of the string that wasn’t consumed by the parser.
The type would then become:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">Parser</span> a = <span class="hljs-type">Parser</span> { <span class="hljs-title">runParser</span> :: <span class="hljs-type">String</span> -&gt; <span class="hljs-type">Maybe</span> (<span class="hljs-title">a</span>, <span class="hljs-type">String</span>) }</span>
</code></pre>
<p>As an example of a parser that would fail, if you take our previous
<em>parser</em> that is able to handle a list of integers, if you give it the
string <code>&quot;[1 ,2&quot;</code>, it will fail, and return <code>Nothing</code>.</p>
<p>Similarly, if we feed the <em>parser</em> with <code>&quot;[1, 2, 3, 4]toto&quot;</code>, it will
consume the part of the string that represents the list of integers, and
leave <code>&quot;toto&quot;</code> as a remaining input. Thus the result would be: <code>Just ([1, 2, 3, 4], &quot;toto&quot;)</code>.</p>
<p>Let’s implement some very basic parsers:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This parser always fails</span>
<span class="hljs-title">failure</span> :: <span class="hljs-type">Parser</span> a
<span class="hljs-title">failure</span> = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-type">Nothing</span>
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This parser always succeeds and returns the value given as input</span>
<span class="hljs-comment">-- (leaving the input string intact)</span>
<span class="hljs-title">return</span> :: a -&gt; <span class="hljs-type">Parser</span> a
<span class="hljs-title">return</span> a = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-type">Just</span> (a, s)
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This parser returns the first char of the input string, and</span>
<span class="hljs-comment">-- fail on empty input</span>
<span class="hljs-title">oneChar</span> :: <span class="hljs-type">Parser</span> <span class="hljs-type">Char</span>
<span class="hljs-title">oneChar</span> = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-keyword">case</span> s <span class="hljs-keyword">of</span>
            [] -&gt; <span class="hljs-type">Nothing</span>
            (c:xs) -&gt; <span class="hljs-type">Just</span> (c, xs)
</code></pre>
<p>Let’s test these parsers:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> failure <span class="hljs-string">&quot;Hello Parser!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (return <span class="hljs-number">42</span>) <span class="hljs-string">&quot;Hello Parser!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-number">42</span>, <span class="hljs-string">&quot;Hello Parser!&quot;</span>)
</code></pre>
</blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> oneChar <span class="hljs-string">&quot;Hello Parser!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-string">&#x27;H&#x27;</span>,<span class="hljs-string">&quot;ello Parser!&quot;</span>)
</code></pre>
</blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> oneChar <span class="hljs-string">&quot;&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<p>The basic parsers seem to behave as expected. We get <code>Nothing</code> in case
of failure, and they are able to partially consume the input. So all
is good, but what about more complex parsers? We would like to parse
strings, or more complex patterns. Let’s try to recognize a string from
the input, using our basic parsers:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">string</span> :: <span class="hljs-type">String</span> -&gt; <span class="hljs-type">Parser</span> <span class="hljs-type">String</span>
<span class="hljs-title">string</span> <span class="hljs-string">&quot;&quot;</span> = return <span class="hljs-string">&quot;&quot;</span>
<span class="hljs-title">string</span> (c1:xs1) = <span class="hljs-type">Parser</span> $ \s -&gt;
  <span class="hljs-keyword">case</span> runParser oneChar s <span class="hljs-keyword">of</span>
    <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
    <span class="hljs-type">Just</span> (c2, rest) -&gt;
      <span class="hljs-keyword">if</span> c1 == c2
      <span class="hljs-keyword">then</span> <span class="hljs-keyword">case</span> runParser (string xs1) rest <span class="hljs-keyword">of</span>
        <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
        <span class="hljs-type">Just</span> (match, rest2) -&gt; <span class="hljs-type">Just</span> (c2:match, rest2)
      <span class="hljs-keyword">else</span> <span class="hljs-type">Nothing</span>
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (string <span class="hljs-string">&quot;Hello&quot;</span>) <span class="hljs-string">&quot;Hello Parser!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-string">&quot;Hello&quot;</span>, <span class="hljs-string">&quot; Parser!&quot;</span>)
</code></pre>
</blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (string <span class="hljs-string">&quot;Hello&quot;</span>) <span class="hljs-string">&quot;Foo Bar&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (string <span class="hljs-string">&quot;&quot;</span>) <span class="hljs-string">&quot;Hello Parser!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-string">&quot;&quot;</span>,<span class="hljs-string">&quot;Hello Parser!&quot;</span>)
</code></pre>
</blockquote>
<p>This isn’t very convenient (but it works)… Because we have to write
the boilerplate to <em>compose parsers</em> over and over. Hopefully, we know a
famous structure that allows composition in Haskell, and this is called
<em>Monad</em> (and I won’t make yet another tutorial on <em>Monads</em>, so I will
assume you already are familiar with this concept). That means we could
avoid all the boilerplate, by making our <code>Parser</code> type an instance of
<em>Monad</em>. This would allow us to use the <em>do syntax</em> to cleanly compose
our parsers! Sweet!</p>
<p>To do so, we’ll have to make our <em>Parser</em> an instance of: <em>Functor</em>,
<em>Applicative</em> and <em>Monad</em>.</p>
<h4>Parser is a Functor</h4>
<p>First of all, our Parser is an instance of <a href="https://en.wikibooks.org/wiki/Haskell/The_Functor_class" target="_blank" rel="noopener noreferrer"><em>Functor</em></a>,
which means we can <code>map</code> functions over the result of our parsing:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">instance</span> <span class="hljs-type">Functor</span> <span class="hljs-type">Parser</span> <span class="hljs-keyword">where</span></span>
    <span class="hljs-comment">-- fmap :: (a -&gt; b) -&gt; Parser a -&gt; Parser b</span>
    <span class="hljs-comment">-- 1. Run parser on input string.</span>
    <span class="hljs-comment">-- 2. Apply function on result of parsing.</span>
    fmap f p = <span class="hljs-type">Parser</span> $ \s -&gt;
      <span class="hljs-keyword">case</span> runParser p s <span class="hljs-keyword">of</span>
        <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
        <span class="hljs-type">Just</span> (a, rest) -&gt; <span class="hljs-type">Just</span> (f a, rest)
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- Parse `String` &quot;42&quot; and then convert it to `Int` using `read`</span>
<span class="hljs-title">parse42</span> :: <span class="hljs-type">Parser</span> <span class="hljs-type">Int</span>
<span class="hljs-title">parse42</span> = (fmap read $ string <span class="hljs-string">&quot;42&quot;</span>)

<span class="hljs-title">runParser</span> parse42 <span class="hljs-string">&quot;42 is the answer!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-number">42</span>, <span class="hljs-string">&quot; is the answer!&quot;</span>)
</code></pre>
</blockquote>
<h4>Parser is an Applicative</h4>
<p>Secondly, we can make our parser an instance of
<a href="https://en.wikibooks.org/wiki/Haskell/Applicative_functors" target="_blank" rel="noopener noreferrer"><em>Applicative</em></a>.
This part wasn’t obvious for me. All the examples I found were
about instances for easy types like <code>Maybe</code>, but I found a <em>Parser</em> to
be pretty different. But thanks to the types and some use-cases (that
you’ll find below), I figured the following implementation (which will
hopefully be correct…):</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">instance</span> <span class="hljs-type">Applicative</span> <span class="hljs-type">Parser</span> <span class="hljs-keyword">where</span></span>
    <span class="hljs-comment">-- pure :: a -&gt; Parser a</span>
    <span class="hljs-comment">-- Wrap a value inside a parser, leaving input unchanged.</span>
    pure a = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-type">Just</span> (a, s)
    <span class="hljs-comment">-- (&lt;*&gt;) :: Parser (a -&gt; b) -&gt; Parser a -&gt; Parser b</span>
    <span class="hljs-comment">-- 1. Run first parser on input (resulting in a function (a -&gt; b).</span>
    <span class="hljs-comment">-- 2. Run second parser on remaining input, left by first parser.</span>
    <span class="hljs-comment">-- 3. Apply function (a -&gt; b) on result of second parser.</span>
    p1 &lt;*&gt; p2 = <span class="hljs-type">Parser</span> $ \s -&gt;
      <span class="hljs-keyword">case</span> runParser p1 s <span class="hljs-keyword">of</span>
        <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
        <span class="hljs-type">Just</span> (f, rest) -&gt; <span class="hljs-keyword">case</span> runParser p2 rest <span class="hljs-keyword">of</span>
          <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
          <span class="hljs-type">Just</span> (a, rest2) -&gt; <span class="hljs-type">Just</span> (f a, rest2)
</code></pre>
<p>The usefulness of the previous instance might not be obvious, but it
allows us to <code>lift</code> some function inside the realm of parsers. For
example if we want to take the result of several parsers and then group
their results into a tuple, we can do it using <em>Applicatives</em>:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">parseTuple</span> :: <span class="hljs-type">Parser</span> (<span class="hljs-type">Char</span>, <span class="hljs-type">Char</span>)
<span class="hljs-title">parseTuple</span> =  (,) &lt;$&gt; oneChar &lt;*&gt; oneChar
<span class="hljs-title">runParser</span> parseTuple <span class="hljs-string">&quot;ab&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> ((<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>), <span class="hljs-string">&quot;&quot;</span>)
</code></pre>
</blockquote>
<p>This is the kind of constructs we will use to convert the raw parsed
structure into our own types (e.g: an AST).</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">AST</span> =</span>
    <span class="hljs-type">Foo</span> <span class="hljs-type">String</span>
  | <span class="hljs-type">Bar</span> <span class="hljs-type">String</span>
  | <span class="hljs-type">Pair</span> <span class="hljs-type">Char</span> <span class="hljs-type">Char</span>
  <span class="hljs-keyword">deriving</span> (<span class="hljs-type">Show</span>)

<span class="hljs-title">parseFoo</span>, parseBar, parsePair :: <span class="hljs-type">Parser</span> <span class="hljs-type">AST</span>
<span class="hljs-title">parseFoo</span> = <span class="hljs-type">Foo</span> &lt;$&gt; string <span class="hljs-string">&quot;foo&quot;</span>
<span class="hljs-title">parseBar</span> = <span class="hljs-type">Bar</span> &lt;$&gt; string <span class="hljs-string">&quot;bar&quot;</span>
<span class="hljs-title">parsePair</span> = <span class="hljs-type">Pair</span> &lt;$&gt; oneChar &lt;*&gt; oneChar
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> parseFoo <span class="hljs-string">&quot;foo bar&quot;</span>
<span class="hljs-title">runParser</span> parseBar <span class="hljs-string">&quot;bar baz&quot;</span>
<span class="hljs-title">runParser</span> parsePair <span class="hljs-string">&quot;xyz&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-type">Foo</span> <span class="hljs-string">&quot;foo&quot;</span>, <span class="hljs-string">&quot; bar&quot;</span>)
</code></pre>
</blockquote>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span>(<span class="hljs-type">Bar</span> <span class="hljs-string">&quot;bar&quot;</span>, <span class="hljs-string">&quot; baz&quot;</span>)
</code></pre>
</blockquote>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> (<span class="hljs-type">Pair</span> <span class="hljs-string">&#x27;x&#x27;</span> <span class="hljs-string">&#x27;y&#x27;</span>, <span class="hljs-string">&quot;z&quot;</span>)
</code></pre>
</blockquote>
<h4>Parser is a Monad</h4>
<p>Last but not least, our parser is a <a href="https://en.wikibooks.org/wiki/Haskell/Understanding_monads" target="_blank" rel="noopener noreferrer"><em>Monad</em></a>. Which means it must implement: <code>&gt;&gt;=</code>, <code>&gt;&gt;</code>, <code>return</code> and <code>fail</code>:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-class"><span class="hljs-keyword">instance</span> <span class="hljs-type">Monad</span> <span class="hljs-type">Parser</span> <span class="hljs-keyword">where</span></span>
    <span class="hljs-comment">-- (&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b</span>
    <span class="hljs-comment">-- 1. Run first parser on input.</span>
    <span class="hljs-comment">-- 2. Feed result of parsing to `f`.</span>
    <span class="hljs-comment">-- 3. Run second parser (result of `f`) on remaining</span>
    <span class="hljs-comment">--    input (left by first parser)</span>
    p &gt;&gt;= f = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-keyword">case</span> runParser p s <span class="hljs-keyword">of</span>
                    <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
                    <span class="hljs-type">Just</span> (a, rest) -&gt; runParser (f a) rest
    <span class="hljs-comment">-- (&gt;&gt;) :: Parser a -&gt; Parser b -&gt; Parser b</span>
    <span class="hljs-comment">-- 1. Run first parser on input.</span>
    <span class="hljs-comment">-- 2. Run second parser on remaining input (left by first parser)</span>
    <span class="hljs-comment">-- We ignore result of first parser.</span>
    p1 &gt;&gt; p2 = <span class="hljs-type">Parser</span> $ \s -&gt; <span class="hljs-keyword">case</span> runParser p1 s <span class="hljs-keyword">of</span>
                    <span class="hljs-type">Nothing</span> -&gt; <span class="hljs-type">Nothing</span>
                    <span class="hljs-type">Just</span> (_, rest) -&gt; runParser p2 rest
    <span class="hljs-comment">-- return :: a -&gt; Parser a</span>
    return = pure
    <span class="hljs-comment">-- fail :: String -&gt; Parser a</span>
    fail _ = <span class="hljs-type">Parser</span> (const <span class="hljs-type">Nothing</span>)
</code></pre>
<p>Thanks to this definition we can use the <code>do</code> syntactic sugar, which
will ease the implementation of more complex parsers. Let’s see what we
can do.</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- Parse a specific `Char` from the input</span>
<span class="hljs-title">char</span> :: <span class="hljs-type">Char</span> -&gt; <span class="hljs-type">Parser</span> <span class="hljs-type">Char</span>
<span class="hljs-title">char</span> c = <span class="hljs-keyword">do</span>
    c1 &lt;- oneChar
    <span class="hljs-keyword">if</span> c == c1
       <span class="hljs-keyword">then</span> return c1
       <span class="hljs-keyword">else</span> failure
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (char <span class="hljs-string">&#x27;H&#x27;</span>) <span class="hljs-string">&quot;Hello!&quot;</span>
<span class="hljs-title">runParser</span> (char <span class="hljs-string">&#x27;e&#x27;</span>) <span class="hljs-string">&quot;Hello!&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span>(‘<span class="hljs-type">H</span>’,“ello!”)
</code></pre>
</blockquote>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<p>We can also implement a cleaner version of our <code>string</code> parser (found above):</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- Parse a specific pattern from the input</span>
<span class="hljs-title">string&#x27;</span> :: <span class="hljs-type">String</span> -&gt; <span class="hljs-type">Parser</span> <span class="hljs-type">String</span>
<span class="hljs-title">string&#x27;</span> [] = return []
<span class="hljs-title">string&#x27;</span> (c:xs) = <span class="hljs-keyword">do</span>
    c1 &lt;- char c
    rest &lt;- string&#x27; xs
    return (c1:rest)
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">runParser</span> (string&#x27; <span class="hljs-string">&quot;Hello&quot;</span>) <span class="hljs-string">&quot;Hello&quot;</span>
<span class="hljs-title">runParser</span> (string&#x27; <span class="hljs-string">&quot;Hello&quot;</span>) <span class="hljs-string">&quot;Foo&quot;</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span>(<span class="hljs-string">&quot;Hello&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)
</code></pre>
</blockquote>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<p>The <code>do</code> notation makes it very easy to combine parsers! We now have
some basic building blocks that we could use to implement more parsing
combinators: <code>choice</code>, <code>many</code>, <code>option</code>, etc. But I’ll leave it as an
exercise.</p>
<p>Moreover, it would be interesting to implement an error reporting
mechanism, as well as position tracking (to locate errors in the input),
but I’ll leave it for another blog-post (or as an exercise for the
reader!).</p>
<h2>What I learned while reinventing the wheel</h2>
<p>Implementing (very) basic parsing combinators led me to better
understand the foundation of libraries like <em>Parsec</em> or <em>Attoparsec</em>,
and to implement not so trivial instances of typeclasses like
<em>Applicatives</em> and <em>Monads</em>. Although basic, I think it’s a good way
to be more familiar with the <em>DSL</em>-like capabilities of Haskell, and
to feel the power that the language offers in term of domain-specific
modeling.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Feedback from Hash Code 2016 qualification round]]></title>
            <link>https://remusao.github.io//posts/hashcode-2016-feedback.html</link>
            <guid>https://remusao.github.io//posts/hashcode-2016-feedback.html</guid>
            <pubDate>Fri, 12 Feb 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<figure><a href="../images/hashcode2016.jpg" target="_blank" rel="noopener noreferrer"><img src="../images/hashcode2016.jpg" alt=""></a><figcaption>hashcode</figcaption></figure>
<p>Yesterday was the qualification round for <a href="https://hashcode.withgoogle.com/" target="_blank" rel="noopener noreferrer">Hash Code 2016</a> contest, organized by
Google. I already had the opportunity to participate next, and made it to the
final round with my team.  For this new edition, the team and motivation was
the same but we thought a bit about how we could improve our organization to be
more efficient. This post is about what I will take away from this competition.</p>
<h1>The Competition</h1>
<p>For this third edition, the concept stays the same, you can participate in
<em>teams</em>, and must perform well during the qualification round to make it to the
final round (which takes place in Google headquarters in Paris). Duration of
qualification round is about <em>4 hours</em>, and <em>final is a whole day</em>. Usually the
difficulty of the problem of qualification is lower than for the final. Though
this year’s challenged seemed a bit more complex than the previous one.</p>
<h1>The problems</h1>
<p>All the problems from Hash Codes contests are pretty much of the same kind
everytime since they are <em>optimization problems</em>. You’re given a situation, and
you want to maximize some output of the problem given an initial step:</p>
<ul>
<li><strong>2014 Final</strong>: <a href="https://hashcode.withgoogle.com/2014/tasks/hashcode2014_final_task.pdf" target="_blank" rel="noopener noreferrer">Optimize routing of Street view cars</a> in a city.</li>
<li><strong>2015 Qualification</strong>: The task was about <a href="https://hashcode.withgoogle.com/2015/tasks/hashcode2015_qualification_task.pdf" target="_blank" rel="noopener noreferrer">optimizing a data center</a>.</li>
<li><strong>2015 Final</strong>: <a href="https://hashcode.withgoogle.com/2015/tasks/hashcode2015_final_task.pdf" target="_blank" rel="noopener noreferrer">Optimize wireless internet coverage</a> using Loons.</li>
<li><strong>2016 Qualification</strong>: Optimize schedule of drones to deliver orders to customers on a 2D grid.</li>
<li><strong>2016 Final</strong>: Optimize something else…</li>
</ul>
<p>This kind of problems are interesting because it takes a <em>broad range of skill
and knowledge to solve them</em>, plus, <em>you can’t find the global optimum</em> (or at
least not easily/in a reasonnable time).  So the goal of any of this
competitions it to find a better solution than your competitors, or a least, a
good enough solution.</p>
<h1>Team Organization</h1>
<p>Organizing a team during such a short period of time, on a complex problem is
challenging. There are a lot of ways you can do it:</p>
<ul>
<li><em>Everyone is programming</em>.</li>
<li><em>Split the tasks among team members</em>.</li>
<li><em>You can define a schedule to brainstorm/code/visualize/give feedback</em>.</li>
<li>etc.</li>
</ul>
<p>Last year, we chose an approach where we would <em>talk and brainstorm with the
whole team</em> during the contest. <em>Not everyone was coding</em> and one of the team
member did some very <em>useful visualization</em> to gain insight, while others were
implementing some ideas from the discussions we had about the challenge.  This
approach was kind of Ok, we made it to the final, but didn’t perform very well
during the final round. Here are some short comings:</p>
<ul>
<li>Not everyone was at ease with programming.</li>
<li>Not everyone knows the same programming languages.</li>
<li>We didn’t participate in this kind of competition before.</li>
<li>Brainstorming a lot can bring a lot of ideas, but <em>you can’t try everything</em>, so it’s better to stick to one or two promising ideas that aren’t too difficult to implement in a short time.</li>
<li>Coding speed matters so you better go with a programming language that you know very well.</li>
</ul>
<p>We weren’t very satisfied with what we did that year, so we tried a different
approach this year. We observed that a lot of teams seem to go with a more
individual approach, where everyone is programming. That’s what we tried:</p>
<ol>
<li>Read problem statement, <strong>making sure everyone understood the same things</strong>.</li>
<li>Carefully consider the inputs, to <strong>list every information at our disposal</strong>.</li>
<li><strong>Made sure that the score to optimize was clear to everyone</strong>.</li>
<li>Initial brainstorm on some solutions, ways to solve the problem.</li>
<li>Then everyone tried to implement a working solution, using what we discussed.</li>
</ol>
<p>We had little interactions after <strong>step 4</strong>, which wasn’t a good thing in my
opinion. What we observed is that <strong>we talked less</strong>, and had <strong>a bit less
fun</strong>. We didn’t interact as much as last year, and <strong>not everyone felt like
they participated</strong> in the team’s work, due to individual solutions.</p>
<h1>Challenges</h1>
<p>Here is what I found to be difficult during this qualification round:</p>
<ul>
<li><strong>Your worst ennemy is complexity</strong>.</li>
<li><em>Your second worst is your concentration</em>.</li>
<li>Being reasonable about the solution to choose.</li>
</ul>
<p>What I found useful was to decide early on <em>a method that isn’t too complex</em> or
too hard to implement. The most important is to <em>submit a solution</em>. <em>Better
have a simple solution that works than a complex one that doesn’t</em>. Your goal
is not to find the best solution ever, but to find a solution <em>good enough</em> to
make if to the final round.  Moreover if your first simple solution works, you
should have sufficient time to improve it before the end of the round (if you
don’t, that means your solution was maybe too complex, or that you took a big
risk).</p>
<p>One of my teammates, Florian, posted a <a href="https://flothesof.github.io/thoughts-before-hashcode-2016.html" target="_blank" rel="noopener noreferrer">blog post</a>
this week, before the competition to explain what he thought would be a good
way to tackle the coming qualification. I mainly agree with him, in the light
of what happened yesterday, but I tried to clarify some point in the comments
(that was before the contest). Some of my thoughts on the subject evolved:</p>
<blockquote>
<p>[…] the top-down divide and conquer approach that you describe (as lazy
evaluation), is more about breaking the problem into a maximum number of small
sub-parts than it is about modelling the problem. You can see that, for
example, last year’s winners didn’t create classes or structs, they just used
plain C arrays. And this is more about breaking the complexity of the problem,
and deferring complexity to later as much as you can. This helps keep track of
what you’ve done, what you’re doing, and what remain to be done, while managing
complexity: “I know my solution must look like do A, then B, and C at a high
level, and I know I can do A, B, C later, with the same top-down approach.
Let’s not think about this know, it would waste time and concentration.”</p>
</blockquote>
<p>What I think now is that, you can go with a low-level language and less
modelization if you are well prepared to program in a short period of time.
Otherwise, you would better stick with the clean step-by-step approach to limit
complexity, and <strong>validate your steps as you go</strong>. It’s crucial to limit
potential errors and bugs, so that you are confident your solution will work.
<strong>You can’t afford lot of debug in a competition</strong>.</p>
<blockquote>
<p>[…] the code doesn’t have to be clean, or readable, in a general way. It
must be clear to you, at least during the time of the competition, which is
only a few hours. This is why I think it’s not necessary to add comments, or
create classes/struct/etc. to model your ideas into code. Rather it’s a race
against time and complexity and you can use this kind of programming constructs
to break the complexity of the problem even further, but not to be readable.
Breaking into small part is also useful to refactor, try new ideas, change
stuff, quickly (and I agree that modelling can help too there, but I don’t
think it’s a low hanging fruit in this kind of competition) .</p>
</blockquote>
<p>This point is similar to the previous one, except that you should not be too
confident in your ability to handle a complex problem/solution in a short
amount of time. <strong>Better be slow and right, than fast and wrong</strong>.</p>
<blockquote>
<p>[…] it’s better to have a slow solution that works than a quick solution
that doesn’t. But I would argue that this argument can be held against what you
say too, because we also can say that it’s better to have an ugly/dirty/oneshot
solution that works, than a beautifully designed/readable solution that
doesn’t. So it’s more quick &amp; dirty but works, than high-level/well-designed
code that doesn’t […]</p>
</blockquote>
<blockquote>
<p>[…] it can be an advantage to develop the solution in a fast language like
C++ or Java, instead of a more dynamic language like Python. I may be wrong,
but I think you have better chances to have a fast-enough solution in C++ with
ugly code, no modelling or optimization effort than it is to achieve reasonable
performance in Python (this is mainly true for the kind of problem we have to
tackle in the Hash Code: optimization and number crunching). When you have to
explore big solution spaces looking for an optimum, with little time to think
about an elegant solution, you’re playing against time, so it’s good to use a
language in which you can go quick and dirty, but still get reasonable
performances.</p>
</blockquote>
<p>It’s true only if you can come up with a working program in this language,
during the time of the competition. If you don’t feel like you can, stick with
the easier, well-known language. <strong>Working but slow solution in <em>Python</em> is
better than a fast non-working solution in <em>C++</em>.</strong></p>
<h1>Take-away</h1>
<p><strong>TL;DR</strong>:</p>
<ul>
<li><em>Master your programming environment</em>.</li>
<li><em>Manage/avoid complexity if you can</em>.</li>
<li>Don’t go for a too complex/fancy solution.</li>
<li><em>Communication with your team members is good</em> if you want to feel like you’re competing together.</li>
<li><strong>Have fun!</strong></li>
</ul>
<p>Now we’ll try to improve our solutions during the extended round. I’m eager to
read some blog posts on the problem we had to tackle. Insight from other teams
will definitely be interesting!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rubik's Cube records]]></title>
            <link>https://remusao.github.io//posts/rubiks-cube-records.html</link>
            <guid>https://remusao.github.io//posts/rubiks-cube-records.html</guid>
            <pubDate>Wed, 27 Jan 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Following on the recent hype around the robot
that is able to solve a Rubik’s cube <a href="http://hackaday.com/2016/01/27/robot-solves-rubiks-cube-in-just-one-second/" target="_blank" rel="noopener noreferrer">in a second</a>
(which seems a big improvement over the previous robot that was able to
solve it in about 3 seconds), I got interested in human records, and
their evolution over the year.</p>
<p>The <a href="https://www.worldcubeassociation.org" target="_blank" rel="noopener noreferrer">World Cube Association</a>
provides dataset about ranking, records, players in
Rubik’s Cube competitions. They offer a <a href="https://www.worldcubeassociation.org/results/misc/export.html" target="_blank" rel="noopener noreferrer">downloadable
dataset</a>
for data science purpose. But since it would be too easy to use a TSV
;), I’ll show how we can extract data from this website, and use Pandas
get some insight.</p>
<h1>Players</h1>
<p>We’ll first try to explore data about results of
Worldwide competitions that we can find on <a href="https://www.worldcubeassociation.org/results" target="_blank" rel="noopener noreferrer">this
page</a>.</p>
<p>Let’s use <code>requests</code> to fetch HTML from the URL. If you go directly on
the page, you’ll see that you can select the number of results you’re
interested in, countries, years, etc. All theses parameters can be
specified in the URL too. In this post, I’ll use all the data (all
players, all years, all countries):</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> requests
r = requests.get(<span class="hljs-string">&quot;https://www.worldcubeassociation.org/results/events.php?eventId=333&amp;regionId=&amp;years=&amp;show=All%2BPersons&amp;single=Single&quot;</span>)
</code></pre>
<p>Beautifulsoup will let you manipulate HTML without dealing too much with
low-level details.</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
soup = BeautifulSoup(r.text, <span class="hljs-string">&#x27;html.parser&#x27;</span>)
</code></pre>
<p>You can ask him to find and extract one particular part of the HTML, in
our case it would be <code>table-responsive</code> which represents the array of
results:</p>
<pre class="code" data-lang="python"><code>table = soup.find(<span class="hljs-string">&quot;div&quot;</span>, {<span class="hljs-string">&quot;class&quot;</span>: <span class="hljs-string">&quot;table-responsive&quot;</span>})
raw_lines = [
    line.contents[:<span class="hljs-number">5</span>]
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> table.find_all(<span class="hljs-string">&quot;tr&quot;</span>)
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(line) == <span class="hljs-number">6</span>
]
raw_lines[<span class="hljs-number">0</span>]
</code></pre>
<blockquote>
<p>1 | <a href="/results/p.php?i=2011ETTE01" target="_blank" rel="noopener noreferrer">Lucas Etter</a> | 4.90 | USA | <a href="/results/c.php?i=RiverHillFall2015" target="_blank" rel="noopener noreferrer">River Hill Fall 2015</a>
— | — | — | — |</p>
</blockquote>
<p>We get a list of <code>HMTL Entities</code> that we will process to extract the
data we need. But first, let’s automate this extraction process with a
function, since every tables on this website respect the same format:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
<span class="hljs-keyword">import</span> requests

<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_table_raws</span>(<span class="hljs-params">url, cols</span>):
    r = requests.get(url)
    soup = BeautifulSoup(r.text, <span class="hljs-string">&#x27;html.parser&#x27;</span>)
    table = soup.find(<span class="hljs-string">&quot;div&quot;</span>, {
        <span class="hljs-string">&quot;class&quot;</span>: <span class="hljs-string">&quot;table-responsive&quot;</span>
    })

    raw_lines = [
        line.contents
        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> table.find_all(<span class="hljs-string">&quot;tr&quot;</span>)
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(line) == cols
    ]

    <span class="hljs-keyword">return</span> [[c.text <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> line] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> raw_lines]
</code></pre>
<p>Since we’ll have to deal with dates and timings, we could use this
little helpers to do the conversions:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">extract_year_from_competition</span>(<span class="hljs-params">competition</span>):
    <span class="hljs-comment"># Format is [name] [year]</span>
    <span class="hljs-keyword">return</span> <span class="hljs-built_in">int</span>(competition.strip().rsplit(<span class="hljs-string">&#x27; &#x27;</span>, <span class="hljs-number">1</span>)[-<span class="hljs-number">1</span>])

<span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_timing_to_seconds</span>(<span class="hljs-params">timing</span>):
    <span class="hljs-keyword">try</span>:
        <span class="hljs-comment"># Try to convert directly in seconds</span>
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(timing)
    <span class="hljs-keyword">except</span> ValueError:
        <span class="hljs-keyword">try</span>:
            <span class="hljs-comment"># Format should be [minutes]:[seconds].[tenth]</span>
            minutes, rest = timing.split(<span class="hljs-string">&quot;:&quot;</span>, <span class="hljs-number">1</span>)
            seconds, tenth = rest.split(<span class="hljs-string">&quot;.&quot;</span>, <span class="hljs-number">1</span>)
            <span class="hljs-keyword">return</span> (
                <span class="hljs-built_in">float</span>(minutes) * <span class="hljs-number">60</span> +
                <span class="hljs-built_in">float</span>(seconds) +
                <span class="hljs-built_in">float</span>(tenth) / <span class="hljs-number">100</span>
            )
        <span class="hljs-keyword">except</span> ValueError:
            <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>
</code></pre>
<p>Let’s use our helpers to extract all the data:</p>
<pre class="code" data-lang="python"><code>url = <span class="hljs-string">&quot;https://www.worldcubeassociation.org/results/events.php?eventId=333&amp;regionId=&amp;years=&amp;show=All%2BPersons&amp;single=Single&quot;</span>
clean_table = []
<span class="hljs-keyword">for</span> rank, (_, person, timing, country, competition, _) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(get_table_raws(url, <span class="hljs-number">6</span>)):
    year = extract_year_from_competition(competition)
    timing = convert_timing_to_seconds(timing)
    clean_table.append((rank + <span class="hljs-number">1</span>, person, timing, country, competition, year))

clean_table[:<span class="hljs-number">5</span>]
</code></pre>
<blockquote>
<pre class="code" data-lang="python"><code>[(<span class="hljs-number">1</span>, <span class="hljs-string">u&#x27;Lucas Etter&#x27;</span>, <span class="hljs-number">4.9</span>, <span class="hljs-string">u&#x27;USA&#x27;</span>, <span class="hljs-string">u&#x27;River Hill Fall 2015&#x27;</span>, <span class="hljs-number">2015</span>),
 (<span class="hljs-number">2</span>, <span class="hljs-string">u&#x27;Keaton Ellis&#x27;</span>, <span class="hljs-number">5.09</span>, <span class="hljs-string">u&#x27;USA&#x27;</span>, <span class="hljs-string">u&#x27;River Hill Fall 2015&#x27;</span>, <span class="hljs-number">2015</span>),
 (<span class="hljs-number">3</span>, <span class="hljs-string">u&#x27;Collin Burns&#x27;</span>, <span class="hljs-number">5.25</span>, <span class="hljs-string">u&#x27;USA&#x27;</span>, <span class="hljs-string">u&#x27;Doylestown Spring 2015&#x27;</span>, <span class="hljs-number">2015</span>),
 (<span class="hljs-number">4</span>, <span class="hljs-string">u&#x27;Feliks Zemdegs&#x27;</span>, <span class="hljs-number">5.39</span>, <span class="hljs-string">u&#x27;Australia&#x27;</span>, <span class="hljs-string">u&#x27;World Championship 2015&#x27;</span>, <span class="hljs-number">2015</span>),
 (<span class="hljs-number">5</span>, <span class="hljs-string">u&#x27;Mats Valk&#x27;</span>, <span class="hljs-number">5.55</span>, <span class="hljs-string">u&#x27;Netherlands&#x27;</span>, <span class="hljs-string">u&#x27;Zonhoven Open 2013&#x27;</span>, <span class="hljs-number">2013</span>)]
</code></pre>
</blockquote>
<pre class="code" data-lang="python"><code><span class="hljs-built_in">len</span>(clean_table)
</code></pre>
<blockquote>
<pre class="code" data-lang="python"><code><span class="hljs-number">47465</span>
</code></pre>
</blockquote>
<p>Let’s see if we can gain some insight from this dataset using Pandas:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

df = pd.DataFrame(
    data=clean_table,
    columns=(
        <span class="hljs-string">&#x27;Rank&#x27;</span>,
        <span class="hljs-string">&#x27;Person&#x27;</span>,
        <span class="hljs-string">&#x27;Timing&#x27;</span>,
        <span class="hljs-string">&#x27;Country&#x27;</span>,
        <span class="hljs-string">&#x27;Competition&#x27;</span>,
        <span class="hljs-string">&#x27;Year&#x27;</span>
    ))

df.head()
</code></pre>
<blockquote>
<table>
<thead>
<tr>
<th>Rank</th>
<th>Person</th>
<th>Timing</th>
<th>Country</th>
<th>Competition</th>
<th>Year</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Lucas Etter</td>
<td>4.9</td>
<td>USA</td>
<td>River Hill Fall 2015</td>
<td>2015</td>
</tr>
<tr>
<td>2</td>
<td>Keaton Ellis</td>
<td>5.09</td>
<td>USA</td>
<td>River Hill Fall 2015</td>
<td>2015</td>
</tr>
<tr>
<td>3</td>
<td>Collin Burns</td>
<td>5.25</td>
<td>USA</td>
<td>Doylestown Spring 2015</td>
<td>2015</td>
</tr>
<tr>
<td>4</td>
<td>Feliks Zemdegs</td>
<td>5.39</td>
<td>Australia</td>
<td>World Championship 2015</td>
<td>2015</td>
</tr>
<tr>
<td>5</td>
<td>Mats Valk</td>
<td>5.55</td>
<td>Netherlands</td>
<td>Zonhoven Open 2013</td>
<td>2013</td>
</tr>
</tbody>
</table>
</blockquote>
<p>We see that the first entry is the <em>World record</em> by <a href="https://www.youtube.com/watch?v=vh0W8E4cNkQ" target="_blank" rel="noopener noreferrer">Lucas
Etter</a>. If you didn’t see,
watch it now, it’s very impressive.</p>
<pre class="code" data-lang="python"><code>df[<span class="hljs-string">&quot;Timing&quot;</span>].describe()
</code></pre>
<blockquote>
<p>|
— | —
count | <code>47465.000000</code>
mean  | <code>35.078421</code>
std   | <code>27.492358</code>
min   | <code>4.900000</code>
25%   | <code>17.350000</code>
50%   | <code>26.720000</code>
75%   | <code>43.830000</code>
max   | <code>648.000000</code></p>
</blockquote>
<blockquote>
<p>Name: Timing, dtype: float64</p>
</blockquote>
<p>We have 47465 entries. The average time of resolution in these
competitions is 35 seconds, which is actually pretty fast. The maximum,
of 648 seconds (10 minutes) seems more reasonable to me…</p>
<pre class="code" data-lang="python"><code>%matplotlib inline
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
plt.style.use(<span class="hljs-string">&#x27;ggplot&#x27;</span>)
</code></pre>
<p>We can count the number of players for each country:</p>
<pre class="code" data-lang="python"><code>country_count = df[[<span class="hljs-string">&quot;Country&quot;</span>]].apply(pd.value_counts)
country_count[:<span class="hljs-number">20</span>]
</code></pre>
<blockquote>
<table>
<thead>
<tr>
<th>Country</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>USA</td>
<td>8918</td>
</tr>
<tr>
<td>China</td>
<td>6286</td>
</tr>
<tr>
<td>India</td>
<td>4659</td>
</tr>
<tr>
<td>Brazil</td>
<td>2039</td>
</tr>
<tr>
<td>Poland</td>
<td>1739</td>
</tr>
<tr>
<td>Canada</td>
<td>1526</td>
</tr>
<tr>
<td>Germany</td>
<td>1092</td>
</tr>
<tr>
<td>Indonesia</td>
<td>1090</td>
</tr>
<tr>
<td>France</td>
<td>1065</td>
</tr>
<tr>
<td>Japan</td>
<td>999</td>
</tr>
<tr>
<td>Philippines</td>
<td>993</td>
</tr>
<tr>
<td>Spain</td>
<td>977</td>
</tr>
<tr>
<td>Mexico</td>
<td>932</td>
</tr>
<tr>
<td>Korea</td>
<td>869</td>
</tr>
<tr>
<td>Ukraine</td>
<td>848</td>
</tr>
<tr>
<td>Taiwan</td>
<td>828</td>
</tr>
<tr>
<td>Russia</td>
<td>817</td>
</tr>
<tr>
<td>Australia</td>
<td>766</td>
</tr>
<tr>
<td>Peru</td>
<td>671</td>
</tr>
<tr>
<td>Colombia</td>
<td>627</td>
</tr>
</tbody>
</table>
</blockquote>
<p>No surprise, bigger countries are more represented in Rubik’s Cube
competitions. It would be interesting to compare these numbers with the
actual population, to see if Rubik’s Cube is more <em>“popular”</em> in some
countries.</p>
<p>Let’s visualize the countries with more than 200 players using a barplot:</p>
<pre class="code" data-lang="python"><code>country_count[country_count &gt; <span class="hljs-number">200</span>].dropna().plot(kind=<span class="hljs-string">&quot;bar&quot;</span>)
</code></pre>
<figure><a href="../images/output_27_1.png" target="_blank" rel="noopener noreferrer"><img src="../images/output_27_1.png" alt=""></a><figcaption>Players per country</figcaption></figure>
<p>We can do the same for players:</p>
<pre class="code" data-lang="python"><code>df[[<span class="hljs-string">&quot;Person&quot;</span>]]
    .apply(pd.value_counts)
    .apply(pd.value_counts)
</code></pre>
<blockquote>
<table>
<thead>
<tr>
<th>Number of participations</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>46709</td>
</tr>
<tr>
<td>2</td>
<td>305</td>
</tr>
<tr>
<td>3</td>
<td>26</td>
</tr>
<tr>
<td>4</td>
<td>13</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
</tr>
<tr>
<td>6</td>
<td>1</td>
</tr>
</tbody>
</table>
</blockquote>
<p>It appears that the vast majority of player only <em>participated one
time</em>. And only about 0.007% participated more than once. Can we
conclude that players are more hobbyist than professional? Another
information that could be interesting is the age of the participants,
since the World Champion is very young, it would be fun to have more
insight about the average or mean age of Rubik’s Cube champions.</p>
<h1>Records</h1>
<p>Let’s now get to the world records, and try to see how they evolve over
the years. The code is pretty similar to the previous section, so we’ll
just use our generic function for table extraction:</p>
<pre class="code" data-lang="python"><code>url = <span class="hljs-string">&quot;https://www.worldcubeassociation.org/results/regions.php?regionId=&amp;eventId=333&amp;years=&amp;history=History&quot;</span>
clean_table = []
<span class="hljs-keyword">for</span> (_, single, avg, person, country, competition, _) <span class="hljs-keyword">in</span> get_table_raws(url, <span class="hljs-number">7</span>):
    single = convert_timing_to_seconds(single.strip())
    avg = convert_timing_to_seconds(avg.strip())
    year = <span class="hljs-built_in">float</span>(extract_year_from_competition(competition))
    clean_table.append((person, single, avg, country, competition, year))

clean_table[:<span class="hljs-number">5</span>]
</code></pre>
<pre class="code" data-lang="python"><code>[
  (<span class="hljs-string">u&#x27;Lucas Etter&#x27;</span>, <span class="hljs-number">4.9</span>, <span class="hljs-literal">None</span>, <span class="hljs-string">u&#x27;USA&#x27;</span>, <span class="hljs-string">u&#x27;River Hill Fall 2015&#x27;</span>, <span class="hljs-number">2015.0</span>),
  (<span class="hljs-string">u&#x27;Collin Burns&#x27;</span>, <span class="hljs-number">5.25</span>, <span class="hljs-literal">None</span>, <span class="hljs-string">u&#x27;USA&#x27;</span>, <span class="hljs-string">u&#x27;Doylestown Spring 2015&#x27;</span>, <span class="hljs-number">2015.0</span>),
  (<span class="hljs-string">u&#x27;Mats Valk&#x27;</span>, <span class="hljs-number">5.55</span>, <span class="hljs-literal">None</span>, <span class="hljs-string">u&#x27;Netherlands&#x27;</span>, <span class="hljs-string">u&#x27;Zonhoven Open 2013&#x27;</span>, <span class="hljs-number">2013.0</span>),
  (<span class="hljs-string">u&#x27;Feliks Zemdegs&#x27;</span>, <span class="hljs-number">5.66</span>, <span class="hljs-literal">None</span>, <span class="hljs-string">u&#x27;Australia&#x27;</span>, <span class="hljs-string">u&#x27;Melbourne Winter Open 2011&#x27;</span>,
  <span class="hljs-number">2011.0</span>),
  (<span class="hljs-string">u&#x27;Feliks Zemdegs&#x27;</span>,
   <span class="hljs-number">6.18</span>,
   <span class="hljs-literal">None</span>,
   <span class="hljs-string">u&#x27;Australia&#x27;</span>,
   <span class="hljs-string">u&#x27;Melbourne Winter Open 2011&#x27;</span>,
   <span class="hljs-number">2011.0</span>)
]
</code></pre>
<pre class="code" data-lang="python"><code>df = pd.DataFrame(
    data=clean_table,
    columns=(<span class="hljs-string">&#x27;Person&#x27;</span>, <span class="hljs-string">&#x27;Single&#x27;</span>, <span class="hljs-string">&#x27;Avg&#x27;</span>, <span class="hljs-string">&#x27;Country&#x27;</span>, <span class="hljs-string">&#x27;Competition&#x27;</span>, <span class="hljs-string">&#x27;Year&#x27;</span>))

df.head()
</code></pre>
<blockquote>
<p>Person | Single | Avg | Country | Competition | Year
—    | —    | — | —     | —         |
0 | Lucas Etter | 4.90 | <code>NaN</code> | USA | River Hill Fall 2015 | 2015
1 | Collin Burns | 5.25 | <code>NaN</code> | USA | Doylestown Spring 2015 | 2015
2 | Mats Valk | 5.55 | <code>NaN</code> | Netherlands | Zonhoven Open 2013 | 2013
3 | Feliks Zemdegs | 5.66 | <code>NaN</code> | Australia | Melbourne Winter Open 2011 | 2011
4 | Feliks Zemdegs | 6.18 | <code>NaN</code> | Australia | Melbourne Winter Open 2011 | 2011</p>
</blockquote>
<pre class="code" data-lang="python"><code>df = df.sort([<span class="hljs-string">&quot;Year&quot;</span>, <span class="hljs-string">&quot;Single&quot;</span>], ascending=[<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>])
df[df[<span class="hljs-string">&quot;Single&quot;</span>].notnull()].plot(x=<span class="hljs-string">&quot;Year&quot;</span>, y=<span class="hljs-string">&quot;Single&quot;</span>, legend=<span class="hljs-string">&quot;Test&quot;</span>)
plt.title(<span class="hljs-string">&quot;World records of Rubik&#x27;s Cube&quot;</span>)
</code></pre>
<figure><a href="../images/output_36_1.png" target="_blank" rel="noopener noreferrer"><img src="../images/output_36_1.png" alt=""></a><figcaption>World records of Rubik’s Cube</figcaption></figure>
<h1>Last words</h1>
<p>It would seem reasonable to conclude that <em>we are now on a plateau</em>. One think that could bring even more insight would be to compare this evolution to, say, evolution among sprinters’ world records over time, etc. I guess we’re hitting the same kind of limitation.</p>
<p>A major difference is that in Rubik’s Cube, you’re limited both by your fingers’ dexterity, and the speed at which your brain can process information, whereas in athletics, it’s more about physical performance. <em>I would be curious to see which one is more limiting: brain, or body</em>.</p>
<p>Another open question for me is: <em>how much does the final score depends on the initial configuration of the Rubik’s Cube?</em> I know that they are able to look at it before the beginning, so maybe this is negligible, maybe not.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Learning a new language]]></title>
            <link>https://remusao.github.io//posts/learning-a-new-language.html</link>
            <guid>https://remusao.github.io//posts/learning-a-new-language.html</guid>
            <pubDate>Mon, 25 Jan 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<figure>
<a href="../images/learning.png">
<img src="../images/learning.png" alt="learning" style="width:80.0%">
</a>
</figure>
<p><strong>Facts</strong>:</p>
<ol>
<li>I’m leaving for Germany in 2 months, for an undetermined duration.</li>
<li>I don’t speak German.</li>
<li>I decided to learn it.</li>
</ol>
<p>In this post, I intend to give a short description of the <em>tools and methodology I use to learn German</em>.
Keep in mind that this is neither a “definitive guide”, nor a “how to”, only some notes on what I found on my journey to learning a new language (which just began).
I would be glad to get some tricks, advices and such from the comments as well.</p>
<p>Here is an overview of what we will talk about in this post:</p>
<ul>
<li><strong>Duolingo</strong></li>
<li><strong>Memrise</strong></li>
<li><strong>Readlang</strong></li>
<li><strong>Anki</strong></li>
<li>Good will and method</li>
</ul>
<h1>What it takes to learn a new language</h1>
<p><em>One</em> of the main difficulties in learning a language is <strong>memorizing stuff</strong>.
This is what I’ll focus on in this post (and this is by no mean the only difficulty!).
You have to learn new things: news <em>words</em>, new <em>rules</em>, new <em>pronunciations</em>, <em>new everything</em>.
And it can be hard to make it stick in your head for good, especially if it’s very different from what you already know.</p>
<p>It has been shown that it’s not efficient to just learn something in one shot, by simply reading it.
<em>Your memories are highly organized, structured, connected</em>. So it’s much more efficient to:</p>
<ul>
<li><strong>Create context</strong> around something you want to remember (sounds, images, videos, mnemonics)</li>
<li><strong>Structure your learning</strong> (connect to existing knowledge, learn similar things in batch)</li>
<li><strong>Review your new knowledge</strong> at the right time, with <a href="https://en.wikipedia.org/wiki/Spaced_learning" target="_blank" rel="noopener noreferrer">increasing spacing</a>.</li>
</ul>
<p>As it happens, there are lot of applications that can help you organize and optimize your learning.
Some are generic in the kind of knowledge you can learn, others focus on languages.
I’m mainly using the following four tools at the moment: <a href="http://ankisrs.net/" target="_blank" rel="noopener noreferrer">Anki</a>, <a href="https://www.memrise.com/" target="_blank" rel="noopener noreferrer">Memrise</a>, <a href="https://www.duolingo.com/" target="_blank" rel="noopener noreferrer">Duolingo</a>, <a href="https://readlang.com" target="_blank" rel="noopener noreferrer">ReadLang</a> (with no particular order of importance).
In fact, I’m trying to combine multiple ways of learning, so that I can see the same stuff <em>several times</em>, with <em>different point of views</em>, <em>different materials</em> (images, sounds, etc.).
Right now, I’m only exploring the potential ways of using the tools, and I expect the way I use them will evolve over time.</p>
<h1>The Apps</h1>
<h2>Anki</h2>
<figure><a href="../images/anki.jpg" target="_blank" rel="noopener noreferrer"><img src="../images/anki.jpg" alt=""></a><figcaption>anki</figcaption></figure>
<p><a href="https://en.wikipedia.org/wiki/Anki_%28software%29" target="_blank" rel="noopener noreferrer">Anki</a> is an application that helps you create cards, and then make you review them at the right time.
This is based on a <a href="https://en.wikipedia.org/wiki/Spaced_repetition" target="_blank" rel="noopener noreferrer">spaced repetition method</a>, that helps you review stuff just when you’re about to forget it!
You can attach text, images, sound and videos to a card, so that you have context associated with each new knowledge (this helps to remember, a lot…).
I use it to create my own card to remember the new vocabulary I encounter, that I can then review later.</p>
<p>I also like that it provides a web interface, an Android App and a Desktop client (for GNU/Linux).
If you create an account, it’s possible to synchronize your cards between devices and download decks from other people, although it’s recommanded to create your own cards.</p>
<h4>Pros</h4>
<ul>
<li>Does one thing, well.</li>
<li>Multi-plateform (Webapp, mobile, desktop), Anki got you covered.</li>
<li><em>Create your own cards</em>.</li>
<li>Attach any content you’d like to cards.</li>
<li>Sync across devices.</li>
<li>Extensive <a href="http://ankisrs.net/docs/manual.html" target="_blank" rel="noopener noreferrer">documentation</a>.</li>
<li><em>Open-source</em>.</li>
<li>Nothing fancy, only what is needed.</li>
</ul>
<h4>Cons</h4>
<ul>
<li>Reviews feel a bit “simplistic” compared to other tools (Memrise, Duolingo).</li>
</ul>
<h2>Memrise</h2>
<figure><a href="../images/memrise.png" target="_blank" rel="noopener noreferrer"><img src="../images/memrise.png" alt=""></a><figcaption>memrise</figcaption></figure>
<p><a href="https://www.memrise.com/" target="_blank" rel="noopener noreferrer">Memrise</a> is a collaborative platform that provides the tools to make you learn almost any kind of content — although it’s used a lot for languages.
People can follow “classes” on the topics they like. It’s a bit like Anki, but more social, you don’t have to create your own card (I know you can download decks for Anki too),
instead, you get to select topics that you want to learn, and start straight away to learn new “words”. You can follow friends, compare your progress, gain “experience”, etc.
The development is pretty active too, so expect to see lot of new features.</p>
<p>To better understand how it works, <a href="http://www.memrise.com/science/" target="_blank" rel="noopener noreferrer">they highlight</a> that Memrise is built on three main “scientific” principles:</p>
<ol>
<li><em>Elaborate encoding</em>: Memrise helps you vividly assimilate new knowledge, promoting deep encoding and superior memory.</li>
<li><em>Choreographed testing</em>: Testing strengthens memories in variety of ways.</li>
<li><em>Scheduled reminders</em>: By spacing reminders, learning can be made up to x3 more efficient.</li>
</ol>
<p>The third “fact” is one of the selling points of the app (according to me). <strong>I like that</strong> they offer a great variety of ways to review stuff:</p>
<ul>
<li><em>[listening]</em> Write German from a German audio record</li>
<li><em>[listening]</em> Select German audio record from an English Sentence</li>
<li><em>[writing]</em> Write English translation from German sentence</li>
<li><em>[writing]</em> Write German from an English sentence</li>
<li><em>[selection]</em> Select English translation from a selection of words</li>
<li><em>[selection]</em> Select English translation from a selection of translations</li>
</ul>
<h4>Pros</h4>
<ul>
<li>Makes you practice <em>listening</em> skill (from and to German) and <em>writing</em> skills in multiple ways (English to German, German to English).</li>
<li>Tests diversity allows the reviews to <em>stay interesting and stimulating</em>.</li>
<li>Remainders to make you <em>review</em> and <em>learn</em> new words.</li>
<li>Allows you to <em>download</em> all the assets of the classes, so that you can practice <em>fully off-line</em>.</li>
</ul>
<h4>Cons</h4>
<ul>
<li><em>Misses the ability to make you speak</em> in German, and this is something Duolingo does.</li>
<li>The classes are more <em>“basic”</em> and a bit less organized than in duolingo.</li>
</ul>
<h2>Duolingo</h2>
<figure><a href="../images/duolingo.png" target="_blank" rel="noopener noreferrer"><img src="../images/duolingo.png" alt=""></a><figcaption>duolingo</figcaption></figure>
<p><a href="https://www.duolingo.com" target="_blank" rel="noopener noreferrer">Duolingo</a> is an application that helps you learn various languages.
It’s a bit more structured than Memrise (as it’s specifically designed to teach languages), and group knowledge by “lessons” that form a kind of <em>“learning unit”</em>.
Behind the scene, it uses more or less the same tools (or at least ideas) to help you remember your lessons:
<em>“Duolingo’s algorithms figure out when you should practice words to get them into your long-term memory.”</em>.
What I find interesting is that, once you master some subject for the first time, you get rewarded by a “strong” power-bar that means it’s still “fresh” in your memory.
Then, as time goes, Duolingo acknowledges that the memory of this particular lesson will fade, and make you review it, just in time to make the memory stronger.</p>
<p>Furthermore, once you get a good mastery of a language, you can access the <a href="https://www.duolingo.com/translations" target="_blank" rel="noopener noreferrer">Immersion</a> section of the application,
that allows you to practice your skills on translation of real content.
And I think this is part of their business model (Duolingo is free and doesn’t make use of ads, it’s a rare thing…).</p>
<h4>Pros</h4>
<ul>
<li>Makes you learn by <em>batch of coherent topics</em>.</li>
<li><em>Difficulty gradually increases</em>.</li>
<li>Experience and progress is pretty smooth.</li>
<li>Great Webapp and mobile app.</li>
<li>Keep track of your progress.</li>
<li><em>Well-structured lessons</em>.</li>
</ul>
<h4>Cons</h4>
<ul>
<li>Exercices could be even more diverse.</li>
<li>Difficult to use with a bad connection.</li>
<li>Any way to download content for off*line usage?</li>
</ul>
<h2>ReadLang</h2>
<p><strong>Edit</strong>: As mentionned in the comments by Steve Ridout (creator of Readlang), I made a few mistakes in my description of ReadLang:</p>
<ol>
<li>Firefox is supported using the <a href="http://readlang.com/webReader" target="_blank" rel="noopener noreferrer">Bookmarks</a>.</li>
<li>There is some support for mobile devices using <a href="https://readlang.uservoice.com/knowledgebase/articles/342854-is-there-a-readlang-android-app" target="_blank" rel="noopener noreferrer">Chrome on android</a> and <a href="https://readlang.uservoice.com/knowledgebase/articles/342855-is-there-a-readlang-ios-ipad-or-iphone-app" target="_blank" rel="noopener noreferrer">Safari on iOS</a>.</li>
<li>You can export your flashcards from the web interface and import it in Anki right away, which is very nice.</li>
</ol>
<figure><a href="../images/readlang.png" target="_blank" rel="noopener noreferrer"><img src="../images/readlang.png" alt=""></a><figcaption>readlang</figcaption></figure>
<p><a href="https://readlang.com/" target="_blank" rel="noopener noreferrer">ReadLang</a> is a bit different from the other tools… at first. It doesn’t seem like it will help you remember stuff, instead,
it’s a wonderful webapp that can assist you in the wild, while you’re reading content on the Internet (blog-posts, news, etc.).
You can see him as your reading companion, always there to offer you a hand while stuck at understanding content in your target language.
It’s a <em>WebReader</em>, that allows you to <em>click on words</em>, or <em>highlight sentences</em> as you read, to translate and speak the text.
It works really well, and is so discrete that you would forget it’s there, if it was not for the little green icon at the top of your screen.</p>
<p>To be totally honest, when I told you ReadLang wasn’t meant to make you remember stuff… <em>I lied!</em>
Because it automatically creates flashcards of words and sentences you translate, so that you can review them later. Like Memrise or Duolingo, it will help you review the right cards at the right time.
It also automatically extract information from online dictionaries to fill the cards, but you can edit them anyway to add even more context.
So it’s pretty full of useful features. But I only started to use it a few days ago, and I’m sure I’ll get to know the tool better in the next weeks/month.</p>
<p>There is a Free version, limited in terms of number of translations per day, but you can get away with 5 dollars per month to unleash its full power.
It’s the only tool I give money for, but it’s worth it. I would also like to mention that this is the work of only one man, Steve Ridout, so <em>kudos</em> to him, because Readlang can compete with applications developed by much larger teams.</p>
<p>The only (small) drawback is that, it’s a little bit less intuitive to use on mobile devices, since there is no native application, but it’s totally doable thanks to the Chrome extension and Bookmarks for Firefox and Safari.</p>
<p>So at the end, I really like Readlang, which offers a unique set of features. It could replace Anki for a day-to-day use, and if you ever need to review your cards offline, you can export your cards and import them in Anki seamlessly.</p>
<h4>Pros</h4>
<ul>
<li>Unique set of features, and <em>all batteries included</em>.</li>
<li><em>Translation</em> and <em>speaking</em> of sentences as you read.</li>
<li>Multiple languages supported.</li>
<li>You can use any online dictionary.</li>
<li><em>Automatic flashcard creation</em>.</li>
<li>Flashcard export to Anki.</li>
<li>Well designed.</li>
</ul>
<h4>Cons</h4>
<ul>
<li>Limited support for mobile (no native application).</li>
<li><s>No support for Firefox</s></li>
</ul>
<p>All this tools help you to review your knowledge in some spaced repetition way.
Memrise and Duolingo are somehow <em>in the same niche</em>, and ReadLang seems to be pretty much as feature-full as Anki.
But I found their approach to be slightly different, and each tool brings its own benefits so I like to use both at the same time… for now.
In the long run, I suspect I would only need either Anki or ReadLang (or both if I can synchronize my cards between ReadLand and Anki), and maybe one of Duolingo or Memrise.</p>
<h2>Adding context</h2>
<p>Context is important because it helps you make links with things you already know, hence, ease the memorization.
There are multiple ways of creating contexts, and the best is to combine them.
The more context you have, the better. Here is what I usually do when I encounter a new word, or sentence:</p>
<ul>
<li>Find an <em>image associated with the word</em> in some way.</li>
<li><em>Speak the words</em>, phrases (en register that in Anki)</li>
<li>Instead of just associating a word in English to a German word, <em>use a canned sentence</em>.</li>
<li>Do I know a word that looks or sound like the new word I’m trying to learn? Maybe, so this is good to write it down on the card too, as a <em>mnemonic</em>.</li>
</ul>
<p>The very fact of looking for context to add to your cards… creates context by itself.
<em>Spending time polishing your cards is good</em>, and will help you remember them.
You can even improve them over time, adding more context, finding new canned sentences, etc.
It takes time, but it’s worth it. You can even create several cards for the same knowledge, but with different contexts.</p>
<p>For example, if I were to remember the word <em>“Todesstern”</em> which means <em>“Death Star”</em>. I can create the following card:</p>
<h3>Front</h3>
<figure><a href="../images/deathstar.jpg" target="_blank" rel="noopener noreferrer"><img src="../images/deathstar.jpg" alt=""></a><figcaption>deathstar</figcaption></figure>
<p><em>“Wie wir sehen, umkreist der &lt;?&gt; den Waldmond Endor.”</em></p>
<h3>Back</h3>
<ul>
<li><em>Speak the word death star in German</em></li>
<li>German Word:“Todesstern”</li>
<li>English Word: “Death Star”</li>
<li>Mnemonic: stern = star and in “todes” we have “des” that we can read as “death”.</li>
</ul>
<h1>What I learned so far</h1>
<p>I’m doing my first steps in German, and I realize that the ecosystem of applications that can help you learn (and in particular, learn a new language), is rich.
There are so much tools that it’s hard to know which one(s) to use.
Moreover, you often find the same features in different tools. But I think it’s already a big win to use at least one tool, even if you chose it randomly,
because almost every apps selling improved memorization use the same kind of methods (spaced increasing reviews), which is <em>much more efficient</em> than a naive learning.
I hope that as I progress, I can take advantage of this tools to learn faster, better and more durably.</p>
<p>Furthermore, I think we shouldn’t take the quest of the best tools as the goal, it’s just a way to ease the learning.
Also, you should prefer being in direct contact with people speaking your target language if you can, and try to learn by speaking, which is invaluable.</p>
<p>To put it in a nutshell:</p>
<ol>
<li>Duolingo and Memrise can help you learn the basics of the language step-by-step, starting with most common words and increasing difficulty smoothly toward more advanced topics.</li>
<li>ReadLang is a companion of choice during your day-to-day reading, it’s non-obstrusive and can greatly help you improve your undestanding of the language, automatically creating flashcard for you to review later.</li>
<li>Anki is a solid choice for card edition and review, but I feel it’s not at all vital if you already use Readlang. It can nonetheless be used in complement when you need to review knowledge without an internet connection or to keep track of new words if you don’t have access to ReadLang for some reason.</li>
</ol>
<h3>References</h3>
<p>For further reading, here are some references.</p>
<h4>From Memrise science page</h4>
<p>V. A. Benassi, C. E. Overson &amp; C. M. Hakala (Eds.) (2014). <em>Applying the science of learning in education: Infusing psychological science into the curriculum</em>. Society for the Teaching of Psychology web site: <a href="http://teachpsych.org/ebooks/asle2014/index.php" target="_blank" rel="noopener noreferrer">http://teachpsych.org/ebooks/asle2014/index.php</a>.</p>
<p>Bjork, R. A., Dunlosky, J. &amp; Kornell, N. (2013). <em>Self-regulated learning: Beliefs, techniques, and illusions</em>. Annual Review of Psychology, 64, 417-444. <a href="http://bjorklab.psych.ucla.edu/pubs/RBjork_Dunlosky_Kornell_2013.pdf" target="_blank" rel="noopener noreferrer">http://bjorklab.psych.ucla.edu/pubs/RBjork_Dunlosky_Kornell_2013.pdf</a>.</p>
<p>Brown, P. C., Roediger, H. L., &amp; McDaniel, M. A. (2014). <em>Make it stick: The science of successful learning</em>. Cambridge, MA: Harvard University Press.</p>
<p>Pashler, H., Bain, P. M., Bottge, B. A., Graesser, A., McDaniel, M. A., &amp; Metcalfe, J. (2007). <em>Organizing instruction and study to improve student learning</em> (NCER Publication No. 2007–2004). Washington, DC: National Center for Education Research, Institute of Education Sciences, U.S. Department of Education. <a href="http://ies.ed.gov/ncee/wwc/pdf/practice_guides/20072004.pdf" target="_blank" rel="noopener noreferrer">http://ies.ed.gov/ncee/wwc/pdf/practice_guides/20072004.pdf</a>.</p>
<p>Potts, R. &amp; Shanks, D. R. (2014). <em>The benefit of generating errors during learning</em>. Journal of Experimental Psychology: General, 143, 644-667. <a href="http://discovery.ucl.ac.uk/1399515/1/RPottsLastRevision.pdf" target="_blank" rel="noopener noreferrer">http://discovery.ucl.ac.uk/1399515/1/RPottsLastRevision.pdf</a></p>
<p>Roediger, H. L., Putnam, A. L., &amp; Smith, M. A. (2011). Ten benefits of testing and their applications to educational practice. In J. Mestre &amp; B. Ross (Eds.), Psychology of learning and motivation: Cognition in education (pp. 1-36). <a href="http://psych.wustl.edu/memory/Roddy%20article%20PDF's/BC_Roediger%20et%20al%20(2011)_PLM.pdf" target="_blank" rel="noopener noreferrer">http://psych.wustl.edu/memory/Roddy%20article%20PDF’s/BC_Roediger%20et%20al%20(2011)_PLM.pdf</a></p>
<h4>Misc posts</h4>
<ul>
<li><a href="http://www.wired.com/2008/04/ff-wozniak/" target="_blank" rel="noopener noreferrer">Want to Remember Everything You’ll Ever Learn? Surrender to this Algorithm</a></li>
<li><a href="https://medium.com/life-learning/how-to-learn-5c6c815051#.7hiowltv7" target="_blank" rel="noopener noreferrer">How to Learn</a></li>
<li><a href="http://www.memrise.com/science" target="_blank" rel="noopener noreferrer">Memrise Science</a></li>
<li><a href="http://fourhourworkweek.com/2014/03/21/how-to-learn-a-foreign-language-2/" target="_blank" rel="noopener noreferrer">12 Rules for Learning Foreign Languages in Record Time</a></li>
</ul>
<p>And much, much more…</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A tour of IHaskell extensions]]></title>
            <link>https://remusao.github.io//posts/ihashell-extensions-tour.html</link>
            <guid>https://remusao.github.io//posts/ihashell-extensions-tour.html</guid>
            <pubDate>Mon, 11 Jan 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<h2>Introduction</h2>
<p>In my previous <a href="https://remusao.github.io/install-ihaskell-on-ubuntu-1404-with-stack.html" target="_blank" rel="noopener noreferrer">post</a>,
I tried to provide a step-by-step explanation of how to install
<a href="https://github.com/gibiansky/IHaskell" target="_blank" rel="noopener noreferrer">IHaskell</a> on Ubuntu 14.04 (Should also
work on other versions). Now is time to start using it!</p>
<p>This post is not a quickstart on how to use IHaskell, as it has already been
covered in the <a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/IHaskell.ipynb" target="_blank" rel="noopener noreferrer">official documentation</a>.
And there are more advanced examples here:</p>
<ul>
<li><a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Conjugate%20Gradient.ipynb" target="_blank" rel="noopener noreferrer">Conjugate Gradient</a></li>
<li><a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Gradient-Descent.ipynb" target="_blank" rel="noopener noreferrer">Gradient Descent</a></li>
<li><a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Homophones.ipynb" target="_blank" rel="noopener noreferrer">Homophones</a></li>
<li><a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Static%20Canvas%20IHaskell%20Display.ipynb" target="_blank" rel="noopener noreferrer">Static Canvas IHaskell Display</a></li>
</ul>
<p>Instead, I’ll focus more on something a bit more mysterious for me:
<em>displaying custom Haskell types in notebooks</em>. I’ll first try to give a
quick explanation on how it works, and then give basic examples of the
provided integrations with existing libraries (aeson, blaze, charts,
diagrams, etc.). I’ll also try to show how to support your custom types.</p>
<p><strong>Disclaimer</strong>: Some of the information found in the post may be
redundant with other sources (like official documentation, and in
particular the last post in the list above: <em>Static Canvas IHaskell
Display</em>), but I hope this post will bring value by giving an overview
of what is possible with <em>IHaskell</em>, explained with the words of a
newcomer. Comments and fixes would be greatly appreciated!</p>
<h2>How does it work?</h2>
<p>Jupyter allows you to embed arbitrary HTML, and this mechanism is used
by IHaskell to display values in custom ways. The <code>IHaskellDisplay</code>
typeclass is used to this effect. By providing an instance for
your own types, they can be displayed in notebooks (we’ll see
later that some extensions already exist to provide such display
to known Haskell libraries). A <code>Display</code> can be of several types,
but for now we will focus on <code>html</code> and <code>plain</code> (see <a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Static%20Canvas%20IHaskell%20Display.ipynb" target="_blank" rel="noopener noreferrer">this notebook</a> for more information).</p>
<p>Note that you can provide several choices of display outputs so that
your custom type can be display in notebooks <em>(html)</em> or console <em>(plain
text)</em>, the frontend will then select the best choice.</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-keyword">import</span> IHaskell.Display

<span class="hljs-comment">-- Custom data type</span>
<span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">Answer</span> = <span class="hljs-type">Answer</span></span>

<span class="hljs-comment">-- Make it &quot;displayable&quot;</span>
<span class="hljs-class"><span class="hljs-keyword">instance</span> <span class="hljs-type">IHaskellDisplay</span> <span class="hljs-type">Answer</span> <span class="hljs-keyword">where</span></span>
    <span class="hljs-comment">-- List of two kinds of Display: html and plain text</span>
    display value = return $ <span class="hljs-type">Display</span> [htmlDisplay, txtDisplay]
        <span class="hljs-keyword">where</span>
            <span class="hljs-comment">-- HTML Display</span>
            htmlDisplay = html <span class="hljs-string">&quot;&lt;div&gt;The answer is 42!&lt;/div&gt;&quot;</span>
            <span class="hljs-comment">-- Plain Text Display</span>
            txtDisplay = plain <span class="hljs-string">&quot;42&quot;</span>

<span class="hljs-comment">-- Display an instance of our type</span>
<span class="hljs-type">Answer</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="sh"><code>The answer is 42!
</code></pre>
</blockquote>
<p>In the following sections we’ll see how to use some of the extensions
officially provided by <em>IHaskell</em> to display types of known libraries.
The packages we’ll need are:</p>
<ul>
<li>ihaskell-basic</li>
<li>ihaskell-aeson</li>
<li>ihaskell-blaze</li>
<li>ihaskell-charts</li>
<li>ihaskell-diagrams</li>
<li>ihaskell-magic</li>
</ul>
<p>You can install them using stack if you intend to try this out yourself:</p>
<pre class="code" data-lang="sh"><code>stack build             \
    ihaskell-basic      \
    ihaskell-aeson      \
    ihaskell-blaze      \
    ihaskell-charts     \
    ihaskell-diagrams   \
    ihaskell-magic
</code></pre>
<h2>ihaskell-basic</h2>
<p>IHaskell <a href="https://hackage.haskell.org/package/ihaskell-basic" target="_blank" rel="noopener noreferrer">basic</a> contains
<em>“Instances of IHaskellDisplay for default prelude data types”</em>. Currently,
only <code>Maybe</code> seems to be supported. Maybe some more <em>Displays</em> will be provided
in the future?</p>
<p>Anyway, here is how you can use it, and what it looks like:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- import IHaskell.Display.Basic</span>
<span class="hljs-type">Just</span> <span class="hljs-number">42</span>
<span class="hljs-type">Just</span> (<span class="hljs-type">Just</span> <span class="hljs-string">&quot;Foo Bar Baz&quot;</span>)
<span class="hljs-type">Nothing</span>
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Just</span> <span class="hljs-number">42</span>
<span class="hljs-type">Just</span> <span class="hljs-type">Just</span> <span class="hljs-string">&quot;Foo Bar Baz&quot;</span>
<span class="hljs-type">Nothing</span>
</code></pre>
</blockquote>
<h2>ihaskell-aeson</h2>
<p><a href="https://hackage.haskell.org/package/aeson" target="_blank" rel="noopener noreferrer">Aeson</a> is a library used to
manipulate <em>JSON</em> format from Haskell. It allows you to use <code>ToJSON</code> and
<code>FromJSON</code> typeclasses to convert your custom data-types <em>to</em> and <em>from</em>
JSON format.</p>
<p>In our small example, we declare a type of document with an arbitrary
number of metadata attached, here is how we could do it:</p>
<pre class="code" data-lang="haskell"><code>:extension <span class="hljs-type">OverloadedStrings</span>

<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.Text <span class="hljs-keyword">as</span> T
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.Aeson <span class="hljs-keyword">as</span> A
<span class="hljs-comment">-- IHaskell.Display.Aeson</span>

<span class="hljs-class"><span class="hljs-keyword">newtype</span> <span class="hljs-type">Property</span> = <span class="hljs-type">Property</span> <span class="hljs-type">T</span>.<span class="hljs-type">Text</span></span>
<span class="hljs-class"><span class="hljs-keyword">newtype</span> <span class="hljs-type">Value</span> = <span class="hljs-type">Value</span> <span class="hljs-type">T</span>.<span class="hljs-type">Text</span></span>
<span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">Metadata</span> = <span class="hljs-type">Metadata</span> [(<span class="hljs-type">Property</span>, <span class="hljs-type">Value</span>)]</span>

<span class="hljs-class"><span class="hljs-keyword">newtype</span> <span class="hljs-type">Body</span> = <span class="hljs-type">Body</span> <span class="hljs-type">T</span>.<span class="hljs-type">Text</span></span>
<span class="hljs-class"><span class="hljs-keyword">newtype</span> <span class="hljs-type">Title</span> = <span class="hljs-type">Title</span> <span class="hljs-type">T</span>.<span class="hljs-type">Text</span></span>
<span class="hljs-class"><span class="hljs-keyword">data</span> <span class="hljs-type">Document</span>  = <span class="hljs-type">Document</span></span>
    { _title :: <span class="hljs-type">Title</span>
    , _body :: <span class="hljs-type">Body</span>
    , _metadata :: <span class="hljs-type">Metadata</span>}
<span class="hljs-class">
<span class="hljs-keyword">instance</span> <span class="hljs-type">A</span>.<span class="hljs-type">ToJSON</span> <span class="hljs-type">Metadata</span> <span class="hljs-keyword">where</span></span>
   toJSON (<span class="hljs-type">Metadata</span> d) = <span class="hljs-type">A</span>.object $ [p <span class="hljs-type">A</span>..= v | (<span class="hljs-type">Property</span> p, <span class="hljs-type">Value</span> v) &lt;- d]
<span class="hljs-class">
<span class="hljs-keyword">instance</span> <span class="hljs-type">A</span>.<span class="hljs-type">ToJSON</span> <span class="hljs-type">Document</span> <span class="hljs-keyword">where</span></span>
   toJSON (<span class="hljs-type">Document</span> (<span class="hljs-type">Title</span> t) (<span class="hljs-type">Body</span> b) m) = <span class="hljs-type">A</span>.object [
       <span class="hljs-string">&quot;title&quot;</span> <span class="hljs-type">A</span>..= t,
       <span class="hljs-string">&quot;body&quot;</span> <span class="hljs-type">A</span>..= b,
       <span class="hljs-string">&quot;metadata&quot;</span> <span class="hljs-type">A</span>..= <span class="hljs-type">A</span>.toJSON m]

<span class="hljs-title">document</span> = <span class="hljs-keyword">let</span> body = <span class="hljs-type">Body</span> <span class="hljs-string">&quot;Lorem Ipsum&quot;</span>
               title = <span class="hljs-type">Title</span> <span class="hljs-string">&quot;Foo Bar&quot;</span>
               metadata = <span class="hljs-type">Metadata</span> [
                   (<span class="hljs-type">Property</span> <span class="hljs-string">&quot;Encoding&quot;</span>, <span class="hljs-type">Value</span> <span class="hljs-string">&quot;UTF-8&quot;</span>),
                   (<span class="hljs-type">Property</span> <span class="hljs-string">&quot;Author&quot;</span>, <span class="hljs-type">Value</span> <span class="hljs-string">&quot;Jonh Doe&quot;</span>)]
           <span class="hljs-keyword">in</span> <span class="hljs-type">Document</span> {_title=title, _body=body, _metadata=metadata }

<span class="hljs-type">A</span>.<span class="hljs-type">Null</span>
<span class="hljs-type">A</span>.<span class="hljs-type">Bool</span> <span class="hljs-type">True</span>
<span class="hljs-type">A</span>.toJSON document
</code></pre>
<blockquote>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">null</span>

<span class="hljs-title">true</span>

{
    <span class="hljs-string">&quot;body&quot;</span>: <span class="hljs-string">&quot;Lorem Ipsum&quot;</span>,
    <span class="hljs-string">&quot;metadata&quot;</span>: {
        <span class="hljs-string">&quot;Author&quot;</span>: <span class="hljs-string">&quot;Jonh Doe&quot;</span>,
        <span class="hljs-string">&quot;Encoding&quot;</span>: <span class="hljs-string">&quot;UTF-8&quot;</span>
    },
    <span class="hljs-string">&quot;title&quot;</span>: <span class="hljs-string">&quot;Foo Bar&quot;</span>
}
</code></pre>
</blockquote>
<h2>ihaskell-blaze</h2>
<p><a href="https://hackage.haskell.org/package/blaze-html" target="_blank" rel="noopener noreferrer">Blaze</a> is a fast combinator library used to assemble <em>HTML</em> documents directly in Haskell code <em>(<a href="https://wiki.haskell.org/Embedded_domain_specific_language" target="_blank" rel="noopener noreferrer">Embedded Domain Specific Language</a>)</em>. According to the official description, <em>“the project is aimed at those who seek to write web applications in Haskell – it integrates well with all Haskell web frameworks.”</em></p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This example if from the IHaskell official introduction</span>
:extension <span class="hljs-type">OverloadedStrings</span>

<span class="hljs-comment">-- import IHaskell.Display.Blaze</span>
<span class="hljs-keyword">import</span> Control.Monad
<span class="hljs-keyword">import</span> Prelude <span class="hljs-keyword">hiding</span> (<span class="hljs-title">div</span>, <span class="hljs-title">id</span>)
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Text.Blaze.Html4.Strict <span class="hljs-keyword">as</span> B
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Text.Blaze.Html4.Strict.Attributes <span class="hljs-keyword">as</span> A

<span class="hljs-title">forM</span> [<span class="hljs-number">1</span>..<span class="hljs-number">5</span>] $ \size -&gt; <span class="hljs-keyword">do</span>
  <span class="hljs-keyword">let</span> s = <span class="hljs-type">B</span>.toValue $ size * <span class="hljs-number">70</span>
  <span class="hljs-type">B</span>.img <span class="hljs-type">B</span>.! <span class="hljs-type">A</span>.src <span class="hljs-string">&quot;https://www.google.com/images/srpr/logo11w.png&quot;</span> <span class="hljs-type">B</span>.! <span class="hljs-type">A</span>.width s
</code></pre>
<img src="../images/google-logo.png" width="70">
<img src="../images/google-logo.png" width="140">
<img src="../images/google-logo.png" width="210">
<img src="../images/google-logo.png" width="280">
<img src="../images/google-logo.png" width="350">
<h2>ihaskell-charts</h2>
<p><a href="https://hackage.haskell.org/package/Chart" target="_blank" rel="noopener noreferrer">Charts</a> is a <em>“2D charting library for haskell”</em>. Here a two examples taken from the <a href="https://github.com/timbod7/haskell-chart/wiki" target="_blank" rel="noopener noreferrer">official wiki</a> on github. To adapt examples to notebooks, you must replace any reference of <code>toFile</code>, etc. by <code>toRenderable</code>.</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This example is taken from the wiki: https://github.com/timbod7/haskell-chart/wiki/example%205</span>
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Graphics.Rendering.Chart.Easy <span class="hljs-keyword">as</span> E

<span class="hljs-title">values</span> :: [(<span class="hljs-type">String</span>, <span class="hljs-type">Double</span>, <span class="hljs-type">Bool</span>)]
<span class="hljs-title">values</span> = [ (<span class="hljs-string">&quot;Mexico City&quot;</span>, <span class="hljs-number">19.2</span>, <span class="hljs-type">False</span>)
         , (<span class="hljs-string">&quot;Mumbai&quot;</span>, <span class="hljs-number">12.9</span>, <span class="hljs-type">False</span>)
         , (<span class="hljs-string">&quot;Sydney&quot;</span>, <span class="hljs-number">4.3</span>, <span class="hljs-type">False</span>)
         , (<span class="hljs-string">&quot;London&quot;</span>, <span class="hljs-number">8.3</span>, <span class="hljs-type">False</span>)
         , (<span class="hljs-string">&quot;New York&quot;</span>,<span class="hljs-number">8.2</span>,<span class="hljs-type">True</span>)]

<span class="hljs-title">pitem</span> (s, v, o) = <span class="hljs-type">E</span>.pitem_value <span class="hljs-type">E</span>..~ v
              $ <span class="hljs-type">E</span>.pitem_label <span class="hljs-type">E</span>..~ s
              $ <span class="hljs-type">E</span>.pitem_offset <span class="hljs-type">E</span>..~ (<span class="hljs-keyword">if</span> o <span class="hljs-keyword">then</span> <span class="hljs-number">25</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)
              $ <span class="hljs-type">E</span>.def

<span class="hljs-type">E</span>.toRenderable
  $ <span class="hljs-type">E</span>.pie_title <span class="hljs-type">E</span>..~ <span class="hljs-string">&quot;Relative Population&quot;</span>
  $ <span class="hljs-type">E</span>.pie_plot . <span class="hljs-type">E</span>.pie_data <span class="hljs-type">E</span>..~ map pitem values
  $ <span class="hljs-type">E</span>.def
</code></pre>
<figure><a href="../images/ihaskell-chart.svg" target="_blank" rel="noopener noreferrer"><img src="../images/ihaskell-chart.svg" alt=""></a><figcaption>pie chart</figcaption></figure>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- This example is taken from the wiki: https://github.com/timbod7/haskell-chart/wiki/example%2012</span>
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Graphics.Rendering.Chart.Easy <span class="hljs-keyword">as</span> E

<span class="hljs-title">r&#x27;</span> x y z = sqrt $ x^<span class="hljs-number">2</span> + y^<span class="hljs-number">2</span> + z^<span class="hljs-number">2</span>
<span class="hljs-title">efield</span> sign x y = (sign * x / r, sign * y / r) <span class="hljs-keyword">where</span> r = r&#x27; x y <span class="hljs-number">10</span>
<span class="hljs-title">bfield</span> sign x y = (-sign * y / r^<span class="hljs-number">2</span>, sign * x / r^<span class="hljs-number">2</span>) <span class="hljs-keyword">where</span> r = r&#x27; x y <span class="hljs-number">10</span>
<span class="hljs-title">square</span> a s = [(x, y) | x &lt;- range, y &lt;- range] <span class="hljs-keyword">where</span> range = [-a, -a + s..a] :: [<span class="hljs-type">Double</span>]
<span class="hljs-title">add</span> (x1, y1) (x2, y2) = (x1 + x2, y1 + y2)

<span class="hljs-title">ef</span> (x, y) = efield <span class="hljs-number">1</span> (x - <span class="hljs-number">20</span>) y `add` efield (-<span class="hljs-number">1</span>) (x + <span class="hljs-number">20</span>) y
<span class="hljs-title">bf</span> (x, y) = bfield <span class="hljs-number">1</span> (x - <span class="hljs-number">20</span>) y `add` bfield (-<span class="hljs-number">1</span>) (x + <span class="hljs-number">20</span>) y
<span class="hljs-title">grid</span> = square <span class="hljs-number">30</span> <span class="hljs-number">3</span>

<span class="hljs-title">vectorField</span> title f grid = fmap <span class="hljs-type">E</span>.plotVectorField $ <span class="hljs-type">E</span>.liftEC $ <span class="hljs-keyword">do</span>
    c &lt;- <span class="hljs-type">E</span>.takeColor
    <span class="hljs-type">E</span>.plot_vectors_mapf <span class="hljs-type">E</span>..= f
    <span class="hljs-type">E</span>.plot_vectors_grid <span class="hljs-type">E</span>..= grid
    <span class="hljs-type">E</span>.plot_vectors_style . <span class="hljs-type">E</span>.vector_line_style . <span class="hljs-type">E</span>.line_color <span class="hljs-type">E</span>..= c
    <span class="hljs-type">E</span>.plot_vectors_style . <span class="hljs-type">E</span>.vector_head_style . <span class="hljs-type">E</span>.point_color <span class="hljs-type">E</span>..= c
    <span class="hljs-type">E</span>.plot_vectors_title <span class="hljs-type">E</span>..= title

<span class="hljs-title">main</span> = <span class="hljs-type">E</span>.toRenderable $ <span class="hljs-keyword">do</span>
    <span class="hljs-type">E</span>.setColors [<span class="hljs-type">E</span>.opaque <span class="hljs-type">E</span>.black, <span class="hljs-type">E</span>.opaque <span class="hljs-type">E</span>.blue]

    <span class="hljs-type">E</span>.layout_title <span class="hljs-type">E</span>..= <span class="hljs-string">&quot;Positive and Negative Charges&quot;</span>
    <span class="hljs-type">E</span>.plot $ vectorField <span class="hljs-string">&quot;Electric Field&quot;</span> ef grid
    <span class="hljs-type">E</span>.plot $ vectorField <span class="hljs-string">&quot;B-field&quot;</span> bf grid
<span class="hljs-title">main</span>
</code></pre>
<figure><a href="../images/ihaskell-field.svg" target="_blank" rel="noopener noreferrer"><img src="../images/ihaskell-field.svg" alt=""></a><figcaption>field</figcaption></figure>
<h2>ihaskell-diagrams</h2>
<p><a href="http://projects.haskell.org/diagrams/" target="_blank" rel="noopener noreferrer">Diagrams</a> is a <em>“powerful, flexible, declarative domain-specific language for creating vector graphics”</em>. That is, it provides a flexible embedded DSL used to describe vectorized figures that you can then render using different backends.</p>
<pre class="code" data-lang="haskell"><code>:extension <span class="hljs-type">NoMonomorphismRestriction</span>
:extension <span class="hljs-type">FlexibleContexts</span>
:extension <span class="hljs-type">GADTs</span>

<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Diagrams.Prelude <span class="hljs-keyword">as</span> D
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Diagrams.TwoD.Sunburst <span class="hljs-keyword">as</span> S
<span class="hljs-keyword">import</span> Data.Tree (<span class="hljs-title">unfoldTree</span>)

<span class="hljs-title">aTree</span> = unfoldTree (\n -&gt; (<span class="hljs-number">0</span>, replicate n (n - <span class="hljs-number">1</span>))) <span class="hljs-number">6</span>
<span class="hljs-title">diagram</span> $ <span class="hljs-type">S</span>.sunburst aTree <span class="hljs-type">D</span>.# <span class="hljs-type">D</span>.centerXY <span class="hljs-type">D</span>.# <span class="hljs-type">D</span>.pad <span class="hljs-number">1.1</span>
</code></pre>
<figure><a href="../images/ihaskell-diagram1.svg" target="_blank" rel="noopener noreferrer"><img src="../images/ihaskell-diagram1.svg" alt=""></a><figcaption>field</figcaption></figure>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- import Diagrams.Backend.SVG.CmdLine as</span>
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Diagrams.Prelude <span class="hljs-keyword">as</span> D
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Diagrams.TwoD.Factorization <span class="hljs-keyword">as</span> F

<span class="hljs-title">diagram</span> $ <span class="hljs-type">F</span>.fdGridList <span class="hljs-number">6</span> <span class="hljs-type">D</span>.# <span class="hljs-type">D</span>.center <span class="hljs-type">D</span>.# <span class="hljs-type">D</span>.pad <span class="hljs-number">1.05</span>
</code></pre>
<figure><a href="../images/ihaskell-diagram2.svg" target="_blank" rel="noopener noreferrer"><img src="../images/ihaskell-diagram2.svg" alt=""></a><figcaption>field</figcaption></figure>
<h2>ihaskell-magic</h2>
<p>In this case, libmagic is used to determine type of files using magic
values at the beginning, which allows us to display binary content in
notebooks, in the right way. For example, if we want to display an
image (png, jpeg, svg, etc.), we just have to read its content as a
<code>ByteString</code>, then <code>libmagic</code> is used behind the scene by <em>IHaskell</em> to
determine what kind of content it is, based on the magic bytes present
in the file, and then inline it in the notebook.</p>
<p>What is important to understand here, is that an instance of
IHaskellDisplay is defined for both <code>ByteString</code> and <code>Text</code>, in case
this strings represent something else than text (images, for example),
<em>IHaskell</em> is able to know it thanks to <code>libmagic</code> and display the content
accordingly, otherwise, it just displays the string.</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.ByteString <span class="hljs-keyword">as</span> B
<span class="hljs-type">B</span>.readFile <span class="hljs-string">&quot;./haskell-logo.png&quot;</span>
</code></pre>
<figure><a href="../images/output_25_0.png" target="_blank" rel="noopener noreferrer"><img src="../images/output_25_0.png" alt=""></a><figcaption>Haskell logo</figcaption></figure>
<pre class="code" data-lang="haskell"><code>:extension <span class="hljs-type">OverloadedStrings</span>
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.ByteString <span class="hljs-keyword">as</span> B
<span class="hljs-string">&quot;This is a string of type ByteString&quot;</span> :: <span class="hljs-type">B</span>.<span class="hljs-type">ByteString</span>
</code></pre>
<pre class="code" data-lang="sh"><code>This is a string of <span class="hljs-built_in">type</span> ByteString
</code></pre>
<pre class="code" data-lang="haskell"><code>:extension <span class="hljs-type">OverloadedStrings</span>
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.Text <span class="hljs-keyword">as</span> T
<span class="hljs-string">&quot;This is a string of type Text&quot;</span> :: <span class="hljs-type">T</span>.<span class="hljs-type">Text</span>
</code></pre>
<pre class="code" data-lang="sh"><code>This is a string of <span class="hljs-built_in">type</span> Text
</code></pre>
<h2>ihaskell-static-canvas</h2>
<p>Following on the <a href="https://github.com/gibiansky/IHaskell/blob/master/notebooks/Static%20Canvas%20IHaskell%20Display.ipynb" target="_blank" rel="noopener noreferrer">excellent introduction</a>
from the author of <em>IHaskell</em>. Let’s try to use
<a href="https://github.com/jeffreyrosenbluth/static-canvas" target="_blank" rel="noopener noreferrer">static-canvas</a> to
create more elaborate inlings in notebooks! The github page is full
of <a href="" target="_blank" rel="noopener noreferrer">examples</a> that we can try out right now. But before that, we
must create an instance of <code>IHaskellDisplay</code> for <code>CanvasFree</code> (which
is taken directly from the mentionned tutorial (I hope it’s Ok, since
<code>ihaskell-static-canvas</code> doesn’t seem to be part of Stackage LTS at the
moment).</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-keyword">import</span> IHaskell.Display <span class="hljs-comment">-- From the &#x27;ihaskell&#x27; package.</span>
<span class="hljs-keyword">import</span> IHaskell.IPython.Types (<span class="hljs-type">MimeType(..)</span>)
<span class="hljs-keyword">import</span> Graphics.Static  <span class="hljs-comment">-- From the &#x27;static-canvas&#x27; package.</span>

<span class="hljs-comment">-- Text conversion functions.</span>
<span class="hljs-keyword">import</span> Data.Text.Lazy.Builder (<span class="hljs-title">toLazyText</span>)
<span class="hljs-keyword">import</span> Data.Text.Lazy (<span class="hljs-title">toStrict</span>)
</code></pre>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">-- Since CanvasFree is a type synonym, we need a language pragma.</span>
:extension <span class="hljs-type">TypeSynonymInstances</span>
:extension <span class="hljs-type">FlexibleInstances</span>
<span class="hljs-class">
<span class="hljs-keyword">instance</span> <span class="hljs-type">IHaskellDisplay</span> (<span class="hljs-type">CanvasFree</span> ()) <span class="hljs-keyword">where</span></span>
  <span class="hljs-comment">-- display :: CanvasFree () -&gt; IO Display</span>
  display canvas = return $
    <span class="hljs-keyword">let</span> src = toStrict
      $ toLazyText
      $ buildScript width height canvas
    <span class="hljs-keyword">in</span> <span class="hljs-type">Display</span> [<span class="hljs-type">DisplayData</span> <span class="hljs-type">MimeHtml</span> src]
    <span class="hljs-keyword">where</span> (height, width) = (<span class="hljs-number">200</span>, <span class="hljs-number">600</span>)
</code></pre>
<p>Now let’s try some example:</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-keyword">import</span> Graphics.Static
<span class="hljs-keyword">import</span> Graphics.Static.ColorNames

<span class="hljs-title">text</span> :: <span class="hljs-type">CanvasFree</span> ()
<span class="hljs-title">text</span> = <span class="hljs-keyword">do</span>
  font <span class="hljs-string">&quot;italic 60pt Calibri&quot;</span>
  lineWidth <span class="hljs-number">6</span>
  strokeStyle blue
  fillStyle goldenrod
  textBaseline <span class="hljs-type">TextBaselineMiddle</span>
  strokeText <span class="hljs-string">&quot;Haskell&quot;</span> <span class="hljs-number">150</span> <span class="hljs-number">100</span>
  fillText <span class="hljs-string">&quot;Haskell!&quot;</span> <span class="hljs-number">150</span> <span class="hljs-number">100</span>

<span class="hljs-title">text</span>
</code></pre>
<figure><a href="../images/ihaskell-canvas.png" target="_blank" rel="noopener noreferrer"><img src="../images/ihaskell-canvas.png" alt=""></a></figure>
<h2>Conclusion</h2>
<p>This was a short introduction without much new stuff, but it gave me a
better understanding on how <em>IHaskell</em> (and in a way, <em>Jupyter</em>) works.
Thanks to the awesome work of some haskellers, we are able to benefit
from the great <em>Jupyter</em> ecosystem, and I think it can bring a lot to
<em>Haskell</em> itself. It’s easier to share code, easier to write about
<em>Haskell</em>-related stuff, easier to dig into a new projet.</p>
<p><em>IHaskell</em> is a solid foundation for more to come: more widgets, more
integrations with <em>Haskell</em> libraries, etc. I wonder if, for example, we
could use <em>Blaze</em> to generate <em>Display</em> on-the-fly? Could we reuse some
code from the <em>Python</em> Kernel of <em>Jupyter</em>? I’m also looking forward to
try the <code>ihaskell-widgets</code> extension.</p>
<p>That’s pretty much it, I’d like to say I’m very excited for Haskell,
because it becomes much more accessible for newcomers, thanks to (for
example) Stack, IHaskell, and lot of effort that is being made by the
community. I hope I can continue to contribute at my level to this
effort!</p>
<p>Thanks for reading!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Installing IHaskell on Ubuntu 14.04 with Stack]]></title>
            <link>https://remusao.github.io//posts/ihaskell-ubuntu-14-04-install.html</link>
            <guid>https://remusao.github.io//posts/ihaskell-ubuntu-14-04-install.html</guid>
            <pubDate>Thu, 07 Jan 2016 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>In this post, we’re going through the installation of IHaskell on
GNU/Linux (Ubuntu 14.04 in my case, though it should be pretty similar
on other ditributions) step-by-step. We’ll see how the use of <em>Stack</em>
will simplify the whole process, and how to get all the dependencies
right!</p>
<h2>Install Stack</h2>
<p>From <em>Stack</em> official <a href="http://docs.haskellstack.org/en/stable/install_and_upgrade.html" target="_blank" rel="noopener noreferrer">documentation</a>, for Ubuntu 14.04:</p>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">sudo</span> apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 575159689BEFB442
<span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;deb http://download.fpcomplete.com/ubuntu trusty main&#x27;</span> \
    |<span class="hljs-built_in">sudo</span> <span class="hljs-built_in">tee</span> /etc/apt/sources.list.d/fpco.list
<span class="hljs-built_in">sudo</span> apt-get update &amp;&amp; <span class="hljs-built_in">sudo</span> apt-get install stack -y
</code></pre>
<p>You should now be able to run the <code>stack</code> executable in a shell:</p>
<pre class="code" data-lang="sh"><code>stack --<span class="hljs-built_in">help</span>
</code></pre>
<p>Being up-to-date is important, so setup your <em>Stack</em> global configuration <code>~/.stack/global/stack.yaml</code>:</p>
<pre class="code" data-lang="yaml"><code><span class="hljs-attr">flags:</span> {}
<span class="hljs-attr">resolver:</span> <span class="hljs-string">lts-4.0</span>
<span class="hljs-attr">packages:</span> []
<span class="hljs-attr">extra-deps:</span> []
</code></pre>
<p>Tell <em>Stack</em> to setup everything (download package list, install latest <em>GHC</em> release, etc.):</p>
<pre class="code" data-lang="sh"><code>stack setup
</code></pre>
<p>Note that you can lookup the latest release of stackage at anytime on this <a href="http://www.stackage.org/lts" target="_blank" rel="noopener noreferrer">page</a>.</p>
<h2>Install ZeroMQ latest version</h2>
<p>If you try to install IHaskell directly, you’ll get an error since Ubuntu 14.04 ships with an older version of ZeroMQ. We need a more recent release. There are several ways to install it:</p>
<ol>
<li>Compile it from source</li>
<li>Use Nix</li>
</ol>
<p>We’re going to compile it from source. I’ll follow the way of the official <a href="https://github.com/gibiansky/IHaskell#install-zeromq" target="_blank" rel="noopener noreferrer">README</a>:</p>
<pre class="code" data-lang="sh"><code><span class="hljs-comment"># Compiling from source:</span>
git <span class="hljs-built_in">clone</span> git@github.com:zeromq/zeromq4-x.git libzmq
<span class="hljs-built_in">cd</span> libzmq
./autogen.sh &amp;&amp; ./configure &amp;&amp; make
<span class="hljs-built_in">sudo</span> make install
<span class="hljs-built_in">sudo</span> ldconfig
</code></pre>
<p>That will do the trick! If you don’t like to install packages in global scope, feel free to install it in a user folder (Add the <code>--prefix=LOCATION</code> directive to <code>./configure</code>, and change <code>LD_LIBRARY_PATH</code> and <code>PATH</code> in your shell configuration accordingly).</p>
<h2>Install Jupyter</h2>
<p><strong>EDIT</strong>: Following Florian’s comment, it appears that <em>IPython</em> is now officialy named <em>Jupyter</em>, so we might as well install it in our virtualenv. The only change in the instructions is to replace <code>pip install ipython</code> by <code>pip install jupyter</code> (Note that <em>IPython</em> is a dependency of <em>Jupyter</em>).</p>
<p>IHaskell requires a recent version of <em>Jupyter</em>, so we need to install it ourselves. There are several options:</p>
<ol>
<li>Use pip and install it globaly (<code>pip install jupyter</code>)</li>
<li>Use pip and install it in a virtualenv (<strong>This is what we will do here</strong>)</li>
<li>Use <a href="https://nixos.org/nix/" target="_blank" rel="noopener noreferrer">nix</a> <em>(You’re on your own)</em></li>
<li>Use <a href="https://www.continuum.io/downloads" target="_blank" rel="noopener noreferrer">conda</a> (<code>conda update jupyter</code>)</li>
</ol>
<p>If you’re on a fresh install: <code>sudo apt-get install python-virtualenv python-dev ncurses-base</code></p>
<p>With <code>virtualenv</code>:</p>
<pre class="code" data-lang="sh"><code>virtualenv venv-ihaskell
<span class="hljs-built_in">source</span> venv-ihaskell/bin/activate
</code></pre>
<p>With <code>virtualenvwrapper</code>:</p>
<pre class="code" data-lang="sh"><code>mkvirtualenv ihaskell
workon ihaskell
</code></pre>
<p>Now we install <em>Jupyter</em>:</p>
<pre class="code" data-lang="sh"><code>pip install jupyter
</code></pre>
<h2>Install IHaskell</h2>
<p>Nothing simpler, just use <em>Stack</em>:</p>
<pre class="code" data-lang="sh"><code>stack build ihaskell
</code></pre>
<p>You may want to install extra packages to enhance <em>IHaskell</em> capabilities. Here are the ones supported by Stackage:</p>
<ul>
<li>ihaskell-aeson</li>
<li>ihaskell-blaze</li>
<li>ihaskell-charts</li>
<li>ihaskell-diagrams</li>
<li>ihaskell-rlangqq</li>
<li>ihaskell-magic</li>
<li>ihaskell-juicypixels</li>
<li>ihaskell-hatex</li>
<li>ihaskell-basic</li>
</ul>
<p>Some others are not in the LTS snapshot of Stackage, but could be useful in the future. I don’t know about the current maturity of these packages:</p>
<ul>
<li>ihaskell-widgets (conflict with current version of singletons)</li>
<li>ihaskell-parsec (conflict with current version of aeson)</li>
<li>ihaskell-plot</li>
</ul>
<h2>Setup IHaskell</h2>
<p>If everything went well, you should have <em>Jupyter</em> (latest version) and <em>ihaskell</em> installed properly. The last step is to install the <em>IHaskell Kernel</em> into <em>Jupyter</em>.</p>
<pre class="code" data-lang="sh"><code>stack <span class="hljs-built_in">exec</span> ihaskell -- install
</code></pre>
<p>Now run the notebook server and enjoy:</p>
<pre class="code" data-lang="sh"><code>stack <span class="hljs-built_in">exec</span> jupyter -- notebook
</code></pre>
<p>Open your browser and go to: <code>http://localhost:8000</code></p>
<h2>What’s next</h2>
<p>Thanks to Stack, the install process went very smoothely (appart from some dependency we had to install ourselves).
Using IPython with a Haskell Kernel I believe writing about Haskell will be a much pleasant experience since it’s really easy
to export a notebook either in HTML or Markdown.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pytest—Paramaterize tests with external data]]></title>
            <link>https://remusao.github.io//posts/pytest-param.html</link>
            <guid>https://remusao.github.io//posts/pytest-param.html</guid>
            <pubDate>Wed, 26 Nov 2014 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I recently began to make heavy use of <a href="http://pytest.org/latest/" target="_blank" rel="noopener noreferrer">pytest</a>
in my day-to-day Python development. It’s a wonderful tool, but I won’t
explain to you every features it provides and why it’s awesome. Instead,
I’ll explain how I managed to cleanly externalize the data used for my
tests in external files (that can be of any format: yaml, json, python
files). The idea here is to <em>separate the code that performs the test</em>,
from the <em>input data used to perform the test</em>.</p>
<ul>
<li><em>test_feature.py</em></li>
</ul>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_my_feature</span>(<span class="hljs-params">one_example</span>):
    <span class="hljs-keyword">assert</span> one_example
</code></pre>
<ul>
<li><em>data_feature.yaml</em></li>
</ul>
<pre class="code" data-lang="yaml"><code><span class="hljs-attr">tests:</span>
    <span class="hljs-attr">test1:</span>
        <span class="hljs-string">...</span>
    <span class="hljs-attr">test2:</span>
        <span class="hljs-string">...</span>
</code></pre>
<h2>First solution: yield</h2>
<p>The first solution would be to use <code>yield</code> to generate tests, as it’s supported
by <code>py.test</code> (as long as you don’t want to use fixtures in your test function…).</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">check</span>(<span class="hljs-params">example</span>):
    <span class="hljs-comment"># perform your test</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_feature</span>():
    <span class="hljs-keyword">for</span> test <span class="hljs-keyword">in</span> generate_tests():
        <span class="hljs-keyword">yield</span> check, test
</code></pre>
<p>Here, <code>py.test</code> will understand that <code>test_feature</code> will yield several tests and that
the <code>check</code> function must be used to perform the test, so it is almost equivalent to do:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_feature</span>():
    <span class="hljs-keyword">for</span> test <span class="hljs-keyword">in</span> generate_tests():
        check(test)
</code></pre>
<p>Except that in this last snippet of code, the tests will stop as soon as one fails.
With the <code>yield</code>-version, every tests will be ran even if some fail. This is useful
if you have lot of tests, and you want to know which ones fail (not just the first one).</p>
<p><strong>Problem</strong>: if you want to use fixtures with your <code>test_feature</code> functions, it breaks:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">check</span>(<span class="hljs-params">example</span>):
    <span class="hljs-comment"># perform your test</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_feature</span>(<span class="hljs-params">my_fixture</span>):
    <span class="hljs-keyword">for</span> test <span class="hljs-keyword">in</span> generate_tests():
        <span class="hljs-keyword">yield</span> check, test
</code></pre>
<p>This will tell you that <code>test_feature</code> expects one argument but that none are provided.</p>
<p>End of the story…
Wait, no, <code>py.test</code> is awesome remember? So there must be a solution!</p>
<h2>Parametrization</h2>
<p>One of the cool features of <code>py.test</code> is the ability to add parameters on our
tests or fixtures, so that a test is ran once for each parameter (from <a href="http://pytest.org/latest/parametrize.html" target="_blank" rel="noopener noreferrer">py.test doc</a>):</p>
<pre class="code" data-lang="python"><code><span class="hljs-comment"># content of test_expectation.py</span>
<span class="hljs-keyword">import</span> pytest
<span class="hljs-meta">@pytest.mark.parametrize(<span class="hljs-params"><span class="hljs-string">&quot;input,expected&quot;</span>, [
    (<span class="hljs-params"><span class="hljs-string">&quot;3+5&quot;</span>, <span class="hljs-number">8</span></span>),
    (<span class="hljs-params"><span class="hljs-string">&quot;2+4&quot;</span>, <span class="hljs-number">6</span></span>),
    (<span class="hljs-params"><span class="hljs-string">&quot;6*9&quot;</span>, <span class="hljs-number">42</span></span>),
]</span>)</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_eval</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, expected</span>):
    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">eval</span>(<span class="hljs-built_in">input</span>) == expected
</code></pre>
<pre class="code" data-lang="python"><code>$ py.test
=========================== test session starts ============================
platform linux -- Python <span class="hljs-number">3.4</span><span class="hljs-number">.0</span> -- py-<span class="hljs-number">1.4</span><span class="hljs-number">.26</span> -- pytest-<span class="hljs-number">2.6</span><span class="hljs-number">.4</span>
collected <span class="hljs-number">3</span> items

test_expectation.py ..F

================================= FAILURES =================================
____________________________ test_eval[<span class="hljs-number">6</span>*<span class="hljs-number">9</span>-<span class="hljs-number">42</span>] _____________________________

<span class="hljs-built_in">input</span> = <span class="hljs-string">&#x27;6*9&#x27;</span>, expected = <span class="hljs-number">42</span>

<span class="hljs-meta">    @pytest.mark.parametrize(<span class="hljs-params"><span class="hljs-string">&quot;input,expected&quot;</span>, [
        (<span class="hljs-params"><span class="hljs-string">&quot;3+5&quot;</span>, <span class="hljs-number">8</span></span>),
        (<span class="hljs-params"><span class="hljs-string">&quot;2+4&quot;</span>, <span class="hljs-number">6</span></span>),
        (<span class="hljs-params"><span class="hljs-string">&quot;6*9&quot;</span>, <span class="hljs-number">42</span></span>),
    ]</span>)</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_eval</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, expected</span>):
&gt;       <span class="hljs-keyword">assert</span> <span class="hljs-built_in">eval</span>(<span class="hljs-built_in">input</span>) == expected
E       <span class="hljs-keyword">assert</span> <span class="hljs-number">54</span> == <span class="hljs-number">42</span>
E        +  where <span class="hljs-number">54</span> = <span class="hljs-built_in">eval</span>(<span class="hljs-string">&#x27;6*9&#x27;</span>)

test_expectation.py:<span class="hljs-number">8</span>: AssertionError
==================== <span class="hljs-number">1</span> failed, <span class="hljs-number">2</span> passed <span class="hljs-keyword">in</span> <span class="hljs-number">0.01</span> seconds ====================
</code></pre>
<p>So here our <code>test_eval</code> function has been called <em>three times</em>. Once for each parameter.
Great! But what if you want your parameters to come from another file, or from a function.
In other words, what if you want to <em>dynamically parametrize</em> your function?</p>
<h2>Hooks at the rescue</h2>
<p><a href="http://pytest.org/latest/plugins.html#well-specified-hooks" target="_blank" rel="noopener noreferrer">Hooks</a> allow you to plug code into <code>py.test</code> at diffent stages of the test run.
The hook that can be useful for us is <code>pytest_generate_tests</code> that will allow
to generate several calls to the same test function, but with different arguments
(from <a href="http://pytest.org/latest/funcargs.html#basic-generated-test-example" target="_blank" rel="noopener noreferrer">py.test doc</a>):</p>
<pre class="code" data-lang="python"><code><span class="hljs-comment"># content of test_example.py</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">pytest_generate_tests</span>(<span class="hljs-params">metafunc</span>):
    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;numiter&quot;</span> <span class="hljs-keyword">in</span> metafunc.funcargnames:
        metafunc.parametrize(<span class="hljs-string">&quot;numiter&quot;</span>, <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))

<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_func</span>(<span class="hljs-params">numiter</span>):
    <span class="hljs-keyword">assert</span> numiter &lt; <span class="hljs-number">9</span>
</code></pre>
<pre class="code" data-lang="python"><code>$ py.test test_example.py
=========================== test session starts ============================
platform linux2 -- Python <span class="hljs-number">2.7</span><span class="hljs-number">.1</span> -- pytest-<span class="hljs-number">2.2</span><span class="hljs-number">.4</span>
collecting ... collected <span class="hljs-number">10</span> items

test_example.py .........F

================================= FAILURES =================================
_______________________________ test_func[<span class="hljs-number">9</span>] _______________________________

numiter = <span class="hljs-number">9</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_func</span>(<span class="hljs-params">numiter</span>):
&gt;       <span class="hljs-keyword">assert</span> numiter &lt; <span class="hljs-number">9</span>
E       <span class="hljs-keyword">assert</span> <span class="hljs-number">9</span> &lt; <span class="hljs-number">9</span>

test_example.py:<span class="hljs-number">6</span>: AssertionError
==================== <span class="hljs-number">1</span> failed, <span class="hljs-number">9</span> passed <span class="hljs-keyword">in</span> <span class="hljs-number">0.02</span> seconds ====================
</code></pre>
<p>Great, so the last things to do is:</p>
<ol>
<li>Detect functions that make use of a fixture whose name starts with <code>data_</code></li>
<li>Load the corresponding file or resource for the test source</li>
<li>Parametrize the function with each of the data</li>
</ol>
<p>For example, here is what you can do:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">pytest_generate_tests</span>(<span class="hljs-params">metafunc</span>):
    <span class="hljs-string">&quot;&quot;&quot; This allows us to load tests from external files by
    parametrizing tests with each test case found in a data_X
    file &quot;&quot;&quot;</span>
    <span class="hljs-keyword">for</span> fixture <span class="hljs-keyword">in</span> metafunc.fixturenames:
        <span class="hljs-keyword">if</span> fixture.startswith(<span class="hljs-string">&#x27;data_&#x27;</span>):
            <span class="hljs-comment"># Load associated test data</span>
            tests = load_tests(fixture)
            metafunc.parametrize(fixture, tests)
</code></pre>
<p>Here, the <code>load_tests</code> function takes as argument the name of the fixture <code>data_X</code>
and will:</p>
<ol>
<li>Load the corresponding file</li>
<li>Extract the different test-cases</li>
<li>Return a list of all the cases</li>
</ol>
<p>For example, if your tests are stored in a Python file:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> importlib


<span class="hljs-keyword">def</span> <span class="hljs-title function_">load_tests</span>(<span class="hljs-params">name</span>):
    <span class="hljs-comment"># Load module which contains test data</span>
    tests_module = importlib.import_module(name)
    <span class="hljs-comment"># Tests are to be found in the variable `tests` of the module</span>
    <span class="hljs-keyword">for</span> test <span class="hljs-keyword">in</span> tests_module.tests.iteritems():
        <span class="hljs-keyword">yield</span> test
</code></pre>
<p>The data file (<code>data_my_feature.py</code>) could look something like:</p>
<pre class="code" data-lang="python"><code>tests = [
    <span class="hljs-number">1</span>,
    <span class="hljs-number">2</span>,
    <span class="hljs-number">3</span>,
    <span class="hljs-number">4</span>,
    <span class="hljs-number">5</span>,
    <span class="hljs-number">6</span>,
    <span class="hljs-number">7</span>,
    <span class="hljs-number">8</span>,
    <span class="hljs-number">9</span>
]
</code></pre>
<p>The test function will then be invoked for each case.</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_feature</span>(<span class="hljs-params">data_my_feature</span>):
    <span class="hljs-keyword">assert</span> data_my_feature &lt; <span class="hljs-number">5</span>
</code></pre>
<h2>Conclusion</h2>
<p>Here it’s not really interesting, but the benefits are numerous:</p>
<ol>
<li>storing your data in a database, or in yaml/json formatted files, or whatever</li>
<li>other people can add tests to your project, without having to dig into the code</li>
<li>provide a common format to define tests in external files</li>
<li>reuse the same data for several tests</li>
<li>the data is not hard-coded in Python source-code</li>
</ol>
<p>TL;DR: <code>py.test</code> is awesome. Make tests. Get data for your tests from external sources.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Decompressing bzipped files with Julia]]></title>
            <link>https://remusao.github.io//posts/decompressing-bz2-files-with-julia.html</link>
            <guid>https://remusao.github.io//posts/decompressing-bz2-files-with-julia.html</guid>
            <pubDate>Tue, 22 Jul 2014 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I’m currently working with Wikipedia dumps, and to save space, it’s a
good thing to make scripts that read directly content from (and write
results to) BZipped files.</p>
<h2>Setup</h2>
<p>Tests where executed on my personal computer:</p>
<ul>
<li>i7</li>
<li>16GB of ram</li>
</ul>
<p>On a small Wikipedia dump of <em>407MB</em>. All timings are in <em>seconds</em>.</p>
<h2>bzcat alone</h2>
<p>To have a point of comparison, I decompressed the dump using <em>bzcat</em> alone. The timing is <em>64 seconds</em>.</p>
<pre class="code" data-lang="sh"><code>$ time 1&gt;/dev/null bzcat wikidump.xml.bz2
</code></pre>
<h2>Using Python</h2>
<p>It’s easy enough with <em>Python</em> thanks to the <code>bz2</code> module that allows to transparently manipulate a compressed file as if it were a normal opened file. Before jumping to Julia, let see how it is done in Python:</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> bz2


<span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
    in_stream = bz2.BZ2File(sys.argv[<span class="hljs-number">1</span>])
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> in_stream:
        <span class="hljs-built_in">print</span>(line)
    in_stream.close()


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:
    main()
</code></pre>
<p>Nothing easier, it takes <em>85 seconds</em> to run.</p>
<h2>What about Julia?</h2>
<p>Since I really love <em>Julia</em> language, I was tempted to do the same with Julia. Here are the differents solutions that I went through, with their respective timings.</p>
<h3>Using bz2 Python module through PyCall</h3>
<p>The first naive option is to use the original module from Python. It’s easy enough using the <code>PyCall</code> module. We can install it like so:</p>
<pre class="code" data-lang="julia"><code>julia&gt; Pkg.add(<span class="hljs-string">&quot;PyCall&quot;</span>)
julia&gt; Pkg.update()
</code></pre>
<p>The script:</p>
<pre class="code" data-lang="julia"><code><span class="hljs-keyword">using</span> PyCall
<span class="hljs-meta">@pyimport</span> bz2

<span class="hljs-keyword">function</span> main()
    in_stream = bz2.BZ2File(<span class="hljs-literal">ARGS</span>[<span class="hljs-number">1</span>])
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> in_stream
        println(line)
    <span class="hljs-keyword">end</span>
    in_stream[:close]()
<span class="hljs-keyword">end</span>
</code></pre>
<p>But then we hit the wall… timing is: <em>1352 seconds</em>. This is likely due to the conversion between <em>Python</em> and <em>Julia</em> datatypes. So not the best option for a data-intensive usage.</p>
<h3>Piping result of bzcat to Julia</h3>
<p>The second option that came to my mind was: “why not using <em>bzcat</em>?”. It’s easy enough, we just have to read from <code>STDIN</code>:</p>
<pre class="code" data-lang="julia"><code><span class="hljs-keyword">function</span> main()
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> eachline(STDIN)
        print(line)
    <span class="hljs-keyword">end</span>
<span class="hljs-keyword">end</span>
</code></pre>
<p>Here is the invocation:</p>
<pre class="code" data-lang="sh"><code>$ bzcat wikidump.xml.bz2 | julia bz2_bench.jl
</code></pre>
<p>Timing is now a more reasonable <em>72 seconds</em>. So that is less than the <em>Python</em> version shown above. But this is not satisfactory enough. Why not use the wonderful capabilities of <em>Julia</em> to run external commands an pipe results?</p>
<h3>Invoking bzcat from Julia</h3>
<p>It is easy to invoke commands from inside <em>Julia</em> using backquotes: <code>run(`cmd`)</code> and <code>|&gt;</code> to pipe between commands and streams. Let’s do it:</p>
<pre class="code" data-lang="julia"><code><span class="hljs-keyword">function</span> main()
    file = <span class="hljs-literal">ARGS</span>[<span class="hljs-number">1</span>]
    run(<span class="hljs-string">`bzcat <span class="hljs-subst">$(file)</span>`</span> |&gt; STDOUT)
<span class="hljs-keyword">end</span>
</code></pre>
<p>The script is equivalent to: <code>bzcat wikidump.xml.bz2</code>, but it’s quite impressive to see how easy it is to do this inside a Julia script.
This time is about <em>66 seconds</em>, more or less the same than with the external piping from <code>bzcat</code>.</p>
<p>But it would be useful to get lines of contents from the stream, like it was in the original <em>Python</em> script. For this task, <em>Julia</em> standard library offers a multitudes of handy functions. The one we will use is <code>readsfrom</code> that returns two things: stdout of the given process, and the process itself. Here it is in action:</p>
<pre class="code" data-lang="julia"><code><span class="hljs-keyword">function</span> main()
    file = <span class="hljs-literal">ARGS</span>[<span class="hljs-number">1</span>]
    <span class="hljs-literal">stdout</span>, p = readsfrom(<span class="hljs-string">`bzcat <span class="hljs-subst">$(file)</span>`</span>)
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> eachline(<span class="hljs-literal">stdout</span>)
        print(line)
    <span class="hljs-keyword">end</span>
<span class="hljs-keyword">end</span>
</code></pre>
<p>Timing is now about <em>74 seconds</em>, this is <em>10 seconds</em> faster than the first <em>Python</em> version. But we don’t rely on a module. Instead, we make use of the ability to play with command invocations, stream pipings, and the like that <em>Julia</em> allows.</p>
<h2>Timings</h2>
<figure>
<a href="../images/bz2-julia-bench.png">
<img src="../images/bz2-julia-bench.png" alt="Bench">
</a>
<figcaption>Timings.</figcaption>
</figure>
<p>Timings are relatively close since the big work is done in the decompression, that’s why there isn’t much difference between <em>Julia</em> and <em>Python</em>.</p>
<h2>Conclusion</h2>
<p>I was first tempted to implement a <em>Julia</em> wrapper over <em>bzlib</em>, but what for? When it’s so easy to invoke external commands and manipulate their input and output streams.
<em>Julia</em> is a young language, but it’s so flexible and extensible, that often I forget about it!</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Installation de Julia]]></title>
            <link>https://remusao.github.io//posts/julia-installation.html</link>
            <guid>https://remusao.github.io//posts/julia-installation.html</guid>
            <pubDate>Fri, 14 Feb 2014 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Suite au premier article sur le langage Julia, voici un guide rapide de mise en
route de votre environnement pour utiliser le langage.</p>
<p>Voici le plan :</p>
<ul>
<li>Compiler Julia depuis les sources</li>
<li>Coloration syntaxique et indentation sous vim</li>
<li>Environnement IJulia (équivalement de IPython)</li>
</ul>
<h2>Compilation</h2>
<p>Tout d’abord compiler l’interpréteur Julia depuis les sources. Notez que si
votre distribution <em>linux</em> dispose d’un paquet Julia dans ses dépôt ou si vous
ne désirez pas compiler Julia depuis les sources, il est toujours possible
d’installer une version pré-compilée depuis la
<a href="http://julialang.org/downloads/" target="_blank" rel="noopener noreferrer">page téléchargement</a> du site officiel.</p>
<p>Commençons tout d’abord par récupérer les sources de Julia :</p>
<pre class="code" data-lang="sh"><code>git <span class="hljs-built_in">clone</span> https://github.com/JuliaLang/julia.git
<span class="hljs-built_in">cd</span> julia
</code></pre>
<p>Ensuite, vérifiez que les dépendances suivantes sont bien disponibles sur votre
système :</p>
<ul>
<li><a href="http://www.gnu.org/software/make/" target="_blank" rel="noopener noreferrer">GNU make</a></li>
<li><a href="http://gcc.gnu.org/" target="_blank" rel="noopener noreferrer">gcc et g++</a> (ou <a href="http://clang.llvm.org/" target="_blank" rel="noopener noreferrer">Clang</a>)</li>
<li><a href="http://gcc.gnu.org/" target="_blank" rel="noopener noreferrer">gfortran</a></li>
<li><a href="http://git-scm.com/" target="_blank" rel="noopener noreferrer">git</a></li>
<li><a href="http://www.perl.org/" target="_blank" rel="noopener noreferrer">perl</a></li>
<li><a href="http://www.gnu.org/software/wget/" target="_blank" rel="noopener noreferrer">wget</a> (ou <a href="http://curl.haxx.se/" target="_blank" rel="noopener noreferrer">curl</a>, ou <em>fetch</em>)</li>
<li><a href="http://www.gnu.org/software/m4/" target="_blank" rel="noopener noreferrer">m4</a></li>
<li><a href="http://www.gnu.org/software/patch/" target="_blank" rel="noopener noreferrer">patch</a></li>
</ul>
<p>Si tout est installé, lancez la compilation (notez que <strong>N</strong> est à remplacer
par le nombre de cœurs dont dispose votre processeur, cela peut grandement
améliorer le temps de compilation) :</p>
<pre class="code" data-lang="sh"><code>make -j N
</code></pre>
<p>La première fois que vous compilez Julia, des dépendances vont être téléchargées
puis compilées, c’est pourquoi cela peut prendre un certains temps. La
compilation peut consommer jusqu’à <em>700 Mo de mémoire</em> et <em>1.5 Go d’espace
disque</em>. Les éventuelles compilations futures seront moins gourmandes.</p>
<p>Une fois la compilation terminée, vous disposez d’un
<a href="http://en.wikipedia.org/wiki/Symbolic_link" target="_blank" rel="noopener noreferrer">lien symbolique</a> vers l’exécutable
Julia. Afin qu’il soit accessible depuis n’importe quel endroit, vous pouvez
le rajouter à votre <code>PATH</code> (vous pouvez le rajouter dans le fichier de
configuration de votre Shell favori en remplaçant <code>$(pwd)</code> par le chemin
absolu vers le dossier julia dans lequel se trouve le lien symbolique) :</p>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">export</span> PATH=<span class="hljs-string">&quot;<span class="hljs-subst">$(pwd)</span>:<span class="hljs-variable">$PATH</span>&quot;</span>
</code></pre>
<p>Julia intègre tout le nécessaire pour gérer l’installation, la mise à jour
et la création de packages. Ces fonctionnalités sont disponibles depuis un
prompt Julia. La première fois que vous lancez Julia, il est nécessaire
d’initialiser les packages :</p>
<pre class="code" data-lang="sh"><code>$ julia
julia&gt; Pkg.update()
</code></pre>
<p>Les principales commandes disponibles sont :</p>
<ul>
<li><strong>Pkg.update()</strong> : met à jours les différents packages installés</li>
<li><strong>Pkg.add(“Package”)</strong> : installe le package <em>Package</em> ainsi que ses éventuelles dépendances</li>
<li><strong>Pkg.rm(“Package”)</strong> : supprime le package <em>Package</em></li>
</ul>
<h2>Coloration syntaxique et indentation</h2>
<p>Cette explication n’est valide que pour les utilisateurs de l’éditeur
<a href="http://www.vim.org/" target="_blank" rel="noopener noreferrer">Vim</a>. Voici des explications différentes en
fonction de la manière dont vous gérez les extensions.</p>
<h3>Pathogen</h3>
<pre class="code" data-lang="sh"><code><span class="hljs-built_in">cd</span> ~/.vim
<span class="hljs-built_in">mkdir</span> -p bundle &amp;&amp; <span class="hljs-built_in">cd</span> bundle
git <span class="hljs-built_in">clone</span> git://github.com/JuliaLang/julia-vim.git
</code></pre>
<h3>Vundle</h3>
<p>Ajouter un nouveau Bundle à votre <code>.vimrc</code> :</p>
<pre class="code" data-lang="sh"><code>Bundle <span class="hljs-string">&#x27;JuliaLang/julia-vim&#x27;</span>
</code></pre>
<p>Lancer Vim et mettre à jour vos Bundle :</p>
<pre class="code" data-lang="sh"><code>:BundleInstall!
</code></pre>
<h3>Manuel</h3>
<pre class="code" data-lang="sh"><code>git <span class="hljs-built_in">clone</span> git://github.com/JuliaLang/julia-vim.git
<span class="hljs-built_in">cd</span> julia-vim
<span class="hljs-built_in">cp</span> -R * ~/.vim
</code></pre>
<p>Voilà qui devrait vous fournir la coloration syntaxique ainsi que l’indentation
pour les fichier dont l’extension et <code>.jl</code>.</p>
<h2>IJulia</h2>
<p>IJulia permet d’interfacer Julia à l’environnement de développement interactif
<strong>IPython</strong>. Cela permet notamment d’utiliser le mode <strong>notebook</strong>, qui combine
du code, du texte, et des contenus multimédias (dessin, etc.) dans un même
environnement. Pour l’installer vous aurez besoin d’avoir sur votre système :</p>
<ul>
<li><strong>IPython</strong> en version <code>1.0</code> ou supérieure</li>
<li><a href="http://jinja.pocoo.org/docs/" target="_blank" rel="noopener noreferrer">Jinja2</a>, <a href="http://www.tornadoweb.org/en/stable/" target="_blank" rel="noopener noreferrer">Tornado</a>, et <a href="https://github.com/zeromq/pyzmq" target="_blank" rel="noopener noreferrer">pyzmq</a></li>
</ul>
<p>Ensuite il faut installer le package IJulia depuis un prompt julia :</p>
<pre class="code" data-lang="julia"><code>$ julia
julia&gt; Pkg.add(<span class="hljs-string">&quot;IJulia&quot;</span>)
julia&gt; Pkg.update()
</code></pre>
<p>Une fois ceci fait, vous n’avez plus qu’à lancer IPython de la manière
suivante. Pour le mode notebook :</p>
<pre class="code" data-lang="sh"><code>ipython notebook --profile julia
</code></pre>
<p>Et voilà, le tour est joué. C’est tout pour cet article. Vous devriez
normalement avoir de quoi démarrer à programmer en Julia et exécuter
vos programmes. A bientôt pour de nouvelles aventures !</p>
<p>Afin de réaliser cet articles je me suis inspiré de la documentation présente
sur les dépôts officiels de <a href="https://github.com/JuliaLang/julia" target="_blank" rel="noopener noreferrer">Julia</a>,
<a href="https://github.com/JuliaLang/julia-vim" target="_blank" rel="noopener noreferrer">julia-vim</a> et
<a href="https://github.com/JuliaLang/IJulia.jl" target="_blank" rel="noopener noreferrer">IJulia</a>.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Julia]]></title>
            <link>https://remusao.github.io//posts/julia-intro.html</link>
            <guid>https://remusao.github.io//posts/julia-intro.html</guid>
            <pubDate>Thu, 13 Feb 2014 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Aujourd’hui j’aimerais parler d’un langage de programmation que je viens de
découvrir : <strong>Julia</strong>. Je vais donc vous le présenter succinctement et donner
mon ressenti après quelques jours d’utilisation.</p>
<h2>Qu’est-ce que c’est ?</h2>
<p>Le Julia est un langage :</p>
<ul>
<li><strong>Haut niveau</strong> (<em>garbage collection</em>)</li>
<li><strong>Dynamique</strong></li>
<li><strong>Interprété</strong></li>
<li><strong>Disposant d’un compilateur JIT</strong> (<em>backend LLVM</em>)</li>
<li><strong>Performant</strong></li>
</ul>
<p>Il s’agit d’un subtile mélange entre les langage <strong>Python</strong>, <strong>R</strong> et
<strong>Matlab</strong>. Python pour une partie de la syntaxe et les constructions élégantes du
langage (<em>list comprehension</em>, boucles <em>for</em>, etc.), Matlab et R pour l’intégration
des vecteurs, matrices et opérations associées dans la bibliothèque standard,
en faisant un langage particulièrement adapté pour l’analyse numérique, le
<em>machine learning</em>, et toute autre application nécessitant des outils d’algèbre
linéaire, et des fonctions mathématiques diverses.</p>
<pre class="code" data-lang="julia"><code><span class="hljs-comment"># Dynamic type</span>
a = <span class="hljs-number">42</span>          <span class="hljs-comment"># Int</span>
a = <span class="hljs-string">&quot;toto&quot;</span>      <span class="hljs-comment"># String</span>
a = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]   <span class="hljs-comment"># Vector</span>
a = [<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>]     <span class="hljs-comment"># 1x3 Matrix</span>
a = [<span class="hljs-number">1</span>:<span class="hljs-number">3</span>]       <span class="hljs-comment"># same 1x3 Matrix</span>

<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> a
    println(test)
<span class="hljs-keyword">end</span>

<span class="hljs-comment"># Output</span>
<span class="hljs-comment"># 1</span>
<span class="hljs-comment"># 2</span>
<span class="hljs-comment"># 3</span>
</code></pre>
<p>Julia dispose également des atouts suivants :</p>
<ul>
<li><strong>Multi-méthode</strong> permettant un dispatch dynamique en fonction du type des arguments passés aux fonctions</li>
</ul>
<pre class="code" data-lang="julia"><code><span class="hljs-comment"># Method declaration</span>
<span class="hljs-comment"># foo is a function taking one argument of any type</span>
<span class="hljs-keyword">function</span> foo(bar)
    println(bar)
    <span class="hljs-keyword">end</span>

<span class="hljs-comment"># Shorter function declaration</span>
baz(x) = println(x)

<span class="hljs-comment"># Multimethod</span>
<span class="hljs-comment"># Takes an argument of type Int (Haskelish syntax)</span>
myprint(x::<span class="hljs-built_in">Int</span>) = println(<span class="hljs-string">&quot;Int&quot;</span>)
<span class="hljs-comment"># Takes an argument of type Matrix (of any type)</span>
myprint(x::<span class="hljs-built_in">Matrix</span>) = println(<span class="hljs-string">&quot;Matrix&quot;</span>)
<span class="hljs-comment"># Take an argument of type Matrix of Float64</span>
myprint(x::<span class="hljs-built_in">Matrix</span>{<span class="hljs-built_in">Float64</span>}) = println(<span class="hljs-string">&quot;Matrix of Float64&quot;</span>)

myprint(<span class="hljs-number">42</span>)         <span class="hljs-comment"># First one is called</span>
myprint([<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>])    <span class="hljs-comment"># Second one is called</span>
myprint([<span class="hljs-number">0.5</span> <span class="hljs-number">0.42</span>]) <span class="hljs-comment"># Third one is called</span>
</code></pre>
<ul>
<li>Un système de <strong>template</strong> pour créer du code générique</li>
</ul>
<pre class="code" data-lang="julia"><code><span class="hljs-keyword">function</span> printtype(m)
    println(<span class="hljs-string">&quot;Any type&quot;</span>)
<span class="hljs-keyword">end</span>

<span class="hljs-comment"># Takes argument of type T, in julia a type</span>
<span class="hljs-comment"># is an object, so you can print it</span>
<span class="hljs-keyword">function</span> printtype{T}(m::T)
    println(T)
<span class="hljs-keyword">end</span>

<span class="hljs-comment"># Takes an argument of type T, with the constraint FloatingPoint</span>
<span class="hljs-keyword">function</span> printtype{T &lt;: FloatingPoint}(m::T)
    println(<span class="hljs-string">&quot;Floating Point&quot;</span>)
<span class="hljs-keyword">end</span>

printtype(<span class="hljs-number">42</span>)
printtype(<span class="hljs-number">0.42</span>)
</code></pre>
<ul>
<li>Des <strong>expressions rationnelles</strong> compatible Perl</li>
<li>Des <strong>macros</strong> à la Lisp grâce à l’auto-iconicité du langage</li>
<li>La possibilité de lancer des <strong>commandes Shell</strong>, de piper, etc.</li>
<li><strong>Interfaçage avec le C</strong> sans bindings (simple utilisation de ccall comme une fonction)</li>
</ul>
<pre class="code" data-lang="julia"><code><span class="hljs-comment"># Simple function that wrap a call to libc clock function</span>
clock() = <span class="hljs-keyword">ccall</span>( (:clock, <span class="hljs-string">&quot;libc&quot;</span>), <span class="hljs-built_in">Int32</span>, ())

t = clock()

<span class="hljs-comment"># Do some stuff</span>

println(clock() - t)
</code></pre>
<ul>
<li><strong>Duck-typing</strong> mais possibilité de spécifier les types</li>
<li><strong>Parallélisation</strong> du code aisée en multithreading sur une unique machine ou sur un cluster (tasks, parallel for, etc.)</li>
</ul>
<p>Cet article n’a pas pour but d’être exhaustif à propos de Julia, pour plus
d’exemples je vous redirige vers le documentation officielle du langage :
<a href="http://docs.julialang.org/en/latest/manual/" target="_blank" rel="noopener noreferrer">Documentation</a>.</p>
<h2>Pourquoi l’utiliser ?</h2>
<p>Julia est un langage jeune mais dynamique. Il est pour le moment peu utilisé
mais il gagne à être connu. Grâce aux avantages cités ci-dessus, c’est un
parfait candidat pour tous les projets nécessitant :</p>
<ul>
<li><strong>Performances</strong> (compilation JIT),</li>
<li><strong>Bibliothèque standard</strong> très riche : <em>algèbre linéaire</em>, <em>fonctions mathématiques</em> diverses, etc.</li>
<li>Rassemble les qualités de plusieurs langages bien connus (Matlab, R, Python)</li>
</ul>
<p>Il est très aisé de convertir du code Matlab ou Python vers du Julia car les
différences sont assez peu nombreuses. La manipulation de matrice est très
similaire à celle de Matlab.</p>
<h2>Défauts de jeunesse</h2>
<p>Néanmoins le langage dispose de quelques points faibles, sans doute liés à sa
jeunesse et au manque de projets l’utilisant. Mis à part la richesse de sa
bibliothèque standard, les packages sont encore relativement peu nombreux et
donc selon le projet vous ne trouverez pas forcément les outils nécessaires
(par exemple pour du traitement d’image, il n’existe pas de binding ou
d’équivalent à OpenCV, des packages existent mais les fonctionnalités sont
encore limitées).</p>
<p>L’interpréteur met du temps à se lancer. Selon les ressources de la machine
que vous utilisez cela peut aller de 2-3 secondes à 30 secondes (sur mon
ordinateur portable peu puissant). Bien sûr il est possible de lancer une
session de l’interpréteur une bonne fois pour toutes et de travailler depuis
le prompt, mais cela reste gênant quand vous voulez simplement lancer un
script. Néanmoins, cela devrait s’améliorer à l’avenir, espérons-le, le
langage est encore en phase de release candidate.</p>
<p>Voilà pour cette rapide introduction du langage Julia, cet article n’avait
pas pour but d’être un tutoriel, mais juste de faire connaitre un projet qui
semble avoir de l’avenir. Il est possible que j’utilise ce langage dans mes
prochains articles pour les démonstrations de code.</p>
<p>Quelques ressources supplémentaires :</p>
<ul>
<li><a href="https://github.com/JuliaLang/julia" target="_blank" rel="noopener noreferrer">Github</a></li>
<li><a href="http://docs.julialang.org/en/latest/manual/" target="_blank" rel="noopener noreferrer">Documentation</a></li>
<li><a href="http://julialang.org/" target="_blank" rel="noopener noreferrer">Site officiel</a></li>
</ul>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[C++—Composition de fonctions]]></title>
            <link>https://remusao.github.io//posts/cpp-function-composition.html</link>
            <guid>https://remusao.github.io//posts/cpp-function-composition.html</guid>
            <pubDate>Thu, 30 May 2013 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Lorsque l’on a gouté aux joies des langages fonctionnels, ou que
l’on vient du monde des mathématiques, ou les deux, on est souvent
habitué à “chainer” des appels de fonctions entre eux. Par exemple, si
nous disposons de <code>n</code> fonctions de prototypes suivants :</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">f1</span> :: <span class="hljs-type">T1</span> -&gt; <span class="hljs-type">T2</span>
<span class="hljs-title">f2</span> :: <span class="hljs-type">T2</span> -&gt; <span class="hljs-type">T3</span>
...
<span class="hljs-title">fm</span> :: <span class="hljs-type">Tm</span> -&gt; <span class="hljs-type">Tn</span>
<span class="hljs-title">fn</span> :: <span class="hljs-type">Tn</span> -&gt; <span class="hljs-type">To</span>
</code></pre>
<p>Nous aimerions pouvoir les composer de la manière suivante :</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">fn</span> o fm o ... o f2 o f1
</code></pre>
<p>Ce qui dans un langage comme C++ nous obligerait à faire :</p>
<pre class="code" data-lang="c++"><code><span class="hljs-keyword">auto</span> res1 = <span class="hljs-built_in">f1</span>(arg);
<span class="hljs-keyword">auto</span> res2 = <span class="hljs-built_in">f2</span>(res1);
...
<span class="hljs-keyword">auto</span> resn = <span class="hljs-built_in">fn</span>(resm);
</code></pre>
<p>Ce qui est assez peu élégant. De plus, nous pourrions avoir envie
qu’il n’y ait pas de copie dans les différents passages de
paramètres (ce que nous pouvons faire en passant les arguments par
référence, ou en utilisant un <em>move semantic</em>). Puisque nous ne
faisons rien des résultats intermédiaires, nous aimerions disposer
d’une fonction, qui prendrait les fonctions en arguments, ainsi que
l’argument à donner à la première fonction, et s’occuperait de
faire les appels successifs, tout en passant les arguments par move
semantic ou référence. Une telle fonction peut-être créée en <code>c++11</code>,
voici une solution possible.</p>
<p>L’idée est assez simple, nous utilisons un template récursif qui
correspond a peu de choses près à la fonction suivante, le reste
n’est que du surplut visant à propager les types et déterminer le
type de retour des fonctions (avec <code>std::result_of</code>) :</p>
<pre class="code" data-lang="c++"><code><span class="hljs-built_in">pipeline</span>(arg, f1, f_suivantes) = <span class="hljs-built_in">pipeline</span>(<span class="hljs-built_in">f1</span>(arg), f_suivantes)
</code></pre>
<p>Et enfin voici le code C++ correspondant :</p>
<pre class="code" data-lang="c++"><code><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> PIPELINE_HH_</span>
<span class="hljs-meta"># <span class="hljs-keyword">define</span> PIPELINE_HH_</span>

<span class="hljs-keyword">namespace</span>
{
    <span class="hljs-comment">//</span>
    <span class="hljs-comment">// Extends the behavior of std::result_of for pipelines of function,</span>
    <span class="hljs-comment">// setting field type to the type returned by the last function of</span>
    <span class="hljs-comment">// the pipeline.</span>
    <span class="hljs-comment">//</span>
    <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> In, <span class="hljs-keyword">typename</span> F, <span class="hljs-keyword">typename</span> ...Args&gt;
    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">result_of</span> : <span class="hljs-keyword">public</span> result_of&lt;<span class="hljs-keyword">typename</span> std::result_of&lt;<span class="hljs-built_in">F</span>(In)&gt;::type, Args...&gt; {};

    <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> In, <span class="hljs-keyword">typename</span> F&gt;
    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">result_of</span>&lt;In, F&gt;
    {
        <span class="hljs-keyword">typedef</span> <span class="hljs-keyword">typename</span> std::result_of&lt;<span class="hljs-built_in">F</span>(In)&gt;::type type;
    };
}


<span class="hljs-comment">//</span>
<span class="hljs-comment">// Pipeline of function</span>
<span class="hljs-comment">// usage : pipeline(T arg, f1, f2, ..., fn) with:</span>
<span class="hljs-comment">// f1: T -&gt; T1</span>
<span class="hljs-comment">// f2: T1 -&gt; T2</span>
<span class="hljs-comment">// ...</span>
<span class="hljs-comment">// fn: Tn -&gt; Tm</span>
<span class="hljs-comment">// returns the result of fn(...f2(f1(arg)))</span>
<span class="hljs-comment">//</span>
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> In&gt;
<span class="hljs-function">In <span class="hljs-title">pipeline</span><span class="hljs-params">(In&amp;&amp; a)</span>
</span>{
    <span class="hljs-keyword">return</span> std::forward&lt;In&gt;(a);
}

<span class="hljs-keyword">template</span> &lt;
    <span class="hljs-keyword">typename</span> In,
    <span class="hljs-keyword">typename</span> Function&gt;
<span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">pipeline</span><span class="hljs-params">(In&amp;&amp; a, Function f)</span> -&gt; <span class="hljs-title">decltype</span> <span class="hljs-params">(f(std::forward&lt;In&gt;(a)))</span>
</span>{
    <span class="hljs-keyword">return</span> <span class="hljs-built_in">f</span>(std::forward&lt;In&gt;(a));
}

<span class="hljs-keyword">template</span> &lt;
    <span class="hljs-keyword">typename</span> In,
    <span class="hljs-keyword">typename</span> Function,
    <span class="hljs-keyword">typename</span> ...Args&gt;
<span class="hljs-function"><span class="hljs-keyword">auto</span> <span class="hljs-title">pipeline</span><span class="hljs-params">(In&amp;&amp; a, Function f, Args... args)</span> -&gt; <span class="hljs-keyword">typename</span> result_of&lt;In, Function, Args...&gt;::type
</span>{
    <span class="hljs-keyword">return</span> pipeline&lt;<span class="hljs-keyword">decltype</span> (<span class="hljs-built_in">f</span>(std::forward&lt;In&gt;(a)))&gt;(<span class="hljs-built_in">f</span>(std::forward&lt;In&gt;(a)), args...);
}

<span class="hljs-meta">#<span class="hljs-keyword">endif</span> <span class="hljs-comment">/* !PIPELINE_HH_ */</span></span>
</code></pre>
<p>N’hésitez pas à me faire part de vos remarques.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[XMonad]]></title>
            <link>https://remusao.github.io//posts/xmonad.html</link>
            <guid>https://remusao.github.io//posts/xmonad.html</guid>
            <pubDate>Thu, 14 Feb 2013 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Étant utilisateur de GNU/Linux depuis quelques années maintenant,
j’ai eu l’occasion de tester quelques distributions et quelques
environnements de bureau. Parmi les distributions je suis passé par
Ubuntu, Debian, Fedora pour enfin essayer Archlinux, que je n’ai plus
quitté depuis. En terme d’environnement c’est un peu la même
chose, gnome, xfce, lxde, openbox puis Awesome que j’ai utilisé
pendant une année. Je n’ai jamais trop cherché à modifier la
configuration par défaut, qui me convenait plutôt bien. Puis je me
suis mis au Haskell, et avec lui des envies de refaire le monde, des
envies de pureté, des envies de paresse (enfin pas tant que ça !), et
j’ai ouï dire qu’il existait un gestionnaire de fenêtre écrit
avec ce fabuleux langage : XMonad !</p>
<h2>Présentation de XMonad</h2>
<p>XMonad est un gestionnaire de fenêtre de style « tiling » (c’est
à dire qu’il est capable de gérer tout seul la disposition des
fenêtres afin d’optimiser l’espace). Il est léger, épuré, très
minimaliste. En fait la première fois qu’on le lance il n’y a rien,
à part un curseur de souri ! C’est un bon début. A la différence
d’Awesome qui propose tout de même un minimum syndical (une barre de
tâches, une vue des différents tags, l’heure…). Sur XMonad rien
de tout ça. J’ai vraiment eu l’impression qu’on me fournissait
des briques de base, et qu’ensuite c’était à moi de jouer pour me
construire mon propre gestionnaire de fenêtre, et c’est en quelque
sorte ce que j’ai fait. Heureusement les ressources se trouvent assez
facilement sur internet, à partir de la documentation, d’articles et
d’exemples, on parvient à créer un petit environnement douillet en
quelques heures (à condition de connaitre quelques bribes de Haskell,
car oui, XMonad se configure en Haskell !). Au final, il n’y a pas à
dire, c’est un gestionnaire de fenêtre fonctionnel.</p>
<h2>Installation</h2>
<p>Pour les utilisateur de Archlinux il suffit d’exécuter la commande
suivante ! Pour les autres, un petit tour par la documentation de votre
distribution favorite devrait vous éguiller.</p>
<pre class="code" data-lang="sh"><code>$ pacman -S xmonad xmonad-contrib
</code></pre>
<h2>Configuration</h2>
<p>Venons-en aux sujets qui fâchent, à savoir, la configuration. Comme
dit un peu plus haut, ça se fait en utilisant le langage Haskell et
on place tout ça dans un fichier nommé xmonad.hs dans un dossier
~/.xmonad. Puisque c’est du Haskell, vous l’aurez deviné, ça
se compile. Heureusement cela se fait à chaud, sans avoir besoin de
quitter XMonad, ce qui est très appréciable. Grâce au raccourci Mod</p>
<ul>
<li>q le fichier de configuration est recompilé, si il est correct il
est appliqué à chaud, sinon une fenêtre s’ouvre vous indiquant les
éventuelles erreurs, et l’ancienne configuration est conservée.
Comme ça, pas de risque de casser votre environnement en le modifiant
en cours d’utilisation.</li>
</ul>
<p>Je vais vous présenter ma configuration actuelle, qui est assez
basique, mais comble amplement mes attentes. Ensuite je vais détailler
quelques points importants.</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-comment">{- Config of berson_r -}</span>

<span class="hljs-keyword">import</span> System.Exit
<span class="hljs-keyword">import</span> System.IO
<span class="hljs-keyword">import</span> XMonad
<span class="hljs-keyword">import</span> XMonad.Actions.CycleWS
<span class="hljs-keyword">import</span> XMonad.Actions.GridSelect
<span class="hljs-keyword">import</span> XMonad.Hooks.DynamicLog
<span class="hljs-keyword">import</span> XMonad.Hooks.ManageDocks
<span class="hljs-keyword">import</span> XMonad.Layout.Fullscreen
<span class="hljs-keyword">import</span> XMonad.Layout.NoBorders
<span class="hljs-keyword">import</span> XMonad.Layout.Spiral
<span class="hljs-keyword">import</span> XMonad.Layout.Tabbed
<span class="hljs-keyword">import</span> XMonad.Util.EZConfig(<span class="hljs-title">additionalKeys</span>)
<span class="hljs-keyword">import</span> XMonad.Util.Run(<span class="hljs-title">spawnPipe</span>)
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> Data.Map        <span class="hljs-keyword">as</span> M
<span class="hljs-keyword">import</span> <span class="hljs-keyword">qualified</span> XMonad.StackSet <span class="hljs-keyword">as</span> W


<span class="hljs-comment">-- Main</span>
<span class="hljs-title">main</span> = <span class="hljs-keyword">do</span>
    xmproc &lt;- spawnPipe <span class="hljs-string">&quot;xmobar /home/berson_r/.xmobarrc&quot;</span> <span class="hljs-comment">-- lance xmobar avec le bon fichier de config</span>
    spawn <span class="hljs-string">&quot;nitrogen --restore&quot;</span> <span class="hljs-comment">-- affiche le fond d&#x27;écran</span>
    xmonad $ defaultConfig { <span class="hljs-comment">-- redéfinition de certaines options de XMonad</span>
    <span class="hljs-comment">-- simple stuff</span>
    terminal           = myTerminal,
    modMask            = myModMask,
    workspaces         = myWorkspaces,
    normalBorderColor  = myNormalBorderColor,
    focusedBorderColor = myFocusedBorderColor,

    <span class="hljs-comment">-- key bindings</span>
    keys               = myKeys,
    <span class="hljs-comment">-- mouseBindings      = myMouseBindings,</span>

    <span class="hljs-comment">-- hooks, layouts</span>
    layoutHook         = smartBorders $ myLayout,
    manageHook         = myManageHook,
    logHook            = myLogHook xmproc,
    startupHook        = myStartupHook
    }


<span class="hljs-comment">-- Binding for the mod key</span>
<span class="hljs-title">myModMask</span> :: <span class="hljs-type">KeyMask</span>
<span class="hljs-title">myModMask</span> = mod4Mask

<span class="hljs-comment">-- Default terminal to use</span>
<span class="hljs-title">myTerminal</span> :: <span class="hljs-type">String</span>
<span class="hljs-title">myTerminal</span> = <span class="hljs-string">&quot;urxvt&quot;</span>

<span class="hljs-comment">-- Names of the workspaces</span>
<span class="hljs-title">myWorkspaces</span> :: [<span class="hljs-type">String</span>]
<span class="hljs-title">myWorkspaces</span> = [<span class="hljs-string">&quot;term&quot;</span>, <span class="hljs-string">&quot;web&quot;</span>, <span class="hljs-string">&quot;mail&quot;</span>, <span class="hljs-string">&quot;music&quot;</span>] ++ (map show [<span class="hljs-number">5</span>..<span class="hljs-number">9</span>])

<span class="hljs-comment">-- Color of normal borders</span>
<span class="hljs-title">myNormalBorderColor</span> :: <span class="hljs-type">String</span>
<span class="hljs-title">myNormalBorderColor</span>  = <span class="hljs-string">&quot;#7c7c7c&quot;</span>

<span class="hljs-comment">-- Color of the selected window&#x27;s borders</span>
<span class="hljs-title">myFocusedBorderColor</span> :: <span class="hljs-type">String</span>
<span class="hljs-title">myFocusedBorderColor</span> = <span class="hljs-string">&quot;#ffb6b0&quot;</span>

<span class="hljs-comment">-- Color of current window title in xmobar.</span>
<span class="hljs-title">xmobarTitleColor</span> :: <span class="hljs-type">String</span>
<span class="hljs-title">xmobarTitleColor</span> = <span class="hljs-string">&quot;#FFB6B0&quot;</span>

<span class="hljs-comment">-- -- Color of current workspace in xmobar.</span>
<span class="hljs-title">xmobarCurrentWorkspaceColor</span> :: <span class="hljs-type">String</span>
<span class="hljs-title">xmobarCurrentWorkspaceColor</span> = <span class="hljs-string">&quot;#CEFFAC&quot;</span>

<span class="hljs-comment">-- Custom layout</span>
<span class="hljs-title">myLayout</span> = avoidStruts (
    <span class="hljs-type">Tall</span> <span class="hljs-number">1</span> (<span class="hljs-number">3</span>/<span class="hljs-number">100</span>) (<span class="hljs-number">1</span>/<span class="hljs-number">2</span>) |||
    <span class="hljs-type">Mirror</span> (<span class="hljs-type">Tall</span> <span class="hljs-number">1</span> (<span class="hljs-number">3</span>/<span class="hljs-number">100</span>) (<span class="hljs-number">1</span>/<span class="hljs-number">2</span>)) |||
    tabbed shrinkText tabConfig |||
    <span class="hljs-type">Full</span> |||
    spiral (<span class="hljs-number">6</span>/<span class="hljs-number">7</span>)) |||
    noBorders (fullscreenFull <span class="hljs-type">Full</span>)

<span class="hljs-comment">-- Colors for text and backgrounds of each tab when in &quot;Tabbed&quot; layout.</span>
<span class="hljs-title">tabConfig</span> = defaultTheme {
    activeBorderColor = <span class="hljs-string">&quot;#7C7C7C&quot;</span>,
    activeTextColor = <span class="hljs-string">&quot;#CEFFAC&quot;</span>,
    activeColor = <span class="hljs-string">&quot;#000000&quot;</span>,
    inactiveBorderColor = <span class="hljs-string">&quot;#7C7C7C&quot;</span>,
    inactiveTextColor = <span class="hljs-string">&quot;#EEEEEE&quot;</span>,
    inactiveColor = <span class="hljs-string">&quot;#000000&quot;</span>
}


<span class="hljs-title">myStartupHook</span> = return ()

<span class="hljs-comment">-- Custom rules</span>
<span class="hljs-title">myManageHook</span> :: <span class="hljs-type">ManageHook</span>
<span class="hljs-title">myManageHook</span> = composeAll
    [ className =? <span class="hljs-string">&quot;Chromium&quot;</span>       --&gt; doShift <span class="hljs-string">&quot;web&quot;</span>
    , className =? <span class="hljs-string">&quot;Firefox&quot;</span>        --&gt; doShift <span class="hljs-string">&quot;web&quot;</span>
    , className =? <span class="hljs-string">&quot;Uzbl-core&quot;</span>      --&gt; doShift <span class="hljs-string">&quot;web&quot;</span>
    , className =? <span class="hljs-string">&quot;Thunderbird&quot;</span>    --&gt; doShift <span class="hljs-string">&quot;mail&quot;</span>
    , className =? <span class="hljs-string">&quot;Spotify&quot;</span>        --&gt; doShift <span class="hljs-string">&quot;music&quot;</span>
    , className =? <span class="hljs-string">&quot;Vlc&quot;</span>            --&gt; doFloat
    , className =? <span class="hljs-string">&quot;Steam&quot;</span>          --&gt; doFloat
    , className =? <span class="hljs-string">&quot;Gimp&quot;</span>           --&gt; doFloat
    , manageDocks]
<span class="hljs-comment">--    , isFullscreen --&gt; (doF W.focusDown &lt;+&gt; doFullFloat)]</span>

<span class="hljs-title">myLogHook</span> :: <span class="hljs-type">Handle</span> -&gt; <span class="hljs-type">X</span> ()
<span class="hljs-title">myLogHook</span> xmproc = dynamicLogWithPP xmobarPP {
    ppOutput = hPutStrLn xmproc,
    ppTitle = xmobarColor <span class="hljs-string">&quot;green&quot;</span> <span class="hljs-string">&quot;&quot;</span> . shorten <span class="hljs-number">50</span>
}


<span class="hljs-comment">-- Key bindings --</span>
<span class="hljs-title">myKeys</span> conf@(<span class="hljs-type">XConfig</span> {<span class="hljs-type">XMonad</span>.modMask = modMask}) = <span class="hljs-type">M</span>.fromList $

  <span class="hljs-comment">-- Custom key bindings</span>

  [ ((modMask .|. shiftMask, xK_Return), spawn $ <span class="hljs-type">XMonad</span>.terminal conf) <span class="hljs-comment">-- start term</span>
  , ((modMask, xK_r), spawn <span class="hljs-string">&quot;exe=`dmenu_path_c | yeganesh` &amp;&amp; eval \&quot;exec $exe\&quot;&quot;</span>) <span class="hljs-comment">-- dmenu</span>
  , ((modMask .|. controlMask, xK_m), spawn <span class="hljs-string">&quot;amixer -q set Master toggle&quot;</span>) <span class="hljs-comment">-- mute volume</span>
  , ((modMask .|. controlMask, xK_j), spawn <span class="hljs-string">&quot;amixer -q set Master 10%-&quot;</span>) <span class="hljs-comment">-- dec volume</span>
  , ((modMask .|. controlMask, xK_k), spawn <span class="hljs-string">&quot;amixer -q set Master 10%+&quot;</span>) <span class="hljs-comment">-- inc volume</span>
  , ((modMask, xK_g), goToSelected defaultGSConfig) <span class="hljs-comment">-- display selection grid</span>
  <span class="hljs-comment">-- workspaces</span>
  , ((modMask, xK_Right), nextWS)
  , ((modMask .|. shiftMask, xK_Right), shiftToNext)
  , ((modMask, xK_Left), prevWS)
  , ((modMask .|. shiftMask, xK_Left), shiftToPrev)

  <span class="hljs-comment">-- &quot;Standard&quot; xmonad key bindings</span>

  , ((modMask .|. shiftMask, xK_c), kill) <span class="hljs-comment">-- close selected window</span>
  , ((modMask, xK_space), sendMessage <span class="hljs-type">NextLayout</span>) <span class="hljs-comment">-- change layout</span>
  , ((modMask .|. shiftMask, xK_space), setLayout $ <span class="hljs-type">XMonad</span>.layoutHook conf) <span class="hljs-comment">-- reset layout</span>
  , ((modMask, xK_n), refresh) <span class="hljs-comment">-- resize windows to the correct size</span>
  , ((modMask, xK_Tab), windows <span class="hljs-type">W</span>.focusDown) <span class="hljs-comment">-- move focus to next window</span>
  , ((modMask, xK_j),   windows <span class="hljs-type">W</span>.focusDown) <span class="hljs-comment">-- move focus to next window</span>
  , ((modMask, xK_k),   windows <span class="hljs-type">W</span>.focusUp)   <span class="hljs-comment">-- move focus to previous window</span>
  , ((modMask, xK_m),   windows <span class="hljs-type">W</span>.focusMaster) <span class="hljs-comment">-- move focus to master window</span>
  , ((modMask, xK_Return), windows <span class="hljs-type">W</span>.swapMaster) <span class="hljs-comment">-- swap focused and master window</span>
  , ((modMask .|. shiftMask, xK_j), windows <span class="hljs-type">W</span>.swapDown) <span class="hljs-comment">-- swap focused and next window</span>
  , ((modMask .|. shiftMask, xK_k), windows <span class="hljs-type">W</span>.swapUp) <span class="hljs-comment">-- swap focused and previous window</span>

  <span class="hljs-comment">-- Shrink the master area.</span>
  , ((modMask, xK_h),
     sendMessage <span class="hljs-type">Shrink</span>)

  <span class="hljs-comment">-- Expand the master area.</span>
  , ((modMask, xK_l),
     sendMessage <span class="hljs-type">Expand</span>)

  <span class="hljs-comment">-- Push window back into tiling.</span>
  , ((modMask, xK_t),
     withFocused $ windows . <span class="hljs-type">W</span>.sink)

  <span class="hljs-comment">-- Increment the number of windows in the master area.</span>
  , ((modMask, xK_comma),
     sendMessage (<span class="hljs-type">IncMasterN</span> <span class="hljs-number">1</span>))

  <span class="hljs-comment">-- Decrement the number of windows in the master area.</span>
  , ((modMask, xK_period),
     sendMessage (<span class="hljs-type">IncMasterN</span> (-<span class="hljs-number">1</span>)))

  <span class="hljs-comment">-- Toggle the status bar gap.</span>
  <span class="hljs-comment">-- <span class="hljs-doctag">TODO:</span> update this binding with avoidStruts, ((modMask, xK_b),</span>

  <span class="hljs-comment">-- Quit xmonad.</span>
  , ((modMask .|. shiftMask, xK_q),
     io (exitWith <span class="hljs-type">ExitSuccess</span>))

  <span class="hljs-comment">-- Restart xmonad.</span>
  , ((modMask, xK_q),
     restart <span class="hljs-string">&quot;xmonad&quot;</span> <span class="hljs-type">True</span>)
  ]
  ++

  <span class="hljs-comment">-- mod-[1..9], Switch to workspace N</span>
  <span class="hljs-comment">-- mod-shift-[1..9], Move client to workspace N</span>
  [((m .|. modMask, k), windows $ f i)
      | (i, k) &lt;- zip (<span class="hljs-type">XMonad</span>.workspaces conf) [xK_1 .. xK_9]
      , (f, m) &lt;- [(<span class="hljs-type">W</span>.greedyView, <span class="hljs-number">0</span>), (<span class="hljs-type">W</span>.shift, shiftMask)]]
  ++

  <span class="hljs-comment">-- mod-{w,e,r}, Switch to physical/Xinerama screens 1, 2, or 3</span>
  <span class="hljs-comment">-- mod-shift-{w,e,r}, Move client to screen 1, 2, or 3</span>
  [((m .|. modMask, key), screenWorkspace sc &gt;&gt;= flip whenJust (windows . f))
      | (key, sc) &lt;- zip [xK_w, xK_e, xK_p] [<span class="hljs-number">0</span>..]
      , (f, m) &lt;- [(<span class="hljs-type">W</span>.view, <span class="hljs-number">0</span>), (<span class="hljs-type">W</span>.shift, shiftMask)]]
</code></pre>
<p>Globalement, on peut résumer l’organisation du fichier de configuration comme ceci :</p>
<ol>
<li>Les imports permettant de faire appel à des fonctionnalités de
XMonad, ou toute autre bibliothèque Haskell (car vous pouvez vraiment
mettre n’importe quoi dans votre fichier de configuration, si vous
le vouliez vous pourriez coder factorielle, Fibonacci et un crible
d’Ératosthène pour les afficher dans votre barre des tâches, aucun
problème !).</li>
<li>Des redéfinitions d’options ou de comportements sous forme de constantes.</li>
<li>Une fonction Main qui regroupe tout ceci et spécifie à XMonad
toutes les options, et les comportements que vous désirez. Globalement
vous pourrez quasiment tout modifier via un type enregistrement. Les
champs non spécifiés auront leur valeur par défaut, on se contente
donc de spécifier ce qui nous intéresse.</li>
</ol>
<h2>Barre d’état</h2>
<p>Par défaut, XMonad ne dispose pas d’une barre des tâches. Il en
existe une qui est également en Haskell et qui s’intègre très
simplement avec XMonad, il s’agit de XMobar. Elle est très légère
et permettra de répondre à la plupart des besoins. Il suffit pour la
mettre en place de :</p>
<ol>
<li>Disposer d’un fichier de configuration situé ici : <code>~/.xmobarrc</code>
(vous trouverez le mien un peu plus bas)</li>
<li>Rajouter la ligne : <code>xmproc &lt;- spawnPipe &quot;xmobar /home/berson_r/.xmobarrc</code>
en haut de votre fonction main (cf mon fichier de configuration ci-dessus).</li>
<li>Indiquer quelles informations XMonad doit transmettre à XMobar
lors de l’exécution (les workspaces par exemple). Pour ceci il faut
redéfinir le myLogHook dans le main, je vous invite encore une fois à
regarder mon exemple donné un peu plus haut.</li>
</ol>
<pre class="code" data-lang="haskell"><code><span class="hljs-type">Config</span> { font = <span class="hljs-string">&quot;-*-Fixed-Bold-R-Normal-*-13-*-*-*-*-*-*-*&quot;</span>
, bgColor = <span class="hljs-string">&quot;black&quot;</span>
, fgColor = <span class="hljs-string">&quot;grey&quot;</span>
, position = <span class="hljs-type">TopW</span> <span class="hljs-type">L</span> <span class="hljs-number">90</span>
, lowerOnStart = <span class="hljs-type">True</span>
, commands = [ <span class="hljs-type">Run</span> <span class="hljs-type">Date</span> <span class="hljs-string">&quot;%a %b %_d %H:%M&quot;</span> <span class="hljs-string">&quot;date&quot;</span> <span class="hljs-number">10</span>
, <span class="hljs-type">Run</span> <span class="hljs-type">StdinReader</span>
]
, sepChar = <span class="hljs-string">&quot;%&quot;</span>
, alignSep = <span class="hljs-string">&quot;}{&quot;</span>
, template = <span class="hljs-string">&quot;%StdinReader% }{ &lt;fc=#ee9a00&gt;%date%&lt;/fc&gt; =&lt;&lt;&quot;</span>
}
</code></pre>
<p>Attention, contrairement aux apparences, ce n’est pas du Haskell,
donc ne mettez pas de commentaires dans ce fichier. Une fois les deux
étapes décrites plus hauts effectuées, xmobar devrait s’afficher au
lancement de XMonad. Vous remarquerez qu’il affiche les workspaces,
l’application qui a le focus, l’heure, la date et … c’est tout.
En plus il y a un espace de 10% de la taille de l’écran sur la
droite. Il servira à mettre un trayer. C’est justement l’objet de
la section suivante.</p>
<h2>System Tray</h2>
<p>Par défaut, ni XMonad ni xmobar ne proposent un « trayer », où vous
pourriez voir les icônes des applications en cours d’exécution.
Pour cela j’utilise trayer, qui est très léger et facile à mettre
en place. En fait, une fois qu’on lui a réservé une petite place
(ce qui est notre cas), il suffit de le lancer avec les bonnes options
depuis notre .xinitrc (ou .Xsessions). Voici la commande telle que je
l’utilise :</p>
<pre class="code" data-lang="sh"><code>trayer --SetDockType <span class="hljs-literal">true</span>       \
       --SetPartialStrut <span class="hljs-literal">true</span>   \
       --align right            \
       --alpha 0                \
       --edge top               \
       --<span class="hljs-built_in">expand</span> <span class="hljs-literal">true</span>            \
       --height 12              \
       --heighttype pixel       \
       --tint 0x000000          \
       --transparent <span class="hljs-literal">true</span>       \
       --width 10 &amp;
</code></pre>
<h2>Fond d’écran</h2>
<p>Vous l’aurez compris, XMonad ne propose pas non plus par défaut
d’utilitaire pour changer l’image ou la couleur du fond d’écran.
Mais il est relativement simple d’en mettre un en place. J’ai
personnellement utilisé nitrogen. Il est très simple à utiliser, la
première fois il suffit de le lancer à la main et d’aller chercher
le fond d’écran désiré. Ensuite, il suffira de le relancer à
chaque démmarage avec la commande :</p>
<pre class="code" data-lang="sh"><code>nitrogen --restore &amp;
</code></pre>
<p>Et c’est exactement le rôle de la ligne 23 dans la fonction main du
fichier <code>xmonad.hs</code> :</p>
<pre class="code" data-lang="haskell"><code><span class="hljs-title">spawn</span> <span class="hljs-string">&quot;nitrogen --restore&quot;</span>
</code></pre>
<h2>Raccourcies clavier utiles</h2>
<p>Le seul raccourci qu’il me manquait afin que ce soit parfait, était
le <code>« mod + flèche »</code> afin de se déplacer sur le workspace de droite
ou de gauche. Pour ce faire, il suffit de rajouter les lignes suivantes
dans le tableau des raccourcis personnalisés :</p>
<pre class="code" data-lang="haskell"><code>, ((modMask, xK_Right), nextWS)
, ((modMask .|. shiftMask, xK_Right), shiftToNext)
, ((modMask, xK_Left), prevWS)
, ((modMask .|. shiftMask, xK_Left), shiftToPrev)
</code></pre>
<p>Il y a d’autres options que je n’ai pas détaillées dans cet
article, mais j’ai laissé quelques commentaires dans le fichier de
configuration afin de guider la compréhension. Si jamais ils ne sont
pas suffisents, n’hésitez pas à laisser un commentaire pour poser
une question, ou faire une remarque.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Sciences et critique]]></title>
            <link>https://remusao.github.io//posts/science-et-critique.html</link>
            <guid>https://remusao.github.io//posts/science-et-critique.html</guid>
            <pubDate>Wed, 13 Feb 2013 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Une récente réflexion personnelle m’a amené à considérer
l’influence de l’étude des sciences (mathématiques, physiques,
etc.) sur la capacité à être critique, à faire preuve de
discernement dans la vie des tous les jours. Je prendrai ici appui sur
l’exemple des mathématiques afin d’étayer mon propos, mais le
parallèle avec d’autres sciences est possible.</p>
<p>Je vais donc essayer de présenter quelques traits de caractère, ou
habitudes et montrer en quoi ils peuvent être éveillés et entretenus
par les sciences, et encourager une vision critique et une prise de
recul par rapport aux informations glanées quotidiennement.</p>
<h2>Le doute</h2>
<p>Il est arrivé dans l’histoire des mathématiques que les
mathématiciens, parmi les plus talentueux, en se fiant à leur
instinct, à leur intuition, énoncent des vérités erronées. C’est
en particulier Bourbaki qui écrivit [1] (peut-être pas en premier)
que pour mener un travail rigoureux en mathématiques, il ne fallait
pas écouter son intuition, car celle-ci se trouve souvent impuissante
face à l’abstraction et l’inconnu, en revanche, il est en général
sûr de se fier à des axiomes et des raisonnements logiques rigoureux
afin de cheminer dans l’abstrait. Vous vous demandez peut-être le
lien entre ce que vous venez de lire et le « doute ». Je pense que
pour éviter les pièges, éviter de se tromper en croyant avoir affaire
à l’évidence, il faut tout remettre en doute, y compris sa propre
intuition. C’est ce que les sciences m’ont appris, et c’est ce
que j’ai pris le réflexe de mettre en pratique quotidiennement.
Si l’on commence à remettre en doute même ses intuitions, on est
capable de tout remettre en doute, y compris les autres. Attention,
remettre en doute ne signifie pas rejeter l’autre et son propos,
mais juste procéder à une mise à l’épreuve de l’information
que l’on reçoit. J’entends trop régulièrement des proches
m’énoncer des faits, sortis de nulle part, et qui en cherchant un
peu, se révèlent être faux, mais quand on a lu quelque chose, ou si
on l’a vu à la télévision, c’est que ça doit être vrai… Il
faut chercher l’argumentation, et se ramener à des bases solides,
à un raisonnement, à une logique, presqu’à une démonstration, et
c’est ce qui m’amène au point suivant, la rigueur.</p>
<h2>La rigueur</h2>
<p>La rigueur des sciences, la rigueur mathématique, est un allié
précieux lorsqu’il s’agit de traquer et de démasquer le faux,
déguisé en évidence. La pratique régulière des sciences, en
particulier des mathématiques, pousse à cette rigueur, et c’est
ce qui est reposant avec elles, c’est qu’une fois un théorème
prouvé rigoureusement, il est vrai. Modulo l’erreur inhérente
à l’être humain bien sûr. Mais des faits [2] énoncés par des
philosophes Grecs il y a plus de deux milles ans n’ont jamais été
autant d’actualité, ni autant enseignés dans nos écoles, c’est du
solide ! La rigueur, allié au raisonnement, mène à la preuve, à la
démonstration, et idéalement, nous devrions avoir ce réflexe d’une
analyse rigoureuse des informations qui nous parviennent, et pour cela,
les sciences aident.</p>
<p>De même, lorsqu’on a pris l’habitude de raisonner, de chercher la
preuve, de chercher l’argument pouvant servir à la démonstration,
on est plus enclin à détecter les failles, les erreurs dans les
démonstrations ou les argumentations des autres. Parfois, on peut avoir
cette intuition que quelque chose cloche (il arrive que les intuitions
soient bonnes, d’autres fois non, mais on peut leur laisser leur
chance, et les mettre à l’épreuve). Je pense que c’est ce qu’on
peut appeler du discernement. Capacité d’abstraction</p>
<p>Dernier point important, la capacité d’abstraction. Les
mathématiques enseignent l’art et la manière d’abstraire les
choses. Lorsqu’un problème se présente, le mathématicien exercé
aura plus de facilité à le dépouiller de toute information inutile,
le changer de contexte, le relier à d’autres faits, le regarder
sous un autre angle. Cette capacité à abstraire les choses de leur
contexte premier est essentielle, pour détecter des mécanismes
cachés, des liens masqués, des structures sous-jacentes, quel que soit
le problème considéré. Allié à une ouverture d’esprit et à une
vision globale, c’est à dire, parvenir à ne pas rester focaliser sur
l’information présente, mais arriver à voir toutes les autres en
même temps, prendre le recul nécessaire afin de traiter le problème
dans son ensemble, dans sa globalité et non localement, avec une vision
partielle du contexte, cette qualité permet également de ne pas
considérer qu’une seule version du problème, mais plusieurs. Il est
parfois utile de s’ouvrir à toutes les possibilités. Et encore une
fois, les sciences sont un excellent terrain de jeu pour s’entrainer !</p>
<h2>Contexte</h2>
<p>Dans un monde où il serait plus nécessaire que jamais de remettre en
doute la véracité de l’information à laquelle on peut accéder,
dans une société de l’ouverture, de l’internet et du partage des
données, il est vital de développer des outils nous permettant de
faire le tri dans les quantités astronomiques d’informations que nous
sommes amenés à traiter et assimiler quotidiennement. Le doute, la
rigueur, l’abstraction, l’ouverture d’esprit, la curiosité, sont
les germes de l’indépendance intellectuelle, qu’il est nécessaire
de cultiver continûment. Les sciences, qu’elles soient humaines ou
autres (mathématiques, physique, biologie, philosophies, sociologie,
géopolitique, etc.) sont plus que jamais nécessaires pour comprendre
le monde dans lequel nous vivons.</p>
<p><em>Références</em> :</p>
<ul>
<li>[1] <em>Nicolas Bourbaki – Éléments d’histoire des mathématiques</em></li>
<li>[2] <em>Euclide – Les éléments</em></li>
</ul>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ascii—Astuces]]></title>
            <link>https://remusao.github.io//posts/ascii-astuces.html</link>
            <guid>https://remusao.github.io//posts/ascii-astuces.html</guid>
            <pubDate>Tue, 25 Dec 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Voici quelques petites astuces afin de manipuler plus simplement des
caractères encodés en ASCII.</p>
<h2>Changer la casse</h2>
<p>Cette astuce est indiquée dans le page de <code>man(1)</code> ascii, mais je l’ai
découverte très récemment car je n’avais pas eu le réflexe de lire
les paragraphes se trouvant à la suite de la table ASCII sur cette
page. Afin de changer la casse d’une lettre (c’est à dire
passer de minuscule à majuscule, ou l’inverse), il suffit de changer
le 5ième bit. Celui-ci est à 1 pour les minuscules et à 0 pour les
majuscules. Donc en effectuant un <code>XOR 32</code> avec une lettre on change sa
casse. C’est tout de même pratique !</p>
<pre class="code" data-lang="c"><code><span class="hljs-string">&#x27;A&#x27;</span> ^ <span class="hljs-number">32</span> == <span class="hljs-string">&#x27;a&#x27;</span>
<span class="hljs-string">&#x27;a&#x27;</span> ^ <span class="hljs-number">32</span> == <span class="hljs-string">&#x27;A&#x27;</span>
</code></pre>
<h2>Manipuler les chiffres</h2>
<p>Afin de convertir un entier entre 0 et 9 en son équivalent en
caractère ASCII (‘0’ à ‘9’), on ajoute (ou soustrait selon le
sens de la conversion) la valeur de ‘0’. On peut aussi remarquer
qu’entre un entier et son équivalent en ASCII seuls 2 bits changent.
Il s’agit donc de mettre les 6ième et 5ième bits à 1 (ou 0 si on
désire passer d’un caractère à un entier). Il suffit donc d’un
simple <code>XOR 48</code>, comme ceci :</p>
<pre class="code" data-lang="c"><code><span class="hljs-string">&#x27;9&#x27;</span> ^ <span class="hljs-number">48</span> == <span class="hljs-number">9</span>
</code></pre>
<p>Ces deux astuces sont assez basiques, mais cela peut toujours servir !</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[C++—Taille d'un tableau static en temps constant]]></title>
            <link>https://remusao.github.io//posts/cpp-static-array-size.html</link>
            <guid>https://remusao.github.io//posts/cpp-static-array-size.html</guid>
            <pubDate>Tue, 25 Dec 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>J’ai découvert cette semaine une petite astuce que je trouve assez
élégante, même si son utilité est assez limitée. Il est possible
grâce à un template de garder la trace de la taille d’un tableau
static entre des appels de fonctions. Voyez plutôt :</p>
<pre class="code" data-lang="c++"><code><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T, <span class="hljs-type">int</span> N&gt;
<span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">size</span><span class="hljs-params">(T (&amp;)[N])</span>
</span>{
    <span class="hljs-keyword">return</span> N;
}

<span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>
</span>{
    <span class="hljs-type">int</span> tab[<span class="hljs-number">42</span>];
    cout &lt;&lt; <span class="hljs-built_in">size</span>(tab) &lt;&lt; endl;
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<p>Notre fonction size est une fonction template qui prend en paramètre
le type <code>T</code> des éléments stockés dans le tableau, ainsi que sa taille.
Ainsi lorsqu’on appelle notre fonction <code>size</code> sur un tableau, cette
fonction est spécialisée à la compilation avec la bonne valeur de <code>N</code>
et le bon type <code>T</code> et chaque appel sera remplacé par la valeur <code>N</code>, qui est
la taille du tableau.</p>
<p>Notez également que pour garder l’information de la taille du
tableau, il faut passer une référence sur le pointeur du tableau.
Si notre fonction <code>size</code> avait simplement pris un pointeur en argument
ça n’aurait pas marché puisque le compilateur ne garde pas
l’information de la taille, et considère l’argument comme un simple
pointeur.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ocaml—Hash table vs. pattern matching]]></title>
            <link>https://remusao.github.io//posts/ocaml-pattern-matching-vs-hashtable.html</link>
            <guid>https://remusao.github.io//posts/ocaml-pattern-matching-vs-hashtable.html</guid>
            <pubDate>Thu, 01 Nov 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><em>Disclaimer</em>: This is an old article and the information might be out-dated.</p>
<p>Dans le cadre d’un projet personnel j’en suis venu à réaliser un
lexer avec l’excellent Ocamllex. Afin de matcher les mots clés du
langage source (le langage Python), deux solutions se sont offertes à
moi afin d’associer un token à chaque string représentant un mot
clé :</p>
<ol>
<li>Utiliser une Hashtable dans laquelle chaque entrée (clé, valeur) représente un mot clé et son token associé.</li>
<li>Utiliser le pattern matching où chaque entrée correspond à un token.</li>
</ol>
<p>Les deux solutions ayant une « verbosité » équivalente (j’ai tout
de même une légère préférence pour le pattern matching, que je
trouve un peu plus lisible), je me suis demandé si les performances
étaient équivalentes. J’ai donc réalisé un petit benchmark afin de
comparer les deux solutions.</p>
<p>Les deux méthodes ont donc été testées avec une entrée de <code>3.000.000</code>
de chaines de caractères contenant, à fréquences d’apparition
égales, tous les mots clés possibles ainsi que des mots-clés non
existants.</p>
<p>Le programme a été compilé sans flag d’optimisation particulier. La
machine de test était équipée d’un processeur Atom 1,2 Ghz et 1 Go
de mémoire vive. Voici le résultat:</p>
<ul>
<li>Hashtable :  <code>1,259</code> secondes.</li>
<li>Pattern-matching : <code>2,265</code> secondes.</li>
</ul>
<p>Victoire pour les Hashtables. Dommage que le compilateur n’optimise
pas le pattern-matching en Hash table lorsque c’est possible.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ma vision des mathématiques]]></title>
            <link>https://remusao.github.io//posts/mathematiques-vision.html</link>
            <guid>https://remusao.github.io//posts/mathematiques-vision.html</guid>
            <pubDate>Tue, 31 Jul 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<h2>Socle axiomatique</h2>
<p>Imaginons un socle, les axiomes. En fait, les axiomes ce sont des
propositions, des choses admises en quelque sorte. Comme si on se
mettait d’accord sur certaines règles avant de commencer un jeu. On
admet qu’un certain nombre de propositions sont vraies. Par exemple,
si l’on prend les axiomes du philosophe et mathématicien grec Euclide
— qui sont à la base du monde mathématique classique aujourd’hui — :</p>
<ol>
<li>Il existe toujours une droite qui passe par deux points du plan.</li>
<li>Tout segment peut être étendu suivant sa direction en une droite (infinie).</li>
<li>A partir d’un segment, il existe un cercle dont le centre est un des points du segment et dont le rayon est la longueur du segment.</li>
<li>Tous les angles droits sont égaux entre eux.</li>
<li>Étant donné un point et une droite ne passant pas par ce point, il existe une seule droite passant par ce point et parallèle à la première.</li>
</ol>
<h2>Du socle naît la richesse et la diversité</h2>
<p>Une fois qu’on a ce socle, cette base, eh bien c’est un peu comme
le monde réel. Repensez un instant à la classification périodique de
Mendeleïev, qui répertorie tous les atomes connus, qui sont en nombre
fini. Maintenant ouvrez les yeux et regardez autour de vous, imaginez
que tout ce que vous voyez est composé de ces quelques éléments,
imaginez la richesse qui vous entoure, imaginez qu’à partir de ces
quelques briques de base une telle diversité, une telle richesse
ait pu émerger. Il en est de même avec les mathématiques et leurs
axiomes. Les axiomes sont comme une classification périodique qui
décrirait les éléments — d’ailleurs Euclide exposait les axiomes
dans une série d’ouvrages intitulés Les Éléments — de base du
monde mathématique, et à partir d’eux a pu émerger une diversité
fascinante.</p>
<h2>Un monde abstrait -</h2>
<p>Alors bien sûr ce n’est pas aussi simple d’observer le monde
mathématique pour se rendre compte de sa beauté et de sa richesse que
d’ouvrir les yeux et de regarder ce qui nous entoure. Même si bien
sûr nous avons trouvé des astuces pour essayer de visualiser ces «
choses » abstraites. Par exemple quand nous traçons une courbe sur
notre calculette, ou quand nous mettons des symboles sur des nombres.
Nous essayons de nous approprier ce monde abstrait en lui associant
des repères que nous sommes à même de comprendre. Que ce soient des
symboles ou des représentations graphiques. Lorsque nous écrivons
le symbole 2 ce n’est pas un nombre entier en lui-même, c’est un
symbole propre à notre langage qui désigne le nombre entier — qui
est un concept abstrait — situé entre les nombre entiers 1 et 3. On
voit ici une des limites de notre langage, nous ne pouvons évoquer les
mathématiques directement sans passer par lui, il est en quelque sorte
indissociable des mathématiques et c’est pour ça qu’en général
on considère que le symbole 2 n’est plus un symbole, mais le nombre
entier 2.</p>
<h2>Découverte ou invention ?</h2>
<p>Ce qu’il y a de plus fascinant encore, c’est qu’au delà du fait
qu’un monde d’une infinie richesse puisse exister à partir d’un
nombre fini de briques de base (le socle), que se passe-t-il si l’on
change ce socle ? Est-ce qu’il émerge un monde totalement différent
mais tout aussi riche ? Existe-t-il d’autres socles possibles pour
construire des mondes cohérents ? La réponse est oui, et cela nous
laisse entrevoir une richesse sans limite, c’est ça la puissances
de « mathématiques ». Mais c’est tout de même intriguant, si on
invente un nouveau « socle », est-ce que l’on crée automatiquement
un nouveau monde mathématique cohérent ? Ou est-ce que ce monde
existait déjà et nous venons de le découvrir, ou de prendre
conscience de son existence ? Ces questions sont philosophiques et sont
semblables à d’autres questions telles que : « Est-ce qu’une chose
qu’on ne peut pas voir existe ? » ou encore « Est-ce que quelque
chose qu’on a vu et qu’on ne voit plus existe encore ? ». Dans le
cas des mathématiques, on peut surement parler de vue de l’esprit,
mais existent-ils vraiment ? Ou sont-ils le fruit de l’imagination de
l’être humain ?</p>
<h2>Piste de réponse</h2>
<p>En fait, si l’on fait l’analogie d’un mathématicien avec un
bâtisseur, on peut se dire que lorsqu’on bâti un édifice dans le
monde réel, nous le faisons dans la limite de ce qu’il est possible
de faire avec les lois qui gouvernent notre monde et des outils dont
nous disposons. Et notre monde existait bien avant l’apparition de
l’homme, mais il était vierge. Peut-être en est-il de même avec les
mondes mathématiques. En posant une base axiomatique, un mathématicien
a créé un nouveau monde abstrait vierge et, grâce à des axiomes
et des outils plus avancés tels que des théorèmes et notre logique
les mathématiciens bâtissent des édifices dans ce monde — dans la
limite de ce qu’il est possible de faire en respectant les axiomes de
base —. Je pense qu’il est important de dissocier le monde en tant
que conteneur — dans le sens d’environnement — et le monde en tant
que tout — conteneur ainsi que contenu —.</p>
<h2>Capacité à expliquer des phénomènes réels</h2>
<p>Au delà de ces questionnements — qu’il est intéressant de se
poser —, nous nous rendons compte que les mathématiques sont de
formidables outils pour décrire et expliquer notre monde réel. Comme
si ce monde mathématique était une collection d’outils abstraits ou
un monde parallèle à notre réalité et disposant de caractéristiques
semblables. On peut se demander pourquoi il y a cette ressemblance entre
quelque chose d’apparemment très abstrait et notre monde réel.
C’est assez troublant. Une piste possible pour répondre à cette
question pourrait être la suivante ; nous venons d’évoquer le fait
qu’il existe d’autres « socles » possibles à partir desquels
bâtir les mathématiques, peut-être que Euclide — à qui l’on doit
les axiomes des mathématiques classiques — s’est inspiré du monde
qui l’entourait pour proposer ses axiomes. C’est peut-être parce
que ces axiomes sont logiques vis-à-vis du monde qui nous entoure que
le monde mathématique qui en découle est si proche de notre réalité.
Et pourtant, depuis on sait qu’un rayon lumineux peut se déplacer
de manière courbe dans l’espace-temps — En contradiction avec le
cinquième axiome d’Euclide —. On pourrait donc admettre un autre «
socle » qui dirait que par deux points dans l’espace peuvent passer
une infinité de droites parallèles entre elles — ce qui ne parait
pas naturel —. Et pourtant c’est ce à quoi avaient pensé Gauss et
d’autres mathématiciens après lui.</p>
<h2>Rigueur et perfection</h2>
<p>Une autre chose assez fascinante lorsque l’on pense aux
mathématiques, c’est leur pureté, leur perfection. Lorsque l’on
regarde l’évolution de la physique / chimie, nous voyons que nous
avons un univers (notre monde réel) et nous cherchons à en comprendre
les mécanismes, à en découvrir les briques élémentaires, …
En mathématiques c’est l’inverse, nous disposons des briques
élémentaires — nos axiomes — et nous cherchons à bâtir ou
découvrir l’univers qu’ils peuvent engendrer. Et pour cela nous
nous aidons de raisonnements logiques, d’axiomes, … Ceci est censé
ne laisser place à aucune incohérence ni aucune contradiction. C’est
pourquoi cette discipline dégage ce sentiment de sureté, de solidité
— Il n’en a pas toujours été ainsi. Notamment à l’époque où
Godël a livré son célèbre théorème d’incomplétude —.</p>
<h2>Pour conclure</h2>
<p>Finalement ce que l’on appelle les mathématiques, c’est l’art
d’évoluer dans ces univers abstraits, de visualiser et de comprendre
les œuvres laissées par d’illustres mathématiciens avant nous,
et de bâtir de nouveaux édifices avec les outils qu’ils nous ont
légués.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Compiler Mediatomb sur Arch Linux ARM]]></title>
            <link>https://remusao.github.io//posts/mediatomb-arm-archlinux.html</link>
            <guid>https://remusao.github.io//posts/mediatomb-arm-archlinux.html</guid>
            <pubDate>Tue, 31 Jul 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>En voulant installer le logiciel mediatomb sur le Raspberry Pi que
j’ai reçu récemment je me suis heurté à quelques problèmes
puisque la version dans les dépots de Archlinux ne compilait pas et
aucun paquet précompilé pour Arm n’était disponible. Je vais donc
exposer une solution pour pouvoir le compiler et l’installer. Mais
tout d’abord une petite description du logiciel trouvée sur le site
des créateurs :</p>
<blockquote>
<p>MediaTomb is an open source (GPL) UPnP MediaServer with a nice web user interface, it allows you to stream your digital media through your home network and listen to/watch it on a variety of UPnP compatible devices.</p>
</blockquote>
<p>La marche à suivre pour arriver à compiler le paquet est assez simple,
il suffit de télécharger un patch supplémentaire et de remplacer le
PKGBUILD fourni par un autre que je vais vous donner. Voici comment
faire :</p>
<ol>
<li>Premièrement vous devez télécharger le patch suivant : <a href="http://bugs.debian.org/cgi-bin/bugreport.cgi?msg=5;filename=libavformat_0.11_support.patch;att=1;bug=677959" target="_blank" rel="noopener noreferrer">patch</a>.</li>
<li>Téléchargez également le fichier PKGBUILD suivant : <a href="http://www.pythux.com/exemples/PKGBUILD" target="_blank" rel="noopener noreferrer">PKGBUILD</a>.</li>
<li>Exécutez les commandes suivantes :</li>
</ol>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">cd</span> /tmp
$ yaourt -G mediatomb
$ <span class="hljs-built_in">cd</span> mediatomb
[Copier le patch ici]
[Copier le fichier PKGBUILD ici]
$ makepkg -si
</code></pre>
<p>Sur le raspberry Pi la compilation prend un certain temps, mais ça
vaut le coup. J’espère que ça servira à certains le temps que les
paquets dans les dépôts d’archlinux soient de nouveau compilables
sans modification.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi]]></title>
            <link>https://remusao.github.io//posts/raspberry-pi.html</link>
            <guid>https://remusao.github.io//posts/raspberry-pi.html</guid>
            <pubDate>Tue, 31 Jul 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>J’ai reçu il y a quelques jours le Raspberry Pi que j’avais
commandé sur le site Element 14. Voici une description que j’ai
honteusement recopiée depuis le site d’archlinux pour architecture
arm :</p>
<blockquote>
<p>The Raspberry Pi is a credit-card sized computer that plugs into
your TV and a keyboard. It’s a capable little PC which can be used
for many of the things that your desktop PC does, like spreadsheets,
word-processing and games. It also plays high-definition video.</p>
</blockquote>
<blockquote>
<p>The Raspberry Pi measures 85.60mm x 53.98mm x 17mm, with a little
overlap for the SD card and connectors which project over the edges. The
SoC is a Broadcom BCM2835. This contains an ARM1176JZFS with floating
point running at 700Mhz, and a Videocore 4 GPU. The GPU is capable of
BluRay quality playback, using H.264 at 40MBits/s.</p>
</blockquote>
<p>C’est donc assez rigolo de bidouiller sur une ordinateur au format de
poche. Sa puissance limitée n’est pas faite pour tous les usages,
mais puisqu’il ne prend pas beaucoup de place, ne fait aucun bruit et
ne consomme pas beaucoup d’énergie, il est tout à fait adapté pour
servir de lecteur multimédia (avec mediatomb par exemple).</p>
<p>Comme vous vous en doutez j’ai installé archlinux (la version arm
dédiée au raspberry pi que vous pouvez télécharger gratuitement
ici : archlinux – arm). L’avantage c’est qu’ils fournissent
une image que vous avez juste à installer sur votre carte SD, et vous
n’avez pas à passer par la procédure d’installation classique des
distributions linux. J’ai donc pu me connecter directement en SSH
après avoir lancé mon raspberry Pi. Ce qui était plutôt pratique
puisque je n’avais pas de clavier usb sous la main.</p>
<p>Par contre, prévoyez au moins une carte SD de 4 Go pour faire tourner
votre système. J’en utilise une de 2 Go et en ayant installé
quelques paquets elle est pleine à 94%. Je l’utilise actuellement
pour streamer du contenu présent sur un de mes disques durs externe via
Mediatomb. Cela permet d’accéder à vos vidéos, photos, musiques
depuis n’importe quel périphérique supportant la technologie uPnP.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Visualiser la structure d’un projet python]]></title>
            <link>https://remusao.github.io//posts/visualize-project-structure-python.html</link>
            <guid>https://remusao.github.io//posts/visualize-project-structure-python.html</guid>
            <pubDate>Tue, 31 Jul 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Lors d’une de mes dernières contributions à un projet écrit en
Python, j’ai voulu trouver un moyen de rapidement pouvoir visualiser
la structure d’un projet selon plusieurs critères (dépendances
entres les modules, héritages entre les objets, etc.). J’ai donc
écris un script Python qui permet de générer un graphe à partir de
différentes données.</p>
<p><a href="https://github.com/remusao/PyProjectViewer" target="_blank" rel="noopener noreferrer">Project sur GitHub</a></p>
<p>J’ai essayé de faire en sorte de rentre le projet flexible afin de
pouvoir scanner d’autres types de données à l’avenir (et pourquoi
pas d’autres langages). Pour le moment on peut générer le graphe des
importations ainsi que le graphe de l’héritage.</p>
<p>Le projet est divisé en deux parties :</p>
<ol>
<li>Les fichiers Scan, qui doivent respecter l’interface d’un scanner.</li>
<li>Un objet modelViewer qui s’occupe de parcourir tout votre projet et d’appeler son scanner sur chaque fichier.</li>
</ol>
<p>Ainsi on peut tout à fait rajouter des Scanners à volonté. Pour
finir, voici un graphe de dépendance d’un de mes projets en Python.
Le graphe est coloré et chaque module (chaque dossier) possède sa
propre couleur.</p>
<p>N’hésitez pas à faire des remarques ou à proposer des améliorations !</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[10 bonnes raisons de coder en Python]]></title>
            <link>https://remusao.github.io//posts/10-reasons-to-use-python.html</link>
            <guid>https://remusao.github.io//posts/10-reasons-to-use-python.html</guid>
            <pubDate>Sun, 05 Feb 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Dans la continuité des articles ayant pour objet le langage Python, je
vais essayer de vous donner envie de l’utiliser en vous donnant 10
bonnes raison de le faire :</p>
<ol>
<li>Python est un langage haut niveau avec une syntaxe claire, concise et
lisible basée sur l’indentation. Le code résultant est souvent plus
lisible et plus compacte.</li>
<li>En Python, les types sont automatiquement déduis, ce qui permet de
ne pas avoir à spécifier le type de vos variables, ni les valeurs de
retour des fonctions d’ailleurs.</li>
<li>Python fourni de très nombreuses fonctions, structures de données,
etc… permettant d’augmenter de façon significative la productivité
des développeurs qui l’utilisent. On pourra notamment citer les liste
(qui servent de pile, file, tableau, liste), les dictionnaires, les set,
etc. Sa richesse ne s’arrête pas là puisque vous aurez accès a une
grande partie de la bibliothèque standard du C (module os).</li>
<li>Python est intuitif et accessible. En Python tout est simple, ou
presque. Il est possible d’acquérir les connaissances de base en
très peu de temps.</li>
<li>Python est un langage interprété, ce qui diminue grandement les
temps de développement (souvent au détriment des performances des
programmes, mais il existe des solutions à ce problème). Si vous
cherchez des performances, il est toujours possible de convertir votre
code Python en C++ (avec ShedSkin) ou de l’interpréter avec Pypy
(l’interpréteur doté d’un compilateur Just-in-Time).</li>
<li>Python dispose de fonctionnalités objet très avancées. Quasiment
tout est object en Python (les simples entiers ne sont pas des objets),
vous pouvez mettre n’importe quoi dans n’importe quoi (typage
dynamique). Les listes peuvent accueillir autant de variables de types
différents que vous le souhaitez. Malgré cette forte orientation
objet, il est tout à fait possible de coder en Python sans pour autant
créer de classes ou de se soucier de ce que sont les objets.</li>
<li>Le Python est un langage très utilisé et qui dispose d’une
communauté très active. Il existe d’ailleurs de nombreuses
implémentations du langage, avec chacune ses spécificités (Stackless
Python, Pypy, etc.)</li>
<li>Le Python est extrêmement flexible de part la richesse des modules
que vous pouvez utiliser (il en existe pour tout), et de part la
facilité de l’interfacer avec des modules écris en C ou C++. Que
vous souhaitiez faire du développement web avec Django ou du calcul
scientifique avec Numpy, toutes les portes sont ouvertes !</li>
<li>Malgré sa simplicité apparente, le Python dispose de constructions
extrêmement avancées et puissantes. Vous pouvez vous essayer à la
méta-programmation avec les décorateurs, ou modifier le langage
lui même à la volé en regardant du côté des méta-classes.
Multi-paradigme, vous pourrez aussi bien utiliser la POO, la
programmation fonctionnelle ou encore la programmation structurée.</li>
<li>Python fait tout, Python passe partout. Disponible sur un grand
nombre de plateforme, le Python est un langage portatif et libre.</li>
</ol>
<p><em>Bonus</em> Mais Python c’est aussi un langage de script :p Alors il fera
également très bien l’affaire pour jouer le rôle de « glus » dans
vos projets les plus fous.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Python—Le saviez-vous ?]]></title>
            <link>https://remusao.github.io//posts/python-did-you-know.html</link>
            <guid>https://remusao.github.io//posts/python-did-you-know.html</guid>
            <pubDate>Sun, 05 Feb 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>J’en apprends tous les jours sur le Python, et tous les jours je
suis émerveillé par la richesse de ce langage. Je fais actuellement
quelques recherches sur des utilisations avancées des décorateurs
(afin de faire de la méta-programmation par exemple), j’ai découvert
deux chose :</p>
<ol>
<li>Il est tout à fait possible en Python de déclarer des fonctions à
l’intérieur d’autres fonctions. Par exemple, le code suivant est
tout à fait valide :</li>
</ol>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">toto</span>():
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;toto&#x27;</span>)
    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>
  <span class="hljs-keyword">return</span> toto()
</code></pre>
<ol start="2">
<li>Il est également possible de créer des classes à l’intérieur de fonctions :</li>
</ol>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">dessine_moi_une_classe</span>():
  <span class="hljs-keyword">class</span> <span class="hljs-title class_">Classe</span>():
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">dessine</span>(<span class="hljs-params">self</span>):
      <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;classe&#x27;</span>)

  c = Classe()
  <span class="hljs-keyword">return</span> c
</code></pre>
<p>Bref, tout ceci pour dire que le Python est un langage d’une richesse
insoupçonnée :)</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Python—Construction des listes]]></title>
            <link>https://remusao.github.io//posts/python-list-comprehension.html</link>
            <guid>https://remusao.github.io//posts/python-list-comprehension.html</guid>
            <pubDate>Thu, 02 Feb 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Le type liste du langage python est une des structures les plus utiles
(et utilisées). Elles sont polyvalentes et efficaces. En effet, on
peut aussi bien s’en servir comme tableau, file, pile, listes, etc…
L’outil à tout faire en quelques sorte. Mais leur utilité et leur «
beauté » ne s’arrête pas là, car en plus de fournir de nombreuses
méthodes utiles, le programmeur a la possibilité de construire des
listes de manière très élégante. Voyons voir de plus près de quoi
il s’agit !</p>
<p>Les listes étant représentées entre crochet <code>[</code> et <code>]</code>, c’est
tout naturellement avec ce formalisme que nous allons les créer, en
plaçant entre les crochets des « motifs » décrivant les éléments
contenus dans la liste. Voyons sans plus tarder un exemple :</p>
<pre class="code" data-lang="python"><code>l = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)]
&gt;&gt; [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]
</code></pre>
<p>Nous pouvons bien sûr imaginer des exemples plus complexes comme la
génération de tous les couples de nombres <code>(x, y)</code> avec <code>x</code> et <code>y</code> compris
entre <code>1</code> et <code>9</code> :</p>
<pre class="code" data-lang="python"><code>l = [(x, y) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>) <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)]
</code></pre>
<p>Il est également possible de rajouter des conditions sur les éléments
avec lesquels nous construisons les listes :</p>
<pre class="code" data-lang="python"><code>l = [x*x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>) <span class="hljs-keyword">if</span> x % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>]
</code></pre>
<p>Ce dernier exemple génère la liste contenant les carrés de tous les
nombres pairs compris entre 1 et 10. Vous commencez à comprendre ? Ce
qui est drôle, c’est qu’on peut utiliser des constructions de liste
dans des constructions de liste. Ainsi on peut facilement générer des
matrice (listes de listes) :</p>
<pre class="code" data-lang="python"><code>l = [[x * y <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)] <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)]
</code></pre>
<p>Je vous laisse entrer cette ligne dans un interpréteur Python pour
voir ce que cela donne. On peut ainsi créer des listes contenant a
peu près n’importe quoi avec cette notation. Cette dernière étant
beaucoup plus compacte qu’une ou plusieurs boucles ‘for’, on gagne
beaucoup en lisibilité et compacité en les utilisant. Je précise
également que ce genre de constructions est également disponible pour
d’autres structures de données du Python (notamment les set et les
dictionnaires) :</p>
<pre class="code" data-lang="python"><code>s = {x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)}    <span class="hljs-comment"># crée un set</span>
d = {x : x * x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)}  <span class="hljs-comment"># crée un dictionnaire</span>
</code></pre>
<p>Il y a donc de quoi s’amuser :) Toutefois, attention à ne pas
les utiliser lorsque ce n’est pas nécessaire. Imaginons que vous
souhaitiez initialiser une liste avec 1M éléments ayant tous la même
valeur (disons True). Les deux manières suivantes sont équivalentes :</p>
<pre class="code" data-lang="python"><code>l = [<span class="hljs-literal">True</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">1000000</span>)]
l = [<span class="hljs-literal">True</span>] * <span class="hljs-number">100000</span>
</code></pre>
<p>Bien que produisant le même résultat, la deuxième méthode est
plus rapide que la première, attention donc de ne pas abuser des
constructions de liste :)</p>
<p><strong>Édition du 5 février 2012</strong> :</p>
<p>Dans tous les exemples précédents, c’est la fonction range qui a
été utilisée pour illustrer les constructions de listes. Sachez
qu’il est possible d’utiliser n’importe quel générateur à la
place, et même n’importe quelle structure de données itérable (par
exemple : une liste, un set, etc…).</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Python—Lister le contenu des répertoires]]></title>
            <link>https://remusao.github.io//posts/python-list-directories.html</link>
            <guid>https://remusao.github.io//posts/python-list-directories.html</guid>
            <pubDate>Thu, 02 Feb 2012 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><strong>Disclaimer</strong> : Il est probablement plus simple d’utiliser la fonction
<a href="https://docs.python.org/2/library/os.html#os.walk" target="_blank" rel="noopener noreferrer">os.walk</a> pour lister
récursivement le contenu d’un dossier.</p>
<p>Python est un langage très haut niveau qui permet de faire beaucoup de
choses très facilement. Notamment, il est très facile de manipuler les
fichiers et les dossiers grâce au module os. Les lecteurs connaissant
le langage C remarqueront que les fonctions présentes dans ce module
sont les mêmes que celles de la bibliothèque standard du C (exceptées
certaines fonctions un peu plus « haut-niveau » qui sont seulement
disponibles dans le module os de Python).</p>
<p>Dans cet articles nous allons simplement voir comment lister
récursivement le contenu des dossiers à partir de la position
actuelle. Commençons tout d’abord par inclure le module os comme ceci :</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">import</span> os
</code></pre>
<p>Nous utiliserons ensuite les fonctions suivantes :</p>
<ul>
<li><code>os.listdir(dossier)</code> : Liste le contenu de <code>dossier</code> (fichiers et dossiers)</li>
<li><code>os.chdir(dossier)</code> : On se déplace dans <code>dossier</code>.</li>
<li><code>os.path.isdir(chemin)</code> : Détermine si le <code>chemin</code> donné en paramètre
pointe vers un dossier ou un simple fichier.</li>
<li><code>os.getcwd()</code> : Retourne une chaine de caractères représentant la
position actuelle dans le système de fichiers (sous forme de chemin
absolu).</li>
</ul>
<p>Avec ces quelques fonctions , on peu facilement lister le contenu des
sous-dossiers à partir de la position courante comme ceci :</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse</span>():
  <span class="hljs-string">&quot;&quot;&quot;
    Liste récursivement le contenu des sous-répertoires
  &quot;&quot;&quot;</span>
  <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> os.listdir(os.getcwd()):
      <span class="hljs-keyword">if</span> os.path.isdir(f): <span class="hljs-comment"># si f est un dossier</span>
        os.chdir(f) <span class="hljs-comment"># On va lister son contenu</span>
        parse()
        os.chdir(<span class="hljs-string">&#x27;../&#x27;</span>) <span class="hljs-comment"># On revient au répertoire précédent</span>
      <span class="hljs-keyword">else</span>:
        <span class="hljs-comment"># Traitement sur le fichier f</span>
</code></pre>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Arithmetic lexer]]></title>
            <link>https://remusao.github.io//posts/arithmetic-lexer.html</link>
            <guid>https://remusao.github.io//posts/arithmetic-lexer.html</guid>
            <pubDate>Tue, 27 Dec 2011 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>As part of a project dealing with implementing algorithm to do some
arithmetic on numbers of arbitrary size, arbitrary base and arbitrary
symbols, I had to think about how to write a flexible lexer, capable of
cutting very quickly stream of characters (an arithmetic expression) in
tokens understandable by a parser. So I will write some various articles
on the lexer, parser and evaluation of an arithmetic expression by
making it a point to highlight the various optimizations that I made in
the algorithms to make them as fast as possible. The language used is
C++, but since our priority is to reach the best performances possible,
we will avoid too costly features such as inheritance, virtual class,
etc. … This article will details the following points:</p>
<ol>
<li>Input and number representation.</li>
<li>Memory management.</li>
<li>The Lexer.</li>
</ol>
<h2>Input and number representation</h2>
<p>In order not to lose precious seconds in unnecessary operations such as
resizing of string, repeated IO operations, etc… An expression input
will consist of:</p>
<ol>
<li>Length of the base.</li>
<li>Symbols of the base.</li>
<li>Length of the arithmetic expression.</li>
<li>The arithmetic expression, without blank characters…</li>
</ol>
<p>A correct input could be:</p>
<pre class="code" data-lang="sh"><code>1 5 abcde 10 bc+bca+dec
</code></pre>
<p>So we can easily read the input data with the following code:</p>
<pre class="code" data-lang="c"><code><span class="hljs-type">char</span> newline;

<span class="hljs-comment">// Read the base size</span>
<span class="hljs-type">unsigned</span> base_size;
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span> &gt;&gt; base_size;
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span>.get(newline);

<span class="hljs-comment">// Read the base&#x27;s symbols</span>
<span class="hljs-type">char</span>* base = new <span class="hljs-type">char</span>[base_size + <span class="hljs-number">1</span>];
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span>.read (base, base_size + <span class="hljs-number">1</span>);
base[base_size] = <span class="hljs-string">&#x27;\0&#x27;</span>;

<span class="hljs-comment">// Read the expression&#x27;s size</span>
<span class="hljs-type">unsigned</span> expr_size;
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span> &gt;&gt; expr_size;
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span>.get(newline);

<span class="hljs-comment">// Read the expression</span>
<span class="hljs-type">char</span>* expr = new <span class="hljs-type">char</span>[expr_size + <span class="hljs-number">1</span>];
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">cin</span>.read (expr, expr_size + <span class="hljs-number">1</span>);
expr[expr_size] = <span class="hljs-string">&#x27;\0&#x27;</span>;
</code></pre>
<p>The variable named newline will only be used to « absorb » the \n at
the end of each line. Our expression is represented as a simple array
of characters (we could have done the same thing in C). If you want to
compile the code above, do not forget to add a #include <iostream> at
the top of your file.</p>
<p>Since the role of the lexer is to « cut » our expression into
tokens (numbers, operators, parentheses), we must ask ourself in what
form we will store our numbers, which tokens we will use, etc… It
would be tempting to create a string and to copy the number value
there, it would be the most intuitive. But since we are looking
for maximum performances, we will avoid as possible to use dynamic
memory allocation. Instead we will represent our number as a pair of
integers (offset, size) representing the beginning of the number in the
expression (i.e. the index of its first digit in the array representing
the expression) and its length. So we can work directly on the string
containing the arithmetic expression.</p>
<p>Concerning tokens, we can use a simple enumeration containing an entry for each symbol:</p>
<pre class="code" data-lang="c"><code><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span>
{</span>
  <span class="hljs-type">unsigned</span>  offset;
  <span class="hljs-type">unsigned</span>  size;
} s_number;

<span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">enum</span>
{</span>
  PLUS    = <span class="hljs-number">3</span>,
  MINUS   = <span class="hljs-number">4</span>,
  MULT    = <span class="hljs-number">5</span>,
  DIV     = <span class="hljs-number">6</span>,
  MOD     = <span class="hljs-number">7</span>,
  LPAR    = <span class="hljs-number">2</span>,
  RPAR    = <span class="hljs-number">8</span>,
  NUMBER  = <span class="hljs-number">1</span>
} e_token;
</code></pre>
<p>We will see later why each field of the list is associated with a number.</p>
<h2>Memory management</h2>
<p>We will try as much as possible to do it without dynamic memory
allocation. Our couples (offset, size) and our tokens are then stored
on the stack, using the static allocation, avoiding calls to new/delete
and malloc/free. As we are using the string containing the expression
to store our intermediate results, our memory consumption will be
optimized. We must therefore adapt our algorithms for arithmetic in
order to store the results directly in the string representing the
expression.</p>
<h2>The Lexer</h2>
<p>We will create a <code>Lexer class</code>, containing methods for lexing and some
private variables such as the string containing the expression, the
current offset, etc. …</p>
<p>The use of an object has several advantages in our case:</p>
<ol>
<li>This prevents parsing functions to take a lot of arguments (with
the object of type <code>Lexer</code>, we can afford to give a single argument to
functions).</li>
<li>To determine the next token, the lexer needs some informations,
including the expression, the offset, the variable used to return
the possible pair (offset, size) representing a number, etc. … All
variables can be stored in the object.</li>
<li>This makes the code more readable, without reducing the performances
of the program.</li>
</ol>
<p>Our <code>Lexer</code> will be defined as follows:</p>
<pre class="code" data-lang="c++"><code><span class="hljs-keyword">class</span> <span class="hljs-title class_">Lexer</span>
{
  <span class="hljs-keyword">public</span>:
    <span class="hljs-built_in">Lexer</span> (<span class="hljs-type">char</span>* expr, <span class="hljs-type">char</span>* table,
           <span class="hljs-type">unsigned</span> expr_size, <span class="hljs-type">char</span>* op)
      : <span class="hljs-built_in">num_</span> (<span class="hljs-built_in">s_number</span> ()),
        <span class="hljs-built_in">expr_</span> (expr),
        <span class="hljs-built_in">offset_</span> (<span class="hljs-number">0</span>),
        <span class="hljs-built_in">table_</span> (table),
        <span class="hljs-built_in">expr_size_</span> (expr_size),
        <span class="hljs-built_in">op_</span> (op) {}
    ~<span class="hljs-built_in">Lexer</span> () {}

    <span class="hljs-function"><span class="hljs-type">unsigned</span> <span class="hljs-title">get_token</span> <span class="hljs-params">()</span></span>;

    s_number num_;

  <span class="hljs-keyword">private</span>:

    <span class="hljs-function"><span class="hljs-type">int</span>
    <span class="hljs-title">get_op_</span> <span class="hljs-params">(<span class="hljs-type">char</span> c)</span>
    </span>{
      <span class="hljs-keyword">return</span> (<span class="hljs-type">int</span>)op_[(<span class="hljs-type">int</span>)c];
    }

    <span class="hljs-type">char</span>* expr_;
    <span class="hljs-type">unsigned</span> offset_;
    <span class="hljs-type">char</span>* table_;
    <span class="hljs-type">unsigned</span> expr_size_;
    <span class="hljs-type">char</span>* op_;
};
</code></pre>
<p>You have probably noticed that the constructor of our object <code>Lexer</code> takes
two string parameters named respectively, « table » and « op ». Why
are they useful ?</p>
<p><strong>Table</strong> - Since our program must be able to handle numbers represented
in an arbitrary base with a set of arbitrary symbols, it would be
very difficult to evaluate expressions without modification to make
them easier to compute. So we’re going (during lexing) to transform
numbers by changing the symbols which they are composed of by a set of
contiguous numbers starting from 0 and up to (base_size – 1). For
example:</p>
<pre class="code" data-lang="sh"><code>Old base : abcde
New base : 01234
</code></pre>
<p>It does not change the size of the base, but just the symbols, by this
wait it becomes easier to perform arithmetic operations on numbers.</p>
<p><strong>Op</strong> – The purpose of the variable op is different. During lexing,
we want to determine, for each symbol read, if it’s an operator or
not. We can imagine that for expressions of million of characters,
it makes us millions of tests just for the lexing. We will therefore
greatly reduce the number of tests by creating an array of 256
characters which associate, for each operator (using the ASCII code as
an index in the table) the number that corresponds (the one present
in the enumeration given above) and setting the value 0 to all other
characters. This allows us, first to test if a character is an operator,
and at the same time to know the value associated (to determine which
operator it is).</p>
<p>Finally, the public variable <code>num_</code> will allow the parser, when the lexer
will return a token of type NUMBER, to get the value of the number that
will be presented in this variable.</p>
<p>We code, we optimize a bit and here is the result:</p>
<pre class="code" data-lang="c++"><code><span class="hljs-function"><span class="hljs-type">unsigned</span>
<span class="hljs-title">Lexer::get_token</span> <span class="hljs-params">()</span>
</span>{
  <span class="hljs-keyword">if</span> (offset_ &gt;= expr_size_)
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;

  <span class="hljs-type">int</span> tok = <span class="hljs-built_in">get_op_</span> (expr_[offset_++]);

  <span class="hljs-keyword">if</span> (tok)
    <span class="hljs-keyword">return</span> tok;

  expr_[offset_ - <span class="hljs-number">1</span>] = table_[(<span class="hljs-type">int</span>)expr_[offset_ - <span class="hljs-number">1</span>]];

  num_.offset = offset_ - <span class="hljs-number">1</span>;
  <span class="hljs-type">unsigned</span> length = <span class="hljs-number">1</span>;

  <span class="hljs-keyword">while</span> (!op_[(<span class="hljs-type">int</span>)expr_[offset_]])
  {
    expr_[offset_] = table_[(<span class="hljs-type">int</span>)expr_[offset_++]];
    length++;
  }

  num_.size = length;

  <span class="hljs-keyword">return</span> NUMBER;
}
</code></pre>
<p>This code is not the most optimized but in this version of the program
we will use it like this. Later, during the profiling phase, if it turns
out that this is part of the program is the slowest, we could optimize
it.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Sieve—Even faster!]]></title>
            <link>https://remusao.github.io//posts/sieve-even-faster.html</link>
            <guid>https://remusao.github.io//posts/sieve-even-faster.html</guid>
            <pubDate>Tue, 27 Dec 2011 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p><strong>Disclaimer</strong>: This is an old article and information may be out-dated. You can
find one of the (if not <em>the</em>) fastest implementation there: <a href="http://primesieve.org/" target="_blank" rel="noopener noreferrer">http://primesieve.org/</a></p>
<p>It has been a while since I posted my last article on the blog, my
studies didn’t leave me enough time for writing. But during Christmas
holidays I found some time to share with you some discoveries and
developments that I made recently on the Sieve of Eratosthenes.
This article follows the previous article on the Sieve and aim to
present some optimizations and an attempt to determine the complexity of
the algorithm.</p>
<h2>Last optimizations</h2>
<p>Optimizations that follow are the result of several comments on the
above implementations:</p>
<ul>
<li>Could we not reduce the memory footprint of the program by working
only on arrays of bits instead of chars ? (We could divide the memory
used by 8).</li>
<li>In the main loop, our variable i ranges from 1 in 1, and values
are not always prime numbers, so there is no need to eliminate their
multiples.</li>
</ul>
<p>For the second optimization, we just have to get the next number that
has not yet been eliminated. With a simple loop. We then gain precious
seconds at runtime.</p>
<p>Regarding the first optimization, it turns out that it’s not easy
to work directly on the bits in C, except with bit fields, but this
is complicated in the case of the Sieve of Eratosthenes. So I decided
to implement the algorithm in C++, which offers the type bool, which
takes only one bit in memory as well as Bitset, which are nothing more
than arrays of bits, provided with various operations. Thanks to a
std::vector (or a simple array) of bool the memory usage of the program
is reduced by 8, which is pretty good. But it’s possible to use a data
structure more efficient. You certainly heard about Boost, a library
which provide many very powerful tools for C++, and among this tools
is the Bitset (it also exists in STD, but it is less efficient). Using
Bitset, we gain a little in runtime.</p>
<p>Note that Boost Bitset are initialized to 0 by default, so we must
consider that a number is prime if the value associated in the array is
0 (and not 1 as in a previous implementations).</p>
<pre class="code" data-lang="c++"><code><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cmath&gt;</span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;boost/dynamic_bitset.hpp&gt;</span></span>

<span class="hljs-function"><span class="hljs-type">void</span>
<span class="hljs-title">print_tab</span> <span class="hljs-params">(boost::dynamic_bitset&lt;&gt;&amp; tab)</span>
</span>{
  std::cout &lt;&lt; <span class="hljs-number">2</span> &lt;&lt; std::endl;
  <span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> i = <span class="hljs-number">1</span>; i &lt; tab.<span class="hljs-built_in">size</span> (); i++)
    <span class="hljs-keyword">if</span> (!tab[i])
      std::cout &lt;&lt; <span class="hljs-number">2</span> * i + <span class="hljs-number">1</span> &lt;&lt; std::endl;
}

<span class="hljs-function"><span class="hljs-type">void</span>
<span class="hljs-title">erato</span> <span class="hljs-params">(boost::dynamic_bitset&lt;&gt;&amp; tab)</span>
</span>{
  <span class="hljs-type">unsigned</span> i = <span class="hljs-number">0</span>;
  <span class="hljs-type">unsigned</span> j, step, borne = <span class="hljs-built_in">sqrt</span> (tab.<span class="hljs-built_in">size</span> ());

  <span class="hljs-keyword">for</span> (i = <span class="hljs-number">1</span>; i &lt; borne; i++)
  {
    step = <span class="hljs-number">2</span> * i + <span class="hljs-number">1</span>;
    <span class="hljs-keyword">for</span> (j = i + step; j &lt; tab.<span class="hljs-built_in">size</span> (); j += step)
      tab[j] = <span class="hljs-number">1</span>;

    <span class="hljs-keyword">while</span> (tab[i])
      i++;
  }
}

<span class="hljs-function"><span class="hljs-type">int</span>
<span class="hljs-title">main</span> <span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> **argv)</span>
</span>{
  <span class="hljs-keyword">if</span> (argc != <span class="hljs-number">2</span>)
  {
    std::cout &lt;&lt; <span class="hljs-string">&quot;Please, you must give a number as argument.&quot;</span> &lt;&lt; std::endl;
    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;
  }

  <span class="hljs-type">unsigned</span> size = <span class="hljs-number">0</span>;
  <span class="hljs-keyword">for</span> (<span class="hljs-type">unsigned</span> i = <span class="hljs-number">0</span>; argv[<span class="hljs-number">1</span>][i]; i++)
    size = size * <span class="hljs-number">10</span> + (argv[<span class="hljs-number">1</span>][i] - <span class="hljs-string">&#x27;0&#x27;</span>);

  boost::dynamic_bitset&lt;&gt;* tab = <span class="hljs-keyword">new</span> boost::dynamic_bitset&lt;&gt; (size / <span class="hljs-number">2</span>);

  <span class="hljs-built_in">erato</span> (*tab);
  <span class="hljs-comment">//print_tab (*tab);</span>
}
</code></pre>
<p>With this algorithm we get much better performance than with the
previous implementation.</p>
<h2>Complexity approximation</h2>
<p>The complexity of an algorithm is used to express the number of
operations needed to execution depending on the size of the input (in
our case it will be the limit up to which we want to calculate the prime
numbers).</p>
<p>Soon I will post a more accurate approximation of the complexity of this
algorithm, but my initial investigations suggest that the complexity is
linear (3xN?).</p>
<h2>The last words</h2>
<p>After presenting a number of optimizations to the algorithm of the
Sieve of Eratosthenes, we saw that it is always possible to improve
a program, and this, in two lines of research. First, one can often
optimize the algorithm itself, by choosing appropriate data structures,
trying to reduce the memory footprint or by reducing the number of
calculations needed to compute the result, etc. … One can also optimize
the implementation of the algorithm, it’s often the last step, during
which we will try to find tips, related to language itself, that allow
us to make our program faster by changing the compiler flags (-O,
-march, etc. …), etc. …</p>
<p>The last implementation presented in this article is far from being the
most optimized, we could still find ways to improve performances, for
exemple by eliminating multiples of 3, 5 and 7 at the initialization
of the array or by using bit masks to eliminate several multiples at a
time. However, keep in mind that it is difficult to keep the compactness
and readability of our algorithm with such optimizations.</p>
<p>If you know other optimizations, or have any comments on this article,
feel free to contact me or leave a comment below.</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Crible d'Ératosthène—Un algo pour les trouver tous]]></title>
            <link>https://remusao.github.io//posts/eratosthene-algo-to-find-them-all.html</link>
            <guid>https://remusao.github.io//posts/eratosthene-algo-to-find-them-all.html</guid>
            <pubDate>Tue, 15 Nov 2011 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Il y a quelques temps je me suis intéressé au crible
d’Ératosthène, qui permet de trouver l’ensemble des nombres
premiers inférieurs à une borne donnée. L’application naïve
de l’algorithme dans sa version originale n’étant pas très
performante, j’ai cherché à l’optimiser afin d’obtenir des
performances correctes. Voici donc les différents moyens de rendre cet
algorithme plus efficace. Des fichiers sources en C ou en Python seront
fournis tout au long de l’article.</p>
<ol>
<li>Qu’est-ce qu’un nombre premier ?</li>
<li>Le crible d’Ératosthène.</li>
<li>Optimisations.</li>
<li>Performances.</li>
<li>Conclusion.</li>
</ol>
<p><em>Qu’est-ce qu’un nombre premier</em> – Un nombre premier est un entier
naturel qui n’admet que deux diviseurs, 1 et lui-même. Ce qui exclut
tous les autres entiers naturels (c’est sur cette remarque qu’est
basé le crible d’Ératosthène). Il existe une infinité de nombre
premiers.</p>
<p><em>Le crible d’Ératosthène</em> – L’algorithme du crible
d’Ératosthène est très simple. Prenons un tableau contenant les
entiers de 2 a n (si l’on désire connaitre tous les nombres premiers
inférieurs à n) que l’on suppose tous premiers. Ensuite il suffit,
pour chaque élément du tableau, de supprimer tous ses multiples. Le
pseudo code pourrait donc être le suivant :</p>
<pre class="code" data-lang="python"><code>Crible(entier n):
  Tableau = entiers de <span class="hljs-number">2</span> a n
  Pour chaque i dans Tableau
    supprimer_multiples de i dans Tableau
  Fin Pour Fin Crible
</code></pre>
<p>Le pseudo-code suivant peut aisément être implémenté en Python :</p>
<pre class="code" data-lang="python"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">Supprimer_multiples</span>(<span class="hljs-params">i, tableau</span>):
  <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> tableau:
    <span class="hljs-keyword">if</span> x &gt; i <span class="hljs-keyword">and</span> x % i == <span class="hljs-number">0</span>:
      tableau.remove(x)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">Crible</span>(<span class="hljs-params">n</span>):
  tableau = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, n)]
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tableau:
    Supprimer_multiples(i, tableau)
  <span class="hljs-keyword">return</span> tableau

<span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
  tableau = Crible(<span class="hljs-number">100</span>)
  <span class="hljs-built_in">print</span> tableau

main()
</code></pre>
<p>On remarque que la complexité de cette implémentation n’est pas
du tout adaptée à des <code>n</code> très grands (essayez avec <code>n &gt; 10000</code>, le
résultat va commencer à mettre un certain temps à être calculé).
Voyons comment l’optimiser.</p>
<h2>Optimisations</h2>
<p><em>Première remarque</em>, si le fait de stocker tous les nombres dans un
tableau puis de les supprimer au fur et à mesure peut sembler plus
lisible, ce n’est pas une bonne méthode si l’on recherche les
performances. Une première optimisation est de déclarer un tableau
de n cases qui peuvent chacune contenir soit 1 soit 0 en fonction de
la primalité (ou non-primalité) du nombre correspondant à l’index
considéré dans le tableau. Nous allons voir qu’avec cette technique
nous allons pouvoir nous passer complètement de comparaisons et de
tests (sauf pour les cas d’arrêt des boucles bien évidemment), ce
qui va diminuer grandement le temps de calcul.</p>
<p><em>Deuxièmement</em>, on remarque que pour obtenir tous les multiples d’un
nombre i dans notre tableau dont les index correspondent aux nombres
dont on veut connaitre la primalité, il n’est pas nécessaire de
parcourir tout le tableau en testant à chaque fois le modulo. Pour cela
il suffit de partir de l’index i puis d’aller de i en i dans le
tableau, nous sommes ainsi assurés de passer sur tous les multiples de
i (y compris lui-même). Ceci va grandement améliorer notre algorithme.</p>
<p>Une autre remarque que l’on peut faire est que pour tester la
primalité d’un nombre n, il n’est pas nécessaire de tester la
division par tous les nombres de <code>2</code> a <code>n</code>, il suffit d’aller jusqu’à
la racine carrée de n (au delà on ne peut pas trouver de diviseur
entier).</p>
<p>Enfin, une petite amélioration liée à l’implémentation en C de
l’algorithme, puisqu’on va devoir initialiser notre tableau avec
toutes les cases à 1, autant éliminer tous les nombres pairs (qui ne
sont pas premier puisque divisibles par <code>2</code>). On peut donc initialiser
notre tableau avec deux boucles distinctes, une qui part de 3 et
qui va jusqu’à n de deux en deux en initialisant à 1 les cases
visitées et une autre qui part de 4 et qui va jusqu’à n de deux
en deux en initialisant à 0 les cases parcourues. Voici ce que donne
l’algorithme implémenté en C avec les optimisations précédentes
(sources : <a href="http://www.pythux.com/exemples/erato/crible_1.c" target="_blank" rel="noopener noreferrer">http://www.pythux.com/exemples/erato/crible_1.c</a>). Pour compiler le
fichier source, vous pouvez utiliser soit clang soit gcc (ou un autre
compilateur C) comme ceci :</p>
<pre class="code" data-lang="sh"><code>clang -lm -O3 crible_1.c
gcc -lm -o3 crible_1.c
</code></pre>
<p>Nous pourrions nous arrêter là, puisque les performances sont déjà
très bonnes (11 ms pour un crible jusqu’à 1.000.000 et 40-45
secondes jusqu’à 1.000.000.000), mais nous allons voir qu’il est
encore possible de diminuer drastiquement le temps de calcul. En effet,
nous savons qu’à part le nombre 2, aucun nombre pair n’est premier.
Nous pourrions donc chercher un moyen de ne pas les stocker dans le
tableau, afin de ne garder que les nombres impairs. Nous diviserions
donc dans un premier temps l’espace mémoire occupé par deux. Pour
un crible jusqu’à n = 30, nous aurions à stocker les éléments
suivants :</p>
<pre class="code" data-lang="sh"><code>Les nombres -&gt; [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]
Les index   -&gt; [0, 1, 2, 3, 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]
</code></pre>
<p>Hors, nous ne pouvons plus simplement utiliser les index dans le tableau
pour connaitre les nombres associés. En fait, on peut remarquer que
pour retrouver le nombre associé a chaque case du tableau, il nous
suffit de calculer : <code>index * 2 + 1</code> . Deuxièmement, pour retrouver
les multiples d’un nombre N dans le tableau, il nous suffit d’aller
de N en N dans le tableau en partant de la case <code>N / 2</code>. Enfin, on
remarque qu’avec cette technique, l’algorithme est plus compact
et nous pouvons nous contenter d’initialiser toutes les cases du
tableau à 1 (avec la fonction memset de la bibliothèque <code>&lt;string&gt;</code> du
langage C). Voici le code source de cette implémentation (sources :
<a href="http://www.pythux.com/exemples/erato/crible.c" target="_blank" rel="noopener noreferrer">http://www.pythux.com/exemples/erato/crible.c</a>) :</p>
<pre class="code" data-lang="c"><code><span class="hljs-type">char</span> *<span class="hljs-title function_">erato_opti</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span>
{
  <span class="hljs-type">char</span>  *tab = <span class="hljs-built_in">malloc</span>(n / <span class="hljs-number">2</span>);
  <span class="hljs-type">int</span>   i = <span class="hljs-number">1</span>, j, borne = <span class="hljs-built_in">sqrt</span>(n / <span class="hljs-number">2</span>), step;

  tab = <span class="hljs-built_in">memset</span>(tab, <span class="hljs-number">1</span>, n / <span class="hljs-number">2</span>);

  <span class="hljs-keyword">for</span> (; i &lt;= borne; i++)
  {
    step = <span class="hljs-number">2</span> * i + <span class="hljs-number">1</span>;
    <span class="hljs-keyword">for</span> (j = i + step; j &lt; n / <span class="hljs-number">2</span>; j += step)
      tab[j] = <span class="hljs-number">0</span>;
  }

  <span class="hljs-keyword">return</span> (tab);
}
</code></pre>
<p>Si nous voulons afficher les nombres premiers produits par la fonction
erato_opti il nous suffit d’utiliser l’astuce du <code>nombre = index * 2 + 1</code> et de ne pas oublier d’afficher le nombre 2 (qui n’est pas
contenu dans le tableau) :</p>
<pre class="code" data-lang="c"><code><span class="hljs-type">void</span> <span class="hljs-title function_">print_erato_space</span><span class="hljs-params">(<span class="hljs-type">char</span> *tab, <span class="hljs-type">int</span> n)</span>
{
  <span class="hljs-type">int</span> i = <span class="hljs-number">1</span>;

  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;2\n&quot;</span>);
  <span class="hljs-keyword">for</span> (; i &lt; n / <span class="hljs-number">2</span>; i++)
    <span class="hljs-keyword">if</span> (tab[i])
      <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%i\n&quot;</span>, i * <span class="hljs-number">2</span> + <span class="hljs-number">1</span>);
}
</code></pre>
<p>Vous pouvez compiler les sources précédentes avec l’une ou l’autre
des commandes suivantes :</p>
<pre class="code" data-lang="sh"><code>clang -lm -O3 crible.c
gcc -lm -O3 crible.c
</code></pre>
<h2>Performances</h2>
<p>Voici un récapitulatif des performances obtenues avec les différentes
implémentations :</p>
<table>
<thead>
<tr>
<th>Valeur de N</th>
<th style="text-align:center">1000</th>
<th style="text-align:center">10.000</th>
<th style="text-align:center">1.000.000</th>
<th style="text-align:center">1.000.000.000</th>
</tr>
</thead>
<tbody>
<tr>
<td>Version Python (Pypy)</td>
<td style="text-align:center">30ms</td>
<td style="text-align:center">370ms</td>
<td style="text-align:center">/</td>
<td style="text-align:center">/</td>
</tr>
<tr>
<td>Version Python (CPython)</td>
<td style="text-align:center">42ms</td>
<td style="text-align:center">710ms</td>
<td style="text-align:center">/</td>
<td style="text-align:center">/</td>
</tr>
<tr>
<td>Version C intermédiaire</td>
<td style="text-align:center">1ms</td>
<td style="text-align:center">1ms</td>
<td style="text-align:center">7ms</td>
<td style="text-align:center">40s</td>
</tr>
<tr>
<td>Version C opti</td>
<td style="text-align:center">1ms</td>
<td style="text-align:center">1ms</td>
<td style="text-align:center">6ms</td>
<td style="text-align:center">32s</td>
</tr>
</tbody>
</table>
<h2>Conclusion</h2>
<p>Nous avons vu quelques optimisations possibles sur l’algorithme du
crible d’Ératosthène. Cet article est loin d’être exhaustif,
vous pourrez trouver d’autres optimisations plus ou moins efficaces.
Néanmoins, la plupart des implémentations trouvables sur internet et
qui sont plus performante que celle proposée ici sont moins lisibles et
plus complexes que celle-ci (qui ne fait qu’une dizaine de ligne). Si
vous connaissez d’autres optimisations, n’hésitez pas a poster un
commentaire :)</p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pypy—Make Python faster!]]></title>
            <link>https://remusao.github.io//posts/pypy-makes-python-faster.html</link>
            <guid>https://remusao.github.io//posts/pypy-makes-python-faster.html</guid>
            <pubDate>Thu, 10 Nov 2011 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>J’inaugure ce blog avec un article sur <a href="https://pypy.org/" target="_blank" rel="noopener noreferrer">Pypy</a>, une implémentation de
Python très intéressante du point de vue des performances puisque,
comme nous le verrons un peu plus bas, il est possible de rivaliser avec
des langages compilés statiquement tels que le C ou le C++. L’article
se décomposera de la façon suivante :</p>
<ol>
<li>Qu’est-ce que Python.</li>
<li>Quelles sont les différentes implémentation ?</li>
<li>Qu’est-ce qui caractérise Pypy ?</li>
<li>La compilation JIT (Just-In-Time).</li>
<li>Compiler et utiliser Pypy.</li>
<li>Bref aperçu des performances.</li>
</ol>
<h2>Qu’est ce que Python</h2>
<p>Python est un langage de programmation moderne classé dans la
catégorie des langages de scripts (il est interprété, du moins dans
son implémentation officielle, CPython). Étant très haut niveau, il
permet aux développeurs de gagner en productivité en leur permettant
de se détacher au maximum des contraintes bas niveaux que l’on peut
retrouver sur d’autres langages tels que le C, ce qui en fait un
langage adapté pour l’apprentissage de la programmation. En effet,
il est facile d’accès et rapide à apprendre. Sa syntaxe, basée
sur l’indentation (pas d’accolades ni de mot-clé pour séparer
les « blocs » d’instruction) le rend plus lisible que la plupart
des langages. Pour terminer, voici quelques spécificités du langage
: Inférence de type, fonctionnalités objet avancées, type entier de
taille arbitraire, compréhension de listes permettant de créer des
listes de manière élégante, etc …</p>
<h2>Quelles sont les différentes implémentations</h2>
<p>Le langage Python étant placé sous licence libre, il en existe de
nombreuses implémentations ayant chacune leurs spécificités. En voici
quelques-unes :</p>
<ol>
<li><em>CPython</em> : Implémentation officielle (la plus connue) écrite en C.</li>
<li><em>Pypy</em> : Implémentation disposant d’un compilateur JIT (Just-In-Time).</li>
<li><em>ShedSkin</em> : Implémentation disposant d’un compilateur
Python-to-C++ et offrant des performances très intéressantes du point
de vu du temps d’exécution.</li>
<li><em>Stackless</em> : Implémentation qui se passe de la pile d’appels du
C en la remplaçant par une structure de données propre au Python.
Cette implémentation est grandement basée sur le paradigme de la
concurrence, faisant appel à des Tasklets (sorte de micro-threads)
afin de simuler une exécution parallèle des programmes. Les Tasklets
peuvent être créées par centaines (voire milliers), communiquer entre
elles facilement, être mise en pause ou réveillées instantanément,
etc …</li>
<li><em>Jython</em> : Implémentation écrite en Java.</li>
<li><em>Iron Python</em> : Implémentation écrite en C#.</li>
</ol>
<h2>Qu’est-ce qui caractérise Pypy</h2>
<p>Pypy est une implémentation de Python, écrite en Python, et proposant
(entre autres), un compilateur JIT (cf paragraphe suivant) lui
permettant de délivrer des performances dignes de la plupart des
langages compilés statiquement (C, C++, etc…). Pypy offre également
une consommation mémoire réduite par rapport à CPython, et supporte
la plupart des bibliothèques disponibles avec l’implémentation
officielle.</p>
<p>Il est également possible de compiler Pypy pour obtenir une version
SandBox ou Stackless de Python. D’autres langages sont également
supportés par Pypy (Javascript, Scheme, etc…) puisque ce dernier
utilise une chaine de traitement qui peut analyser des programmes
écrits en RPython (un subset réduit du langage Python), les
traduire en code C puis les compiler en code machine, ce qui permet
à n’importe quel langage d’être utilisé avec Pypy à condition
qu’ils puissent être traduit en RPython. Pour plus d’informations,
je vous invite à consulter le site officiel de Pypy dont le lien est
communiqué en fin d’article.</p>
<h2>La compilation JIT (Just-In-Time)</h2>
<p>Le langage Python offrant des outils très haut niveau (tels que des
fonctionnalités Objet avancées), il est difficile et globalement
inefficace (comparativement à des langages plus bas niveaux tels que le
C) de le compiler statiquement, on ne se tournera donc pas vers de la
compilation statique si l’on recherche des performances honorables. Il
existe heureusement une alternative très performante à la compilation
statique, il s’agit de la compilation JIT (Just-In-Time, ou « à la
volée »). C’est cette technologie qui est utilisée dans le projet
Pypy, ce qui permet d’offrir au langage Python des performances dignes
de langages compilés statiquement tels que le C ou le C++. Voyons de
quoi il s’agit.</p>
<p>La compilation Just-In-Time (ou dynamique) représente une approche
hybride entre la compilation statique et l’interprétation, elle a
pour but d’obtenir des performance égales, voire supérieures, à la
compilation statique classique. Les compilateurs JIT convertissent du
Bytecode en code machine à la volée (au moment de l’exécution).
Mais pour limiter la dégradation des performances, plusieurs techniques
sont utilisées. Premièrement, il est possible de mettre en cache
certaines parties d’un programme afin de ne pas avoir à les
retraduire inutilement lors d’exécutions ultérieures si leur code
source n’a pas été modifié entre temps. Deuxièmement, grâce à
un système de détection des points chauds (parties d’un programmes
étant très sollicitées lors de l’exécution), le compilateur peut
décider de traduire une partie du programme en code machine si cela
s’avère plus intéressant qu’une simple interprétation en terme de
temps d’exécution.</p>
<p>De plus, de nombreuses optimisations ne sont possibles qu’au moment
de l’exécution du programme. Un compilateur JIT peut donc utiliser
les informations du contexte d’exécution afin d’améliorer les
performance d’un programme. Notamment, il est possible d’adapter le
code machine produit en fonction de l’architecture du processeur ou
encore d’effectuer de l’inlining de bibliothèques dynamiques, sans
perdre pour autant les avantages du linkage dynamique.</p>
<p>La compilation JIT est utilisée par la machine virtuelle du Java ou
encore le C#.</p>
<h2>Compiler et utiliser Pypy</h2>
<p>Il existe deux solutions pour utiliser Pypy. Soit votre distribution
Linux favorite vous le propose directement depuis ses dépôts, auquel
cas il vous suffit de l’installer, soit vous pouvez télécharger
les sources depuis le mercurial de Pypy. Attention néanmoins, si
vous installez Pypy depuis les dépôts de votre distribution, il est
possible qu’il remplace une version existante de Python sur votre
ordinateur.</p>
<p><em>Building from sources</em> : Nous allons voir ici comment télécharger les
sources de Pypy, les compiler puis utiliser le binaire produit. Avant
toute chose, il faut savoir que la compilation de Pypy est extrêmement
gourmande en ressources (mémoire vive et CPU), si vous n’avez pas
4 Go de RAM sur votre PC, il faudra passer par les dépôts de votre
distribution, sans quoi vous risquez de partir en Swap infini …</p>
<p><em>Liste des dépendances</em> : <a href="http://pypy.readthedocs.org/en/latest/getting-started-python.html#translating-the-pypy-python-interpreter" target="_blank" rel="noopener noreferrer">http://pypy.readthedocs.org/en/latest/getting-started-python.html#translating-the-pypy-python-interpreter</a></p>
<p>Une fois toutes les dépendances installées, récupérez les sources de
Pypy en lançant la commande suivant :</p>
<pre class="code" data-lang="sh"><code>$ hg <span class="hljs-built_in">clone</span> https://bitbucket.org/pypy/pypy
</code></pre>
<p>Rendez-vous ensuite dans le répertoire goal :</p>
<pre class="code" data-lang="sh"><code>$ <span class="hljs-built_in">cd</span> pypy/pypy/translator/goal
</code></pre>
<p>Lancez enfin le script avec Python (ou avec Pypy lui-même si vous
l’avez déjà installé, ce qui vous fera économiser du temps et de
la mémoire) :</p>
<pre class="code" data-lang="sh"><code>$ python2 translate.py -Ojit
</code></pre>
<p>Vous apprécierez au passage les fractales de Mandelbrot qui seront
dessinées dans votre terminal pendant la compilation.</p>
<p>Une fois le long processus terminé, un binaire nommé pypy-c est
normalement présent dans le répertoire. Vous pouvez le renommer et/ou
le déplacer afin de l’utiliser comme bon vous semble. Il remplace le
binaire Python traditionnel, vous pouvez donc l’utiliser de la façon
suivante :</p>
<pre class="code" data-lang="sh"><code>$ ./pypy mon_script.py <span class="hljs-comment"># votre script python</span>
</code></pre>
<h2>Bref aperçu des performances</h2>
<p>Pour terminer, voici un bref aperçu des performances de Pypy
comparativement à d’autres implémentations/langages disponible sur
la page Performance officielle du site de Pypy : <a href="http://speed.pypy.org/" target="_blank" rel="noopener noreferrer">http://speed.pypy.org/</a></p>
<h2>Bibliographie</h2>
<ul>
<li><a href="http://pypy.org/index.html" target="_blank" rel="noopener noreferrer">http://pypy.org/index.html</a></li>
<li><a href="http://fr.wikipedia.org/wiki/PyPy" target="_blank" rel="noopener noreferrer">http://fr.wikipedia.org/wiki/PyPy</a></li>
<li><a href="http://en.wikipedia.org/wiki/PyPy" target="_blank" rel="noopener noreferrer">http://en.wikipedia.org/wiki/PyPy</a></li>
<li><a href="http://en.wikipedia.org/wiki/Just-in-time_compilation" target="_blank" rel="noopener noreferrer">http://en.wikipedia.org/wiki/Just-in-time_compilation</a></li>
<li><a href="http://www.python.org/" target="_blank" rel="noopener noreferrer">http://www.python.org/</a></li>
<li><a href="http://fr.wikibooks.org/wiki/Python" target="_blank" rel="noopener noreferrer">http://fr.wikibooks.org/wiki/Python</a></li>
</ul>
<p>Le mot de la fin—Toutes les propositions et remarques sont bien
évidemment les bienvenues :)</p>
]]></content:encoded>
        </item>
    </channel>
</rss>